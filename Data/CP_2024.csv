,Title,email,KeyWords,Abstract,domain,Institution,Country,Latitude,Longitude
0,PERSPECTIVE-AGNOSTIC MODELING: THE CASE FOR ENGINEERING MANAGEMENT’S USE OF APPLIED CATEGORY THEORY,@oregonstate.edu,"Applied Category Theory, Systemic Modeling, Organization Diagnosis","Engineering Managers utilize many tools to manage their work throughout their organizations. A common tool in the engineering management arsenal used to accomplish their work is modeling, which allows practitioners to collect their ideas in one place and communicate them to stakeholders. While effective, many of these modeling processes depend on inconsistent timeframes or individual stakeholder views, and it is difficult to rigorously capture individual contexts, which limits the model’s general applicability and ability to merge with other models or processes. Applied Category Theory contrasts with these modeling processes by re maining agnostic towards stakeholder perspectives and generalizable enough to accommodate inconsistent timeframes and multiple bodies of knowledge. Applied Category Theory is also mathematically rigorous, allowing models to be universally communicable to a ll stakeholders and provide a clear structure for integrating new knowledge and updating current-state models. This research will illustrate the use of applied category theory in modeling a small organizational setting in pursuit of collecting information and diagnosing organizational problems. This research will also detail a selection of the mathematically rigorous concepts utilized for modeling via applied category theory with suggestions for future research directions that may be needed for more complic ated cases. Utilizing this research, engineering managers will be able to examine scenarios within their organizations and model them in a generalizable and universally communicable way. Through utilizing applied category theory modeling, practitioners will also ensure that as many stakeholders as possible can utilize a shared and holistic perspective when addressing organizational challenges. Keywords Applied Category Theory, Systemic Modeling, Organization Diagnosis Introduction Within the course of business, organizational actors regularly examine the practices of their organizations to ensure that they are effectively pursuing the established organizational processes and goals. These examinations can relate to both processes occurring strictly within one department, and to processes occurring between departments. Often, these examinations focus on the representation of abstract processes, or the optimization of processes to improve the performance of the organization and the unit s within it, and many modeling approaches attempt to address these challenges. Examples of these modeling approaches include, but are not limited to: Business Process Model and Notation (Business Process Model and Notation (BPMN), Version 2.0, 2013) , Model-Based Testing, Model-Driven Engineering (Lopes & Guerreiro, 2023) , Flowcharting, IDEF techniques, Petri Nets, various simulation techniques including Discrete-Event Simulation, Agent-Based simulation, and System Dynamics, and various knowledge -based techniques including Knowledge-Based Systems and Qualitative Simulation (Giaglis, 2001) , and Systems Modeling Language (OMG Systems Modeling Language (SysML) , 2024). While each technique has individual advantages and contexts in which it thrives, each technique has its own disadvantages. Processes relating to the representations of abstract elements and processes cann ot fully capture the specific interactions of the systems at play and run the risk of being exploited by bad-faith actors who wish to push for their own agendas at the expense of other potentially valid solutions to existing problems. Conversely, simulatio n and knowledge -based techniques risk focusing too much on the interaction and transfer of data and neglecting the interaction of other more qualitative systems that may influence the effectiveness of the processes being modeled. In the context of organiza tional problem diagnosis and holistic intervention a modeling theory that captures the interaction of organizational systems without neglecting the",oregonstate.edu,Oregon State University,United States,44.56305595,-123.28392337694638
1,DEVELOPING A VIRTUAL SIMULATION GAME FOR EVALUATING PEER EFFECTS ON WORKPLACE SAFETY BEHAVIORS,@oregonstate.edu,"Peer effects, safety behavior, simulation, virtual reality, social comparison","There is a need to evaluate and manage peer effects on workplace safety behaviors as unmanaged peer effects can cause the formation and spread of safety-violating behaviors, thus leading to increased accident occurrence and poor safety culture. There is currently a lack of research on evaluating peer effects on safety behaviors which is partly due to the complexity of  modeling social interactions and the safety risks associated with implementing and evaluating safety behaviors. The objective of this study was to develop a theory-based virtual reality simulation game to study the effects of peer on workplace safety behaviors. The virtual reality game was developed through a three -stage systematic process that involved: a ) Modelling inducement of  peer effects  through information transmission and Festinger’s social comparison  theory, b) Identification and satisfaction of Manski’s requirements for identifying endogenous peer effects, c) Modelling safety behaviors based on workplace safety behaviors concepts and ideas, and d) Designing a virtual simulation game according to the theories in (a, b, and c). While the validity of the game is not discussed in this study, this study discusses the virtual reality game design, and the design of the experiment to study peer effects on safety behaviors. Keywords Peer effects, safety behavior, simulation, virtual reality, social comparison Introduction Peer effects refer to the change in behaviors of a person (receiver) caused by a peer (source) . Existing studies do not have a consistent definition for peers as they define peers based on their study objectives, however, in this study, we define a peer as someone who possesses similar strength to the receiver while acting in the same role as the receiver. In this context, strength refers to the power or capacity to impact others. People may possess similar strengths if they are coworkers with the same authority within an organization Peer effects can be largely categorized into two groups, endogenous peer effects, and exogenous peer effects. Endogenous peer effects are peer effects caused by the source’s behavior, while exogenous peer effects are effects caused by the source's  characteristics (Manski, 1993). This study focuses on endogenous peer effects in the workplace and for the remainder of this study will refer to endogenous peer effects as “peer effects”. Peer effects also exist  in the wor kplace and have  been shown to affect employee  performance (Villeval, 2020, Mas and Moretti, 2009), decision-making (Rosaz et al., 2016), risk-taking (Gioia, 2017), and safety violations (Liang et al., 2018b). In the workplace, peer effects have shown varying outcomes on employee behaviors (Villeval, 2020) , for example, studies have found increased employee performance due to peer effects (Falk and Ichino, 2006; Mas and Moretti, 2009; Cadsby et al., 2019),  while other studies have found decreased perfor mance due to peer effects (Newman and Tafkov, 2014; Silver, 2021). Since peer effects can occur naturally (without management intervention) and can lead to negative outcomes, it is crucial to understand how peer effects may impact employee safety behaviors in the workplace. There is substantial research on peer effects, however, there is a lack of studies that explore peer effects on safety behaviors. Liang et al. (2018b) developed an agent-based model based on existing workplace safety data to show the spread of safety violations within a construction crew . Using existing data for research  provides useful insight into answering the research questions, however, the methods involved in analyzing such data can be challenging if the data was not collected to study peer effects (Manski, 1993). If the existing data was not collected to study peer effects, the data may not explicitly differentiate between the source  and receiver in the  peer effect process , Manski ( 1993) describes this challenge as the “reflection problem”. Studying peer effects using existing data can also be challenging",oregonstate.edu,Oregon State University,United States,44.56305595,-123.28392337694638
2,EXPLORING CATEGORICAL STRUCTURES FOR CONTEXT- INFORMED PERFORMANCE APPRAISAL SYSTEMS IN MODERN WORKPLACES,@oregonstate.edu,"Performance appraisal, systems thinking, category theory, sheaf theory, performance pattern recognition","Traditional performance appraisal  (PA) methods, often reliant on static measures, are increasingly misaligned with the needs o f organizations in the complex, continuously evolving, modern work environment. Such methods offer only a snapshot of team performance from a fixed perspective, failing to capture a  context-informed scope of performance over time. This limitation restricts engineering managers' ability to make context-informed decisions on resource allocation, potentially misaligning actions or objectives with current or future organizational needs and exacerbating discrepancies between evaluated and actual performance. Con sequently, inaccurately assessed employees may feel undervalued or experience decreased motivation and job satisfaction, potentially resulting in higher turnover rates. Addressing these shortcomings requires reevaluating team performance measurement and management. One potential solution for facilitating this approach is adopting mathematical methods that signal changes in team dynamics to leadership and support responsive behavior adjustments based on context -derived insights. Observing patterns in these b ehaviors, tracking their changes, and leveraging the information they provide becomes a relevant strategy by allowing leaders to monitor the interplay between the team's behaviors and the context in which it operates. This approach enables engineering managers to observe the identification of shifts and disruptions within team dynamics. This paper introduces a novel mathematical appraisal model, incorporating the transdisciplinary principles of systems thinking and categorical sheaf  theory to enhance engineering managers' understanding of team performance with context-informed insights. Keywords Performance appraisal, systems thinking, category theory, sheaf theory, performance pattern recognition Introduction In m odern organizations, p erformance appraisal (PA) systems maintain relevance in organizational management, guiding many functions , including resource allocation, employee development, and strategic planning decisions (Cappelli & Conyon, 2018; Coens & Jenkins, 2002) . Traditional appraisal methods, which often rely on static and isolated measure ments, may not effectively capture the complexity and dynamism of contemporary work environments (Levy & Williams, 2004). These methods offer a limited view of team performance, lacking the context for accurate assessment and responsive management (Smither et al., 2005; Spitzer, 2007). These limitations are particularly evident in engineering management, where projects typically involve intricate interdependencies, requiring timely adjustments based on real -time data and evolving conditions. Traditional PA methods fall short of capturing the dynamic and interdependent nature of team performance (Levy & Williams, 2004; Mathieu et al., 2019) . Failing to capture the complexity and dynamism of modern work environments can lead to inaccurate assessments and management decisi ons, impacting  resource allocation, employee development, and strategic planning, potentially causing inefficiencies and missed opportunities for improvement. A more nuanced approach is necessary to accurately reflect team performance and provide the context for effective and responsive management (Levy & Williams, 2004). By adopting a systems perspective, engineering managers can gain clarity and precision when describing the relationships between different organizational components and their collective impact on performance . However, current approaches in PA  systems often lack scalability and adaptability, suggesting the need for incorporating mathematical rigor. Abstract m athematical frameworks, such as category theory  (CT), sheaf theory, and their",oregonstate.edu,Oregon State University,United States,44.56305595,-123.28392337694638
3,A BIBLIOMETRIC REVIEW OF ENGINEERING MANAGEMENT OVER TEN YEARS (2014-2023),@kingston.ac.uk,"Engineering management, epistemology, systematic search, bibliometric review, co-occurrence map.","The subject of engineering management is concerned with the management of organizations, people and projects in a technological or engineering systems context and there are many studies across the field of engineering management in the extant literature. Engineering management also represents an approach to tackle the grand challenges of today, such as the need for sustainable development as well as digit al transformation. Therefore, it is important for scholars to have a deep understanding of the scope of the subject as well as emerging patterns in the knowledge base and consequently this research study conducted a bibliometric review of engineering manag ement. The review was underpinned by a systematic search of the literature on engineering management over a 10 -year period (2014-2023). This allowed the documents to be categorized according to publication metrics accompanied by bibliometric analysis to determine a number of parameters, including co-occurrence of keywords, co-occurrence of text, and co-authorship in terms of countries. The bibliometric review provides insights into emerging trends across the subject of engineering management as well as collaboration patterns combined with an exploration of the intellectual structure of the subject. The study concludes with recommendations for the development of the engineering management subject. Keywords Engineering management, epistemology, systematic search, bibliometric review, co-occurrence map. Introduction The subject of engineering management is concerned with the management of organizations, people , and projects in the context of technological or engineering systems . Engineering management is practiced widely across technical environments and the discipline is implicitly linked to the organizational role of the engineering manager. Moreover, engineering management is carried out  in different situations and across a range of industrial sectors, such as manufacturing, construction, production, transport ation and business administration. Consequently , engineering management has been researched extensively, and there are many studies across the field of engineering management in the extant literature . There have been a number of articles that have sought to describe the main features of the discipline as well as the historical basis of the subject, for example, see the work of Lannes (2001), Roberts (2004), Kocaoglu (2009), Omurtag (2009), Chang (2016) and He (2023). Indeed, one of the challenges associated with the engineering management discipline is codifying the features of the subject, since it includes a broad range of topics and problem areas  associated with both human and non -human elements ( Spurlock et al., 2008). Engineering management can also be viewed in terms of the challenges for technical organizations and engineering managers, including the business environment trends a nd challenges (e.g. globalization) ; organizational trends and challenges (e.g. implementing a process-based organization); and engineering management/manager trends and challenges (e.g. understanding and managing uncertainty) (Kotnour & Farr, 2005). In ter ms of a definition, the American Society for Engineering Management (ASEM) defines engineering management as “ an art and science of  planning, organizing, allocating resources, and directing and controlling activities that have a technological component” (Shah, 2015, p. 3). Interestingly, while engineering management is a subject area with a corresponding academic discipline; it is also composed of several  sub-areas, which collectively can be viewed as the ‘building blocks’ of engineering management. These sub-areas include, for example, leadership and organizational management, project management, supply chain management, technology management, engineering economy, and systems engineering; many of which are described as domain areas in the Engineering Management Body of Knowledge (Shah, 2015). Reflecting on this situation further, engineering management would appear to be both a defined area of knowledge in its own right as well as representing a set of semi -independent knowledge areas. For instance, in the case of project management, there are studies that are focused on the",kingston.ac.uk,Kingston University,United Kingdom,51.403073899999995,-0.3032181426130893
4,ASEM 4.0/5.0 – EVOLVING THE ENGINEERING MANAGEMENT PROFESSION THROUGH INDUSTRY 4.0/5.0 COLLABORATIVE NETWORKS,@odu.edu,"collaborative networks, Industry 4.0, Industry 5.0, cyber-physical systems","The American Society for Engineering Management was created and matured under Industry 3.0 automation.  The emergence of Industry 4.0 and 5.0 are forcing all organizational sectors to rethink their long-term strategy with respect to emerging horizontal/vertical cyber-physical systems integration.  This leaves open the question of the directions in which ASEM should evolve into the 21 st century.  This paper reports an initial mapping of Industry 4.0 and 5.0 technologies and initiatives as goal-oriented, long-term strategic collaborative networks.  The research method began with the Boston Consulting Group nine technologies of Industry 4.0 (2015) and the Industry 5.0 technologies within its human-centric, sustainability, and resilience initiatives  as an initial conceptual framework .  Research questions were derived from collaborative network theory in the context of  the Industry 4.0/5.0 conceptual framework.  Key word searches were performed, and a corpus of journal articles was assembled with respect to the research questions. A systematic literature review was conducted using Industry 4.0/5.0 collaborative networks concepts identified from evidential coding rules developed.  The emergent Industry 4.0/5.0 cyber-physical collaborative networks  goal- oriented, long-term strategic concepts were organized within the collaboration  theoretical framework.  The paper concludes by suggesting directions for ASEM to consider in its own strategic evolution into 21st century collaborative cyber-physical systems. Keywords collaborative networks, Industry 4.0, Industry 5.0, cyber-physical systems Introduction The primary objective of Industry 4.0 is the integration of smart technologies into  autonomous massive horizontally and vertically collaborative manufacturing  value-chain networks across the Internet of Th ings to achieve innovative levels of competitive advantage through individualized product customization.   (Erboz, 2017; Ojra, 2018 , Rupp, Schneckenburger, Merkel, Börret, and Harrison, 2021 )   Industry 5.0 extends the massive horizontally and vertically collaborative networks to the objectives of human-centric, sustainable, and resilient societies.  Industry 5.0 envisions smart technologies collaborating with humans in virtual intelligent systems to enhance societal well-being. (Skobelev and Borovik, 2017 ; Paschek, Mocan, and Draghici, 2019 )  The drive toward massive horizontally and vertically integrated virtual intelligent collaborative systems is forcing all organizational sectors to rethink long -term collaboration strategy.  The central question is how massive horizontally and vertically integrated virtual intelligent collaborative systems will change business collaboration strategy. (Kraaijenbrink, 2022)  ASEM leadership is faced with the same question with respect to its long-term cyber-physical collaboration strategy.  The question for ASEM is how will Industry 4.0 and 5.0 massive horizontally and vertically integrated virtual intelligent collaborati on systems impact the ASEM customer value proposition strategy as it moves into 21 st century collaborative cyber-physical systems? Essential Collaborative Networks Theory A problem-driven concept analysis is motivated by epistemic questions about a phenomen on for which the analyst believes the answer s can be synthesized from existing r esearch literature.  Concept synthesis requires a reference",odu.edu,Old Dominion University,United States,36.8862699,-76.30972478839735
5,CAN ONLINE TRAINING REPLACE FACE-TO-FACE TRAINING? EVIDENCE OF LEAN MANUFACTURING TRAINING FOR INDUSTRY PERSONNEL IN THE US,@uky.edu,"Online, Face-to-face, Training, Lean Manufacturing.","Online training recently surged due to the COVID -19 global pandemic, and many higher learning institutions transformed face-to-face learning into online learning. This study analyzes the perception and performance of industry participants for face-to-face and online Lean Manufacturing training from 2019 - 2021. The researchers assessed the performance of online and face-to-face participants using pretests and post-tests. Paired t-tests were utilized to evaluate if the differences in the pretests and post -tests were statistically different. Furthermore, the p erceptions of online and face-to-face participants were gathered through a survey questionnaire. The study results indicated that Lean Manufacturing could be learned effectively through online and face -to-face formats. Industry participants also suggested best practices to improve online and face -to-face training. The study can be helpful to higher learning institutions and organizations that want to teach Lean Manufacturing online to industry participants. In addition, online learning requires designing a training program and selecting instructional delivery methods and techniques that enhance learning and knowledge transfer. Therefore, the suggestions given by the industry participants could be helpful for Lean Manufacturing instructors. According to the authors’ knowledge, this is the first study that offers the perception and performance of industry participants trained for Lean Manufacturing using face -to-face and online methods in the USA. Keywords Online, Face-to-face, Training, Lean Manufacturing. Introduction The coronavirus-19 (COVID-19) outbreak forced higher learning institutions and other organizations to transition to online learning and training. Face-to-face training became impossible due to the social distance requirement enforced by the government due to the pandemic. Although face-to-face training became impossible, some organizations such as healthcare, food processing, fire -fighting, and pharmaceuticals remained operational in 2020 and needed their employees to learn about Lean Manufactu ring. Thus, training was only possible via online platforms. During the pandemic, many organizations began to use online training to quickly guide workers and upskill them to meet the ever-changing job requirements (Verma et al., 2020). Online training also enabled employees to collaborate remotely on how to improve their working environment without the need to have face -to-face training. Although several studies have compared the impact of online and face -to-face learning in engineering (Fouad et al., 2021; Martínez et al., 2019; Schnieder et al., 2022) , few st udies have been done to show how these two modes of learning impact industry personnel. Many studies focused on the impact of online and face -to-face learning on university students (Hoffman & Elmi, 2020; Khraishi, 2020). Furthermore, although several universities have offered online Lean Manufacturing training, few studies show how Lean Manufacturing training can be conducted online (McKie et al., 2021) . McKie et al. (2021)  examined how face -to-face Lean Manufacturing was converted to online training for the Engine Manufacturing center in the United Kingdom during the lockdown. The study revealed the number of trained participants before , during, and after the lockdown. However, the study did not compare the performance in online and face-to-face tests; it only highlighted the number of quizzes taken by the online participants.",uky.edu,University of Kentucky,United States,38.026629099999994,-84.50472223981663
6,ENHANCING HEALTHCARE MANAGEMENT IN LMICS THROUGH BIG DATA: STRATEGIES FOR DATA QUALITY IMPROVEMENT AND CONTEXTUAL INTEGRATION,@uj.ac.za,"Big data, Electronic Health Record, Healthcare, Interoperability, Universal Health Coverage.","The potential of big data to revolutionize healthcare in low - and middle-income countries (LMICs) is hindered by challenges such as limited data availability and poor alignment with local healthcare needs. This study critically analyses the current state of big dat a in LMIC healthcare and develops a framework to enhance data utility while ensuring contextual relevance and user -friendliness. The methodology involves examining successful big data applications and identifying best practices in data quality improvement, interoperability, and capacity building within digital healthcare systems. The findings offer practical insights for optimising big data analytics in LMICs, addressing issues such as data incompatibility with local healthcare practices and infrastructure constraints. The expected impact includes guiding policymakers and healthcare providers in LMICs towards more effective big data implementations, aiming to improve healthcare delivery and patient outcomes. This study contributes to the advancement of equit able and efficient healthcare systems in LMICs by focusing on tailored, sustainable big data solutions. Keywords Big data, Electronic Health Record, Healthcare, Interoperability, Universal Health Coverage. Introduction The advent of big data has ushered in a transformative era in healthcare, promising advancements in delivery and management across the globe (Aceto , Persico, & Pescapé, 2020; Karatas, Eriskin, Deveci, Pamucar, & Garg , 2022). Big data, characterized by its volume, velocity, variety, and vera city, offers the potential to revolutionize healthcare systems, particularly in high-income countries (HICs) where it has already demonstrated its effectiveness in improving diagnostics, facilitating personalized treatment plans, enhancing disease surveill ance, and optimizing resource allocation (Batko & Ślęzak, 2022). The capacity to analyze massive and diverse data sources, such as electronic health records (EHRs), genomic data, medical imaging, and wearable device data, has opened unprecedented opportuni ties for precision medicine, early disease detection, and proactive healthcare interventions (Khatib , Hamidi, Ameeri, Zaabi, & Marqab, 2022). However, harnessing the transformative power of big data in low- and middle-income countries (LMICs) presents unique challenges (Kaur , Garg, & Gupta , 2021; López , Rico-Olarte, Blobel, & Hullin , 2022). These challenges are deeply rooted in the complex interplay of socio-economic, technological, and infrastructural factors prevalent in many LMICs (Bagherian & Sattari, 2022). Data scarcity, often due to underdeveloped data collection and reporting systems, poses a significant hurdle (Hoxha, Hung, Irwin, & Grépin, 2022). Even when data is available, concerns regarding its quality, including accuracy, completeness, and consistency, often undermine its reliability for decision-making (Díaz Iturry, Alves -Souza, Ito, & da Silva , 2021). Additionally, limitations in technological infrastructure, such as inadequate storage capacity and computing power, can impede the effective pro cessing and analysis of big data (Kumar & Mostafa, 2020). The scarcity of trained personnel equipped with the necessary skills to manage and interpret big data further exacerbates these challenges (Chen, Lin, & Wu, 2020). The unique healthcare context of L MICs necessitates solutions tailored to their specific needs and priorities (Xiong et al., 2023). LMICs often grapple with a higher prevalence of infectious diseases, malnutrition, and maternal and child health issues, distinct from the disease burden in H ICs (World Health Organization, 2024). Moreover,",uj.ac.za,University of Johannesburg,South Africa,-26.18493745,27.99979246435022
7,LEVERAGING AI FOR UNBIASED ANALYSIS OF EMERGING TECHNIQUES IN ACADEMIC LITERATURE,@uj.ac.za,"Artificial intelligence, AI engineering and applications, Machine learning, Decision making, Word embedding","In the rapidly evolving landscape of artificial intelligence (AI), the challenge of quantifying knowledge drift and emerging techniques persists due to inherent biases in expert knowledge. AI engineers often apply techniques subjectively based on their understanding, making it difficult to measure knowledge evolution objectively. To address this, we propose leveraging AI to process extensive academic research data, providing an unbiased assessment of the emergence and application of techniques.  This stud y employs natural language processing (NLP) techniques, including knowledge embedding, abstractions, named entity recognition (NER), and knowledge graphs , to extract cutting-edge knowledge using a large corpus of academic literature , enabled by  techniques such as  Retrieval- Augmented Generation (RAG) to generate  summaries, keywords, and abstracts for analysis. NER facilitates identifying and classifying entities such as persons, organizations, and locations. Word2Vec measures the similarity and diversity of words and entities, uncovering new associations and patterns. Integrating knowledge graphs organizes the extracted knowledge into a coherent and comp rehensive structure, allowing for easy querying, visualization, and reasoning. This approach enables a deeper understanding of techniques' emergence, application, and suitability within specific domains, helping identify inflection points and trends in knowledge evolution. Keywords Artificial intelligence, AI engineering and applications, Machine learning, Decision making, Word embedding Introduction Humanity has entered the era of Fourth Industrial Revolution (4IR), or Industry 4.0, where AI plays a crucial role. 4IR signifies the transition from traditional manufacturing, where machines perform set routines, to digital manufacturing, where machines c ommunicate with each other, self -monitor, and collaborate autonomously (Oztemel & Gursev, 2020). AI can be described as intelligence shown by machines or the study of how digital computers and algorithms carry out tasks and solve complex problems, typica lly requiring human intelligence, and inclusive of reasoning, prediction, and the ability to adapt to changing situations, often surpassing human capabilities (Giuggioli & Pellegrini, 2023). The definition of AI has continually evolved since computer scientist John McCarthy first described it over 60 years ago as “the science and engineering of making intelligent machines” (Andersen, 2002). Today, AI encompasses various subsets, including machine learning (ML) and its further subset, deep learning (DL) (Giuggioli & Pellegrini, 2023). ML techniques such as classification, dimensionality reduction, regression, and object recognition, are extensively used for tasks such as predictions, recommendations, and detection (Bindra et al., 2021) . These technologies have firmly established themselves over the past decade and are projected to grow exponentially in the future (Bindra et al., 2021). AI has witnessed exponential growth lately, driving advancements across various domains (Gill et al., 2022) ; which have revolutionized industries such as healthcare, finance, and transportation, enhanced efficiency and created new opportunities for innovation (Dwivedi et al., 2021). This rapid evolution, however, presents significant challenges, particularly in understanding and quantifying knowledge drift (KD) in AI —the gradual",uj.ac.za,University of Johannesburg,South Africa,-26.18493745,27.99979246435022
8,EXPLORING STATE CHIEF INFORMATION OFFICERS INVOLVEMENT IN INFORMATION TECHNOLOGY STRATEGIC PLANNING FOR REMOTE COLLABORATION SAIC MITRE,@saic.com,"State Chief Information Officers, Information Technology Strategic Planning, Remote Collaboration .","State Chief Information Officers (CIOs) have a vital role in information technology (IT) organizations; they lead and sponsor information system (IS) pr ograms, ensure operations, and provide technologies and capabilities for their organizations. Previous studies (Eiras, 2010; Haffke et al., 2016; Mitchell, 2015; Muller, 2011; Roberts et al., 2014) have discussed CIOs’ effectiveness in organizational manag ement, and CIOs’ skillsets and credentials for roles and responsibilities involved in leading an organization. Compliance with Presidential Executive Orders 13571 and 13576 requires federal government agencies to undertake appropriate steps to streamline a nd improve digital services, and deliver an efficient, effective, and accountable federal government. At the state government level, the CIO position is established in each of the 50 U.S. states and tasked with providing oversight and managing state inform ation technology (IT) and information system (IS). Investigating CIOs’ involvement in dealing with IT initiatives in their organizations can identify practices leading to successful implementations (Porfirio et al., 2020). Keywords State Chief Information Officers, Information Technology Strategic Planning, Remote Collaboration . Introduction The term CIO was first used in the early 1980s and later associated with the main responsibilities of planning, operating, and managing an organization’s IT resources, IT investment, and IT management as a corporate executive leader (Ostrowski & Helfert, 2011). The Clinger -Cohen Act of 1996 mandated the position of CIO; this individual would take the steps necessary to implement and manage IT and processes through policies and strategic plans to meet organizational business and mission needs (Government Accountability Office, 2001). CIOs exist in many industries including commercial, private, and government industries as well as various research and academic institutes;  they strive for their organization’s success by meeting their goals and objectives. Scant research literature pertaining to State CIOs is available (De Tuya et al., 2020). Some reports from the U.S. Government Accountability Office (GAO) cover topics on U.S. federal government CIOs, and reports from the National Association of State Chief Information Officers (NASCIO) covering topics on U.S. state government CIOs are also available. However, current literature includes limited information about State CIOs (McCarthy et al., 2021). A gap exists in the literature pertaining to State CIOs’ involvement, and the implications of IT strategic planning and remote collaboration during the height of the COVID-19 pandemic. Problem",saic.com,,,46.3144754,11.0480288
9,"A GENERALIZED, INDUCED PROTOCOL FOR SYSTEM DYNAMICS MODEL REPLICATION IN AN ALTERNATIVE SOFTWARE",@tec.mx,"Model Replication, Protocol, System Dynamics, Simulink, Vensim","The ability to simulate is influenced considerably by the software technology a vailable to the modeler.   The access, availability, and use of simulation software are , in turn, affected by cost considerations, geographical constraints of access owing to the location of modelers, multilingual capabilities of the software, and compatibi lity of simulation software with local technology infrastructure, among other factors.  Given that new knowledge can only be built upon existing knowledge, the replicability of existing models is of paramount importance.   In addition, the ability to replicate needs to be independent of the availability of the software technology used to build the original model.   In our endeavor to replicate a model in different software, we have induced a generic protocol that modelers can use to guide them in a similar endeavor concerning System Dynamics simulation. Keywords Model Replication, Protocol, System Dynamics, Simulink, Vensim Introduction Among the issues preventing the widespread adoption of System Dynamics (SD) modeling in approaching complex real-world situations, the difficulty of model replication stands out for its lack of literature and tools dedicated to its amelioration (Elizondo-Noriega, Beruvides, et al., 2019) .  As more efforts are made to build, calibrate, and validate new SD models, few seem to share sufficient information that would allow others to replicate their work, and in turn, even fewer attempt to do so regardless of recent efforts in the System Dynamics discipline like the SDM -DOC approach followed by the System Dynamics Review.  Models published before the SDM-DOC format implementation or publish ed in journals other than the System Dynamics Review are even more challenging to replicate but not impossible.  The problems this scarcity of information produces are only exacerbated by the technical hurdles one can encounter when trying to replicate a m odel, such as unexpected changes between versions of the same modeling software or a lack of flexibility in exporting and representing results. In previous work by Elizondo-Noriega et al. (2019a), the authors recreated an SD model (not documented as it is suggested in the SDM -DOC format) that was originally reported by Visuwan and Tannock (Visawan & Tannock, 2004).  This model is referred to as the VT model, and it describes the interactions between defect prevention activities and the profitability of a vehicle manufacturing firm.  Since the initial replication, this model has been expanded upon by the authors and used to study the economic impact of leasing or purchasing industrial robots, carrying out Six Sigma projects, and implementing RFID tech nology (Elizondo-Noriega et al., 2019b, 2019c, 2019d, 2021, 2021a, 2022). The model replication mentioned above was performed using Vensim (Ventana Systems, 2023), while Visuwan and Tannock used Stella, i.e. , two different SD simulation software environments .  Elizondo-Noriega et al. (20 19a) decided to use Vensim because it is a widely used option in both industry and research due to different factors such",tec.mx,,,46.3144754,11.0480288
10,MODELING ENGINEERING CHANGE ADMINISTRATION IN PAINTED BODY MANUFACTURING OPERATIONS ACROSS NEW PRODUCT INTRODUCTION PHASES: A SYSTEM DYNAMICS APPROACH,,"Engineering Change Administration, System Dynamics, Painted Body Manufacturing Operations .","This study rigorously examines the complexities inherent in Engineering Change Administration (ECA) for painted body processes within automotive manufacturing during the New Product Introduction phase. Utilizing a System Dynamics approach, developed throug h a collaborative effort between a leading global automotive  Original Equipment Manufacturers (OEM) and academic researchers, this paper models the introduction and implications of engineering changes. The analysis delineates two principal pathways for the  implementation of changes: (1) the lean implementation pathway and (2) the late implementation request pathway, elucidating their respective operational complexities and coordination demands. Key analytical metrics developed include the complexity index a nd the quality coordination cost, which quantitatively assess the challenges and variability associated with the implementation of engineering changes. These metrics serve as critical indicators for evaluating the efficiency and potential complications in the integration of new engineering features. The findings underscore the necessity for strategic planning and the pivotal role of specialized ECA departments in optimizing change management processes. This research enhances the scholarly understanding of painted body ECA operations and contributes valuable insights towards advancing manufacturing efficacy and quality within the automotive industry. Keywords Engineering Change Administration, System Dynamics, Painted Body Manufacturing Operations . Introduction The automotive industry is currently experiencing a paradigm shift as a result of the integration of information technologies and the emergence of Industry 4.0, commonly known as the cloud era (Martinez, 2021). This technological transformation is not unique to the automotive sector but has significantly impacted the way car projects",,,,46.3144754,11.0480288
11,"NAVIGATING THE COMPLEXITIES OF ENGINEERING MANAGEMENT: INSIGHTS INTO METRICS, MEASUREMENTS, AND PITFALLS",,"Metrics, Measurement, Performance, Strategy","In the realm of Engineering Management, the reliance on metrics and measurements stands as a cornerstone for effective decision-making processes. These quantitative tools offer insights into performance dynamics and facilitate informed strategic choices. However, the uncritical application of metrics devoid of profound domain expertise presents significant challenges. This abstract explores the pitfalls inherent in utilizing metrics and measurements within Engineering Management without comprehensive understanding, emphasizing the potential consequences and proposing strategies for navigating this complex terrain. Keywords Metrics, Measurement, Performance, Strategy Introduction Overview of Metrics and Measurements Metrics and measurements are fundamental tools in the realms of engineering and management, providing a quantitative basis for evaluating performance, making decisions, and driving improvements. In essence, metrics are specific, measurable values used to t rack and assess the status of a process or system. Measurements, on the other hand, involve the collection of quantitative data related to these metrics. Together, they form the backbone of systematic evaluation and control in various professional domains (Drucker, 1954). The significance of metrics and measurements cannot be overstated. They enable engineers and managers to transform abstract goals into concrete, actionable objectives. By setting clear benchmarks, organizations can monitor progress, identify areas for improvement, and ensure alignment with strategic goals. For instance, key performance indicators (KPIs) are widely used to gauge oper ational efficiency, quality control metrics ensure product standards, and project management metrics help in tracking project timelines and budgets (Kerzner, 2017). Historically, the use of metrics and measurements has evolved alongside technological and methodological advancements. From early industrial engineering practices to contemporary data-driven management approaches, the sophistication and application of metrics have expanded dramatically. The advent of information technology has further revolutionized this domain, enabling the collection, analysis, and interpretation of vast amounts of  data with unprecedented precision and speed (Kaplan & Norton, 1992). Purpose and Scope of the Paper Despite their crucial role, the reliance on metrics and measurements is not  without pitfalls. This paper aims to shed light on the common challenges and potential downsides associated with an over -reliance on these tools, particularly in the absence of profound domain knowledge. The purpose is to explore how a superficial underst anding of metrics can lead to misguided decisions, inefficiencies, and even significant failures (Mintzberg, 1979). The paper will highlight several key pitfalls, such as the misleading simplicity of metrics, the risk of developing tunnel vision, and the tendency to game the system to meet metric -based targets. These issues often arise when metrics are used in isolation, without a deep understanding of the underlying processes and contexts they are meant to represent. A central theme of this discussion is the importance of domain knowledge. Profound expertise in the specific field of application is essential for interpre ting metrics accurately and making informed decisions. Without this expertise, there is a risk of misinterpreting data, overlooking critical nuances, and failing to account for qualitative factors that metrics alone cannot capture (Liker, 2004).",,,,46.3144754,11.0480288
12,SIMULATION-BASED EVALUATION OF THE COST OF QUALITY ASSOCIATED WITH RFID ADOPTION IN A MANUFACTURING FIRM,@kettering.edu,"Modeling, Economics, Decision making.","In this study, we adapt a previously developed System Dynamics model of Radio Frequency Identification (RFID) technology adoption by an automotive manufacturing firm to evaluate the cost of quality associated with such an endeavor. RFID technology is effective in increasing throughput and preventing quality -related defects in its various applications. Using a foundational model in the discipline of Cost of Quality, this study assesses the quality cost impact of RFID adoption. The goal of this study is to hi ghlight the potential for the positive impact of RFID adoption on a firm’s quality objectives. This study is one part of an overarching research direction that intends to shed light on the monetary implications of technology absorption to help firms make informed technology investment decisions. Keywords Modeling, Economics, Decision making. Introduction Quality Management (QM) as a discipline continues to attract the attention of academics and practitioners alike for a plethora of reasons including its centrality to the efficiency of production and service systems. In the current milieu of supply chain risks, a pressing need to adapt quickly to changing customer expectations  and high inflation and input costs, the ability of organizations to deliver high  throughput while maintaining high quality by making effective use of limited resources and reducing defects is crucial for them to survive and be profitable. Given this context, one strategy among several others that are available to organizations is the absorption of new technology and management practices to reduce defects in production and/or customer complaints whilst also increasing throughput. The impact of new technology implementation has been researched well. Imai (1986) discusses the discontinuities in costs and improvements caused by new technology absorption that require sustained efforts to stabilize. Liker ( 2004) speaks of the famous Toyota Production System (TPS) and its ability to integrate new technology w ith the intention of keeping its processes and systems lean, one example being the jidoka (human- machine automation). Schiffauerova & Thomson (2006) suggest that C ost of Quality (CoQ) measurement should be a part of the overall QM program because it lends direction to targeted efforts at reducing CoQ. There exist several methods to define and interpret the CoQ that can be broadly categorized into either the classical or the modern models (see Exhibit 1).  At a foundational level, the CoQ is the sum of the costs associated with conformance and non -conformance to quality expectations. Conformance costs are the sum of the costs associated with (i) ensuring defects and issues are prevented before they occur an d (ii) the costs associated with appraisal of output to ensure defects and issues, if they have occurred, do not reach the end consumer. Non-conformance costs are the failure costs associated with poor quality like defective inventory management and customer returns. Per Dale and Plunkett (1995), quality costs could include the costs associated with ensuring high quality across all process stages such as design and operations, maintenance of a quality management system and continuous improvement initiatives, and the costs of product and service failures such a customer returns.",kettering.edu,Kettering University,United States,43.014042200000006,-83.7140043528519
13,CYBERSECURITY AND INSIDER RISK: ANALYZING SECURITY BEHAVIORS AND PROPOSING MITIGATIONS,@towson.edu,"Survey research, human error, insider risk, security behavior, election security","With globalization, information technology has been relentlessly evolving. Sectors such as business, finance, and healthcare have been increasingly relying on the development of technologies to enhance their efficiencies .  The challenge persists in safeguarding data against evolving threats, with human error being a significant risk factor. Therefore, in this research , we consider the human element as an insider risk for cybersecurity. Human errors in cybersecurity include unintentional lack of attention resulting in breaches or incidents, activities such as clicking  on phishing links that contain viruses, keeping a we ak password, compromising IP address, not updating software, etc . This research aims to understand individual responses to personal cybersecurity practices and propose effective measures for mitigating cybersecurity risks.   Using a survey distributed via Amazon MTurk with 27 Likert -scale questions built from the Security Behavior Intentions Scale (SeBIS) and the Human Aspects of Information Security Questionnaire (HAIS-Q) inventories, 763 usable responses were collected. By applying information theory, we arrive at an overall conclusion of inconsistency and uncertainty in insider behaviors, particularly within device securement, password generation, and social media use. Additionally, there are strong connections between behavioral intentions and demographic factors. Furthermore, we also compare our results with a known sample of SeBIS data collected on United States poll workers, to examine any considerable differences.   The goal of the comparison is to examine potential robustness in security behaviors across sectors and demographic groups. Keywords Survey research, human error, insider risk, security behavior, election security Introduction and Motivation Information security plays a vital role in any industry. An organization’s information security posture impacts several organizational aspects, such as competitive advantage, customer satisfaction, legal and regulatory compliance, and risk management (Johnson, 2009; Dor & Elovici, 2016).  Additionally, threats to i nformation security have become common and will not disappear any time soon (Moore , 2023). In 2020 and 2021, the United States saw the highest number of breached users, with 174.4 million and 212.4 million users affected, respectively (Surfshark, 2021). Despite advancements in modern threat detection software, cybercriminals exploit the fact that the effectiveness of any security measure depends on proper user implementation (Hacker News, 2021). A study by Stanford and Tessian, a leading cybersecurity organ ization, revealed that approximately 88% of all data breaches result from employee mistakes. Furthermore, the study highlighted that employees are less likely to admit their errors if they fear severe judgment from their organizations (Sjouwerman, 2023). The intricacies of modern cyberattacks highlight the complexity of data protection and the necessity to enhance information security. According to the Data Breach Investigation Report (Verizon, 2023), 74% of all breaches include the human element, with peop le being involved either via error, privilege misuse, use of stolen credentials, or social engineering. Human behavior, whether intentionally or through negligence, is a great source of risk to information assets (Safa & Maple, 2019). In 2015, Ubiquiti disclosed in a U.S. Securities and Exchange Commission filing that it had fallen victim to an external entity that impersonated employees and made fraudulent re quests to its finance department, leading to the transfer of $46.7 million from a Hong Kong subsidiary to overseas accounts held by third parties (Morgan, 2016). As another recent example, the video game publisher behind the Call of Duty  franchise,",towson.edu,Towson University,United States,39.38697675,-76.61858035588965
14,DATA DRIVEN TRADE-OFF ANALYSIS FOR CYBERSECURITY,@ucmail.uc.edu,"Data driven cybersecurity, trade-off analysis, cyber security risk management","Trade-off analysis, a specialization of systems engineering, addresses design criteria like security, cost, performance, and compliance. Monte Carlo simulations are commonly employed to generate impact scenarios for trade-off analysis combined with solution alternatives that accommodate industry-specific considerations and uncertainties. In the cyber domain, this paper proposes a methodology for data -driven trade-off analysis in cybersecurity, leveraging industry reports as primary data sources using confidentiality, integrity, and availability as trade -off analysis objectives. Distribution functions are derived to manage and mod el uncertainties for various industries . The approach given in this study aims to facilitate informed choices and to enhance cybersecurity  decision making and  risk management efforts for various industry sectors. Keywords Data driven cybersecurity, trade-off analysis, cyber security risk management Introduction Cybersecurity involves numerous features that require trade-offs. Balancing security with other factors like usability, cost, privacy, openness, convenience, risk acceptance, performance, innovation, centralization, or interoperability falls into the field of trade-off engineering. Prioritizing security measures often means sacrificing some level of usability, making systems more complex or inconvenient for users. A strong cybersecurity soluti on may require significant investment, posing threats to budgets and resources. Enhancing security can conflict with privacy efforts, as stronger security often involves more extensive data collection and monitoring. Implementing additional security measur es may impact end-to-end system performance, which can result in client loss in Business-To-Consumer (B2C) services. Decentralized, decoupled architectures increase reliability but pose another threat to security. Finally, interoperability and threat intel exchange can be slowed down or hampered by security concerns, resulting in paralysis by analysis. In more technical terms, the trade -off for cybersecurity from a security vs. information technology features perspective requires tangible analysis. Tangible trade-off points could be strong encryption versus ease of use, defense- in-depth strategies versus resource consumption, access control restrictiveness vs. accessibility, encryption strength vs. data storage, visibility into threats with intrusiveness, and real-time monitoring with resource utilization, speed vs. accuracy, and automation versus human intervention during monitoring. In this research, we used the three pillars of cybersecurity (Bishop, 2002) - confidentiality, integrity, and availability - to implement a trade-off analysis. For confidentiality, some of the trade-off inflection points could be privacy vs. access: protecting confidentiality often involves limiting access to sensitive information, which may hinder legitimate users who need acc ess. Encryption vs. performance is another confidentiality -relevant trade-off: encrypting data ensures confidentiality but can limit system performance, especially in computing organizations. The integrity pillar could include versioning vs. storage space: storing multiple versions of data enhances integrity but requires additional storage space, often causing cloud service providers to present versioning with additional fees.",ucmail.uc.edu,,,46.3144754,11.0480288
15,"A BUSINESS PROCESS MODELLING, INDUSTRY 4.0, AND IT CAPABILITIES INTEGRATION PERSPECTOVE TOWARDS CONSTRUCTION SME OPTIMIZATION",@uj.ac.za,"SMEs, Business Process Modelling, Industry 4.0, Construction, BPMN, Optimization","For an extended period, the construction industry in developing countries has remained traditional in its approach to operational innovation. While its counterparts, such as the manufacturing industry, are process-centered and dynamic, construction still needs to improve its business processes for better productivity and overall performance. Though several methodologies such as project management have been employed, this industry needs to be more standardized and processed. Business process modeling is proposed as a contemporary model to assist construction SMEs in overcoming the industry’s inefficiencies. Modeling a process enables simulation to improve productivity and optimize project operations. The study shows that organizing the construction terrain and optimizing its operational parameters is feasible. Using modeling and simulation shows that project durations, resource us age, labor, and project costs can be optimized through comparison with simulated results. Keywords SMEs, Business Process Modelling, Industry 4.0, Construction, BPMN, Optimization Introduction Small and medium enterprises (SMEs) are an uncontended force in stimulating national economic growth, promoting employment, and encouraging innovation. Governments, locally and abroad, have sought to promote the SME sector to harness and exploit their innovations for growth. While other sectors like manufacturing industry are marked with progression and standardization in their processes for optimal operations and sustainable development, the construction industry has remained primitive in its approach criticized for lack of productivity,  primitiveness, unstandardized, wasteful, low in profit and high risk  (Tezel et al., 2018). According to Tayeh, Alaloul, and Muhaisen (2019) and Cliquet et al. (2017), construction SMEs are characterized not only by lack of strategic intent but also by schedule and cost overruns, absence of process thinking and lack of client focus. Cliquet, Hendrikse, Sreckovic, and Windsperger (2017) suggest ed that construction firms must innovate business practices and processes into competitive, adaptive ones.  Recent studies (Arashpour et al., 2017; Arashpour et al., 2016) show that SMEs in construction represent a significant part of national economic architecture , thus require highly effective corporate management of their  business processes and systems. Viswanathan & Telukdarie (20 21) suggested that SMEs face strategic alignment challenges like failure to incorporate business process modeling and information technology for improved performance. Industry 4.0 has not significantly found expression through information system incorporation into construction SMEs. In that context, Nowotarski and Paslawski (2017) posit that priority needs to be given to the study of construction SMEs and information systems incorporation, focusing on optimizing business processes. Using business proces s modeling is one significant step to standardize  construction operations and enabl e a process-based approach towards better -performing SMEs. Business process modeling incorporates IT capabilities  to create visual processes that may continuously be improve d (Mahmood et al., 2018). Construction SMEs must use IT and industry 4.0 -relevant tools like business process modeling to improve operational performance. Against this premise, this study aims to investigate business process optimization within the construction industry with a particular interest in modeling to harness benefits to enable  SMEs to combat failure and gain competitive advantage in the current market conditions. This paper answers the following relevant questions: What are the current primary  issues confronting the construction SMEs? How can business process modelling be used to solve and improve construction performance? What are the main KPIs that modelling and simulation may be used to optimise in SMEs projects?",uj.ac.za,University of Johannesburg,South Africa,-26.18493745,27.99979246435022
16,TOWARD A HUMANISTIC APPROACH TO LEADERSHIP IN ENGINEERING MANAGEMENT,@colorado.edu,"Leadership, Management, Humanistic Psycholgy, Harmonic Leadership","This paper explores the transformative potentia l of harmonic leadership within leadership and engineering management practices, challenging the prevailing profit-centric paradigms of contemporary organizations. Harmonic leadership emphasizes harmony, empathy, and personal growth, integrating humanistic  psychology principles with traditional resilience and perseverance. Historically, humanistic approaches have been marginalized in profit-driven environments. This paper argues that this dichotomy is outdated and counterproductive, presenting empirical evidence and case studies showing how a leadership ethos rooted in empathy, compassion and psychological safety can drive sustainable success. By fostering personal development and innovation, organizations can achieve higher levels of employee engagement and resilience. In engineering management, applying harmonic leadership is particularly significant. Engineering managers balance technical challenges, team dynamics, and project deadlines. This study synthesizes findings from psychology, leadership theory, and business management to illustrate that prioritizing the human element in leadership enhances profit goals. Harmonic leadership emerges as a strategic imperative for engineering managers navigating the modern business landscape while ensuring team well-being and motivation. Keywords Leadership, Management, Humanistic Psycholgy, Harmonic Leadership Introduction Humanistic psychology emerged in the mid -20th century as a response to the limitations of psychoanalytic and behaviorist approaches. This psychological framework emphasizes the inherent potential of individuals to grow, achieve self -actualization, and expe rience personal fulfillment. At its core, humanistic psychology is founded on several key principles. Abraham Maslow, Carl Rogers, Kurt Lewin, and Rollo May were instrumental in it’s formation. One of the most significant is self-actualization, a concept popularized by Abraham Maslow, which refers to the process of realizing and fulfilling one’s potential. Humanistic psychologists believe that individuals are inherently motivated to achieve their fullest capabilities and that this drive is a fundamental as pect of human nature  (Acevedo, 2018). Empathy is another cornerstone of humanistic psychology. This principle stresses the importance of understanding and sharing the feelings of others, fostering deeper connections and enhancing communication (Miralles et al., 2024).  Empathetic interactions are seen as crucial for creating a supportive environment that is conducive to personal growth. Furthermore, humanistic psychology values the intrinsic worth of human experience, prioritizing the subjective experiences of individuals. It respects each person’s thoughts, feelings, and perceptions as essential components of their identity and well-being. The approach also champions continuous personal growth and development, advocating for environments that support lifelong learning, self -reflection, and the pursuit of meaningful goals. A holistic perspective is integral to humanistic psychology, considering the physical, emotional, social, and spiritual dimensions of individuals. This comprehensive view acknowledges th e complexity of human experience and the interdependence of various aspects of life. Introducing the concept of harmonic leadership, we propose a new model for humanistic management and leadership that aligns closely with the principles of humanistic psychology. Harmonic leadership is a resonant and integrative approach  to leadership that combines inspirational vision, adaptability, and  human-centric values to foster a collaborative, noncompetitive  environment. It emphasizes",colorado.edu,University of Colorado at Boulder,United States,,
17,ADVANCING LEADERSHIP THROUGH HUMANISTIC MENTAL TOUGHNESS,@colorado.edu,"Leadership, Resilience, Humanistic Psychology, Humanistic Mental Toughness, Engineering Management","This paper explores the transformative potential of integrating a humanistic mental toughness model within leadership and management practices, with a particular focus on applications in engineering management. By challenging the prevailing profit-centric paradigms of contemporary organizations, this study juxtaposes  the principles of humanistic psychology—emphasizing empathy, self -actualization, and personal growth —with traditional models of mental toughness characterized by resilience and perseverance. This model advocates for a leadership approach that values individuals' psychological and emotional well-being alongside organizational objectives. Humanistic mental toughness in business emphasizes the importance of balancing resilience and perseverance with empathy, self -awareness, and psychological well -being. In a competitive corporate environment, traditional mental toughness—focused solely on pushing through adversity—can lead to burnout, reduced productivity, and high employee turnover. However, adopting a humanistic approach allows leaders and employees to navig ate challenges while maintaining mental health and fostering a supportive workplace culture. This approach recognizes that acknowledging vulnerabilities and taking steps to address them can lead to more sustainable performance and innovation. By valuing the holistic well-being of individuals, businesses can cultivate a more engaged, motivated, and resilient workforce, ultimately driving long-term success and creating a positive organizational climate. Keywords Leadership, Resilience, Humanistic Psychology, Humanistic Mental Toughness, Engineering Management Introduction In the dynamic and ever -evolving landscape of contemporary organizations, the demands placed on leaders and managers are both multifaceted and profound. Traditional leadership paradigms,  deeply entrenched in profit -centric ideologies, have long emphasized resilience and perseverance as cornerstones of effective management. However, a growing body of evidence suggests that these conventional models may fall short in addressing the holistic  needs of individuals within organizations. This paper posits that the integration of a humanistic mental toughness model within leadership and management practices, particularly within the realm of engineering management, offers a transformative approach that bridges the gap between organizational objectives and individual well -being. Humanistic psychology, with its focus on empathy, self-actualization, and personal growth, provides a compelling framework for reimagining leadership (Acevedo, 2018; Schneide r et al., 2014) . Unlike the traditional models that prioritize financial outcomes over individual welfare, the humanistic mental toughness model advocates for a leadership ethos that places equal importance on the psychological and emotional well-being of team members.  This approach is not only morally and ethically sound but also strategically advantageous. In environments where innovation, employee engagement, and resilience are paramount, the nurturing of these humanistic qualities can lead to sustainable organizational success (McGregor, 2006). In the sections that follow, we will delve deeper into the principles of humanistic psychology and mental toughness, explore the limitations of traditional leadership models, and present practical applications of the humanistic mental toughness model within engineering management. Our goal is to provide leaders and managers with actionable insights and strategies to navigate the complexities of the modern business landscape while ensuring the well -being and motivation of their teams. Through this exploration, we seek to contribute to the ongoing discourse on effective leadership and management practices, advocating for a shift towards a more empathetic and human-centered approach.",colorado.edu,University of Colorado at Boulder,United States,,
18,LEAN FINANCING: A LEAN SIX SIGMA CASE AT BANK OF AMERICA,@westpoint.edu,"Process Improvement, Lean Six Sigma, Financial Industry","Bank of America (BoA) was one of the first financial services institutions to adopt a Lean Six Sigma methodology as a process improvement strategy.  In the early 2000s, BoA became a pioneer in the financial services industry by adopting a methodology previously reserved for manufacturing giants such as General Electric, Toyota, and Motorola. Lean Six Sigma is a hybrid approach combining Lean methodology, which focuses on removing non -value added, and Six Sigma methodology, a methodology that aims to improve quality while removing variability in the process. Under the leadership of Kenneth D. Lewis, the bank embarked on a comprehensive integration of this p rocess improvement methodology through an extensive deployment of personnel specialized in Lean Six Sigma principles with the bank investing in the training of individuals across various levels of expertise, including master black belts, black belts, and green belts. The enhancements that resulted from the adoption of Lean Six Sigma including increased quality of services, cost reduction, increased customer satisfaction, increased productivity, and an added benefit of 2 billion dollars. This study examines the tools and techniques employed in this quality management initiative, notably Define, Measure, Analyze, Improve, Control (DMAIC) underscoring their role in facilitating continuous improvement and operational excellence. Through this historical case study of Bank of America, the paper aims to shed light on the effective adaptation and implementation of Lean Six Sigma in a non-manufacturing context, offering valuable insights for other financial institutions considering similar process improvement strategi es. Keywords Process Improvement, Lean Six Sigma, Financial Industry Introduction Lean Six Sigma is an integrative methodology that merges the principles of Lean and Six Sigma approaches. Motorola first introduced and developed Six Sigma as a methodology  aimed at process improvement through the reduction of variation, with a goal to achieve no more than 3.4 defects per million opportunities (Schroeder , et al., 2008). On the other hand, the Lean methodology, which prioritizes waste minimization while ensur ing quality and cost-efficiency, was pioneered by Toyota (Womack, 1994). Although Lean Six Sigma has been predominantly applied within the manufacturing sector, its utility in minimizing operational inefficiencies and establishing a competitive advantage has been increasingly recognized in the financial sector as well. In the banking industry, the application of Lean Six Sigma has proven effective in enhancing customer satisfaction and reducing the costs associated with operational inefficiencies and costs, which account for roughly 20% of the total costs in the sector (Jiju, et al., 2019). In the early 2000s, Bank of America (BoA), one of the pioneering financial institutions to implement Lean Six Sigma strategies, has achieved notable improvements including increased customer delight, higher rates of deposit processing, a reduction in the occurrence of missing items on customer statements, and a decrease in defects across electronic channels like ATMs and online banking (Lasater Institute, 2008). This paper intends to explore the adoption and practices of Lean Six Sigma at Bank of America in the early 2000s, focusing particularly on their application of the Define, Measure, Analyze, Improve, Control  process (DMAIC ), benchmarking, and Failure Mode and Effects  Analysis (FMEA) as key components of their strategy (Milton, 2004). Through this examination, the paper aims to illustrate the important role of Lean Six Sigma in transforming financial operations and enhancing overall institutional performance. Background In a SEC filing on Oct, 2003, Bank of America announced a merger with FleetBoston Financial to expand their financial market share and footprint in the industry. One of the elements highlighted in this merger was a commitment",westpoint.edu,,,46.3144754,11.0480288
19,A REVIEW OF RESEARCH ON SUPPLY CHAIN ANTIFRAGILITY: UNVEILING ENABLERS FOR RESILIENCE ENHANCEMENT,@gmail.com,Antifragility; Supply Chain; Disruption; Uncertainty; Collaboration; Risk Management; Redundancy,"This comprehensive literature review delves into the concept of supply chain antifragility (SC -AF), exploring its significance in developing supply chains (SC) that not only withstand disruptions but thrive in the face of adversity. Antifragility (AF) transcends traditional notions of robustness, resilience, and adaptability, emphasizing the ability of SCs to benefit from volatility and uncertainty.  In an interconnected business world marked by increasing complexity and unpredictability, the adoption of AF methods is essential for sustainable SC development.  This review traces the evolution of supply chain management (SCM) concepts  from initiation up to the development and incorporation of AF.  Research methods employed both pre - and post -COVID-19 have predominantly centered on theoretical development, calling for future studies to prioritize inductive research and the practical imp lementation of AF strategies. Through an extensive analysis of the literature, four major enablers of SC-AF emerged: digital capabilities, risk management, collaboration, and redundancy.  Notably, digital capabilities emerged as the foundation of SC -AF, underpinning the effectiveness of other enablers.  This literature review underscores the imperative of integrating digital technologies and emphasizes the need for holistic approaches to enhance SC resilience and agility in an increasingly turbulent environment. Keywords Antifragility; Supply Chain; Disruption; Uncertainty; Collaboration; Risk Management; Redundancy Introduction In today’s interconnected and rapidly evolving global landscape, supply chains  (SC) stand as the lifeblood of economies, ensuring the seamless flow of goods and services across various sectors.  However, conventional supply chain management paradigms often fall short in addressing the complexities and uncertainties inherent in modern business environments.  Disruptions, ranging from natural disasters to geopolitical tensions and pandemics, frequently expose the vulnerabilities of traditional SC structures, leading to cascading disruptions with far -reaching consequences. In recent years, the concept of antifragility (AF) has emerged as a novel lens to view and bolster the resilience of SCs.  Coined by Nassim Nicholas Taleb, AF describes systems that not only withstand shocks and disturbances but thrive and improve in the face of adversity  (Taleb, 2014).  While robustness and resilience  focus on bouncing back from disruptions, antifragility transcends mere survival, embodying the capacity to harness disruptions as opportunities for growth and innovation. This paper aims to explore the application of AF to SCs in today’s current research,  determining how it is revolutionizing traditional approaches in supply chain management  (SCM).  Central to this exploration is the identification of enablers – factors and strategies that facilitate the cultivation of AF SCs.  By conducting a comprehensive literature review, we intend to parse through existing knowledge, theories, and empirical evidence to",gmail.com,,,46.3144754,11.0480288
20,INTEGRATED STRATEGY FORMULATION OF FOREIGN-OWNED R&D SUBSIDIARIES,@dc.tohoku.ac.jp,"Research & Development, Foreign Owned-Subsidiary, Strategy formulation, Multinational corporations.","Purpose: Parent companies usually control a subsidiary’s operations and decision-making process and policies. This research highlights how subsidiary research and development (R&D) contributes the global strategy formulation of a parent company in the context of changes in the Integrated Responsiveness framework and transnatio nal models. Methodology: We conducted surveys with 149 companies in Japan, of which 92 companies conducted R&D activities. Ten companies, nine R&D managers, and one managing director of different industrial companies were selected  to interview. Findings: We found four cases of how R&D subsidiaries incorporate their requirements into global  strategies in the context of changes. Four methods of integrating R&D subsidiaries’ strategies with the parent company have been explained. Further, we showed that global strategy formulation should not be restricted to headquarters, as dilemmas occur within competing departments in the subsidiaries, which negatively impact innovation and performance. Digital transformation suggests the potential of a new subsidiary management model as ""Silent headquarter."" In addition, the originally is to provide useful insight in the importance of centralization to enhance performance. It fills  the research gap in the global strategy formulation process by R&D subsidiaries. R&D leaders at subsidiary levels strike a balance between global considerations and the host country. This concerns the need for initiative and value proposition to their local customers, combined with the operation a s a transnational model. The findings clarify how h igh-performing subsidiary R&D leaders can engage parent company strategy formulation. Keywords Research & Development, Foreign Owned-Subsidiary, Strategy formulation, Multinational corporations. Introduction T Understanding how research and development (R&D) organizations relate to local responsiveness and global integration within the organization strategies of multinational corporations (MNCs) is important. R&D organizations are integrated and centrally operated, particularly from headquarters (Prahala d & Doz, 1987). From a management perspective, challenges related to differentiation and global integration, such as business multidimensionality, cross - functional organizations, and regionalization of headquarters, should be addressed (Galbraith, 2012). H owever, it remains unclear whether these organizational strategies effectively promote innovation generation and establish organizations that can survive in competitive environments. Subsidiaries foster new business opportunities in the global market and i mprove operational efficiency through competition among branches within the company (Birkinshaw & Hood, 1998). In the context of globalization theories and business development, it is necessary to rely on corporate companies’ policies as well as balance them with contributions from subsidiary R&D organizations (Asakawa, 2001). The issue of globalization, often referred to as the ‘global yo-yo effect’, is a complex and recurring topic of debate within MNCs (Ghemawat & Vatrappen, 2015). Within this context, it has been suggested to consider the differences between countries and narrow down the scope of innovation, to reduce the range of adaptation by influencing the local environment. As an example, from a functional perspective, there are challenges in determining the boundaries between the front and back ends of P&G’s marketing operations, indicating remaining iss ues in terms of innovation and growth (Ghemawat, 2018). According to a survey conducted by McKinsey, 63% of respondents felt increased pressure to demonstrate excellent short -term financial performance, whereas 86% believed that making decisions with a lon ger-term perspective would lead to improved profits and innovation. The importance of seeking long-term capital, exemplified by R&D, has also been discussed (Dobbs, 2015). Therefore, the discussion on the",dc.tohoku.ac.jp,,,46.3144754,11.0480288
21,SYSTEM OF SYSTEMS ENGINEERING: A LITERATURE REVIEW AND RESEARCH FRONTIERS,@odu.edu,"System of Systems Engineering, Literature Review, Research Frontiers","System of Systems Engineering (SoSE) has existed and been developing for well over 2 decades. The time is appropriate to take a reflective look at the past and examine the future evolution of this nascent field. To address this challenge, this paper is focused on two primary objectives. First, a literature review of the SoSE field is conducted. This literature review  (1) organizes the SoSE body of knowledge and provides a synthesis of major crosscutting themes, and (2) provides a scholarly critique and identifies  gaps in the current state of the S oSE field. The second objective is focused on providing a corresponding development framework for the field. This framework is targeted to guide the continuing evolution of the SoSE field and explore the research frontier for the field. The research frontier for SoSE is examined across the holistic and integrated spectrum of philosophical, theoretical, axiomatic, axiological, methodological, method, and application development dimensions. Challenges for the future SoSE research frontier are suggested. The paper closes with a suggestion of the importance of past SoSE field contributions and the promise of the future relevance of SoSE to support the holistic integration of multiple complex systems. Keywords System of Systems Engineering, Literature Review, Research Frontiers Introduction Since its early inception in the mid to late 1990s, System of Systems Engineering (SoSE) has evolved . The earliest instantiations of SoSE were justifiably focused on technical interoperability . Interoperability involves the integration of multiple systems, primarily from the perspective of technology. In the early stages of SoSE, technology integration was certainly a formidable task. However, although technology integration will always be a ‘concern’ (e.g. legacy system incorporation), a continuing focus on ‘technology first, technology only’ solutions is a limited view of SoSE and misses the mark with respect to the more holistic treatment of the evolving SoSE field  and problems . The introduction of advancements such as the Internet of Things, Blockchain, Industry 4.0, and accessible AI were on the distant horizon when SoSE was coming into prominence. However, they are no longer on the horizon but rather mainstays. Along with the advent of these new influences on the landscape of modern systems, SoSE must evolve to remain relevant. The characteristics of this landscape facing SoSE have been articulated elsewhere (Keating, et al. 2022). However, we reiterate their highlights below as they set an appropriate backdrop for the challenges and pressures facing the SoSE field and its evolution (Exhibit 1). • Increasing Complexity – At a most basic level, complexity entails a high number of variables/entities, rich interrelationships among entities/variables, constant dynamic shifting over time, and a high degree of emergence (structural, behavioral, and performance patterns that only come about as a system operates and cannot be known  or predicted in advance).  As complexity continues to increase, SoSE will be challenged to provide methods, tools, and processes that appreciate and effectively deal with complexity.",odu.edu,Old Dominion University,United States,36.8862699,-76.30972478839735
22,COMPLEX SYSTEM GOVERNANCE: NEXT GENERATION SYSTEM OF SYSTEMS ENGINEERING,@odu.edu,"System of Systems Engineering, Complex System Governance, Next Generation","This paper examines Complex System Governance (CSG) as a next -generation evolution of System of Systems Engineering (SoSE). SoSE was initially focused on addressing communications interoperability issues  between complex technological systems. However, while technical interoperability was highly problematic in the early stages of SoSE field development, these issues have largely subsided. However, SoSE has not sufficiently evolved to recognize and address the challenges of not only ‘hard’ systems issues (e.g. , technology, procedure, schedule, cost) but also the ‘soft’ systems issues (e.g., human, social, organizational, managerial, political, policy) that plague modern systems. In response, CSG has emerged as an evolution of SoSE, directed to the design, execution, and evolution of essential system functions to provide communications, control, integration, and coordination across nine metasystem functions and corresponding communication channels. This paper positions CSG as a next -generation theoretically grounded, methodologically driven, and model -based approach to SoSE. In this paper, three primary themes are explored. First, the SoSE shortcomings in dealing with increasing complexity, ambiguity, and uncer tainty inherent in integrating multiple complex systems are examined. The CSG response to these shortcomings is also explored. Second, an overview of CSG is provided to explore the fundamentals essential to understanding this emerging field. Third, implications of CSG as a next-generation approach to SoSE are suggested. The paper closes by suggesting the essence of CSG. Keywords System of Systems Engineering, Complex System Governance, Next Generation Introduction Our present -day systems move faster, are more interconnected, are increasingly complex, and enable possibilities beyond what could have been imagined  just a decade ago. We have the fortune, or misfortune, to be witnessing  the advent of such advances as cryptocurrency based on blockchain technology, the explosion of AI, the Internet of Things, the Internet of Bodies, and Industry 4.0 to name a few. Yet, here we are, continually frustrated with systems that inevitably fall short of our expectations and somehow seem to generate a s just as many problems as they are intended to address. It is almost cliché to suggest that we are experiencing difficulties in addressing complex systems as we seem incapable of matching the acceleration of information, interconnectedness, and technology  driving our current state of affairs. For all the ‘goodness’ that complex systems have brought, they have also left a wake of problems that appear intractable given our current paradigms and methods of attack (Rainey & Jamshidi, 2018). Everyone has suffer ed the consequences of underperforming systems, where we are disappointed in the performance that was promised but not delivered. Out of this frustration, the Complex System Governance (CSG) field was born as a next -generation System of Systems Engineering  (SoSE) approach. SoSE was ushered in, amid great fanfare, over two decades ago with the promise to permit the effective integration of multiple complex systems to provide capabilities beyond any of the constituent systems being integrated (Keating, 2003).  However, as with many ‘new and novel’ things, SoSE has not  lived up to the early promises made of the nascent  field. For all of the",odu.edu,Old Dominion University,United States,36.8862699,-76.30972478839735
23,SYSTEMS THEORY-BASED FRAMEWORK FOR DISCOVERY AND CLASSIFICATION OF METASYSTEMIC PATHOLOGIES IN ENGINEERED COMPLEX SYSTEMS,@uscupstate.edu,"Engineered systems, engineering design, system pathology, problem formulation, systems theory","Systems Theory is recognized as core to methodologies for designing, assessing, and developing engineered complex systems, yet the deepest foundations underlying Systems Theory have not been brought together into a cogent framework to better understand systemic problem formulation for engineering design. Pathologies, generally taken as variations from normal or healthy conditions, have long been a mainstay in the medical research community. However, there has been very limited investigation of the extrapola tion of the pathology -based paradigm to diagnostic engineering of design issues in complex systems. Thus, the proposed research integrates two fields that deal with systems but have not been extensively examined. The result is a systems theory -informed par adigm for the incorporation of pathologies for engineering design. Second, the exploration of different analysis models to explore the applicability of systems pathology in engineered complex systems is provided as a potential for breakthrough development to enable understanding of systemic issues. There are numerous decision -support approaches to aid in the design, execution, and development of engineered systems (e.g., fuzzy sets, soft systems methodology). However, the examination of such models against the backdrop of systems theory -based pathologies offers the potential for a breakthrough in our understanding and evolution of engineered system s. The paper closes with contributions and a suggested path forward toward pathology-informed problem-engineered complex systems. Keywords Engineered systems, engineering design, system pathology, problem formulation, systems theory Introduction The operational environment for engineered systems is experiencing dramatic shifts as we head further into the 21 st century. Engineered systems are systems designed or adapted to interact with an anticipated operational environment to achieve one or more intended purposes while complying with applicable constraints. In this case, engineered systems have to contend with elem ents of uncertainty, complexity, information, vulnerability, contextual influences, holism, and grounding. Exhibit 1 provides a further elaboration on factors forming the operational landscape. Exhibit 1. Operational Landscape for Engineered Systems. Characteristic A Brief Description Uncertainty Limited confidence in understanding cause-effect relationship in complex interactions, limiting the value of traditional analysis methods Complexity Systems do not operate in isolation. They tend to have many variables and elements that are richly interconnected exhibiting dynamic behavior that can not be predicted from individual elements making it a challenge to mount effective responses Information Increased volume of information, including aspects of disinformation and misinformation, veracity, trustworthiness, accessibility, and adequacy",uscupstate.edu,,,46.3144754,11.0480288
24,THE ROLE OF MERGERS AND ACQUISITIONS AS AN APPLICATION OF BENCHMARKING,@cranfield.ac.uk,"Benchmarking, mergers and acquisitions, market structures, market complexity, lifecycle, firm alliance formation,","The market can be a highly competitive environment for firms where the utilization of various strategies and methods can determine their long-term market viability. Benchmarking is one such method that firms utilize to enhance their market position, which occurs within market maturi ty. Benchmarking refers to a process firms use to comparatively analyze their performance against relevant competitors. Firms will also implement mergers and acquisitions as these activities reinforce the benchmarking process, which can assist with a wide range of market obstacles that emerge with market maturity. Given how frequently firms utilize mergers and acquisitions within mature market phases, it is vital to enhance the current understanding about the potential influence they have upon a fir m’s strategic motivations and functional contributions to their competitive strategies, which can have far-reaching ramifications. In essence, firms may be unknowingly undermining their market position by inefficiently using the resources at their disposal. With enhanced understanding firms can most effectively utilize the strategies, methods, and tools at their disposal to identify current best-practices, which should support their progression within the market. This paper will aim to enhance this unders tanding about the role mergers and acquisitions play in developing a firm’s strategic market dominance by examining the techniques involved with evaluating their contributions within market maturity. This paper will also use the Lifecycle Theory to interpr et relevant market -based activities as this theory generally models a firm’s market progression, from entry to eventual decline. Keywords Benchmarking, mergers and acquisitions, market structures, market complexity, lifecycle, firm alliance formation, market share, strategic management, effectiveness and efficiency zones, ecosystems, channels, comparative analysis. Introduction Our approach is built on lifecycle model to explain the evolution of firm conditions and novel technique to intro duce M&A as a  subset of benchmarking and ju dge M&A activi ties within this context using the fundamental metrics of SPACE, a strategic analysis method, to  come to grips with the host of M&A targets that exist in markets . Both lifecycles comprehend the overall scenario and the detailed analysis through SPACE technique serves as starting point to estimate total contribution to effectiveness and efficiency. We can, using AI, reduce the number of targets from hundreds to an essential few and evaluate the pas impacts of closing M&A deals on the firm’s performance. The market functions at two distinct levels, which are known as the surface and the deep structures ((exhibit 2, Koplyay & Goldsmith 2023 update ) The surface structure  within early market phases is largely defined by a firm’s efforts to maximize their market effectiveness via customer base expansion strategies.  Efficiency within late market phases, emphasizes the maximization of productivity and is defined by the market dynamics involved with a firm’s customer profiling activities and their efforts to reinforce pre -existing customer relations (Dobni & Luffman, 2003). This shifting focus between structures occurs as each will exert differing market -based pressures and circumstances upon firms, which will compel them to react distinctively within each market phase and accompanying structures. The Lifecycle Theory will influence how firms progress along various market phases.  Firms will begin their lifecycle with market entry and continuous ly progress to the consecutive market phase thereafter. If firms are unable",cranfield.ac.uk,Cranfield University,United Kingdom,52.070132900000004,-0.6287023427161589
25,THE FUTURE OF MEGAPROJECT MANAGEMENT,@stevens.edu,"Megaproject, complexity, uncertainty, data analytics, artificial intelligence, leadership .","The integration of data visualization, artificial intelligence (AI), and machine learning (ML) with human knowledge transfer across teams presents signi ficant opportunities for managing the world's largest programs, commonly referred to as megaprojects. According to the Oxford Handbook of Megaproject Management, megaprojects are characterized as “large -scale, complex ventures that typically cost $1 billio n or more, take many years to develop and build, involve multiple public and private stakeholders, are transformational, and impact millions of people.” These projects often function as mega-systems marked by operational uncertainty, behavioral complexity, pluralistic decision-making, and external environmental volatility. Despite the fundamental role of uncertainty management in megaproject leadership, the project management literature offers limited coverage on this topic. Similarly, the visualization of uncertainties has not been extensively analyzed. In response to these gaps, this study introduces a new assessment framework designed to categorize and describe the dimensions of uncertainty in megaprojects. We developed an innovative megaproject uncertain ty framework to use as a project assessment and management playbook for megaproject uncertainties. The framework was tested on historical case studies and ongoing megaprojects. This paper will discuss the development, application, and evaluation of the Megaproject Uncertainty Framework.. Keywords Megaproject, complexity, uncertainty, data analytics, artificial intelligence, leadership . Introduction Megaprojects, according to the Oxford Handbook of Megaproject Management, are “large -scale, complex ventures that typically cost $1 billion or more, take many years to develop and build, involve multiple public and private stakeholders, are transformational, and impact m illions of people” (Flyvbjerg, 2017). Megaprojects are often also often mega -systems that operate with dimensions of operational uncertainty, behavioral complexity, pluralistic decision-making, and volatility of the external environment (Stevens, 2010). While project management encourages careful up-front planning of known-knowns and known-unknowns (risks), megaproject success is strongly linked to successful management of project unknown-unknowns or uncertainties. Management of project uncertainties funda mentally differs from the management of project risk. Often, projects are based on assumptions that have uncertainty, leading them to overly optimistic planning (Flyvbjerg & Gardner, 2023). While classical project management has a well -established tradition of risk management, the concept of uncertainty, particularly in large, complex projects, has not been adequately addressed in the literature or in practice. Frequently, project uncertainties and their underlying assumptions are not distinguished from pro ject risks, despite the need for inherently different leadership and management approaches. In this work we introduce the concept of a “Project Uncertainty Framework,” developed from extensive literature review on both successful and non -successful megapro jects. This framework is evaluated based on historical case studies and an existing megaproject that is entering a phase of significant investment ramp -up. The outcome is a set of best practices for management of uncertainty in megaprojects. This paper is structured as follows: it begins with a review of the relevant literature, followed by a presentation of the project uncertainty Framework, and concludes with the best practices organized within that framework. Examples of best practices derived from the case studies are provided to illustrate the application of the framework.",stevens.edu,Stevens Institute of Technology,United States,40.744809599999996,-74.0252392276461
26,CAPTURING & CULTIVATING THE ENTREPRENEURIAL MINDSET: A RAPID SURVEY APPROACH IN ENGINEERING EDUCATION,@student.montana.edu,"Entrepreneurial mindset, rapid survey, curiosity, connections, creating value, confidence .","Engineering students are taught to think creatively, solve complex problems, and engage with stakeholders. These competencies form the foundation of the entrepreneurial mindset (EM): defined by Kern Entrepreneurial Engineering Network (KEEN) as the set of attitudes, dispositions, and behaviors that shape a unique approach to problem-solving, innovation, and value creati on. This research focuses on creating and validating the Entrepreneurial Mindset Assessment Survey (EMAS) to capture the cognitive, behavioral, and emotional aspects of EM. The survey evaluates key constructs, including curiosity, connections, creating value, from KEEN, and introduces confidence (4Cs). EMAS aims to serve as a near real-time tool for data collection on student EM, offering insights for instructors to help cultivate the 4Cs in the classroom. During the Spring 2024 semester, EMAS was distri buted to two MSU Industrial and Management Systems Engineering courses, Intro to Systems Thinking  and Capstone, with two other validated instruments to support its fidelity. Out of the 51 students, 38 responded to the survey and analyses were conducted to assess EMAS as a reliable and valid measure of the 4Cs. Statistical analysis proved that EMAS is highly reliable and demonstrated convergent, discriminant, and concurrent validity. Additionally, confidence significantly mediated the relationship between connections and EM. The tool reinforces personal and professional development, cultivating strong leadership and equipping future engineers with strategic decision-making and innovative problem-solving skills crucial for effective engineering management . EMAS not only aids in assessing students' progress but also serves as a catalyst for cultivating an EM indispensable for success in today's dynamic landscape. Keywords Entrepreneurial mindset, rapid survey, curiosity, connections, creating value, confidence . Introduction Throughout their education, engineering undergraduate students are taught how to think creatively, solve complicated problems, and interact with stakeholders and teammates. These students are exposed to academic resources that are integral to creating stakeholder -focused solutions which parallel the thinking processes of entrepreneurship. The entrepreneurial mindset (EM) can have a positive effect on decision making, strategy development, resource management, and leadership growth which are invaluable traits not only for a college student, but also one in their chosen profession (Daspit et al., 2021). Therefore, the characteristics of EM are beneficial to students’ success in the program and post-graduation, whether it is in higher education or industry fields. EM is an increasingly popular approach for measuring the mental attitude, resiliency, and resourcefulness of students in the classroom and their potential beyond it. EM refers to the state of mind which allows people to identify and act on opportunities in the world to create something of value. One study concluded that EM can be broken down into cognitive, behavioral, and emotional aspects that explain the way of thinking, problem-solving, and living (Daspit et al., 2021). Even more recently, the Kern Entrepreneurial Engineering Network (KEEN), an organization dedicated to supporting EM in engineering students and faculty, described EM as a  combination of the 3C’s: curiosity, connections, and creating value (“Entrepreneurial Mindset,” 2 024). Although these three constructs can address the cognitive and behavioral aspects of EM, other research suggests that they fail to completely capture the emotional aspect. Confidence has been proven to be an effective predictor of entrepreneurs and se lf-efficacy, capturing the individual’s belief that their ideas and actions will be successful (Maczulskij & Viinikainen, 2023; Seppänen et al., 2021). As such, there is a need to introduce a fourth C, confidence, to measure the personal power to handle ri sks, challenges, and relationships.",student.montana.edu,,,46.3144754,11.0480288
27,SYSTEMS APPROACHES TO IDENTIFY BARRIERS AND ENABLERS TO HEALTHCARE DELIVERY,@oregonstate.edu,"Healthcare system management, managing complexity, systems approach, healthcare delivery","Improving access to healthcare services involves intervening in complex, multi -stakeholder organizations, often requiring multidisciplinary approaches to study its barriers and enablers. This paper discusses findings about barriers and enablers to healthcare delivery found using systems methods. To address the issue of underwhelming healthcare access globally, this study was designed to gain insights into the primary barriers and enablers to healthcare access, using the Province of Buenos Aires, Argentina, as a case study. Multi-sited, ethnographic, health narrative interviews with patients and providers from July to September 2022 were analyzed for barriers and enablers to healthcare delivery in the province. The barriers and enablers identified were evaluated for their prevalence and relationships. The results of this study demonstrated the prevalence and connections of barriers driving the overburdening system, which drives months-long wait times and an increased financial burden on patients. The findings of these barriers and enablers point to the benefit of utilizing a systems perspective to evaluate the healthcare system, as insights not discussed in literature were discovered, such as the influence of trust on healthcare system navigation.  The model discussed is relevant for engineering managers, as anthropological methods and a systems approach can provide insights about complex relationships driving current performance and existing areas to capitalize on for systems improvement. Keywords Healthcare system management, managing complexity, systems approach, healthcare delivery Introduction Organizations increasingly face wicked problems that exhibit complexity at multiple levels, reducing engineering managers’ abilities to properly identify underlying issues, understand the interaction of complexities, and efficiently determine problem-resolution approaches. Healthcare delivery is a wicked problem for engineering managers in healthcare administration due to its implications for guiding capital and staffing investments, providing quality care, and guiding best approaches for primary and second ary levels of care . The difficulty in managing a system and adapting a general method for delivery of healthcare services due to the complex web of stakeholders, users, workers, supplies, resource limitations, and other inputs within distinct environmental, geographic, and contextual settings has led to underwhelming performance of healthcare systems globally   (Closser et al., 2022; World Health Organization & World Bank, 2017) . This underperformance occurs even with substantial global healthcare expenditu res (OECD Health Expenditure and Financing Database , 2023). Thus, the World Bank a nd World Health Organization (WHO) (2017, p. v) estimate that “at least half of the world’s population still lacks access to essential health services” and “ almost 100 million people are pushed into extreme poverty each year because of out-of-pocket health expenses.” More broadly, identifying systemic barriers and enablers is a beneficial methodology for problem identification and diagnostics in order to provide efficient guidance for investments, quality care, and direct approaches for levels of care. As a wicked problem, h ealthcare delivery exhibits differing levels of complexity , where a single disciplinary approach will yield incomplete results. Thus, it is beneficial to study the barriers and enablers of healthcare delivery, which can emerge from a systems approach (Sillitto et al., 2019). A case study was devised to develop an initial model of resolving wicked problems through a systems approach for the Province of Buenos Aires, Argentina. It was selected due to the researchers’ access and the prevalence of mixed public -private healthcare systems globally, increasing the range of healthcare systems to which the study could apply. Though Argentina achieved nominal universal healthcare",oregonstate.edu,Oregon State University,United States,44.56305595,-123.28392337694638
28,APPLICATIONS OF ENGINEERING STATISTICS FOR ANALYSIS OF AEROSPACE MATERIALS TESTING,@astate.edu,"Engineering Statistics, Statistical Equivalency, Carbon-Epoxy Composite Materials, t-Test","Many engineering statistical theories are commonly applied for the analysis of te st data collected in the aerospace industry. Materials engineers are responsible for completing mechanical and physical testing of a specific material to better understand the material properties. In many cases, they are also responsible for assessing how a new variable might impact the material properties by completing testing and evaluating for statistical equivalency  to the baseline. Carbon-fiber epoxy composite materials are a more popular choice for the construction of aerospace applications due to the ir stiffness to weight ratio , and corrosion resistance. The objective of this paper is to review the specific engineering statistical t ools used to evaluate equivalency of the composite material properties when adjusting a variable. In this instance, an an alysis will be performed to evaluate if there is a change  of the composite material properties due to revising the cure  cycle to improve production schedule and costs. For evaluating equivalency of strength properties, a Test for Decrease in Mean or Minimu m Individual Value will be explained and used. Fo r, modulus or physical properties, a Test for Change in Mean by means of a t-test will be explained and used. The results of the statistical analysis will determine if the change in cure resulted in equivalent material properties to the baseline. Keywords Engineering Statistics, Statistical Equivalency, Carbon-Epoxy Composite Materials, t-Test Introduction A wide variety of engineering statistical tools are utilized in the aerospace industry for analyzing data. In many instances there is an interest to evaluate the statistical equivalency of a new data set to an existing data set. For this paper, a statistical analysis will be performed on a new set of data for a carbon-epoxy material system to evaluate the effects of an alternate cure cycle. The specific statistical tests used will include a Test for Decrease in Mean or Minimum Individual Value and a Test for Change in Mean using a t-test. Composite materials are simply the combination of a reinforcing fiber with a matrix material to make one cohesive structure. A carbon-fiber epoxy composite consists of carbon fibers as the reinforcing fiber material and ep oxy resin as the matrix material. Due to their physical and mechanical properties, thermosetting polymers cured with epoxy resins have found a broad range of applications, mainly as matrices in advanced composites for aircraft and automotive applications (Ramírez-Herrera et al., 2021). To optimize the mechanical performance and temperature stability, it is critical to understand the reaction chemistry of the specific carbon epoxy system being used. Changes in the cure profile can dramatically impact the curing kinetics and furthermore change the mechanical and physical properties of the system. One common method used to evaluate the strength of the chemical bond after curing is called the degree of cure. The classic methods of resin characterization are diff erential scanning calorimetry (DSC) and dynamic mechanical analysis (DMA); these methods provide excellent information on the degree of cure ( García-Manrique et al., 2019). For this study, a pathfinder was completed to evaluate reducing the overall cure cycle without signficiantly impacting the degree of cure for the final product. The goal of reducing the cure cycle is to save time and money for large scale production activities. The next step was to build panels with this alternate cure cycle, test the mechanical stregth, and evaluate for statistical equivalency when compared to the baseline cure data. Many test methods are used to evaluate the mechanical properties of a composite material depending on your property of interest. For example, different techniques can test for overall strength in tension and compression or",astate.edu,Arkansas State University,United States,35.8447472,-90.67262556246513
29,LEVERAGING DIGITAL TWIN TECHNOLOGY FOR EVALUATING POTENTIAL FIRE RISKS IN NUCLEAR POWER PLANTS,@smail.astate.edu,"Digital Twin, Fire Protection, Simulations, Monitoring, Core Damage Frequency, Computational Fluid Dynamics .","Digital twin technology has proven to be extremely valuable in enhancing safety and efficiency across a range of industries, including the application within the nuclear power sector. This paper focuses on the use of digital twins for evaluating fire risks in nuclear power plants. By simulating the systems and processes of a facility digital twins could allow for precise simulations and predictive analyses of fire scenarios. The paper provides an overview of fire incidents at nuclear power facilities along with the regulatory responses and limitations of current fire models in use today. It explores the role of technology in  nuclear safety practices and examines how it can potentially mitigate fire risks. Additionally, an analysis is conducted to evaluate the effectiveness of using digital twins for assessing fire risks in nuclear power plants and fostering a safety culture. The simulations carried out by digital twins demonstrate their value as tools for risk assessment, prevention strategies, real time monitoring alerts, emergency preparedness training and predictive maintenance strategies. Furthermore, this paper addresses the challenges and regulatory obstacles associated with implementing solutions into nuclear power operations. By capitalizing on their potential, nuclear organizations can proactively mitigate fire risks while improving overall operational efficiency, with in the industry. Keywords Digital Twin, Fire Protection, Simulations, Monitoring, Core Damage Frequency, Computational Fluid Dynamics . Introduction Nuclear power plant fires have a longstanding history that stretches over decades. Each fire event has led to new safety practices, regulatory responses, and technological innovations designed to prevent or mitigate fire -related incidents. Since commercial nuclear generation first began decades ago, fires have presented serious threats to facility safety and integrity; understanding their historical context provides insight into lessons learned as well as potential adoption of Digital Twin (DT) techniques to increase safety. At the time of their design in the US, many nuclear plants did not place much importanc e on fire safety as an aspect of design. Plants were constructed without due regard for prevention or mitigation measures against fires; however, incidents and near misses highlighted their risks; one early incident occurring at Browns Ferry Nuclear Plant saw fire break out involving electrical cables which caused catastrophic system failure (U.S. Nuclear Regulatory Commission [NRC] 1975) prompting reevaluation of fire protection practices and requirements worldwide. After the Browns Ferry event, regulatory  bodies recognized the significance of creating comprehensive fire protection programs and installing additional safety measures within the nuclear industry. As a result, guidelines issued to licensees by the U.S. Nuclear Regulatory Commission (NRC) starte d outlining specific perceptive requirements for Fire Protection Program mandatory elements including fire prevention, detection, and response measures (NRC, 2009). These changes in focus led to improvements in fire protection including installing fire - resistant materials, fire barriers, improved detection systems and pre-fire response plans (NRC, 2009). The Chernobyl disaster occurred in 1986 and demonstrated the devastating repercussions that fire can have in nuclear facilities. An explosion and subsequen t fire at this plant resulted in radioactive releases and widespread contamination, further emphasizing the importance of effective fire prevention and control measures for nuclear facilities. Lessons learned from these incidents led to steady advancements in fire safety practices for nuclear power plants, including fire modeling, fire -resistant materials, compartmentalization, and fire detection technology innovations.",smail.astate.edu,,,46.3144754,11.0480288
30,CLOSING THE REFERRAL LOOP TO IMPROVE THE PATIENT EXPERIENCE VIA APPOINTMENT ACCURACY,@tamu.edu,"Scheduling, process improvement, automation, healthcare.","ABC Health is a leading provider of specialized rehabilitative services across 33 hospitals in the Unite d States. One of its flagship facilities, New Branch  Regional Rehabilitation Hospital (NBRRH), ranks among the top 10% of hospitals nationally and serves the growing New Braunfels, Texas community  (Ernest Health, 2023) . The area has seen a significant rise in its 60-and-above population, driven by healthcare costs below the national average, resulting in a booming demand for outpatient rehabilitation services valued at $64 million in 2021, with a projected annual growth rate of over 7.5% from 2022 -2028. ABC Healthcare opened an Outpatient Physical Center under NBRRH in March 2023, recognizing an opportunity to expand its market share. However, the center has faced challenges maintaining consistent patient numbers due to scheduling and referral tracking issue s, impacting productivity and profitability. Despite efforts to build relationships with local primary care providers and insurance networks, the problem persists. To address this, a six -month, three-phase initiative is proposed to assess and enhance the r eferral management process at NBRRH's Outpatient Physical Center. This project aims to identify existing process issues, analyze data to uncover bottlenecks and develop an Outpatient Referral Management Tool (RMT) and process flow map for implementation. Leveraging existing resources, this project represents a relatively low investment to improve efficiency and patient satisfaction, ensuring NBRRH's continued success in meeting the healthcare needs of the growing New Braunfels community. Keywords Scheduling, process improvement, automation, healthcare. Introduction ABC Health is a post -acute healthcare company that provides rehabilitation and Long -Term Acute Care (LTAC) services. It was founded in 2003 and is headquartered in Albuquerque, New Mexico. ABC Health operates a network of thirty-three world -class rehabilitation hosp itals and LTAC facilities across the continental United States. These facilities offer specialized care for patients recovering from severe medical conditions, surgeries, injuries, or illnesses that require intensive rehabilitation or extended acute care b eyond what a traditional hospital offers. The company’s LTAC facilities provide an elevated level of healthcare compared to conventional acute hospitals. These facilities are purpose-built to cater to patients with intricate medical conditions requiring extended hospitalization. They frequently serve individuals who are critically ill, demanding continuous monitoring and specialized treatment.  Its patient - centered philosophy, practical and efficient processes, and timely services are best realized in one of  its flagship hospitals—New Branch Regional Rehabilitation Hospital (NBRRH), ranked in the top 10% of hospitals nationwide. The NBRRH is a 40-bed inpatient and outpatient facility focused on personalized attention and treatment of College Station and the surrounding community. This facility achieved a year -to-date revenue of $29.34 Million. In the past year, it served 777 discharges, accumulating an impressive 11,810 patient days (NBRRH, 2023). ABC Healthcare sought to expand its market by opening a satellite Outpatient Physical Center to capture this demand. ABC Healthcare proposed that the new clinic be under the operational control of NBRRH. The clinic has been in operation since March 2023. Within the past few months, the Outpatient Physical Center has no t been able to maintain a continual patient census because of scheduling and lack of referral tracking. This could have resulted from deficiencies in the technology used due to a lack of improvements, training, or the absence of a referral management playb ook.",tamu.edu,Texas A&M University - College Station,United States,30.6108618,
31,AN EXAMINATION OF STAMPING EFFICIENCIES TO ESTABLISH MANUFACTURING CAPABILITY IN A LEAN MANUFACTURING ENVIRONMENT,@csn.edu,"Start-up, Automotive stamping, GSPH, KPI, DMAIC, Problem solving, Histogram, SIPOC","Y-Tec Keylex Toyotetsu Alabama (YKTA) which is a Tier 1 suppl ier for the joint Mazda -Toyota Manufacturing (MTM) facility needed to conduct a study. This examination would be to improve the stamping efficiency while maintaining the lean manufacturing environment. Amidst  the forecasted rise of  production numbers this study will justify whether stamping production  (ST) can maintain amongst an aggressive ramp up, if so then how will this be accomplished.  This study will exemplify DMAIC problem solving by identifying the Key Performance Indicators (KPI)that directly correlate to stamping efficiency and capacity. This study will Define the issue and important factors, Measure the important factors found, Analyze the root causes and most influential aspects, Improve low hanging fruit and more critical issues, and Control and standardize the new methods of recovery. Keywords Start-up, Automotive stamping, GSPH, KPI, DMAIC, Problem solving, Histogram, SIPOC Introduction YKTA Stamping Engineering (ST ENG) wanted to study closing the gap and  adding lean practices to the  stamping department. Stamping which is a sheet metal forming technology is comprised of stamping and deep drawing, has been widely used in automotive manufacturing, aerospace, and rail industries to manufacture metal components (Liu, S. et al., 2022) Press machines are used to create these parts, as for YKTA five Komatsu brand presses have been specifically made to accomplish the needs of Mazda and Toyota. The maintenance department being studied is so unique due to the projected repair time calculated based on the lead time of materials to the MTM facility. YKTA is the sole proprietor of the components it makes for the Corolla Cross and Mazda CX -50 therefore when machine downtime occurs there in not another option.  YKTA stamps weld, and paints approximately 80% of the sub assembly parts for these vehicles.  With only 2 days of inventory inside the YKTA facility, stamping has the smallest cut at 8 hours due to the entire manufacturing process starting with stamping. A bare bones method of seeing this breakdown is a SIPOC diagram illustrating what happens along the way. Exhibit 1.  YKTA SIPOC Diagram Suppliers Inputs Process Outputs Customer Steel-Processing Raw material steel Stamping Vehicle Components MTM Steel Mill Raw resin plastic Welding Customer Service Consumer Injection Assembly",csn.edu,College of Southern Nevada,United States,36.00650975,-114.96580474912994
32,IMPROVING SALES FORCE EFFECTIVENESS THROUGH THE DEVELOPMENT AND STANDARDIZATION OF A DATA-DRIVEN VALUE PROPOSITION,@tamu.edu,"Sales effectiveness, value proposition, sales management.","Well-designed growth efforts that leverage organizational capabilities are important for th e sustainability of distribution businesses in today’s competitive environment. Growth efforts into new geographies, market segments or verticals comprise many of the strategies employed by distributors to grow their businesses. Much of the responsibility to execute company growth strategies resides with the sales force. Without a clear value proposition to present to customers, sales efforts can be slowed, product and service offerings can become commoditized, and growth efforts can be stifled. Left to rel y on tribal knowledge and individual experience or to react to each unique customer whims can also create inconsistent and frustrating experiences for the customer and limit sales force effectiveness. This paper explores the role of a customer -focused valu e proposition in sales force performance and the importance of the value co-creation process in the development and deployment of said proposition. A framework for gathering VOC data is demonstrated whereby a sampling of customers, salespeople, and vendor partners from a distributor in the Pacific Northwest are interviewed using a seven -point Likert scale and qualitative responses to evaluate perceptions of the impact of specific value drivers on the customer’s decision to purchase. Opinions from each channel participant are compared to identify alignment between opinions and gaps where potential opportunities for improvement may exist. Resulting examples of a value proposition and tools designed to aid in value proposition deployment and measurement of impact on sales force effectiveness are also presented. Keywords Sales effectiveness, value proposition, sales management. Introduction Aggie Distribution Co.(ADC)  is a family -owned wholesale distributor of Heating, Ventilation, Air Conditioning (HVAC) and Pumps (PU) located in the Pacific Northwest region of the United States. The company operates 25 locations across five states with service to Hawaii and Alaska, and employs over 600 employees. The company is divided into regions by grouping several locatio ns together by geography. Markets are served by each division’s representation in most branches. The 25 branches are currently divided in to five regions – the Columbia region (eastern WA, northern ID, and western MT), Great Sale Lake region (UT) Puget reg ion (western WA), Snake region (southern ID), and the Willamette region (western OR). Sales efforts are directed by a team of divisionally focused outside salespeople that report to Regional Sales Directors and inside salespeople that report to local Branch Managers. There are currently 86 outside salespeople and 150 inside salespeople. There are various competitors within Aggie Distribution Co. ’s footprint represented by local and national distributors alike. ADC is unique in the number of markets served relative to most competitors. Many are more specialized and focus on one market alone. Those that are less specialized may only compete in one or two markets. Because of ADC’s diversity in markets served the company is exposed to wide variation in selling strategies and value propositions (VP) from competing distributors. Furthermore, share held by ADC in any market varies depending on geography and competitors present. ADC believes that its lack of a value proposition that is based on meeting specific customer needs in these markets is causing slower growth than desired  by company management. ADC’s salesforce",tamu.edu,Texas A&M University - College Station,United States,30.6108618,-96.35206061388457
33,FORECASTING TECHNIQUES FOR ARMY SUPPLY SUPPORT ACTIVITIES,@westpoint.edu,"Supply Support Activities, Weighted Moving Average, Forecasting Techniques","The United States Army Sustainment Command is a subordinate command in the U.S. Army responsible for logistical capability and materiel readiness.  Its purpose is to enable a full -scale of military op erations. Army Sustainment Command constantly seeks new ways to support Supply Support Activities (SSA) despite challenging operational environments. This includes the garrison environment as well as during combat training exercises and wartime.  Due to this wide variety of tempos  and workplace environments, finding methods to support SSAs and understand their complexities still is a priority of the Army Sustainment Command in which orders are critical for supporting units to properly function. The high volatility and fluctuations of deployment make finding a method to efficiently manage this process important. Inaccurate workload predictions lead to inefficiencies at all levels of the process, resulting in potential delays and wasting time and resources. This paper aims to address these challenges by evaluating different forecasting techniques and apply mean absolute deviation and mean squared error evaluation to recommend which model best meets the commander’s needs. The approach presents a novel approach to informing leadership on how to plan future training and operations based on predicted workload distributions of the SSA. The outcomes  of the study include a prioritized selection of forecasting methodologies and a decision support framework considering SSA leadership. Keywords Supply Support Activities, Weighted Moving Average, Forecasting Techniques Introduction The United States Army Sustainment Command provides logistical support to Army forces across all areas of operations, in garrison training and deployed operations. Being properly equipped is a  critical aspect of meeting operational requirements (“Army Techniques Publication 4-42”, 2019). Whether it be equipment, supplies, maintenance, transportation, and more, the Army Sustainment Command oversees the Army’s supply chain; a critical role to enable further operations. (Army Sustainment Command, 2023) Support of this scale takes a large amount of labor to run effectively. Army Sustainment Command would like to decide if historical data sources in Army Vantage, the Army data analytics platform, can be used to predict Supply Support Activities (SSA) workload. (“Army Techniques Publication 4-42”, 2019) From the prediction of this workload, leadership could figure out ideal times to conduct other readiness-building activities from qualifying on the range to dental appointments. (Army Sustainment Command, 2023) SSA workload is an issue that can vary drastically ranging from almost no work to exceeding workforce capacity. Due to this unpredictability, finding time for soldiers working at the SSA to complete normal soldier duties like a hearing or dental exam, qualify with their M4, etc. may be quite difficult. As such, the use of a model that can better predict the upcoming workload  of an SSA based on historical data and most recent data patterns would help with planning training like this whether it be at the platoon, company, or even battalion level. (Saldana, 2024)  Exhibit 1 displays the overlapping deployment/redeployment cycles in conjunction with the number of materials one singular SSA was backlogged with at a time.  This culminates in inventory losses which come at a hefty sum highlighted in bright red in the figure.",westpoint.edu,,,46.3144754,11.0480288
34,"INTEGRATING GENERATIVE ARTIFICIAL INTELLIGENCE WITH SYSTEMS ARCHITECTING DIAGRAM CREATION: ADVANCEMENT, CHALLENGES, OPPORTUNITIES AND FUTURE PERSPECTIVES",@odu.edu,"Artificial Intelli gence, Machine Learning, Deep Learning, Natural Language Processing, Generative AI,","Generative AI (GenAI) serves as a powerful tool that can create a wide range of content, including but not limited to text, speech, images, code, videos, and 3D models. ChatGPT stands out as a particularly appealing Generative Pre - trained Transformer (GPT) model that offers supplementary capabilities through GPTs and plugins. These extensions enable users to engage with the chatbot and improve its functionality, surpassing mere content generation. Our study delves into the potential of ChatGPT, specifically  GPT-4, to expedite the creation of diagrams to support the system architecting process. To this end, we explored the use of ChatGPT's Diagrams Show Me plugin, which leverages Mermaid syntax, to generate the sequence, activity, state, UML activity, IDEF0, and DoDAF OV-5b diagrams. The same case study was used to render each diagram form during this investigation, allowing for a comparison of different types. The implication of paraphrasing the case description on the plugin's functionality was also investig ated in our research, specifically focusing on text comprehension and entity identification. Our qualitative results contend that visualization performed competently with straightforward diagram forms such as sequence, activity, and state diagrams. Moreover, the diagram layouts changed visibly after paraphrasing the case study into an input and output format. The alteration resulted in more linear diagram formats that generally showed less suitable results for systems architecting. While human involvement continues to be essential in system architecture, utilizing GenAI holds a noteworthy potential to accelerate the diagram generation process, even for individuals lacking prior programming experience. Keywords Artificial Intelli gence, Machine Learning, Deep Learning, Natural Language Processing, Generative AI, Conversational AI, Content Generation, ChatGPT, Chatbot, Diagram Generation, System Architecture. Introduction Systems architecting is an engineering progression through the conception of the system's elements, interconnections, and behaviors while designing and developing the composite structures (Handley, 2016; Maier, 2009) . Effective communication of the resulting architectural renderings is the primary result of this stage (Handley, 2019). Therefore, visual representations (Yalim & Handley, 2023) , such as diagrams, are critical in conveying the sometimes complicated system designs to stakeholders (Cloutier et al., 2010; Handley, 2012, 2022) . However, the manual generation of diagrams can be a n onerous, time-consuming, and error-prone task, especially for large-scale systems with numerous interrelated components. This manual effort can lead to inconsistencies, miscommunications  among engineers, managers, clients, and delays in the process. Of interest is whether GenAI can be devoted to speeding up the systems architecting by automating the diagram creation process with its human-like content generation capability. Relevance of Topic to the Engineering Management While systems architecting may not be a primary responsibility for most engineering managers, understanding and leveraging this approach is important for effective leadership in modern engineering environments. As engineering projects grow increasingly complex and  interdisciplinary, engineering managers need to be capable of leading their teams through the complex designs and implementations of systems. The use of an AI-driven tool is being introduced in this article, which can give engineering managers the ability to transform their roles. Managers can drastically reduce time spent on manual tasks  and focus more on strategy by leveraging automated diagram creation . AI tools",odu.edu,Old Dominion University,United States,36.8862699,-76.30972478839735
35,"IMPLEMENTATION OF GENERATIVE AI (GEN AI) INTO THE GRADUATE ENGINEERING MANAGEMENT PROGRAM AT CALIFORNIA STATE UNIVERSITY, NORTHRIDGE",@csun.edu,"Artificial intelligence, Gen AI in Engineering Management & higher education, AI pedagogy, disruptive change, AI","Since December 2022, Generative AI (Gen AI) has grown tremendously and is being increasingly incorporated into various engineering domains. This is because the incorporation of Gen AI can help increase efficiencies in engineering processes and functions; thereby leading to significant cost savings. This time and cost savings value creates a business case for businesses to increasingly start incorporating Gen AI into their day-to-day functions – thus making it a highly sought after skill for when engineering management students go into the job market. In order to  provide the M aster of Science in  Engineering Management students with an exposure and basic understanding of what Generative AI is and how it can be used in various engineering management functions, program administration and the faculty at California State University, Northridge initiated a pilot program to explore ways of embedding it into the curriculum. In this paper, the authors discuss the integration of Generative AI into graduate Engineering Management education. The focus is on our  methodology  for the pilot implementation , which includes  the selection process for the programs as well as courses  and initial outcomes from the first courses of the pilot. Lessons learned and best practices fo r embedding effective, ethical use of Generative AI into the curriculum are highlighted in this paper, and initial findings of this study showed the importance of domain knowledge as well as the fact that the Gen AI tool is effectively used in a supporting  role and does not replace the domain knowledge that the student needs. Keywords Artificial intelligence, Gen AI in Engineering Management & higher education, AI pedagogy, disruptive change, AI curriculum integration, Educational Innovation. Introduction Since December 2022, Generative AI (Gen AI), has experienced unprecedented growth and adoption in a number of different industries, including engineering and various technical sectors. We have seen the introduction of more sophisticated AI models that are capable of generating increasingly complicated outputs for various areas of knowledge, particularly for content creation, automation of repetitive tasks, researching new areas and also for doing complex data analysis (Chakraborty et al., 20 23). Because Gen AI prompts can be written in a conversational tone, making it relatively easy for people to experiment with, use of this technology has increased rapidly . According to a report published by the MIT Technology Review Insights (2023), the i mpact of Gen AI on economies and enterprise will be revolutionary with Gen AI adding between $2.6 and $4.4 trillion in annual value to the global economy. According to the McKinsey Quantum Black AI report ( Singla et al., 2024, p. 1 ), “if 2023 was the year the world discovered Gen AI, 2024 is the year organizations truly begin using it --and deriving business value from this new technology.” Additionally, according to an article published by Deloitte in the 2nd quarter of 2024, 65% of 2000 leaders",csun.edu,"California State University, Northridge",United States,34.2455346,
36,,,,,,,,46.3144754,11.0480288
37,ENHANCING OCCUPATIONAL HEALTH AND SAFETY IN INDUSTRIAL WORKPLACES THROUGH SYSTEM DYNAMICS MODELING,@mtsu.edu,"occupational health and safety (OHS), industrial workplaces, system dynamics modeling, organizational policies,","Occupational health and safety (OHS) in industrial workplaces  is paramount due to the inherent risks associated with hazardous materials, heavy machinery, and physically demanding tasks. Despite implementing existing safety measures, the prevalence of occupational accidents and diseases remains a significant challenge, necessitating a comprehensive understanding of the complex dynamics influencing OHS outcomes. This study employs a quantitative systems thinking approach utilizing system dynamics (SD) modeling methodology to develop an exploratory conceptual model based on an extensive literature review. The model cap tures critical variables, causal relationships, feedback loops, and delays within the OHS system. A causal loop diagram visualizes the interconnected nature of hazardous material concentrations, safety measures, workforce health status, organizational poli cies, and regulatory frameworks. Subsequently, a comprehensive stock-and-flow model facilitates quantitative simulation and analysis of intervention scenarios, including increasing personal protective equipment (PPE) usage from 70% to 95% and enhancing the effectiveness of company health policies from 60% to 125%. The results demonstrate the significance of coordinated and sustained interventions. Increasing PPE usage reduces the peak number of exposed workers from approximately 1,500 to 1,100 and lowers th e maximum number of workers with occupational diseases from 280 to 220. Similarly, enhancing policy effectiveness decreases peak exposed workers from 1,500 to 1,200 and workers with occupational diseases from 280 to 220. The SD model provides a robust deci sion-support framework emphasizing stringent safety protocols, comprehensive training, healthcare support, and robust organizational policies to minimize exposure risks, reduce disease incidence, foster recovery, and avoid re -exposure, ultimately improving  workplace safety, health, and productivity. Keywords occupational health and safety (OHS), industrial workplaces, system dynamics modeling, organizational policies, safety interventions Introduction Occupational health and safety (OHS) are essential in industrial workplaces, especially where there is a comparatively high risk of accidents, injuries, or diseases. According to the International Labour Organization (ILO), approximately 3 million workers worldwide die of work -related risks ( accidents and diseases ), the  majority of which occur in industries (ILO, 2023). Moreover, ILO estimated that 395 million workplace accidents occur without fatalities annually, leading to time off work. These statistics indicate why effective OHS measures are necessary to minimize risks and promote employees' health. Managing OHS in the industrial workplace encompasses various complex and dynamic challenges. Frequently, industrial workers  are exposed to hazardous material s such as chemicals, asbestos, and heavy metals that can result in adverse health issues, including respiratory diseases, cancer, and skin disorders (Schulte et al., 2013). Proper handling, managing, storing, and disposing of these materials is crucial yet challenging. Physical hazards due to heavy machinery and equipment cause severe crush injuries and amputations. Thus, industrial managers must provide rigorous training and maintain a high-risk management safety culture for such dangers (Kines, Andersen, Spangenberg, Mikkelsen, Dyreborg, & Zohar , 2010). Ergonomic risks that are industrial -related activities bear a considerable challenge. Repetitive motions, heavy lifting, and awkward postures are the typical tasks that cause musculoskeletal injuries. Mitig ating these risks requires comprehensive ergonomic assessments and target interventions for specific job tasks (Karasek, Brisson, Kawakami, Houtman, Bongers, & Amick, 1998). Mental health",mtsu.edu,Middle Tennessee State University,United States,35.84860085,-86.36090357044624
38,MICRO-GROUP CASE STUDY – FINDING THE MOST EFFECTIVE GROUP SIZE,@westpoint.edu,"Working Groups, Peer Teaching, Classroom Structure, Student Participation, Dyads, Micro-groups","Classroom group work is a well -known active learning pedagogical method that is used in all types of classroom educational settings.  It is especially useful in the field of engineering because it allows students to develop cooperative learning techniques which will prove useful in other classrooms and in th eir careers.  This pilot research looks to address the most efficient and effective approaches to group work in a daily classroom setting.  Using a project management course as the setting , different approaches and constructs were used throughout the semester to assess the most effective and practical approaches.  Daily active learning exercises were incorporated into the lessons so that students would become familiar with group work approaches.  Section grade averages were used as a proxy assessment indicator of academic success along with classroom surveys.  Results indicate that group work is preferred by the students during normal classroom instruction.  Smaller group size allowed for gr eater effort by weaker students because they could not “get lost” in the crowd.  Connecting weaker students with higher performing students into two person groups also increased understanding and retention of the lower performing students.  Results indicat e that smaller group sizes create pressure on the weaker performing students which created not only discomfort for them, but also increased their motivation to perform.  The results suggest greater retention of course material and higher overall grades because of smaller group activity exercises. Keywords Working Groups, Peer Teaching, Classroom Structure, Student Participation, Dyads, Micro-groups Introduction Student working/design groups in the engineering classroom are ubiquitous throughout the discipline s.  However, identifying the best or optimal group size is a challenge.  Too large of groups produce mixed results concerning learning effectiveness.  Too large of a group can have negative results regarding loafing, resentment, and bad student relationship dynamics.  Likewise, if groups are small and not structured correctly, the outcome can have disastrous learning results.  The efficiency of groups is related to the size of the group, the kind of problem being worked on and the character of the group members.  For this study, a micro group is defined as a group of two students.  The purpose of this pilot study was to improve the overall classroom experience for students taking an introductory project management class and to increase student learning through one-on-one peer collaboration and education.  A secondary purpose of this work is to provide practical options for classroom structure and group pedagogical approaches that can be replicated in other classroom settings. Background It is well known that groups tend to perform better at solving problems than individuals  (Marquart, 1955) (Lorge & Solomon, 1959).  There are several dynamics which allow groups to perform at a higher level and include, but are not limited to, a greater flow of ideas, different problem -solving approaches, sounding board for idea vetting, etc.  What constitutes a group is also a consideration.  In Moreland, et al’s review of group pro cesses they excluded dyads , or two person teams  as groups because they lacked certain group characteristics .  Dyads have a closer “special” bond between the two members, they cannot form coalitions and are characterize as seemingly “different” (Moreland, Hogg, & Hains , 1994) .  On the other hand, there is an argument that dyads are groups in certain instances and should be considered such.  Williams (2010) defines groups as “two or more people” (Williams, 2010).  Williams argues that, by definition, dyads do meet the criteria for groups.  In a dyad, the presence of another person does influence our",westpoint.edu,,,46.3144754,11.0480288
39,ADMISSION CRITERIA FOR ENGINEERING MANAGEMENT MASTER’S DEGREE PROGRAMS IN THE UNITED STATES,@uidaho.edu,"engineering management master’s degree, admission criteria","Engineering Management master’s degree programs at every institution have admission criteria. However, what constitutes admission criteria varies from one program to the next. There are quantitative criteria that exist for nearly all programs, such as the undergraduate grade point average (GPA) and the Graduate Record Exam (GRE). Acceptable values of these criteria vary from one program to the next .  The re are more qualitative criteria, such as letters of recommendation, which are difficult to assess. Furthermore, admission decisions based on these criteria are not absolute as there are provisions for relaxing the acceptance level of the criteria so that students who do not meet the standard can still be admitted into the program.  These situations raise questions as to the purpose of admission criteria, their value, and how they are applied. There are also concerns as to the barriers imposed by admission criteria and if they unnecessarily reduce access to degree pursuit.  In this paper we present information from a variety of sources to provide a better understanding of these issues.  We also summarize the acceptance criteria currently used by 30 engineering management master’s degree programs in the United States to characterize how they are applied. Finally, we make recommendations that engineering management master’s degree programs may consider, along with identifying areas for further study on this topic. Keywords engineering management master’s degree, admission criteria Introduction All degree programs select and admit students based on admission criteria. Engineering management master’s degree programs are no different  though what constitutes required admission criteria vary from one program to the next. Some admission criteria have specific  numerical values such as grade point average (GPA)  or Graduate Record Examination (GRE) (ETS GRE, 2024). These type of criteria  lend themselves to more objective  decision making in graduate admissions.  Many admission criteria do not have numerical values such as letters  of recommendation or a student’s resume. These type of criteria lend themselves to more subjective decision making in graduate admissions. In combination, educational programs use these admission criteria to determine who to admit into their programs and those not to admit. The objective of this paper is to describe the use and purpose of admission criteria and summarize how 30 engineering management master’s degree programs in the U.S. use them in the admissions process. The nature of the students admitted into a program have a significant impact  on the nature of the students that graduate, impacting the reputatio n of the program.  Furthermore, increased student mobility and graduate applicants from different higher education systems , levels of academic skills, and pro ficiency in English language make the admissions process that much more challenging (Kurysheva , et. al., 2023).  Therefore, faculty are very concerned about who they admit and the need for admission criteria to guide their decisions. The primary purpose for having admission criteria  is a desire to admit students into the program  who will be successful at completing all of the requirements of the program and obtain the degree. Degree obtainment is important so that time and financial resources of both the institution and the student are not expended  if the educational pursuit is not completed.  Therefore admission criteria are used to identify students most likely to succeed. Another purpose of admission criteria is to help develop a particular characteristic for a program known as brand identity.  This enables a program to graduate students that have a characteristic background and promote a particular capability to those employing the graduates.  This includes s tudents that help  the program pursue its mission and achieve its vision.",uidaho.edu,University of Idaho,United States,46.72379775,-117.02043898436474
40,A SET-BASED KNOWLEDGE GENERATION FRAMEWORK FOR PRODUCT DEVELOPMENT,@montana.edu,"Set-Based Concurrent Engineering, Product Development, Knowledge Management","The product development process involves a series of complex tasks with engineers facing diverse, often conflicting objectives. The traditional model, c haracterized by identifying the “best” solution early and iteratively modifying it until requirements are met, presents hurdles related to product cost, management's diminishing ability to influence the project as it progresses, and limited knowledge avail ability when key decisions are made. However, front -loading counters these issues by shifting problem -solving to earlier stages of development. By exploring a broader design space earlier in the process, engineers can refine solutions before committing to one. In doing so, front -loading mitigates the above challenges, reducing the need for late engineering changes and fostering continuous improvement. One approach for front -loading is Set -Based Concurrent Engineering (SBCE). A key principle of SBCE is to “m ap the design space,” which aligns with the concept of knowledge generation. “Map the design space” refers to building knowledge about different combinations of design parameters, considering constraints and trade -offs to foster cross- functional understanding. In this paper, we introduce a set -based knowledge generation framework through a comprehensive literature review, synthesizing existing research on front -loading, SBCE, sys tems engineering and knowledge management. The framework offers a step -by-step approach to identifying knowledge requirements in design spaces characterized by multiple objectives and design parameters. Additionally, the framework includes a management sys tem that facilitates the generation of knowledge. By providing organizations with a systematic approach to set -based knowledge generation, the framework aims to enhance decision -making processes in product development, optimize resource allocation, and streamline innovation efforts. Keywords Set-Based Concurrent Engineering, Product Development, Knowledge Management Introduction Product development encompasses the business process through which a company transforms innovation into market- ready offerings (Cantamessa & Montagna, 2016). It represents the tangible result of the research and innovation journey, converting ideas into commercially viable products that meet the needs of end -users and contribute to economic value. Whether it’s Apple, Tesla, or Ube r, innovative products and services shape our lifestyle and inspire new ways of living. Despite its significance, not all companies excel in introducing new products. Harvard professor Clay Christensen highlights that 95% of new products fail (Nobel, 2011) . Typical product development processes aim to quickly develop and choose a single design concept, essentially pinpointing a single spot within the design space. Three key factors impede the effectiveness of this point -based product development approach: 1) product cost implications due to critical early decisions with limited data, 2) management's diminishing influence over design as the cycle progresses, and 3) the constraint of limited knowledge in initial stages, leading to relatively uninformed decisio ns. The need for rework to refine the product, coupled with late engineering changes as undesirable patches, underscores the challenge of making accurate decisions with constrained knowledge (Bernstein, 1998). To overcome these challenges, organizations ma y “front-load” the process  by advancing the identification and resolution of problems associated with the development of a new product to earlier stages and defer decision making to later  stages. This strategic shift aims to accumulate additional knowledge , affording more time for thorough exploration of diverse possibilities. This in turn leads to more informed and effective decision -making in the later stages of product development (Thomke & Fujimoto, 2000; Tuna & Windisch, 2014).  As a result of front -loading",montana.edu,Montana State University - Bozeman,United States,45.6638859,-111.07928704602077
41,DIGITAL AGGREGATION OF A DIGITAL THREAD: A SYSTEMATIC LITERATURE REVIEW,@uah.edu,"Digital thread, digital engineering, data, artificial intelligence","With an increasing prevalence of the digital transformation across multiple industries, there is a need to understand the identification, collection, s orting, and integration of data in forming a digital thread for a system. This research aims to systematically review existing peer-reviewed literature to identify methods and techniques employed for data identification, collection, sorting, and integratio n to form a digital thread. This research also explores the role of artificial intelligence (AI) in creating digital threads. By adopting a data-centric approach emphasizing a single source of truth in the digital thread, stakeholders and decision-makers have updated system information for making real-time decisions. The research contributes to the field of engineering management by providing insights into current strategies for creating a digital thread framework. While there is not a standardized method, there are identifiable patterns in the literature of forming a digital thread. Data selection methods consider factors like data gathering, storage compatibility, and relevance, primarily utilizing traditional manufacturing methods such as IoT sensors and cameras. Data storage relies on methods like SQL databases and data modeling languages to standardize the data while sorting methods vary based on factors such as life cycle stage and metadata attributes for traceability. Integration methods range from unique frameworks to combining data into a single file type. Future research includes the exploration of emerging AI and machine learning techniques for optimizing data acquisition and integration into digital threads, as well as using an AI-generated digital thread to enhance the decision-making process for engineering managers. Keywords Digital thread, digital engineering, data, artificial intelligence Introduction Creating a digital thread involves complex data aggregation processes, beginning with determ ining the relevance of data to be included, feasibly collecting data, sorting data, and ultimately integrating the data into a digital thread (Bonnard et al., 2019). However, the lack of intuitive methods and standardized approaches poses a significant barrier to practical implementation. A standardized method is necessary to select, collect, sort, and transfer data into a digital thread. This research performed a systematic literature review (SLR) to understand and contextualize the current methodologies and technologies used in the formation of digital threads. The researchers aim to bridge this gap by analyzing current methodologies and best practices for forming digital threads. By adopting a data -centric approach and emphasizing the concept of a single source of truth contained within the digital thread, engineering managers have access to updated information to make educated, real-time decisions about their systems. Digital engineering is relevant in countless applications not limited to manufacturing, infrastructure, aerospace, and power systems (Zhang et al., 2024) . Each of these applications has a unique need for implementing a digital thread. In manufacturing, the digital thread can aggregate data from machinery across a facility to better understand progress, estimate completion times and maintenance schedules, and build digital twins more capable of handling the ever-changing data flow inherent to manufacturing (Gery, 2023). Smart manufacturing includes technologies such as the Internet of Things (I oT), artificial intelligence (AI), augmented reality (AR), and big data analytics. These technologies aggregate and integrate data into a digital thread (Loaiza et al., 2023) . In aerospace applications, stakeholder requirements govern the project lifecycle . A digital thread acting as an authoritative source of truth can",uah.edu,University of Alabama at Huntsville,United States,,
42,ECONOMIC ANALYSIS OF PUMPED-HYDRO ENERGY STORAGE SCHEMES AND PRICING OF PUMPING ENERGY IN INDIA,@go.stcloudstate.edu,"Pumped storage schmes, pumping energy pricing, Levelized Cost of Electricity (LCoE).","Worldwide, the Pumped-Hydro Energy Storage Scheme (PHES) is a proven bulk energy storage system used in power grid operations. In PHES, pump energy consumption is more than its energy production and hence differential energy pricing mechanism (peak and off-peak rates) is used in developed nations. But in India, so far, no such pricing system has been adopted as the PHES installations are very few, and the existing energy calculation method accounts for pumping energy as  an expenditure. Recently, as more renewable energy generation developed in the grid, th e government has issued guidelines to promote private participation in PHES development. As the pumping energy cost occupies a major portion of the plant expenditure, an attempt is made in this paper mainly to address the ‘pumping energy pricing’ by consid ering the existing energy calculating pattern and future operation. The general economic analysis, the difference between costs (expenditure) and revenue (income) associated with the project,  was used to calculate the pumping cost. The per unit cost of pum ping energy was calculated a) for the existing plants where pumping energy is mostly fed from thermal power plants, b) peak and off-peak charges, Levelized Cost of Electricity (LCoE) method was used to arrive at the optimal pumping energy cost for a typica l standalone plant, and c) as the independent operator where pumping energy fed from their own solar and wind power plants. The outcome of this analysis would be helpful in standardizing the pumping energy cost in the Indian power sector. Keywords Pumped storage schmes, pumping energy pricing, Levelized Cost of Electricity (LCoE). Introduction Economic power generation, providing affordable cost of energy to the people has always been the priority of any government with maintaining its sustainability and reliability, in which, policy makers and engineering managers are involved in both technical and economic aspects. Maintaining power system reliability, meeting the demand growth and generation expansion are some of the tasks on technical side where as providing way for active participation of private investors towards infra structure development and designing tariffs structure suitable to various consumers such as public, industries, agriculture, investors, etc. at the rates enough to maintain the financial and operational needs of the utilities are on economical side. The structure of Indian power sector has been so designed that the policy is jointly framed by the central and respective state governments, assisted by the engineering managers who are concentrating on balancing the sale, production and purchase cost of energy while approving the tariff and projects. Presently, Indian Power Sector is facing major challenges today with the introduction of reforms, globalization, and liberalization policy of the government. The ever-increasing power demand, increase in Renewable Energy (RE) penetration and low reserve capacity of the country necessitates more energy storage schemes for the power system. The National Electricity Plan (NEP) indicates that 18.8 GW of PHES capacity and 51.5 GW of Battery Energy Storage (BES) are required to integrate the planned renewable energy capacity addition till 2032  (CEA, 2022). For many decades, PHES have been used as proven bulk energy storage systems with high capacity among other types of energy storage systems for grid integration. Though the Indian power grid needs more energy storage schemes for flexible operation, so far, only 4745.6 MW PHES schemes have been developed due to various challenges involved in PHES",go.stcloudstate.edu,,,46.3144754,11.0480288
43,CATEGORY THEORY AS A COMMON LANGUAGE OF EXPRESSION IN SYSTEMS ENGINEERING,@uah.edu,"Category theory, systems engineering, RPYS, mathematics, meta language.","With the recent interest in category theory in the systems engineering community, there is a question of what category theory brings to systems engineering that is not already contained within the mathematical approaches already found in the field. This paper suggests that category theory may be able to serve as a common means of expression, that is, a sort of “meta language” that enables different mathematical approaches within topics of systems engineering and between topics of systems engineering to be e xpressed in common terms. This paper uses reference publication year spectroscopy (RPYS) to identify seminal works related to mathematics in systems engineering and from these works identify both topics of systems engineering and math that commonly occur t ogether. It is shown that these topics of math all have links to category theory, suggesting that category theory may indeed be able to serve as a common means of expression for systems engineering. In possessing a common means of expression for systems en gineering, engineering managers may have new tools for dealing with topics such as requirements tracing, change management, and risk propagation, enabling them to more confidently ensure that their organizations will deliver soundly engineered systems that meet stakeholder needs. Keywords Category theory, systems engineering, RPYS, mathematics, meta language. Introduction Despite its focus on practice and non -mathematical topics like organizations and requirement elicitation, systems engineering (SE) is no stranger to using a range of mathematical representations on the problems it tackles. For example, Wymore (Wymore, 1993) suggested a set-theoretic approach in his work while von Bertalanffy (Bertalanffy, 2003) relied more on controls theory underpinned by differential equations. In addition to these long -established mathematical approaches, category theory is gaining more attention as a potential mathematical foundation for SE (Breiner et al., 2018; Gebreyohannes et al., 2018; Mabrok & Ryan, 2015). The question then becomes what advantages category theory offers, especially considering its reputation for being extremely challenging to learn. This paper explores one such potential advantage, that of a common means of expression within SE. Category theory s tarted life helping to recognize similarities between different topics of math, most notably algebra and topology. This ability to put seemingly disparate mathematical ideas into a common language may also be useful in SE, since different topics of SE tend  to express their thinking using different mathematical perspectives. For engineering managers in particular, the ability to express a wide collection of SE topics in a common language may offer new approaches for requirements tracing, change management, a nd risk assessment. Category theory requires making many implicit assumptions explicit, so using category theory as a common means of expression may help engineering managers identify and resolve incongruent assumptions between teams before they become larger issues. In order to begin exploring this potential advantage, a list of seminal works in SE relating to mathematical foundations was assembled, surveyed for relevance, organized by SE and mathematical topics touched on, and then",uah.edu,University of Alabama at Huntsville,United States,,
44,DEVELOPING A METHODOLOGY TO EXAMINE THE ROLE OF PROJECT CONTRACTS MANAGEMENT AS A PRECURSOR TO MANAGE PROJECTS,@vt.edu,"Project Contracts Management, Multi-Criteria Decision-Making, Project Planning and Controlling","Project Contracts Management (PCM) has gained a lot of importance recently a s strategies such as outsourcing, partnering, etc. have emerged. Since these strategies usually involve third parties, it would be significantly crucial to clarify expectations before the project starts. The goal is to prevent misunderstandings and conflic ts that can have terminating effects on the project’s success. For this reason, it can be suggested that a project closes its required contracts before it starts with the goal of increasing the project’s success probability . Therefore, PCM can be studied as a precursor to Project Management (PM), which is what this paper seeks to do. To achieve this goal, this paper proposes a PCM methodology as a precursor to manage projects. In the guide provided, Multi -Criteria Decision - Making (MCDM) is embedded as a tool to prioritize the contracts of a project. Through the use of MCDM within this framework, the paper advocates for a structured process to prioritize contracts, resulting in enhanced project outcomes. However, it is worth noting that PCM should be continuously monitored during the project and updated if necessary. The most important takeaway from this paper is that considering PCM as a precursor to PM and determining how to invest in closing different contracts of a project equips the project manager with u seful information on more efficient and effective planning and controlling of the project. To accomplish this, the methodology developed in this paper can be used. Keywords Project Contracts Management, Multi-Criteria Decision-Making, Project Planning and Controlling Introduction In recent years, the emergence of strategies such as outsourcing and partnership has resulted in significant complexity in contracts. An agreement for a project is typically reached through a bidding process or by negotiation between the two parties involved. In the past few years, outsourcing contracts for Information Technology alone were worth $100 billion (Dayanand & Padman, 2001). Contracts are important in outsourcing because outsourcing without a clearly defined contract may lead to undesirable outcomes for both parties. This research's main idea revolves around the idea that almost every activity of a project, and thus the entire project, does require at least one contract, which can be either written or oral. In light of the above explanation, it can be concluded that Project Contract s Management (PCM) is something that can be considered and planned before a project starts. This paper aims to study PCM as a precursor to Project Management (PM). Toward this goal, a framework is suggested in this paper for prioritizing and managing the contracts of a project prior to its start. Furthermore, the developed framework utilizes Multi-Criteria Decision-Making (MCDM) methods for prioritizing the contracts of a project. Even though PCM has been studied from different perspectives, little has been done to consider",vt.edu,Virginia Tech,United States,37.22192675,-80.42728184013652
45,EXPLORING THE LANDSCAPE OF MICRO-CREDENTIALING IN ENGINEERING MANAGEMENT,@wsu.edu,"EM Education, Micro-credentialing, Badging, Stackables.","Micro-credentials are gaining traction as a way to certify specific skills and knowledge. This paper explores the current state of micro -credentialing in Engineering Management (EM)  at different institutions . The exploration aims to understand: • The prevalence of micro-credentialing EM programs at different educational institutions • The types of micro-credentials offered (e.g., digital badges, certificates) • The subject areas for micro-credentialing • The perceived benefits and challenges of implementing micro-credentialing programs • Existing institutional policies and support structures surrounding micro-credentials The findings of this survey will provide valuable insights for Engineering Management programs considering developing or expanding micro -credentialing initiatives. It will also contribute to the ongoing dialogue about the potential of micro-credentials to enhance learning pathways and workforce development, as well as for the job seeker to use these micro-credentials to promote themselves to find a job. Keywords EM Education, Micro-credentialing, Badging, Stackables. Introduction The complex, fast-paced, and dynamic business environment demands a workforce equipped with the most high-tech and latest skills, knowledge, and competencies  (World Economic Forum, 2020) . Coupled with advancements in the field of engineering management that are continuously evolving, higher education must react quickly to timely adapt and adjust curricula to ensure students are receiving the most updated knowledge and skills to meet real-world needs. The traditional undergraduate and graduate studies programs  that take 2 -5 years or degree certificates that take 1 -2 years to complete may not be as current and responsive to keep pace with this rapid change. Furthermore, employers expect more diverse and varied skills in their workforce, including specific techn ical competencies relating to the engineering manager job (National Academy of Engineering, 2018). These competencies can range from Six Sigma quality management to project management  and other soft skills such  as communication and leadership. Learning the se technical and soft skills through academic programs alone can be insufficient or impractical for many engineering professionals who do not want to necessarily pursue the full traditional degree programs in order to acquire these proficiencies. The last  decade has seen an increase in the use of alternative credentials in higher education , with micro - credentialing emerging to offer focused learning opportunities to address specific skill gaps and competencies (Educause, 2019). Micro-credential use in higher education is a growing trend stemming from industry needs and a changing demographic of students  (Fong, Janzo w, & Peck, 2016) . Micro -credentials allow traditional and non - traditional students to curate a unique skill set tailored to their personal and p rofessional goals at an affordable price. Micro-credentials also allow institutions to address students and industries with rapidly evolving needs and expectations while providing for educational growth. With universities and private educational service pr oviders",wsu.edu,Washington State University,United States,46.7337716,-117.14980348311619
46,STUDY OF PRIMARY BILIARY CIRRHOSIS PREDICTION USING MACHINE LEARNING ALGORITHMS,@astate.edu,"Primary biliary cirrhosis, Liver cirrhosis, Disease prediction, Machine learning, Healthcare","Primary biliary cirrhosis (PBC) is an autoimmune disorder and long-term cholestatic liver condition that affects adults typically middle -aged women. The effects increase because of abnormal serum concentrations such as alkaline phosphate, albumin, bilirubin, cholesterol, and several oth er different factors. Although the only established medical therapy with ursodeoxycholic acid demonstrated an increase in survival rate without liver transplantation as well as postponing the need for a transplant, it cannot cure it. In the final stage, pa tients develop fibrosis or cirrhosis, so they require it due to its unidentified origin. In this study, we have gone through 418 primary biliary cirrhosis patients’ health reports and use d machine learning (ML) models to predict their needs for liver transplants based on several predictors. We have used several popular ML algorithms namely, logistic regression (LR), k-nearest neighbors (KNN), naïve bayes (NB), random forest (RF), and extreme gradient boosting (Xgb) to predict liver transplant status. We have considered the recall score as it reduces the chances of missing diagnosis or false negatives, and o ur Xgb model outperforms other models by showing a promising 96.8% recall score. The proposed model will aid doctors and PBC patients who have not had a transplant in case of early identification, and transplant timing and monitor the effectiveness. In addition, the hospital manager will be able to identify patients who require more specialized intervention and allocate the resources to those who need it  most. This will greatly increase diagnostic accuracy, capacity planning, and collaborative care leading to an increase in the hospital's reputation. Keywords Primary biliary cirrhosis, Liver cirrhosis, Disease prediction, Machine learning, Healthcare Introduction Primary biliary cirrhosis is considered a chronic, gradually progressing, autoimmune, and cholestatic liver condition . The lack of small intrahepatic bile ducts is the defining feature of this disorder , which ultimately results in fibrosis, eventual cirrhosis, and liver failure (Carey et al., 2015). Its pathophysiology appears to be influenced by both genetic inheritance and environmental variables. The first encounter of a  condition with a PBC-like image was originally reported by (Addison & Gull, 1851) , but the name primary biliary cirrhosis was first used in 1949  when a group of 18 patients with PBC -like characteristics was presented (Ahrens Jr. & Kunkel, 1949) . It is primarily found among middle-aged women (mostly 45-65 years), affecting about 65 out of every 100,000 women.  However, men are also getting affected by it nowadays according to current research. Although the ratio is more like 4-6:1. A number of men are frequently diagnosed with the diseases in later life when the condition has progressed.  The majority of individuals do not exhibit any symptoms at first. Weariness, itching, and inflammation are the most typical signs of this illness that occur in up to 85% of the patients. It is important to early detect the illness before it causes more harm. With the advanced technology, nowadays PBC is being diagnosed more frequently at early ages due to greater knowledge of the disorder and the growing accessibility of detection techno logies, particularly serological testing. However, over 50% of them are asymptomatic when the patients are first diagnosed. Several factors can affect PBC patients such as age, serum bilirubin, serum albumin, serum glutamic oxaloacetic transaminase, alkaline phosphatase, serum cholesterol, ascites, urine copper and to name a few. Regular monitoring",astate.edu,Arkansas State University,United States,,-90.67262556246513
47,KNOWLEDGE MANAGEMENT TO DIGITAL TRANSFORMATION HEALTHCARE SECTOR: CASE STUDY OF THE NATIONAL COMPANY MULTISITE,@gmail.com,"Knowledge management, health, technology management.","Knowledge management, as well as training and knowledge transfer programs, are essential for the development of companies and human talent. In the specific case of healthcare organizations, it is crucial to provide timely service that allows for an accurate diagnosis and offers the best treatment for the patien t's condition. Therefore, the objective of this study is to identify technological management strategies, plans, and programs that foster knowledge transfer between the different units and levels within the studied company. For this research, the case study methodology was used, Yin and Fong . The study protocol is based on the modular case study model and the use of case studies in preparing postgraduate theses in the context of SMEs. The results obtained show that it is unclear whether there are defined strategies for knowledge management. Furthermore, the absence of a methodology for implementing digital tools is identified, which prevents feedback to measure the effectiveness of the adopted technology. However, it is observed that the interviewees show willingness and openness to acquire and share new knowledge. Keywords Knowledge management, health, technology management. Introduction Knowledge management is essential in a changing world where entrepreneurship and innovation create new products and services every day for healthcare and minimize the incidence of diseases and disabilities. Knowledge transfer is important for the development of new solutions and new applications, however, in Mexico the innovation environment is not strong and most of the researchers are individuals, and occasional is just another academic work. The management of technology and integration in the companies that provide healthcare services or health institutions facilitates a process focused on improving the quality and effici ency of the services with the help of technological tools, for example, knowledge management can be found in Industry 4.0 (Lizcano -Jaramillo et al., 2019). Vertical integration refers to how people transmit and communicate in the companies at all levels an d horizontal integration refers to the communication between people and machines where people with the data get information to help make decisions for the company managers (El-Jardali et al., 2023). The subject of this paper is to identify the strategies for knowledge management, plans, and programs to facilitate knowledge transfer between the different units and levels of the company since proper knowledge management is crucial to the prevention, diagnosis treatment, and rehab of disease. If the technology selection doesn’t fit the priorities or has a bad use or planning then it doesn’t have enough tools to fulfill the requirements of the region or the institution, therefore, without an appropriate implementation of the resources in health services, the needs of the target population will not be met (Salas, 2017).",gmail.com,,,46.3144754,11.0480288
48,A NOVEL KNOWLEDGE MAPPING TOOLKIT FOR PRODUCT DEVELOPMENT,@montana.edu,"Set-Based Concurrent Engineering, Product Development, Knowledge Management","The success of innovation hinges significantly on the organization ’s knowledge base, thereby making knowledge a critical competitive a dvantage in developing new products. To innovate successfully, firms must surpass their competitors in knowledge generation. This knowledge generation process unfolds through a series of problem-solving cycles, which act as information processing units that take in pr oblems and knowledge from previous or ongoing projects as inputs and produce solutions as outputs.  Knowledge mapping involves visually representing knowledge, which can also serve to identify the knowledge required to address design problems.  In this paper , we introduce a toolkit for mapping knowledge  to identify knowledge gaps to support problem solving in a product development environment. This toolkit comprises a matrix to prioritize design problems, a knowledge structure matrix to visualize relationships between elements, design parameters, and goals, and a knowledge assessment rubric to identify specific knowledge gaps. The knowledge mapping method  is developed through a  review of literature that integrates past research findings on product development, systems engineering, and knowledge management. Use of this knowledge mapping toolkit can lead to insights into the existing state of design knowledge, which assists the engineering manager in identifying areas where additional knowledge is required or most useful, and therefore where to direct attention and resources. Keywords Set-Based Concurrent Engineering, Product Development, Knowledge Management Introduction Given the rapid pace of change, the creation and management of knowledge have become crucial for business organizations, as adapting to change demands the rapid generation of new knowledge (Mahdi et al., 2011). Consequently, knowledge is no longer merely o ne of the traditional production factors; it has become the most significant resource (Drucker, 1993). Toffler (1990) supports Drucker’s assertion, arguing that knowledge ultimately supplants all other resources.  As a result, the value of most products and  services now largely depends on how effectively knowledge is developed (Quinn, 1992 ). This shift prompts us to reconsider how organizations handle knowledge and, crucially, how they generate new knowledge (Nonaka, 1994). Such a shift in perspective requires the modern corporation to evolve into a knowledge generating organization (Teece, 2000). Innovation, which is a key form of organizational knowledge  generation, is a process in which the  organization creates and defines problems and then  actively develops new knowledge to solve them  (Nonaka, 1994). Studies of problem-solving reveal that iterative trial and error experiments, guided by an understanding of underlying cause-and- effect relationships, are a significant feature of product development (Thomke, 1998; Thomke & Fujimoto, 2000 ). Product development encompasses the series of activities that start with identifying a market opportunity and concludes with the production, sale, and delivery of a product (Ulrich & Eppinger, 2012). Product development revolves around the creation and processing of knowledge, where knowledge from previous or ongoing projects are utilized to generate new knowledge. This process unfolds through a series of problem-solving cycles, which act as informatio n processing units that take in problems or goals as inputs and produce solutions as outputs. Each project consists of numerous interconnected cycles. To reduce lead time in product development, it is crucial to shorten individual problem-solving cycles and eliminate unnecessary ones (Clark & Fujimoto, 1989). This article introduces a toolkit designed for mapping knowledge to identify  knowledge gaps that need to be addressed to solve design problems. This toolkit supports product development managers throughout the early phases of the process, sometime referred to as the “fuzzy front end,” where efficient and targeted knowledge generation plays",montana.edu,Montana State University - Bozeman,United States,45.6638859,-111.07928704602077
49,CONSIDERING STAKEHOLDER PERSPECTIVES IN AN INTEGRATED RESILIENCE FRAMEWORK,@umsystem.edu,"Resilience, Hazards, Resilience Framework, Stakeholder Opinions, Aggregation Strategy, Equity","Existing resilience frameworks focus on specific domains or contexts, which limit their generalizability . In addition, these resilience frameworks do not effectively aggregate stakeholder inputs to inform decision -making. This creates challenges in a resilience planning process. The proposed resilience framework integrates current frameworks and can be customized to fit specific needs and contexts . The framework includes six resilience domains including physical, information, cognitive, social, environmental, and economic. These six domains were chosen based on their coverage in existing resilience frameworks and through insights gained from a literature review. Stakeholder input is gathered, compared, and integrated across stakeholder groups by considering stakeholder opinions of resilience decisions, such as resilience shortfalls, current perceived resilience, or specific resilience improvement projects. Both qualitative and quantitative inputs are obtained from stakeholders and a resilience assessment is created providing information for prioritization. This resilience framework may  then be applied using multi-criteria decision analysis . The framework supports more equitable decision-making across multiple stakeholder groups for complex systems. Keywords Resilience, Hazards, Resilience Framework, Stakeholder Opinions, Aggregation Strategy, Equity Introduction Resilience is a rapidly expanding field of study due to increasing natural and man -made threats. More frequent and critical storms and other weather threats have led many governments and businesses to consider making investments to increase resilience . Social and technological changes have changed the way we receive, process, and share information, which is more heavily influenced by data and algorithms.  Resilience frameworks exist to measure and evaluate resilience, but they often serve as a baseline for these measurements. Unfortunately, these existing resilience frameworks have been developed for specific hazards like  earthquakes, or specific contexts like  cyber systems, transportation, and military installations  (Bruneau et al., 2003 ; Linkov et al., 2013 ; Morshed et al., 2021 ; Richards, 2020). As a result, many resilience frameworks have made simplifications which create gaps in the conceptualization of resilience and limit generalizability. In addition, many existing resilience frameworks are not designed to support stakeholder input and those that do are limited in scope . Stakeholder engagement in decision -making increases the quality of those decision s (Sharpe et al., 2021). Thus, incorporating stakeholder inputs into resilience decision-making is expected to increase the quality of decisions associated with a system’s resilience. Different stakeholder groups each have their own perspectives and priorities (Taeby & Zhang, 2019). These differences make achieving consensus on selecting resilience projects from a set of projects challenging. The proposed framework’s goal is to provide ways to capture differences in stakeholder opinions so that these can be used to support decision-making. It is also imperative to do so in a way that will provide enough information to encourage discussion so that a consensus can be achieved. The proposed framework not only considers a system’s resilience but also how stakeholders will provide information for and be impacted by  resilience project alternatives. Stakeholder priorities can be captured with the proposed integrated framework. Stakeholders’ opinions are considered and differences in stakeholder sub-groups can be compared. In the following sections, this paper reviews existing resilience frameworks, proposes a new integrated",umsystem.edu,,,46.3144754,11.0480288
50,HOW EARLY WITHIN CONCEPT DESIGN SHOULD I SPEND TIME THINKING ABOUT LIFE CYCLE COST?,@erdc.dren.mil,"life cycle cost, Nunn-McCurdy breach, tradeoff analysis, conceptual engineering design","The consensus among product development researchers and practitioners is that life cycle cost (LCC) analysis should occur as early as possible within the system life cycle. The earlier within the concept stage of system design, the greater the associated uncertainty is with respect to LCC estimates. System engineers must find the appropriate points within early system development to conduct LCC analysis that simultaneously aid decision making while not impeding the completion of the conceptual design process. Early cost estimates promote managerial understanding of tradeoffs within development while also enabling LCC oversight and portfolio management by senior leaders. The later in the system life cycle that systems are deemed unaffordable, the greater the quantity of re sources unavailable for other budget needs as well as the loss of time to deliver the capability that the unaffordable system was intended to fulfill. Furthermore, the full cost performance of an acquisition program, partially indicated by falling under th e Nunn -McCurdy breach threshold, relates to the amount of cost modeling done at the earliest stages of conceptual design. Any mandate to estimate LCC at these early stages of concept design is often perceived as difficult and impractical. Therefore, the in troduction of automated tools to support early life cycle costing early in a program has the ability to improve program outcomes. This work demonstrates how fostering the development of LCC analysis tools which are tightly integrated with early conceptual engineering design tools provides the ability to make affordability determinations earlier in the life cycle. Keywords life cycle cost, Nunn-McCurdy breach, tradeoff analysis, conceptual engineering design Introduction During the process of developing a new system, engineers and analysts first produce an initial conceptual design, and cost analysis takes place at some point afterward to quantify the financial impact of the new system. The consensus in the cost-modeling community is that this life cycle cost (LCC) analysis should occur as early as possible within the system life cycle. In fact, according to guidance from the Office of the Secretary of Defense,  “starting the [cost] model building process as early as possible leads to a superior model desi gn […] [and] uncovers holes in the data requirements early in the process” (2022). Nonetheless, there are inherent tradeoffs that depend on the time that analysts implement cost modeling; the earlier within the concept stage of system design that LCC estim ation takes place, the greater the associated uncertainty is with respect to the estimates produced. System engineers must leverage their unique expertise with complex systems to find the point in the life cycle at which to conduct LCC analysis that simultaneously aids managers’ decision-making while not stymieing the overall system design process. Additionally, defense programs must adhere to a complicated set of acquisition policy directives which prescribe some costing activities and seek to impose oversight from the program up through Congressional committees. This work describes how the coupling of LCC analysis tools and early conceptual engineering design tools pro motes higher-quality affordability determinations to inform engineering managers at earlier points within the system life cycle. Background Military acquisition in the United States comprises approximately 30% of the Department of Defense (DoD) annual budget (McNicol, 2018). With such a dramatic share of the budget devoted to acquisi tion, it is crucial for analysts to",erdc.dren.mil,,,46.3144754,11.0480288
51,HOW DO C-SUITE EXECUTIVE TEAMS COMPARE TO THE GENERAL WORKING POPULATION: AN EMPIRICAL ETHNOGRAPHIC STUDY,@purdue.edu,"Engineering chiefs, utilities, leadership development, C suite executives, competencies, behaviors, motivations.","Are the characteristics of C -suite executives different from the general workforce?  Are C -suite executives in the utility industry different from those in other industry segments? This research draws from a sample of 32 individual C -suite executives from four regional utilities that provide power generation and distribution. The utilities are located in four diverse regions, including the Northeast, Southeast, Midwest, and Southwest United States.  The service areas range from major metropolitan regions to rural areas.  TTI TriMetrix DNA Assessment Suite, a global leader of validated assessment and professional development products and services, was used for assessment, professional development, and peer reviewed research.  In addition to data collection, two of the authors were embedded in the organizations over a one-year period, as they conducted in-depth one-on-one professional development working sessions combined with a series of strategic projects that strengthened the capabilities of each organization. Data will be presented to identify similarities and differences between business segments, along with the general working population, where both the C-suite and the general workforce completed the TTI TriMetrix DNA Assessment Suite. Specific areas covered include a) the measurement and ranking the levels of 25 personal and professional competencies, b) data -driven insights into behavioral lead ership styles, and c) the motivational forces shaping behavioral styles. This includes documenting the primary forces shaping behaviors, as well the forces are less likely influencing behavior. Keywords Engineering chiefs, utilities, leadership development, C suite executives, competencies, behaviors, motivations. Introduction Many cultural changes are being driven by the fourth industrial revolution and the shift to green energy.  The authors have been embedded in the public utility sector and have a deep understanding of the executive level management. The authors have witnes sed how the combination of rapidly evolving technology, shifting cultural norms and economic uncertainty have caused executive teams to re -evaluate their approaches to innovation, human resource management and business operations.  The pace of change has made the transformations difficult to manage, especially for legacy companies and small and medium sized enterprises, especially those in the utility sector. This research seeks to build on the work of Schwab (2016), Pistrui and Kleinke (2018, 2019, 2023),  Petrick, and McCreary (2019), and Pistrui, Bonnstetter and Gehrig (2022) to identify emerging trends, and key characteristics associated with engineering managerial leadership teams. This work utilizes data -driven instruments to compare a cross section of  executive teams associated with the utility industry, to the population of executives from other industrial segments, and to a very large population representing a wide range of people in the general population.",purdue.edu,Purdue University,United States,40.430028,-86.92642114650494
52,INTELLIGENT ASSESSMENT MODEL TO INVESTIGATE MENTAL HEALTH: A PLS-SEM & MACHINE LEARNING HYBRID APPROACH,@astate.edu,"PLS-SEM, Machine-Learning, Prediction, Factor Analysis, Mental Health.","Poor mental health conditions are now a serious global issue. Every year, several millions of people are victims of this, and many more endure it their entire lives. The World Health Organization (WHO) anticipates that one-third of women and one-fifth of men may develop severe depressive disorders in their lives. For this reason, employee mental health has become a serious concern since it is crucial to workplace productivity, morale, job satisfaction, t eam relationships, and overall organizational effectiveness. Prioritizing mental health fosters a healthy work environment, resulting in a more resilient and engaged team. This study proposes an assessment model to investigate mental health and analyze the key f eatures that contribute to mental health concerns.  This study  combines partial least squares structural equation modeling (PLS -SEM) with machine learning (ML) to enhance their -cause-predictive and exploratory abilities. Coupling these two strategies improves the  anticipated accuracy of research models . The methodology begins with using PLS-SEM to identify statistically significant features that impact mental health among 17 independent features and the identified features  are “Depression”, “Job Satisfaction”, “Mental health benefits or care provided by the employer”, and “Personal history of a mental health disorder”. After identifying the features, they were treated as input for several ML algorithms such as Logistic Regression, KNN, Random Forest, Decision Tree, etc. Then, a comparative study showed that Random Forest outperforms all other algorithms with 90.26% accuracy. This research will be one of the first attempts to help many organizations maintain healthy mental health. This concept allows organizations to analyze their employees' mental health and take the required steps to care for them. Keywords PLS-SEM, Machine-Learning, Prediction, Factor Analysis, Mental Health. Introduction The rising frequency of mental health diseases has become a serious public health threat that affects millions of individuals worldwide and imposes enormous economic and social expenses  (World Health Organization, 2017). Conventional mental health evaluation methods , such as medical professional interviews and self -report questionnaires, frequently do not have the required accuracy and flexibility to address the intricate nature of mental health disorders. (Kazdin, 2018). These approaches may be hindered by biases, individuality, and lack of ability to dynamically adjust to the changing nature of mental health symptoms. In recent times, machine learning (ML) has gained a great deal of attention, and it has provided new opportunities for the enhancement of many types of predictive evaluations . As a result, ML applications are considered the early preventive method in case of mental health -related issues. For instance, Reddy, et al., (2018) applied different ML algorithms to identify mental stress among employees and identified significant factors that lead to mental stress. In their research, Random forest outperformed other algorithms with an accuracy of 75.13%. Giannakakis, et al., (2019) also employed ML algorithms to predict stress levels, where the author used heart rate variability (HRV) parameter to recognize stress. Pramanta, et al., (2016) applied pulse data as an input variable  to identify stress. In this study, data was collected every five minutes, resulting in a 5 -minute relaxation interval for the user.  It is evident that many researchers have used machine learning to predict stress or mental health, but they have employed different input features, leaving a gap in identifying common, significant factors contributing to  employee mental health.",astate.edu,Arkansas State University,United States,35.8447472,-90.67262556246513
53,GENERATIONAL SUCCESSION AND THE TECHNICAL LEADERSHIP GAP: AN EMPIRICAL INVESTIGATION,@purdue.edu,"Engineering managers, leadership development, next generation executives, generational succession.","Engineering managers must navigate generational succession while simultaneously fostering leadership development. In an era of indu stry 4.0 digital transformation, leadership development is paramount to competitiveness and socio - economic wellbeing. This research provides insights from a sample of 160 next generation executives representing a diverse variety of organizations, professio nal disciplines, and leadership levels.  These next -gen executives were enrolled in a program for working professionals as they were pursuing Doctor of Technology degrees at a land -grant university.  The TTI TriMetrix DNA Assessment Suite, a validated assessment and professional development product, was employed for gathering and analyzing data. TTI instruments are used by organizations and educational institutions for assessment, professional development, and peer reviewed research. Data will be presented  across three dimensions. The first was the measurement of 25 personal and professional competencies including such skills as leadership, conflict management, and interpersonal skills. The second dimension identified and evaluated the diversity of behavior al leadership styles. This provided insights into how they address problems and challenges, as well as how they handle situations involving people. The third dimension probed the motivational driving forces that shaped their behavioral styles. This include d documentation of the primary forces shaping behavior styles and those forces that were less significant. The paper concludes by presenting a series of data- driven insights and options to close the leadership gap and strengthening the talent pipeline. Managing generational successional and the development of technical leaders is vital to global competitiveness, innovation, and socioeconomic well-being. Keywords Engineering managers, leadership development, next generation executives, generational succession. Introduction - Leadership Succession and Generational Transition Many cultural changes are being driven by generational transition.  As the Baby Boomer generation (1946 -64) exits the workforce, the Millennial generation (1981-96) and the Generation Zers (1997-2012) rise to represent most of the technical workforce.  The combination of technological and cultural change has made the transformation to Industry 4.0 difficult to manage, especially for legacy companies and small and medium sized ente rprises, including those in the utility sector. This research seeks to build on the work of Schwab (2016), Pistrui and Kleinke (2018, 2019, 2023), Petrick, and McCreary (2019), and Pistrui, Bonnstetter and Gehrig (2022) to identify emerging trends, and ke y characteristics associated with engineering managerial leadership succession and generational transition. The literature verifies that the engineering talent pipeline is struggling to fill industry’s demand for engineers, especially for digitally savvy engineers. The engineering talent rising in the workforce does not see the world in the same way as their predecessors, who are now retiring and exiting the workforce. Certainly, multi-generational workforces have different perspectives on life, work, their world, and technologies. But recently, the degree to which these perspectives differ has significantly affected workplace harmony and",purdue.edu,Purdue University,United States,40.430028,-86.92642114650494
54,INTRODUCING PROBLEM STRUCTURING METHODS (PSMS) TO ENGINEERING MANAGEMENT EDUCATION,@wmich.edu,"Problem Structuring Methods, Engineering Management Education","In the evolving landscape of engineering management discipline, the capacity to navigate complex, multi-dimensional problems has become crucial. The cha llenges faced in this field are not only technical but also encompass socio - economic, environmental, and organizational dimensions. This multidisciplinary nature calls for educational approaches that equip future engineering managers with comprehensive pro blem-solving skills. Current curricula often focus on traditional analytical methods, potentially leaving a gap in preparing students to handle the “messy problems” that characterize today ’s engineering challenges. Messy problems are those that are difficult to define, multifaceted, and involve multiple stakeholders, requiring innovative and adaptive investigation. To better equip future engineers, this paper proposes the integration of Problem Structuring Methods (PSMs) into the Engineering Management Education curriculum to meet this need. The purpose of this research is to explore the potential of integrating PSM into the Engineering Management curriculum. This study aims to contribute to the evolution of engineering education, ensuring it remains relevant and responsive to the demands of contemporary engineering challenges. This paper reviews current Engineering Management Education curricula and evaluates the extent of PSM integration into current curricula. The outcome is a proposed strategy to include PSM in engineering management education to foster the necessary skills for strategic problem-solving in engineering contexts. Keywords Problem Structuring Methods, Engineering Management Education Introduction Engineering management is a critical field in modern industry, as it combines technical expertise with management skills to efficiently execute projects (Htet et al., 2023) . The increasing complexity of projects and the dynamic industrial environment necessitate a new paradigm in engineering management  education. This includes enhanced professional skills, experience-based judgment, effective knowledge management, and a holistic approach to decision- making (Philbin & Kennedy, 2020). The role of engineering managers is emphasized by the n eed for a new skill set, including soft skills, in the global and multidisciplinary environment (Jovanovic, 2013). Traditional engineering management education primarily focuses on analytical methods designed to solve well - structured pro blems. While these methods are essential, they often fall short of preparing students to handle the complexities of real-world issues (Htet et al., 2023; Jonassen et al., 2006) . In the realm of engineering management, most tools and techniques are designed to address tame problems (Schuelke-Leech, 2020; Seager et al., 2012). These tools excel in environments where the problem parameters are well understood, and the solutions can be quantified. However, the real world often presents managers with messy problems, which are qualitative in nature and require a more nuanc ed, collaborative approach.  Rittel and Webber (1973) introduced the concept of different types of problems, specifically distinguishing between tame and wicked problems. Tame problems are well -defined and have clear solutions. These problems, often found in mathematical and engineering contexts, can  be addressed using traditional analytical and quantitative methods. On the other hand, wicked problems are complex, ill -structured, have no clear solution, and involve multiple stakeholders with differing perspectives. Pidd (2009) describes such complex, ill-structured problems as messes, which are the same concept with Rittel and Webber’s wicked problems. It is worth noting that these types of problems have long been identified. Ackoff referred to them as “messes,” Rittel called them “wicked” problems, Schon described them as “the swamp”, and Checkland identified them as “soft” problems. These",wmich.edu,Western Michigan University,United States,42.2832928,-85.61026110719504
55,MODELLING THE BARRIERS TO SUPPLY CHAIN RESILIENCE IN THE FOOTWEAR INDUSTRY IN BANGLADESH,@gmail.com,"MARCOS Method, Best Worst Method, Footwear Industry, Supply Chain Resilience , Supply Chain Disruption","Various types of disruptions, including natural disasters, pandemics, and geopolitical crises, are putting pressure on manufacturing organizations to build supply chain resilience (SCR). However, building SCR, especially in developing countries, remains a challenging task due to several underlying barriers. Therefore, this study  sought to evaluate how numerous barriers affect supply chain resilience in Bangladesh's footwear sector using a combination of MCDM techniques. The most important barriers were identified through the existing literature and the Delphi technique, and the Best -Worst method (BWM) was then used to rank these barriers in terms of importance. The M easurement Alternatives and Ranking according to the Compromise Solution (MARCOS) method were then used to validate the results. The results of the study offer a complete understanding of the key barriers driving supply chain resilience and the trade -offs involved in decision -making. The findings highlight that lack of collaboration among supply chain partners has the highest impact on the resilience of the footwear industry of Bangladesh . The results lay the groundwork for further research in this field an d can help organizations increase supply chain resilience by concentrating on the most significant barriers. In this study, multiple methods were deployed to offer a comprehensive understanding of the barriers to SCR in Bangladesh's footwear industry.  This study emphasizes the usefulness of a hybrid MCDM approach for supporting supply chain resilience-related decisions. Keywords MARCOS Method, Best Worst Method, Footwear Industry, Supply Chain Resilience , Supply Chain Disruption Introduction In contemporary times, scholars and decision -makers have devoted considerable focus to the turbulence observed in the supply chain due to several disruptions (Dubey  et al., 2012). The phenoenon of turbulence within a supply chain is sometimes denoted as ""supply chain disruption (SCD)."" SCDs have been observed at different points in time due to a variety of reasons (Tomlin, 2006). Certain phenomena can be attributed to human activities, such as armed conflicts and acts of terrorism, while others arise from natural events , such as storms, earthquakes, and pandemics. According to Craighead et al.  (2007), these types of interruptions can have varying durations and can negatively impact the functioning of an organization. Adapting to these disturbances and demonstrating flexi bility in such circumstances might potentially amplify supply chain ambiguity and complexity (Pereira  et al. , 2014) and compel managers to endeavor towards establishing comprehensive and proactive frameworks inside supply networks (Christopher & Towill, 2002). Therefore, the comprehension of how organizations can effectively navigate uncertainties and attain a competitive edge has emerged as a significant subject of inquiry in both scholarly research and practical business settings. The topic of constructin g resilient structures has attracted significant interest in the recent past. Scholars underline the significance of resilience as a critical capability that complements conventional risk management procedures within the context of organizations (Fiksel et al., 2015). In light of this matter, it is proposed that resilience is a viable approach for effectively addressing risk management and facilitating recovery in the event of SCDs (Ambulkar et al. , 2015). According to Melnyk (2014), resilience is considere d to be the fundamental principle underlying contemporary supply chain management (SCM) ideology. By recognizing that every operation in the supply chain has some level of risk (Ponomarov & Holcomb, 2009), companies view supply chain resilience (SCR) as a valuable competence that is both efficient and proactive in many scenarios.",gmail.com,,,46.3144754,11.0480288
56,CARDIOVASCULAR DISEASE PREDICTION USING MACHINE LEARNING FOR DECISION SCIENCE AND ANALYSIS,@gmail.com,"Machine learning, cardiovascular disease prediction, decision science, engineering management","Machine learning (ML) paradigms, principally, feature -engineered ML classifiers, in the field of data science and engineering management are paving way for data-driven predictions, decision engineering, optimized management & overall remodelling of modern engineering management practices. The agility and flexibility of machine learning classifiers especially in healthcare engineering management, aids in predictive medical analysis & engineering, automated quality control, and improved healthcare decision su pport systems. In this paper, we are proposing an in - depth and systematic review of ML -based prediction models for cardiovascular disease prediction (CVD) based on data visuali zation, feature engineering, ML -based algorithms implementation and post -classification metrics assessment. The heart is a crucial organ of the human body, and in contemporary lifestyles characterized by reduced physical activity and suboptimal nutrition, CVD s pose significant health risks. The proficient union of ML with engineering management in predicting CVD s on the basis of clinical data (including demographic information, medical history and previous lab results, if any), medical imaging and genetic information on the lines of feature extraction and pattern recognition can assist in leveraging data-driven insights to improve patient outcomes, streamline healthcare treatment operations and overall resource utilisation. Using the CVD dataset  extracted from Kaggle, we have experimented with feature-based supervised learning techniques such as Decision-tree classifiers (DT), k-nearest neighbor (KNN), Support Vector Machines (SVM), logistic regression and random forest classifier (RF). The Random Forest Classifier, with its 90.75% accuracy, is the most efficient algorithm, out of all, for predicting CVDs, according to the comprehensive study's findings, followed by SVM, KNN, and DT Classifier. Keywords Machine learning, cardiovascular disease prediction, decision science, engineering management Introduction In today’s fast-paced and dynamic era, cardiovascular di seases (CVDs) are becoming increasingly prevalent and are one of the leading causes of mortality worldwide. Factors such as lifestyle habits ( high stress levels, poor dietary trends, lack of physical movement , etc) and genetic contributions influence overall increment in CVDs occur rences (Luthra, n.d.). The heart pumps blood throughout the body, and any dysfunction can lead to severe consequences, including death. Accurate and early (timely) prediction of CVDs is crucial for effective prevention, management, and timely treatment. This study explores the use of machine learning (ML) techniques for predicting CVDs, leveraging clinical data, medical imaging, and genetic information on the basis of classification and prediction techniques (Johnson et al., 2018; Krittanawong et al., 2019; Mohan et al., 2019; Motwani et al., 2017). ML algorithms can analyze large datasets to identify patterns and predict outcomes, offering significant potential for improv ing the accuracy of many engineering applications including CVD predictions and subsequent treatment. This interdisciplinary research combines computer science, biotechnology and biosciences to develop robust predictive models for CVDs, aiming to enhance early detection and treatment strategies (Huang et al., 2018; Krittanawong et al., 2019; Motwani et al., 2017;",gmail.com,,,46.3144754,11.0480288
57,BEYOND THE CODE: AI REGULATIONS AS THE SECRET COMPASS OF ENGINEERING MANAGERS,@google.com,"AI regulations, responsible AI, human centered design, fairness, interpretability, privacy, safety,","Technology is a product of society. As technology evolves, the norms governing it have to mature for enabling its proper use within the society. The int erest in Artificial Intelligence (AI) has surged following the introduction of chatGPT. Firms, both large and small, are competing to develop new products and solutions involving AI. Amidst these developments, leading corporations such as Google and Micros oft have proactively committed to upholding responsible innovation in AI development. Governments worldwide are responding with the creation of guidelines and regulations in the field. Notably, on March 21, 2024 the United Nations General Assembly (UNGA) a dopted landmark regulation on AI. At the heart of these developments in AI are engineering managers who leverage technical advances to build products and services that create value. To effectively harness AI for human benefit, engineering managers must be aware of these evolving regulations governing AI. Some regulations such as Digital Markets Act (DMA) and General Data Protection Regulations (GDPR) have far reaching consequences for organizations globally. Having a working knowledge of these statutory req uirements will enable engineering managers to identify the opportunities and constraints in leveraging AI technology while building products and services. It will allow them to make informed decisions about data collection methods, model training processes, the deployment of AI systems and metrics for their evaluation. At scale, it can become a competitive advantage for the firms they work in, as explored through real-world examples in this paper. Keywords AI regulations, responsible AI, human centered design, fairness, interpretability, privacy, safety, Introduction The advent of increasingly sophisticated AI models, exemplified by OpenAI's ChatGPT launched in Nov 2022, has propelled AI into the mainstream. It has sparked a surge of interest and investment in AI-powered applications across diverse sectors (AI investment, 2023). Notable feature of this phase of AI research is that it is predominantly industry led. In 2023 alone, industry produced 51 notable machine learning models, while academia contributed only 15. (Maslej, et al., 2024). There were also 21 notable models resulting from industry -academia collaborations in 2023, a new high. (Maslej, et al., 2024). Dr. Andrew Ng, a prominent computer scientist and Coursera co-founder, compared AI to electricity in its significance, underscoring its vast potential. (Ng, 2017), AI development covers such broad scope and influence that governing AI becomes vital for the larger social good. This is important considering research from the Stanford’s 2024 AI Index reveals a significant lack of standardization in responsible AI reporting. Leading developers, including OpenAI, Google, Meta and Anthropic, primarily test their models against different responsible AI benchmarks. This practice complicates efforts to systematically compare the risks and limitations of top AI models. (Maslej, et al., 2024) As organizations race to harness the transformative potential of AI, engineering managers  (EMs) find themselves at the forefront of this technological revolution, grappling with the dual challenge of technical in novation and regulatory compliance while developing products, services and models underlying them. This paper aims to shed light on the complex interplay between AI development, the evolving regulatory landscape, novel engineering management processes and thereby emphasizing the indispensable role of engineering managers in navigating this intricate terrain. By exploring the scope, and impact of AI regulations, as well as the specific responsibilities of engineering managers in ensuring compliance and fostering ethical AI practices by aligning processes to new landscape, this paper provides a comprehensive overview of the critical challenges and opportunities that EMs face in the age of AI.",google.com,,,46.3144754,11.0480288
58,IMPLICATIONS OF AI ON THE PRODUCT DEVELOPMENT PROCESS,@Charlotte.edu,"Artificial Intelligence, Product Design, Supply Chain Management","Artificial Intelligence (AI), defined loosely as the ability of a computer system to perform tasks generally associated with human intellectual processes , has developed rapidly over the past two decades and is providing significant advantages in the field of supply chain management. This paper examines how supply chain professionals can access cutting-edge AI developments through the use of commercially av ailable tools and how they can best leverage these new capabilities for developing a new product. A study of the current state of AI development along with an industry survey of available tools for supply chain practitioners was utilized to highlight emerging trends and use cases within the industry  for specifically product creation, sourcing and fulfillment . A small product design experiment was conducted to explore the application of several novel AI tools. The results show that commercially available, AI - powered, tools are accelerating and simplifying supply chain decisions while often reducing costs. From faster product ideation, design, and market research to more autonomous supply chain risk management and customer support, supply chain professionals a nd entrepreneurs can leverage a range of novel, AI -powered, use cases without large investments in data science infrastructure and without a deep understanding of machine learning algorithms. The results point to new paradigms and opportunities within the supply chain industry that should be leveraged to remain competitive. Keywords Artificial Intelligence, Product Design, Supply Chain Management Introduction The concept and technological promise of Artificial Intelligence (AI) dominated the tech nology news sector in the early 2020s and it became one of the most discussed and invested technology movements on the planet, promising to usher in new levels of change not seen since the emergence of the internet (CB Insights, 2024). But where did this all start and why has AI become such a hot topic now? What has fundamentally changed to drive such excitement, high levels of investment and widespread adoption? In 1950 Alan Turing proposed a way to evaluate a machine's ability to mimic intelligent behavior, kno wn today as the Turing Test  (Anyoha, 2024) . Development on systems that could problem solve and simulate limited intelligence progressed slowly through the 1950s and 1960s but diminishing returns led to reduced interest and a period starting in the 1970s known as the AI Winter. In the 1980s interest began to build again with the emergence of systems that could mimic human experts in narrowly defined domains, albeit accomplished through large amounts of manual programming. The 1990s saw the emergence of mach ine learning (ML) - a breakthrough structure that could learn from data fed into a model, offering an alternative to explicit programmed instructions. This technology blossomed with the widespread adoption of the internet in the 2000s and the exponential i ncrease of available data it brought. Advancements in deep learning in the 2010s gave AI algorithms breakthroughs in natural language processing (NLP) and generative capabilities that have made them highly applicable in an ever -growing list of applications (Gold, 2023). Advancements in increasingly powerful computing hardware, most notably GPUs, have allowed these algorithms to be trained and applied against larger and more complex problem sets. With the development of ever more advanced AI models has come a proliferation of tools to apply this technology to a myriad of use cases. Many companies look to leverage AI by buying access and applying their own unique datasets or problem sets (Moore, 2023). Developing on top of the c companies offering advanced large language models (LLMs) (such as Open AI and Google) , are also a slew of businesses leveraging application programming interfaces (APIs) to offer more focused tools to specific industries. A  perhaps near future  example here may be a shipping & logistics company leveraging a combination of their own data (from years of operation in the shipping industry) and",Charlotte.edu,,,46.3144754,11.0480288
59,REINFORCEMENT LEARNING FOR OPTIMAL KICKING ACTIONS IN HUMANOID ROBOTICS: ADVANCING ROBOTIC AUTONOMY AND VERSATILITY,@odu.edu,"Humanoid Robots, Optimization, Reinforcement Learning, RoboCup","Acquiring the necessary skills to perform a work effectively and efficiently  requires a significant investment of time and computing power. Previous applications of Reinforcement Learning (RL) for action optimization in humanoid robotics have shown how promising this technology is for movi ng robotics towards true autonomy and versatility. Therefore, this study offers the first use of RL to create an entirely optimal kicking action for the Alderbaran Nao robot. Kicking motions that were steady, precise, quick, and able to kick farther than a ny existing RoboCup squad were generated by optimizing for a multi -objective reward function. We demonstrate that the ideal kicking motions can be modified to produce angled kicks by putting a dynamic kicking module into practice. We also research on various kicking movements and more intricate search spaces that can benefit from the methodology presented in this study. Keywords Humanoid Robots, Optimization, Reinforcement Learning, RoboCup Introduction Rapid improvements in power sources and motor technology have greatly accelerated the field of robotics, allowing for the creation of smaller, more energy-efficient robots that can also carry out ever-more complex tasks. The evolution of robots has been astounding , from basic sensor -driven devices like Tortoise , which reacted to external stimuli through modifying sensor voltage, to complex robots like Honda's Asimo which demonstrates advanced skills in image recognition and environmental analysis. Asimo demonstrated its ability to carry out dynamic tasks in 2012, including running, hopping on one leg, unscrewing bottles, and pouring liquid into glasses. Each limb has a vast number of motors that support these actions, giving it many Degrees of Freedom (DoF) to enable intricate and accurate movements. With more motors and DoF, the complexity of managing these movements has increased. It used to take a lot of time and error -prone manual coding to program these movements and test the torque and voltage levels. Generally, inverse kinematics has been used in robotics to improve joint movement and provide precise control over robotic limbs and end -effectors, such as hands and feet. Still, the problem of figuring out how to move these end - effectors to complete particular jobs remains, thus we need to progress towards Artificial Intelligence (AI) (Alla et al., 2018; Alla, Soltanisehat, & Taylor 2018; Alla 2019; Lakshminarayan et al., 2023; Kamuni et al., 2024a, 2024b, 2024c) especially learning approaches, to improve and optimize these motions. Supervised learn ing, which depends on training data to produce exemplary solutions that may be improved and optimized , has long been the predominant method in robotics research. But there's a new approach on the horizon called Reinforcement Learning (RL) that looks promising (Kamuni et al., 2024; Kashyap et al., 2022 , 2023, 2024; Kumar et al., 2023 ; Marwah et al., 2023 ; Sa al.,",odu.edu,Old Dominion University,United States,36.8862699,-76.30972478839735
60,INTEGRATIVE MACHINE LEARNING APPROACHES FOR ENHANCED CLASSIFICATION OF GENOMIC SEQUENCES: A NEXT-GENERATION SEQUENCING PERSPECTIVE,@odu.edu,"Next-Generation Sequencing (NGS), DNA Classifier, Ensemble Learning, Optimization, SVMSigmoid","The advent of Next -Generation Sequencing (NGS) techniques has revolutionized genomic research by enabling the rapid sequencing of DNA and RNA. This data can be used for various applications, including genome sequencing, transcriptome profiling, metagenomics, and epigenetics studies. For this study, DNA classifier dataset was extracted from UCI repository of machine learning databases. This vast amount of genomic data necessitates the development of sophisticated machine learning (ML) models for effective cl assification and analysis. This study presents a comprehensive comparison of various ML models, including Support Vector Machines (SVM), Random Forests (RF), and Neural Networks (NNs), approaches, in classifying genomic data. We evaluate these models based  on accuracy, computational efficiency, and their ability to handle high-dimensional data. The comparison reveals distinct strengths and limitations of each model, with NNs and DL approaches showing superior performance in handling complex patterns in geno mic sequences but requiring significant computational resources. Conversely, SVM and RF offer a balance between accuracy and computational demand, making them suitable for applications with limited computational resources. A notable research gap identified is the challenge of integrating diverse genomic data types (e.g., single nucleotide polymorphisms, copy number variations, and gene expression data) in a unified classification model. This gap underscores the need for developing advanced ML models that ca n effectively leverage the heterogeneous nature of genomic data to improve classification outcomes. This study paves the way for future research aimed at bridging this gap, which is critical for advancing personalized medicine and understanding complex gen etic disorders. Keywords Next-Generation Sequencing (NGS), DNA Classifier, Ensemble Learning, Optimization, SVMSigmoid Introduction The Next-generation sequencing (NGS) technologies have fundamentally changed the field of genomics by allowing for the rapid and cost-effective sequencing of complete genomes . This technological advancement has generated an unprecedented volume of genomic data, necessitating robust and sophisticated computational approaches for data analysis and interpretation . Integrative machine learning (ML) approaches have emerged as a powerful set of tools (Alla 2019; Dodda et al., 2024; Kamuni et al., 202 4a) for enhancing the classification of genomic sequences, addressing the challenges associated with the complexity and high dimensi onality of NGS data  (Njage, Henri ,",odu.edu,Old Dominion University,United States,36.8862699,-76.30972478839735
61,"QUANTUM COMPUTING AI FRONTIERS - PEOPLE, TECHNOLOGY AND ECONOMICS",@purdue.edu,"Quantum AI, QAI, Innovation, General Purpose Technology, Dynamic Thinking, Artificial Intelligence, Quantum","Quantum computers, anticipated to be exponentially faster than their classical counterparts, hold the potential to revolutionize artificial intelligence by enabling the efficient processing of vast datasets for enhanced predictions and decision-making. This convergence of Quantum Computing and Artificial Intelligence heralds the emergence of Quantum AI, a new frontier in technological innovation. Both qua ntum computing and AI are individually regarded as general -purpose technologies (GPT’s). Notably, the release of GPTs historically accelerates innovation. The combination of two GPTs releasing within a decade is expected to have an exponential impact. Howe ver, alongside these opportunities come projected risks, including the potential for quantum computers to breach cryptography, automate tasks leading to widespread job loss, exacerbate the digital divide, and facilitate the creation of new materials for biological weapons, among others. Recognizing the disruptive potential, security risks and accelerated diffusion patterns associated with these advancements, this research aims to introduce to the reader the frontiers of quantum computing and its intersection with artificial intelligence. To tackle this topic, this study will delve into several aspects: forecasting the projected availability of quantum technology, examining the synergistic effects resulting from the simultaneous emergence of multiple GPTs, and provide a holistic view from a landscape perspective, focusing particularly on people, technology, and economics. Keywords Quantum AI, QAI, Innovation, General Purpose Technology, Dynamic Thinking, Artificial Intelligence, Quantum Computing. Introduction The slowing of Moore's Law, which has predicted the doubling of transistors on a microchip approximately every two years, leading to exponential growth in computing power, is becoming increasingly evident (Isaacson, 2014; Bell, 2016). As we approach the physical and technical limits of silicon -based technology, the pace of miniaturization and performance enhancement has decelerated. This slowdown poses significant challenges for sustaining the rapid advancements in computing power that have driven innovation for decades (National Research Council, 2011). Quantum Technologies Quantum technologies refer to a range of technologies based on our growing ability to see and control reality on a subatomic (“quantum”) level to build sensors and an ent irely new form of computing and communications (World Economic Forum, 2022). The approach to computation in a quantum computer is fundamentally different from that of classical computers. This new paradigm is grounded in quantum mechanics, the branch of physics that explains the behavior of extremely small particles. But most of the excitement comes from the unique computational power of a quantum computer and recent progress in creating the underlying hardware, software, and algorithms necessary to make it  work (NAB, 2019). Quantum computers are expected to surpass the computational capabilities of classical computers and have a transformative impact on numerous industry sectors (Herman et al., 2023). The quantum computing field is advancing rapidly with important breakthroughs in quantum hardware and software rendering it an increasingly strategic asset",purdue.edu,Purdue University,United States,40.430028,-86.92642114650494
62,FRAMEWORK FOR OBJECTIVE-BASED RISK MANAGEMENT,@spa.com,"Risk, Risks, Management, Objective, FORM, Uncertainty","Despite a migration of risk definitions towards alignment with ISO 3100 0, which defines risk as the effect of uncertainty on objectives, models for risk  management continue to apply a failure -focused definition based upon Norman Rasmussen’s probabilistic risk assessment: probability multiplied by consequence magnitude. This approach is counter to how people actually think about risk in decision making —in terms of achieving objectives—and makes it nearly impossible to model risks from diverse domains (e.g., technical, political, security, etc.) to develop a complete risk picture. As a result, individual risks and mitigations are “managed” rather than consid ered as elements of an integrated system of uncertainties. The Department of Defense recently published an update to their Risk Issues and Opportunities (RIO) Guide that restated their dichotomous definition of risk; the first half of the definition being objective-based and the second half being failure-based. The RIO guide goes on to only apply the second, failure - based portion of the definition to its recommendations for proper risk management. This paper proposes a conceptual methodology for applying a risk management model based upon risk as a measure of the nearness to one or more objectives, which allows for evaluation of risk as a networked system to inform decisions related to those objectives. Such a model also provides the ability to optimize miti gations to maximize effect while minimizing resources expended (i.e., cost or schedule) or changes in performance requirements. Keywords Risk, Risks, Management, Objective, FORM, Uncertainty Introduction In program management as in driving a car, we tend to steer where we are looking. In a well-managed program, clear intermediate objectives or milestones are defined to steer towards a common goal and gauge progress towards an ultimate objective, perhaps to deliver a new ship w ith certain capabilities on the intended date for an agreed-to cost. A good program manager (PM) understands the diverse hazards and sees the best path ahead when making decisions to navigate the program towards success . In fact, each of us mentally integr ates future uncertainties (risks) in the making of every decision , so why is risk routinely managed from the perspective of hazard avoidance  rather than achieving objectives? This is our first problem. The standard model for risk is based upon Norman Rasmussen’s Probabilistic Risk Assessment (PRA), developed in response to the 1979 nuclear reactor accident at the Three Mile Island facility outside Harrisburg, Pennsylvania (Rasmussen, 1981). The PRA quantifies risk by multiplying objective probability (i.e., frequency) with consequence of the event to develop a fault tree of cascading causes and effects. While not minimizing the important contribution of the PRA to safety engineering, the PRA is a normative economic model and does not align with the non-linear manner in which people actually make decisions (Monroe & Beruvides, 2022) . Rasmussen himself identified in his original paper one of the significant weaknesses of the PRA, that a low probability/high consequence event scores the same as a high p robability/low consequence event . This risk ambiguity is our second problem with the current risk management paradigm. The third problem is that of risk fungibility —there is no unit of risk. While there have been some efforts in the past to quantify progra mmatic risk, such as those by Witus and Blackburn on behalf of the Systems Engineering Research Center, the quest remains unanswered (Witus & Blackburn, 2016). Monroe, et al., concluded that while risk",spa.com,,,46.3144754,11.0480288
63,ADVANCED AIR MOBILITY: A SYSTEMS ENGINEERING CHARACTERIZATION OF A COMPLEX OPERATIONAL ENVIRONMENT,@kent.edu,"Advanced Air Mobility, Complex Operational Environment, Systems Engineering, Complex Spaces.","The operational environments that characterize the use of emerging technologies in the national airspace are creating new challenges associated with the sustained safe and secure operations . The use of drones  (unmanned and autonomous) around and within an airport for purposes of package and passenger delivery challenges the management of the airspace. These use cases are characterized by the complex, emergent, innovative, and interdisciplinary nature of several  distinct resources, including cutting -edge technology, infrastructure, socio -environmental impacts , and regulatory and policy aspects . This paper proposes representations of the AAM ecosystem and its characteristics by using existing  foundations and literature  to summarize challenges associated with this complex operational environment. If successful, this  promises to revolutionize airspace transportation, making it more efficient, sustainable, accessible, and safe. We propose a study of the complex operating environment, which incorporates the factors that influence the process of growth and establishment of technology. Keywords Advanced Air Mobility, Complex Operational Environment, Systems Engineering, Complex Spaces. Introduction Implementing cutting -edge, emerging technologies within established, and complex environments presents new hurdles to their ongoing integration. For example, the utilizing of Advanced Air Mobility (AAM) technologies in the National Airspace System ( NAS) for tasks such as package and passenger deliver.  The impacts these advanced emerging technologies are having and will continue to have on the NAS are enormous and require careful management of operations with manned, unmanned, and autonomous aircraft. In thi s way, the challenges related to sustainability reflect the complexity arising from these new Complex Operational Environments (COE), which refers to the effects of the interactions between the elements of the system and its environment. As a result of the se growing advances in the AAM field, there has been a significant increase in interest in both academia and the aviation sector in this area (Al-Rubaye et al., 2023), (Dulia et al., 2021), (Federal Aviation Administration, 2024), (Johnson & Silva, 2022). This paper first aims to identify the main elements, requirements, needs, and future expectations of these complex spaces regarding the regulations, performance, capabilities, and mechanisms of the decision -making process associated with this new COE as id entified in the literature. Based on the characterization of these spaces, a research agenda is proposed, observing and listing the possible existing gaps, driven by the following research questions. 1. Is it possible to develop a framework that extensively and effectively characterizes AAM as a complex system? 2. What are the key challenges and opportunities in research and development to realizing functional AAM? Finally, a high- level vision is outlined regarding the possible improvements that could come about with advances in the field of AAM. The structure of the paper is described as follows. First, the AAM ecosystem, the definition of what an AAM is, and definitions that exist for this type of system are discussed. Then, the COE is discussed and contrasted with complex engineered systems. AAM as an elegant system is then explored, including AAM from a system of systems science perspective. Advanced Air Mobility Ecosystem Mobility has an essential place in the development and progress of human society,  promoting continuous change in the environment and generating profound social impacts (Lin et al., 2023). Emerging technologies such as AAM have",kent.edu,Kent State University,United States,41.144232450000004,-81.33983207322399
64,ISO-MORPHOLOGY BETWEEN THE LORENTZ FACTOR AND THE ENTROPY DECISION RISK MODEL (EDRM) AS A TRANSLATION BETWEEN OBJECTIVE AND SUBJECTIVE PROBABILITY,@gmail.com,"Lorentz, Einstein, Proximity, Time dilation, Homology, Relativity","The Lorentz Factor has long been accepted as fundamental to special relativity, preserving the spacetime interval between two events and leading to concepts such as time dilation.  Current research into applications of the Entropy Decision Risk Model (EDRM ) developed for decision engineering revealed an apparent iso -morphology, (“same morphological structure” as described by Ludwig von Bertalanffy in General System Theory), between the inverse of the Lorentz factor and EDRM as a translation between measurab le objective probability and subjective probably, referred to as proximity. This paper provides an exploratory conceptual analysis of the inverse of the Lorentz factor as the nearness to either zero speed and the speed of the light and potential applicatio ns from physics for decision engineering and decision making under uncertainty. This research also considers the possibility that EDRM’s derivation as the entropy divergence from certainty may also inform special relativity models, thereby benefitting both physics and engineering disciplines. This research has potential implications to engineering management research and practice. Keywords Lorentz, Einstein, Proximity, Time dilation, Homology, Relativity Introduction It is generally assumed that the physical world defines objective reality, upon which the laws of physics are founded. Physical objects can be touched, observed, measured, manipulated , and their behavior precisely predicted deterministically. Conversely, human decision making is presumed to be subjective, intangible, non-linear, not directly measurable, partially predictable (hence the science of psychology) but not deterministic. The question is whether or not the objective and subjective worldviews ever come together, or do they exist independently but in tension? In the late 19 th and early 20 th centuries, as the understanding of the atom and the behavior of its components advanced, classical physics could no longer fully explain observations. Statistical mechanics, quantum mechanics, wave mechanics, and other theories were developed to model the phenomenology of particle behavior, but not the exact position and momentum of a particle, for example ; a conundrum codified in the Heisenberg Uncertainty Principle. Suddenly, the underpinnings of the physical world began to look more like subjective human decision - making processes than the more rigid objective and deterministic world so comfortable to physical scientists. Although some would have us believe that quantum physics is settled science, there are principles laid in its foundation that are still without consensus on the underlying theory . The Born Rule of quantum mechanics is one such example of a principle without any formal theoretical footing—it was literally introduced as a footnote correction to Born’s 1926 paper and no theory or derivation has yet been able to shore it up (Born, 1926; Monroe & Beruvides, 2024). This research is continuing a line of investigation to understand the translation between the objective and subjective world. The first step was the derivation of a relationship between objective and subjective probabilities by building upon work done in the field of behavioral economics and decision making under uncertainty. In 2020, Monroe and Beruvides introduced the idea of a mathematical relationship between objective probability (frequency) and subjective probability (how people perceive probability) based upon entropy divergence from certainty and decades",gmail.com,,,46.3144754,11.0480288
65,A QUALITATIVE STUDY INTO THE CHALLENGES IN ADAPTINGRAILWAY INFRASTRUCTURE TO CLIMATE CHANGE: A SOUTH AFRICAN CONTEXT,@gmail.com,"Railway, Barriers, Resilience, Climate Change, Climate Impact, Adaptation, Transportation, South Africa.","This study examines challenges faced by oper ators of a South African railway in adapting their infrastructure to climate change impacts. The research aims to investigate climate impacts on railway infrastructure, existing adaptation measures, challenges in adaptation, and their influence on railway infrastructure resilience to climate impacts. One - on-one interviews were conducted with seven key participants out of fifteen invited within a single department with a population of fifty engineers and engineering managers. The study used qualitative research strategies to examine data and four qualitative research strategies to ensure reliability and validity: Prolonged Engagement, Triangulation, Member Checking, and Audit Trail. The study finds that extreme weather events such as excessive rainfall, extre me winds, and extreme temperatures significantly impact railway infrastructure. The study recommends proactive measures, adequate funding, leadership commitment, awareness and training programs, and real-time data monitoring to enhance resilience. Keywords Railway, Barriers, Resilience, Climate Change, Climate Impact, Adaptation, Transportation, South Africa. Introduction South Africa’s railway industry is facing significant challenges due to the impact of climate change.  Although the country is ra nked as the 92nd most vulnerable nation in the world to climate change, according to the World Bank Group’s 2021 climate risk profile report (The World Bank Group, 2021) , the region has already experienced several incidents of flooding (Armstrong et al., 2017; Jörn Ahrens & Halbmayer, 2023; Ngubo, 2021), indicating that climate change events can be unpredictable and universal, with detrimental impacts on railway operations and the surrounding area. In April-May 2022, unprecedented flooding resulted in significant human and economic losses, highlighting the inadequacy of civil engineering measures and maintenance of stormwater drainage systems (Jörn Ahrens & Halbmayer, 2023). Expanding research efforts and implementing adaptation measures across various  transportation modes and geographical regions is crucial to addressing these challenges effectively (Wang et al., 2023) . However, the existing literature has predominantly focused on transportation sectors in European countries, with limited attention given to other regions and recent developments in rail transport (Brito, 2022; Mclean & Becker, 2021; Wang et al., 2023) . Furthermore, there is a lack of research regarding existing railway infrastructure adaptation measures, climate impacts, implementation challenges, and their contribution to overall infrastructure resilience against climate impacts in lower- altitude regions like Africa (Brito, 2022). Therefore, this study aims to investigate climate impacts, infrastructure adaptation measures, and their contributions to overall infrastructure resilience in South Africa’s railway industry.  The study  focuses on raising awareness of climate-related challenges and encourage effective adaptation measures. The stud y findings will guide necessary adjustments in infrastructure maintenance, planning, and design considerations, reducing/mitigating climate impacts and improving infrastructure reliability.  By addressing the challenges posed by climate change, the railway industry in South Africa can continue to operate effectively while promoting sustainable development and reducing environmental risks.",gmail.com,,,46.3144754,11.0480288
66,THE INTERNATIONALIZATION OF CAMEROONIAN ENGINEERING SCHOOLS: THE EXPERIENCE OF THE NATIONAL ADVANCED SCHOOL OF PUBLIC WORKS OF YAOUNDE IN PARTNERSHIP WITH GOLDEN GATE UNIVERSITY OF SAN FRANCISCO,@yahoo.fr,"Internationalization, Partnership, Master in Engineering Management","The National Advanced School of Public Works (NASPW) of Yaoundé and Golden Gate University (GGU) of San Francisco, have set up the first degree program between Cameroon and the United States of America. This is the Master in Engineering Management. This Ma ster's program aims to equip engineers with theoretical and practical knowledge in the field of management. The courses are taught by Cameroonian and American teachers. This paternership is supported by the Embassy of the United States of America in Cameroon through the Fulbright Program, hosting conferences, books donations, which contributes to improving the quality of training. This experience is a concrete example of the internationalization of academic institutions in the Cameroonian context. The aim of this paper is to present and analyze the process of establishing and managing this partnership. In a national context where the internationalization of academic institutions is increasingly practiced, the results of this analysis will provide gu idelines likely to contribute to its improvement. This dynamic must contribute not only to meeting national challenges, but also global ones. Our experience in this partnership first consisted of working on behalf of Golden Gate University as project focal point, then as cooperation officer. In second point, the article is also part of an experience -sharing approach between the two institutions. Keywords Internationalization, Partnership, Master in Engineering Management Introduction The action of  universities on the international stage is gaining momentum worldwide. Several activities are carried out in this context such as :  the implementation of online training programs, the creation of joint training programs, the cooperation in research and co -supervision of theses, abroad programs studies, students and faculty members’mobility, among others .Termed as the internationalization of higher education, it essentially involves integrating an international, intercultural, and global dimension into the missions and functions of higher education (Knight, 2004). This definition by Jane Knight, which has been and still serves as a guide for several i nternational organizations (Organisation for Economic Cooperation and Developmment, International Association  of Universities...) and academic institutions, does not enjoy unanimous consent. The development of this phenomenon has led to diverse definitions, interpretations, and operational approaches. The characteristics (justifications, benefits, activities, results, actors) of internationalization differ from one institution to another (Knight, 2004). The partnership between GGU in San Francisco (USA), and the NASPW in Yaoundé (Cameroon), is a concrete example of the internationalization of higher education. It is important to note that international partnerships are one component of the internationalization  of higher education among others. At the university level, international partnership is characterized by a relationship between institutions located in different countries, a formal collaboration that can translate into general, specific, bilateral, or multilateral interuniversity cooperation, through which stakeholders seek mutual benefits (Leng, 2015; Tedrow and Mabobeka, 2007).",yahoo.fr,,,46.3144754,11.0480288
67,MODELLING INFORMAL WASTE COLLECTORS’ PERSPECTIVE FOR PLASTIC SOLID WASTES: ENERGY 4.0,@gmail.com,"Agent-based model, Energy and resource efficiency, Informal waste collectors, Industry 4.0.","Informal waste collectors consist of individuals, alliances, or waste dealers charged with the responsibility to sort, sell, and purchase recyclable materials. Technology has progressively been integrated into the energy sector. In this context “informal waste collections” for efficient and effective delivery of services.  The technological transformations witnessed across the globe can be attributed to  the underlying benefits of Industry 4.0 which offers numerous opportunities. This paper aims to integrate decision -support tools of Industry 4.0 for Energy and resource efficiency termed “Energy 4.0”. The real -time integrated impact assessment of energy protocols such as waste requires a skill that is valuable and can be estimated by quantitative approaches. Solid wastes can be converted into gas to produce energy hence described as one of the energy strategies. The methodology reviews the tools of Industry 4.0, specifically Agent-based simulation. To develop an integrated decision model suitable to explore the interactions and behavioral patterns of informal waste collectors’ perspectives on plastic solid wastes.  Research provides evidence of the use of agent-based models to explicitly associate and explore individuals’ behavioral attributes and etiquette with their social consequences. The outputs indicate expansive or complex relationships amongst the subsets in  context. The results enable relevant stakeholders to better discern the opportunities that the tools of Industry 4.0 provide for energy and resource efficiency. Keywords Agent-based model, Energy and resource efficiency, Informal waste collectors, Industry 4.0. Introduction Digital energy can be described as the free flow of real-time information exchanges. Waste-to-energy or energy-from- waste is the process of generating energy in the form of electricity and/or heat from the primary treatment of w aste, or the processing of waste into a fuel source . This makes waste an important component in energy management. Industry 4.0 has the potential to instantly identify and address sustainability issues aligned with the energy protocols. Energy 4.0 is a gen eral term for the collection of utility hardware, software, and technologies that leverage connectivity, data, and computing . This paper considers simulation as one of the protocols of Industry 4.0 to model informal waste collectors' perspective for an easy flow of information exchanges in real-time. The waste sector encompasses all industrial branches associated with waste management, waste recycling, and waste dumping (Owusu-Sekyere, et. al., 2022). The challenges in the waste sector are vigorous and include population growth, inadequate waste diversion, depletion of landfill airspace, and provision of unfunded waste services (Bui, et. al., 2022). In an African context, weak organizational structure s, inadequate budgets, lack of appropriate skills, lack of enforcement, weak legislation, corruption, low public awareness, conflict, lack of political will, and political instability are among many other reasons for the appalling management of waste (Debrah, et. al., 2022). The concepts of Industry 4.0 that include simulation are evident in emerging literature as suitable to develop an integrated decision-support model (Santos, et. al., 2022) . That is suitable to explore the interactions and beha vioral patterns of informal waste collectors’ perspectives on plastic solid wastes. Informal waste collectors are described as individuals or micro-enterprises responsible to intervene in waste management without being registered or formally charged with providing services for waste management (Sengupta, et. al., 2022). Research Gap",gmail.com,,,46.3144754,11.0480288
68,DIGITAL DETERMINANTS FOR INDUSTRY 4.0 READINESS: SUSTAINABLE MANUFACTURING,@gmail.com,"Industry 4.0, Simulation, Small and Medium-sized Manufacturers, Sustainability.","The COVID pandemic revealed the susceptibilities in manufacturing systems globally. Small and Medium -sized Manufacturers (SMM) are hugely impacted compared to multinational counterparts. SMM falls below certain assets, revenue, and employee thresholds but plays a key role in the stability of the global economy. Hence, sustainable practices are not only relevant to large manufacturing enterprises. Industry  4.0 enables the digital realization and management of sustainable manufacturing systems with new possibilities. This paper aims to investigate the digital determinants for industry 4.0 readiness. A mixed-method approach is considered to structure the inve stigations that facilitate simulating the digital determinants for Industry 4.0 readiness among small and medium-sized manufacturers. Simulation provides a tool suitable to investigate how a process may function as applicable in real -world scenarios. Specifically, a System Dynamics Model (SDM) is developed as a basis of the methodology and quantitative technique for the strategy development. The SDM promotes for effective feedback framework facilitating decision -making in establishing the context of this investigation. The use of a SDM provides originality to this investigation in comparison to current emerging research in a similar investigative context. The outputs from this paper demonstrate the suitability of the industry 4.0 concept specifically simulation to provide tactical and strategic business decision support for Small and Medium-sized manufacturers. The novelty in this paper allows for given sets of digital determinants in Small and Medium-sized manufacturers to be captured heterogeneously, connec ted, and recreated to interact with a capacity to transmit information and modify behaviors. Keywords Industry 4.0, Simulation, Small and Medium-sized Manufacturers, Sustainability. Introduction Small and Medium-sized Manufacturers (SMM) are essential contributors to the development of the global economy (Escoto, et. al., 2022). Rising costs & reduced revenue, managing expansion, securing & managing funds, coping with market competition, attractin g new customers, and skill & talent shortages are some of the multifaceted challenges that have influenced the sustainability of operational protocols with SMM (Escoto, et. al., 2022). The transformations of Industry 4.0 have triggered a paradigm shift in industries globally (Liu, et. al., 2022) . Emerging research is reviewing SMM preparedness to experience and sustain significant industry 4.0 changes (Liu, et. al., 2022). This paper is a valuable addition to current research by assessing the digital determinants for Industry 4.0 readiness. This is aimed at promoting sustainable manufacturing in Small and Medium -sized manufacturers. An Industry 4.0 readiness assessment accounts for an enterprise’s enthusiasm to execute changes. This includes taking on new ca pabilities, business models, and products (Ramanathan & Samaranayake, 2022). This paper explores tools of Industry 4.0 specifically simulation to develop a decision -support framework. Simulation provides an imitative representation of a process or system's functioning by means of another's functioning (Santos, et. al., 2022). A System Dynamics Model forms the basis of the entire investigation and quantitative protools for the strategy development. A decision-support framework in the form of a System Dynamics Model (SDM) is suitable to understand the dynamics and structure of the digital determinants for Industry 4.0 readiness in SMM. A SDM has demonstrated considerable value across various fields, assisting decision -makers to predict and understand th e dynamic behaviour of complex systems (Bayu, et. al., 2022).",gmail.com,,,46.3144754,11.0480288
69,AGILITY IN NEW PRODUCT DEVELOPMENT,,"New product development, agility, discipline, leadership, teams, prioritization, knowledge.","New product development (NPD) is a product company's most important function to perform and improve . Approaches and practices in new product development have evolved. These practices focus on efficiently identifying new product opportunities and rapidly iterating to determine the best new product options to advance. One common theme in modern NPD practices is agility. Whether the concept and practice of agility are focused on new product development processes or focused on the execution and delivery of the new products themselves, the ability to rapidly prototype and bring the various  people and departments involved in new product development together to work as an effective team is recognized as critical to successful new product development. This paper examines important elements of agility in NPD by revisiting new product development practices and then examining challenges to adopting them. The paper considers elements of new product development deemed critical to success in identifying new product opportunities and bringing them to market. Approaches to identi fying new ideas, gaps in organizational capability, and specific practices to ensure effective distribution of information on new product opportunities to the organization are also considered . The paper introduces the importance of prioritization and gover nance as well as leadership training and commitment in support of agile NPD . Finally, the paper addresses certain practical limitation s of agile practices in NPD, recognizing that the broad and diverse landscape of companies and organizations engaged in NPD present an equally broad and diverse set of structural and cultural challenges to adopting and maintaining agile NPD practices. Keywords New product development, agility, discipline, leadership, teams, prioritization, knowledge. Introduction: Building and Sustaining Agility in New Product Development Practices Agility is a theme that has been explored and exploited in various ways since the creation and publication of the Agile Manifesto in 2001. Rooted in manufacturing processes, quality practices, and  new product development, and built upon the collective experiences and thinking of a group of people primarily concerned with software development, the tenets of the Agile Manifesto were initially embraced by software development organizations  and extended to other technical and information technology-oriented organizations (Agile Alliance, 2001). Agile techniques and practices gained traction through the 2000s, sparking the growth of competing frameworks, certifications, and the spread of agile and agility as desirable traits for organizations well beyond the realm of software development. The 2010s saw the wider adoption of agile thinking and practices outside of software development and IT as agile theorists and practitioners expanded adoption of agile principles, the options for training and certification, and frameworks for scaling agile . In the 2020s, some outcomes and research support agility as a critical factor for organizations focused on attaining and sustaining growth and value creation. Th ose firms gain value from agility in all aspects of their operations and outpace their competition (Denning, 2024). In 2024, as even the most notable and ardent theorists and practitioners of agile thinking and frameworks reinforce the utility, practicali ty and effectiveness of agile practices in many verticals and at all levels of organizations, it is useful to recall that agile practices and thinking trace much of their inspiration and content  to concepts that were previously introduced in the realm of new product development. Companies who stake their futures on the success of their NPD organizations do well to note these concepts, revisit them, and where necessary, reinforce or adopt these practices and thinking. The best of these firms systematically and rigorously use and reinforce agility in new product development to maintain their competitive edge in all aspects of NPD, from ideation through product development and delivery. Therefore, an exploration of factors supporting the need and methods for achieving agility in NPD should start with a look at an important foundational definition of agility in NPD. In 1986, Hirotaka Takeuchi and Ikujiro Nonaka  wrote a seminal paper called “The New New Product Development Game”. In this influential Harvard Business Review article , Takeuchi and Nonaka focused on tactics used by successful and well-known companies to develop new products in ways that focused on executing the process",,,,46.3144754,11.0480288
70,THE VITRUVIAN PROGRAM: IDEAL ENGINEERING MANAGEMENT CURRICULUM FOR OPTIMAL STAKEHOLDER SATISFACTION,@uhcl.edu,"Curriculum,  Graduate Program, Stakeholder, Specializations, Content.","Under the umbrella of Engineering Management (EMGT), pursuing an ideal curriculum remains crucial to address the complex needs of the main stakeholders: students, industry, and degree programs. This study focuses on the degree program portion of the equilibrium by analyzing the ten ASEM -certified EMGT Graduate Programs. Results show that the main ten themes that emerge from content analysis are engineering, management, modeling, projects, organizations, technology, design, control, programming, and analysis. A comparison and integration with the ASEM program certification requirements leads to an ""ideal"" curriculum that covers the foundation of the Engineering Management discipline. Keywords Curriculum,  Graduate Program, Stakeholder, Specializations, Content. Introduction Students in any graduate program aspire for quality education and successful po st-graduation job placements. Meanwhile, industries seek fresh talent adept at fitting into job roles with or without the necessary training. Conversely, universities aim for high enrollment, quality students, satisfied alum ni, and fruitful collaborations with industries, including ample co-op and internship opportunities. Existing Engineering Management (EMGT) programs often provide a core curriculum with diverse specializations, yet the question is: Is there an ""ideal"" curriculum that satisfies the requirements of all stakeholders? For instance, the newly certified Master of Engineering Management and Leadership program at Rice University offers a Data Science specialization. In contrast, the University of Arkansas offe rs a Graduate Certificate in Engineering Management Analytics. By analyzing these programs, this study will distill critical insights that can inform the development of an ideal curriculum —the ""Vitruvian Program ""—that meets and exceeds stakeholders ' expectations. The outcomes of this investigation will pave the way for current and future EMGT education that optimally serves the needs of all involved parties, fostering a symbiotic relationship between academia and industry while empowering students to thrive in their careers. Literature Review In the fast-paced world of engineering management, staying ahead means constantly evolving. Technology advances rapidly, industry expectations shift, and global challenges emerge. This also means that the landscape of engineering management education is changing and continuously developing. For those pursuing a degree in this dynamic and organic field, the depth and breadth of the curriculum need to provide cutting -edge, state-of-the-art content for the graduates to be competitive in the job market. According to the 2022 ""Engineering and Engineering Technology by the Numbers "" report published by the American Society of Engineering Education (ASEE), there were 458 Bachelor's Degrees, 2,621 Master's Degrees, and 91 Doctoral Degrees awarded in Engineering Management. In 2021, these numbers were 375 for B.S., 2,836 for M.S., and 83 for Ph.D. In 2020, 668 B.S. degrees were awarded, with Master 's at 2,044 and Doctoral at 47. Notably, while undergraduate education in Engineerin g Management is on an upward trajectory, graduate education (Master 's, specifically) is following the nationwide downward trajectory. Council of Graduate Schools (2023) reports that domestic first-time enrollment declined by 4.7% between Fall 2021 and Fall  2022, as opposed to the international graduate first-time enrollment, which increased by 10.2% in the same time frame.",uhcl.edu,,,46.3144754,11.0480288
71,INTEGRATED MUNICIPAL INFRASTRUCTURE SYSTEMS: A UNIT PROCESSES APPROACH,@ncsu.edu,"Integrated WASH infrastructure, Line Management System, Matrix Management System","According to the Cybersecurity & Infrastructure Security Agency, there are roughly 153,000 public drinking water systems, more than 16,000 publicly owned wastewater treatment systems, 1,269 municipal solid waste landfills, 75 waste-to-energy incinerators, and roughly 7,250 permitted municipal separate storm sewer systems operating under a National Pollutant Discharge Elimination System (NPDES) in the US today. These municipal infrastructures each have their own engineering (physical plant, operation and maintenance, vehicles, and equipment ), administration (budget, human resources, customer relations), and governance (regulation, policies, service area/jurisdiction) divisions. This line management approach is fraught with redundancies and may deprive the municipality of management economies that could be derived from an integrated or matrix management system. In the integrated municipal infrastructure system, each of the four services —drinking water supply (DWS), wastewater and sludge treatment (WST), stormwater management (SWM), and municip al solid waste management (MSW) —would be brought under a management system. The matrix management system provides for coordinated scheduling of operation and maintenance activities, sharing of administrative resources, such as customer billing and human resource management software and personnel, and consistency in the interaction with state or federal regulators over compliance, fee structures, and negotiations over service-area jurisdiction with neighboring municipalities. This paper shows a comparative m odel of the current line management and the proposed integrated or matrix management of municipal infrastructure systems. It focuses on DWS, WST, SWM, and MSW as representative infrastructures and highlights where physical, administrative, and regulatory i nterconnections and interdependencies already call for an integrated approach to managing municipal infrastructure. Keywords Integrated WASH infrastructure, Line Management System, Matrix Management System Introduction Municipal infrastructure may be defined as the system of physical, human, and environmental components that work together to provide essential human services (EHS), such as drinking water, sanitation, energy, and transportation, to a human settlement. We define a municipality as any huma n settlement of multiple residents that has an organized system for providing access to EHS to its residents. It is important to note that municipal in this context is not synonymous with urban. Indeed, local governments in rural areas and villages with informal water committees qualify as municipal systems under the definition used for this study. This study will consider the services of Drinking Water Supply (DWS), Wastewater and Sewage Treatment (WST), Municipal Solid Waste Management (MSW), and Stormwater Management (SWM) as components of a representative municipal WASH infrastructure system. This paper will discuss the following issues: 1. The state of municipal infrastructure currently: i. Historical underinvestment in operation & maintenance ii. Growing urban population and demand",ncsu.edu,North Carolina State University,United States,35.77184965,-78.67408695452633
72,ADHERENCE TO COLORECTAL CANCER SCREENING USING NATIONWIDE UNBALANCED DATA,@unt.edu,"Colorectal cancer, cancer screening, unbalanced data, logistic regression.","The study examined the current status of the colorectal cancer screening adherence using the nationwide representative data from the 2018 Behavioral Risk Factor Surveillance System survey. We also addressed the unbalanced feature of the colorectal cancer screening data.  By fitting logistic regression models with the original unbalanced data, oversampling data and undersampling data , we evaluated the influence of the demographic, socioeconomic,  health- related or behavior -related factors on the compliance with FOBT  (Fecal Occult Blood Test) , colonoscopy, or sigmoidoscopy screening methods, and identified different strategies to tackle  the unbalanced data issues.  The adherence rate was 76.5% in 2018 among the 208,616 respondents that were included in the study. We found a number of factors that related to a lower colorectal cancer screening adherence, such as Asian or Hispanic, never ma rried, lower income, Indian health service, everyday/someday smoker, heavy drinker, etc. Unbalanced data feature affected analysis of FOBT and sigmoidoscopy adherence most significantly while posed little threat to the analysis of the overall screening adherence and colonoscopy adherence.  When analyzing the screening data associated with FOBT and sigmoidoscopy, researchers need be careful about the more severe unbalanced data structure and its consequence. Keywords Colorectal cancer, cancer screening, unbalanced data, logistic regression. Introduction The American Cancer Society estimated 104,610 new cases of colon cancer and 43,340 new cases of rectal cancer in the United States in 2020, among whom, 53,200 people are expected to lose their lives (Cancer.org, 2020). Combined together, the colorectal cancer is ranked as the second leading cause of cancer deaths, immediately after the lung cancer (National Cancer Institute, 2020).  In 2014, the National Colorectal Cancer Roundtable (NCCRT) set an ambitious goal, namely “80% by 2018”, aiming to have 80% of adults aged 50 and older regularly screened for colorectal cancer by 2018 (National Colorectal Cancer Roundtable, 2020). Although some health care providers have reached the 80% goal, no state today has hit  the target yet. Massachusetts took the top seat in the list with the 76% screening rate while national level averaged at 66% according to the National Health Interview Survey in 201 8 (National Colorectal Cancer Roundtable, 2020). Investigating the factors that hinder the patient adherence to colorectal cancer screening provides information and support to better strategically and effectively plan the initiatives that improve and advocate the screening compliance. Researchers have examined a variety of factors that affect patients’ adherence to the colorectal cancer screening. Although there is an extensive literature body on this subject, very few studies have provided an up -to-date comprehensive investigation for the adherence factors using a nationally representative dataset. Logistic regression is frequently adopted as the analysis method in the studies related to colorectal cancer screening. When applied as a classification algorithm, logistic regression works best when the two classes of the binary resp onse variable are represented equally in the dataset, however, this is frequently not the case for the colorectal cancer screening data (Oommen, Baise, & Vogel, 2010; Salas-Eljatib, Fuentes-Ramirez, Gregoire, Altamirano, & Yaitul, 2018). To the best of our knowledge, the problem of unbalanced data was not addressed by the previous studies associated with colorectal cancer screening. Our purposes of this study are 1) to evaluate potential factors associated with patients’ compliance to U.S. Preventive Service Task Force (USPSTF) colorectal cancer screening guidelines using a most recent nationally",unt.edu,University of North Texas,United States,33.2098926,-97.15147624977251
73,A SYSTEMS THINKING PERSPECTIVE FOR SUSTAINABLE HEALTHCARE,@uscupstate.edu,"Complex system governance, healthcare, sustainability, systems thinking","This paper explores the healthcare domain using a systems thinking perspective. Healthcare represents a broad array of services and places where healthcare occurs, including acute care hospitals, urgent care centers, rehabilitation centers, nursing homes a nd other long -term care facilities, specialized outpatient services (e.g., hemodialysis, dentistry, podiatry, chemotherapy, endoscopy, and pain management clinics), and outpatient surgery centers. In addition, some healthcare services are provided in private offices or homes. Systems thinking is a way of making sense of the complexity of the world by looking at it in terms of wholes and relationships rather than by splitting complexity into its parts. It has been used as a way of exploring and developing effective action in complex contexts, enabling systems change by drawing on and contributing to systems theory, management science, and cybernetics. This paper explores a possible intersection of healthcare and systems theory to identify how these two appr oaches might complement and perhaps enhance one another. Three primary aims are explored: (1) First, a short overview of the central tenets and essence of sustainable healthcare, (2) Second, a short overview of the central tenets and essence of systems thi nking/systems theory including strength and assumptions are discussed. (3) Third, the potential compatibility for deployment of systems theory -based framework (i.e., Complex Systems Governance) to enable sustainable healthcare is provided. The paper conclu des with opportunities and challenges for the integration of systems theory within healthcare. Keywords Complex system governance, healthcare, sustainability, systems thinking Introduction The motivation for this paper is to enrich the domain of healthcare. To say that healthcare systems are experiencing a dramatic shift is an understatement. While the domain of healthcare has been successful in the past, some challenges continue to confound the direction of the field , including p oor accommodation of patients’ needs , inability to assimilate the increasingly complex science base, slow adoption of information technology, failure to address growing consumerism among patients, and workforce shortages and discontent (Greiner & Knebel, 2003 ). A key feature of these challenges is increasing complexity. The traditional view of healthcare has been “health professionals are able to diagnose and treat, evaluate new tests and procedures, and develop clinical practice guidelines, all using the training initially received from their academic education and ongoing practice experience” (Greiner & Knebel, 2003). The reality is that “human memory becoming increasingly unreliable in keeping pace with the ever-expanding knowledge base on effective care and its use in health care settings” (Greiner & Knebel, 2003). It is from this perspective that we",uscupstate.edu,,,46.3144754,11.0480288
74,DRIVING INNOVATION THROUGH AGILE METHODS: COMPARATIVE INSIGHTS FROM THE EMBOK AND PMBOK,@ecu.edu,"Agile, Engineering Management, Project Management, Innovation.","This paper examines the role of agile methodologies in driving innovation within engineering management and project management. By comparing the frameworks of the Engineering Management Body of Knowledge (EMBOK) and the Project Management Body of Knowledge (PMBOK) , this study highlights how agile practices are integrated to enhance innovative thinking, streamline processes, and deliver value. The paper examines the unique focus areas of EMBOK and PMBOK , with EMBOK's emphasis on people and engineering processes and PMBOK's focus on deliverables and project execution. The study uncovers the similarities and differences in how these frameworks foster innovation through a comparative analysis. Practical recommendations and strategies are provided for integrating agile approaches to create a synergistic improvement in both fields , ultimately leading to organizational and product innovation. The paper also explores the impact of agile methodologies in building an innovative culture characterized by trust, autonomy, customer involvement , and continuous improvement. Future trends and developments in agile practices are discussed, emphasizing the need for engineering management to fully embrace these methods to drive effective and high-quality outcomes. Keywords Agile, Engineering Management, Project Management, Innovation. Introduction Innovation is critical in engineering and projec t management, enabling organizations to stay competitive and responsive to ever -changing market demands. Agile methodologies, characterized by iterative development, flexibility, and collaboration, have emerged as vital tools for driving innovation in thes e fields. The Engineering Management Body of Knowledge (EMBOK) and the Project Management Body of Knowledge (PMBOK) integrate agile practices (Project Management Institute, 2021; Shah & Nowocin, 2019). However, they do so in ways reflecting their distinct focuses on engineering management and project management. Agile methodologies originated as a response to the limitations of traditional systems development process models, such as the waterfall model (B. W. Boehm, 1981; Royce, 1970)  and the spiral model (B. Boehm, 1986) approaches, which have been commonly used in software development . Th ese tra ditional models’ linear and sequential nature often leads to inflexibility, delayed customer feedback, substantial risk  of project failure, and inefficiencies in resource utilization. In contrast, agile methodologies prioritize adaptability, continuous customer involvement, and iterative development, making them more suited to today’s dynamic project environments. The Agile Manifesto, published in 2001 by a group of software developers, laid the foundation for agile methodologies (Beck & et al., 2001) . It emphasizes values such as individuals and interactions over processes and tools, working software over comprehensive documentation, customer collaboration over contract negotiation, and responding to change over following a plan. These values, support ed by twelve guiding principles, have expanded beyond software development to various domains, including product development, information technology projects, and marketing campaigns. This paper explores how agile methodologies are integrated into the fram eworks of EMBOK and PMBOK and compares their approaches to fostering innovation. By examining the similarities and differences between these two bodies of knowledge, the paper provides practical insights and recommendations for practitioners. The goal is t o",ecu.edu,East Carolina University,United States,35.63285115,-77.48526724763182
75,THE HIDDEN OBSTACLES OF CONTINUOUS FLOW: A CASE STUDY,@buffalo.edu,"Continuous flow, Kanban, Obstacles, Implementation, Case Study","Continuous flow is a straightforward concept —easy to visualize but hard to materialize. This paper is not about sustaining but initiating a mindset of c ontinuous flow. Working professionals, in their attempts to streamline and orchestrate the flows of information, materials, and work, face a road of obstacles that range from the operations not being conditioned for continuous flow and “I can’t” mindsets f rom production associates that make it harder to flip the switch from a push, intermittent and bumpy operations to a pull, continuous, and smooth operations. We present a case of a company that was unprepared for continuous flow. This paper argues that rai sing awareness of those “hidden” or frequently neglected obstacles is the first step to overcoming them. Data from initial assessments of conventional lean metrics (lead time, cycle time, non-value-added percentage, walking distance, wait times, inventory levels, etc.) was pivotal to showing uncomfortable truths about disruptive operations. Leadership was pivotal in refocusing the attention on the future state with projected data. Overcoming one paradigm at a time and small, visible gains on the shopfloor were crucial. Listening sessions and discussion meetings were instrumental in overcoming one of the most challenging obstacles to continuous flow—the “I can’t” mindset. Keywords Continuous flow, Kanban, Obstacles, Implementation, Case Study Introduction This paper focuses on the concept of flow. It is a straightforward concept. Flow is easy to visualize, at least in a manufacturing setting: the product gets delivered on time when the customer needs it, which is easy to say but hard to do. When backlog ord ers have a long history, it is common to attribute them to insufficient production capacity, inventory, or a lack of qualified personnel. These constraints have forced companies to rethink their production planning, scheduling, inventory control, and resource utilization strategies. Just-in-Time (JIT) has proved effective in enabling flow. That is, delivering better productivity, better quality, and less inventory. It focuses on flow, delivering the product or component at the appropriate time and within a minimum cost (Shingo, 1981). JIT has been around for over forty years, and while it proved effective in Japanese companies, it is well known that US companies struggled to deliver similar benefits through JIT (White et al., 2010).  JIT has been adapted. The literature has various definitions from multiple perspectives, such as methodology, philosophy, and management practices. Nevertheless, in practice, getting started with JIT is still challenging. This is particularly true for small - medium organizations , motivating scholars to investigate the conditions for successful implementations (e.g., Lit reviews here). A key component of JIT is Kanban —which can be viewed as a practical methodology for managing and streamlining workflows, reducing waste, and ensur ing that processes produce only what is needed when it is needed in the amount needed (Japan Management Association , 1989 ). This is accomplished with visual signals. Thereby, Kanban is considered as one of the tools to implement JIT principles. This paper specifically focuses on preparing the conditions for implementing Kanban Systems. How do we make it work? What were the obstacles found during its implementation? How do you make it work even when management is committed to JIT but not their subordinates or people who do the work? How do we change the “I can’t” mindset to a “Let’s try”? To answer these questions, this paper discusses the hindering implementation factors and illustrates them with a real effort to implement a Kanban system from scratch.  To this aim, we first provide an overview of Kanban and discuss the limitations of critical success factors, followed by the case study highlighting the obstacles encountered and how these were overcome.",buffalo.edu,State University of New York at Buffalo,United States,43.00188805,-78.78521350495271
76,CONFLICT PROFILES AND TEAM OUTCOMES IN CROSS- DISCIPLINARY TEAMS: AN INTEGRATED LATENT PROFILE ANALYSIS AND NATURAL LANGUAGE PROCESSING APPROACH,@odu.edu,"Cross-disciplinary teams, conflict profiles, teamwork, sentiment analysis","Team conflict is a naturally emerging phenomenon resulting from individuals' interactions during proje ct execution. Cross-disciplinary teams can experience higher levels of conflict than single-discipline teams because of the increased diversity of knowledge and perspectives. Research has shown that team conflict can emerge from different types of disagreements (cognitive and interpersonal), which have different implications for team functioning. Past empirical research has focused on the impact of both conflict types independent from each other while overlooking their combined effects. This work examines t he conflict profiles resulting from the combined levels of interpersonal and cognitive disagreements and their association with team outcomes. The study had two primary goals. The first was to identify emerging team conflict patterns by adopting the confli ct state profiles approach. The second was to examine the differences in four affective outcomes across the conflict profiles. The latent profile analysis (LPA) results revealed three conflict profile categories. Statistical comparisons and sentiment analysis indicated that cross-disciplinary teams with different patterns of co-existing conflict types varied significantly in their task attraction, task commitment, levels of satisfaction, and sentiment about the team experience. This study advances the exami nation of conflict states in cross-disciplinary teams through a methodological approach that combines traditional measures with a natural language processing (NLP) technique to assess the affective component of teamwork. The findings provide insight into the relationship between conflict profiles and team functioning that can be used to develop tools and strategies to prevent and manage conflict. Keywords Cross-disciplinary teams, conflict profiles, teamwork, sentiment analysis Introduction Conflict is a complex phenomenon inherent to interdependent work (O'Neill & Mclarnon, 2018). Research has shown that conflict can vary in form and ou tcomes depending on the type of disagreements they emerge from. Despite different types of conflict naturally coexisting within teams, most empirical studies do not capture their combined effects. This paper uses a team profile perspective to examine confl ict and its impact on team affective outcomes in cross-disciplinary teams.  Cross-disciplinary collaboration involves individuals with diverse backgrounds and perspectives who are brought together to tackle complex problems (Comeau-Vallée & Langley, 2020) . The diverse knowledge, skills, and experiences within cross -disciplinary teams can enhance learning, inn ovation, decision - making, and other performance outcomes. However, these diversified team composition presents a more fertile ground for the emergence of conflicting cognitive and social interactions that can challenge team dynamics (Zhang & Guo, 2019). Such diversified groups require a comprehensive exploration of emerging conflict patterns and the repercussions on team outcomes. Affective outcomes are a key component of team viability that may not be reflected in traditional performance measurements (Pearsall et al., 2009). Affective outcomes evaluate team members' feelings and attitudes toward the te am and its tasks. The present study adopts the conflict profiles perspective to capture the combined presence of different types of conflict as predictors of affective outcomes in cross -disciplinary teams. This approach addresses gaps in prior research tha t examined different types of conflict independently.  Another contribution is the methodological approach that combines traditional measures with natural language processing to assess the affective component of teamwork.",odu.edu,Old Dominion University,United States,36.8862699,-76.30972478839735
77,FRAMEWORK FOR THE DEVELOPMENT OF DYNAMIC CAPABILITIES IN A DIGITAL TRANSFORMATION CONTEXT,@pucpr.edu.br,"Dynamic Capabilities, Digital Transformation, Strategic Competencies.","The development of skills that help achieve various goals and meet business needs poses a relevant challenge for companies across different sectors and sizes, particularly in a context of constant transformation, marked by exponential growth in the application of digital technologies. This s cenario demands actions to ensure that skills are effectively developed and applied to generate results, while organizations seek solutions so that they can better adapt to their environment. The objective of this study is to analyze how organizations can develop and apply dynamic capabilities to create a strategy that prepares them for the challenges related to digital transformation. Dynamic capabilities enable organizations to sense changes in their environment, seize opportunities associated with these changes, and continuously transform their resource base and operations, so that they sustain their competitive advantage. This includes the use of data analytics, organizational agility, and relational and adaptive skills. Starting from elements previously identified in a literature review, a framework for the development of dynamic capabilities in a digital transformation context is presented and discussed. Manufacturing companies may benefit from this framework by considering its elements for their develo pment strategies, especially in an environment where their products are highly impacted by emerging practices and technologies, what must be accompanied by appropriate action plans. Keywords Dynamic Capabilities, Digital Transformation, Strategic Competencies. Introduction Evolutions such as changes in consumer habits and relationships with supply chains, as well as new business models and technologies that emerge every year demand that organizations of different sectors and sizes adapt and address the changes necessary to achieve strategic objectives. This requires not only investments in the development of new products and services, but also efforts to ensure that its structure and organizational processes follow the context that surrounds it, to mitigate risks and address possible opportunities for obtaining strategic advantage. The main objective of this study is to propose a model that exemplifies how the Dynamic Capabilities mechanisms (Teece, 2007) guide strategies that are useful for companies to deal with the context of digital transformation, and how this context leads to the identification of new opportunities. The structure proposed by Warner and Wager (2019) can be considered as a reference for the model that will be proposed in this study. It demonstrates the development of dynamic capabilities in the context of digital transformation. The development of dynamic capabilities in a digital context are presented, contemplating the activities that lead to the identification of opportunities that the company must deal with, thus leading to the transformation of its resources a nd processes. Next, the strategic renewal of elements such as the business model and the organization's culture are presented.   The conceptual structure also contemplates the external triggers that companies need to deal with, such as competitors, customers, and technologies. One example of this type of proposal is the study published by Al Jabri, Shaloh, Shakhoor, Haddoud and Obeidat (2024), in which the impact of dynamic capabilities mechanisms on enterprise agility and the mediating effect of alignment in the information technology area are analyzed.",pucpr.edu.br,,,46.3144754,11.0480288
78,PROPOSING A SOCIO-TECHNICAL FRAMEWORK FOR AFFORDABILITY,@uah.edu,"affordability, socio-technical framework, organizational psychology","There are many interdependent components of an organization that contribute to the overall complexity, primarily due to their interconn ected nature. In complex organizations, internal and external interactions of the organization are often unpredictable when attempting to evaluate individual components in isolation. These interactions should be taken into consideration in a holistic manne r during evaluation rather than attempting to decompose into individual parts. When attempting to examine affordability in organizations, many of these interconnected organizational components may consist of behaviors that impact the overall financial stan ding of the organization. Traditional assessments of affordability often overlook these behaviors in favor of looking at the financial aspects such as costs, budgets, and/or resource allocation. This paper aims to propose a socio -technical framework of aff ordability considering both social and technical aspects in an organization that may contribute to the overall affordability of a project or program. Keywords affordability, socio-technical framework, organizational psychology Introduction Affordability is a key area of interest to organizations as it underlines the justification for continuation or cancellation of projects or  programs (Kneece, Jr. et a l., 2014; Miller & Murphy, 2020; Porter et al., 2015). Due to the abstract nature of affordability, being considered “affordable”  in an organization can be difficult. Moreover, organizational approaches currently lack a standard strategy to examine affordability in organizations. In addition, aspects of affordability that are not directly associated with qu antifiable metrics are difficult for organizations to preemptively account for. This poses a burdensome problem for organizations as management may be expected to address affordability, describe affordability constraints, and achieve affordability as an organizational goal during procurement without any clear idea as to what is considered affordable and what is not affordable (Redman, 2012). Within the domain of systems engineering, affordability is measured in terms of a cost analysis, taking into consideration cost as an independent variable (CAIV), life cycle cost (LCC), total ownership cost (TOC), and systems effectiveness (Redman, 2012). Other assessments of affordability have used metrics such as expected quantities and cost estimates (Sullivan et al.,  2015), planned budgets and cost estimates (Mortlock, 2023), and cost ratios of investment costs divided by personnel number as well as procurement costs divided by operation costs (Porter et al., 2015). While current affordability assessments adequately c apture technical and financial aspects of an organization, they do not take into consideration the social aspects of an organization that may also be contributing to the overall affordability of a project or program. Previous research has shown links betwe en organizational behavior and financial resources (Yeazitzis, 2024), highlighting an area of organizations often overlooked when evaluating affordability. Some assessments have referred to these sorts of aspects as indirect support costs and have recommen ded excluding these from assessment as they are not consistently captured by operating and support cost databases and are indirectly affected by the choice of organizational decision -makers (Boito et al., 2015). However, other assessments have purposefully included both direct and indirect costs during organizational assessments as the inclusion of both allows for a more robust methodology (Duffield et al., 2014). The purpose of this paper is to propose a framework in which the dimensions of affordability t ake into account both social and technical aspects, in turn providing a more holistic",uah.edu,University of Alabama at Huntsville,United States,,
79,AUDITORY SITUATION AWARENESS: THE EFFECTS OF HEARING PROTECTION DEVICES AND IMPACT OF TRAINING,@westpoint.edu,"Situation Awareness, Sound Localization, Training, Workplace Safety","Project managers are responsible for risk mitigation  throughout the entire lifecycle of the project. One major risk for many industrial and military settings with high noise exposure is a lack of a uditory situation awareness (ASA). The hearing protection devices that are required to prevent injury from noise exposure end up degrading the ability to locate sounds, including the sounds of potential hazards. Promisingly, studies have demonstrated the ability to improve sound localization performance while wearing hearing protection devices through training. The majority of th ese studies involve comparing the performance of a control group, who receives no training, with an experimental group that conducts localization training. This training requires time and resources that may not be available. The purpose of this study was to test if training with an over-the-ear hearing protection device through real -world exposure could improve sound localization performance at similar rates as training with a controlled auditory training system. The study found that real -world exposure wearing a hearing protection device improved sound localization performance but not to the extent that training via a regimented protocol using an auditory training system.  In addition, the real- world exposure trained group made little improvement in localization performance in sounds originating from behind the participant. Lastly, subjective ratings showed the real-world trained group and control group reported higher mean ratings in perceived accuracy in ability to locate sounds. These initial findings indi cate more time and focused real - world exposure training may be necessary to improve ASA in the absence of a regimented training program. Keywords Situation Awareness, Sound Localization, Training, Workplace Safety Introduction According to the National Institute for Occupational Safety and Health (NIOSH) , 24.6% of work-related severe injuries or illnesses  from 2011 to 2020 were attributable to contact with an object or equipment (NIOSH, 20 20). Furthermore, over 73% of the contact by an object or equipment were categorized as struck by an object or equipment or caught in or compressed by equipment or objects  (NIOSH, 2020). Many of these injuries occur in industries and occupations with noisy work environments that make it difficult to hear and locate the dangers. Workers operating in noisy environments are required to wear hearing protection devices (HPDs)  to reduce the risk of Noise -Induced Hearing Loss (NIHL) (Occupational Safety and Health Administration [OSH Act], 1970).  Unfortunately, the HPDs worn to protect the workers hearing have been shown to have a deleterious effect on sound localization reducing auditory situation awareness. This dilemma creates a challenge for project managers to reduce the risk of NIHL but ensure safety and survivability in noisy work environments. Literature Review Sound localization is an important factor of auditory situation awareness in industries and occupations where moving equipment and machinery are in close proximity to workers. Sound localization refers to the skill  used to tell the distance, direction, and location of a sound (Jeff ress, 1948). The human auditory system primarily uses two binaural cues to locates sounds within the horizontal plane , interaural time differences (ITDs) and interaural level differences (ILDs). ILDs are the differences in the intensity of sound arriving at the two ears as a result of frequencies above 3,000",westpoint.edu,,,46.3144754,11.0480288
80,DEMYSTIFYING THE ROLES OF ENGINEERING MANAGEMENT IN DIGITAL TRANSFORMATION AND INNOVATION IN SMALL AND MEDIUM SIZED ENTERPRISES,@purdue.edu,"Digital Transformation, Digital Literacy, Engineering Managers, Small and Medium Enterprises (SME), Innovation,","Digital transformation is essential for maintaining competitiveness in today's rapidly evolving global industries. Thi s paper explores the pivotal role of engineering managers in driving digital innovation within Small and Medium-sized Enterprises (SMEs), which are crucial to the U.S. economy, representing 44% of economic activity (U.S. Chamber of Commerce, 2023). SMEs often face challenges in adopting Industry 4.0 technologies due to limited resources, digital literacy gaps, and barriers to technology integration. Drawing on data from the World Bank, NSF, SBA, and BEA, this research investigates the drivers of innovation and digital transformation in SMEs. It applies the Dynamic Thinking framework (Pistrui et al., 2019) and Arena's Adaptive Space model (2018) to examine technological, human, and economic factors influencing engineering managers. The study identifies six le adership typologies —Business, Entrepreneurial, Enabling, Technology, Operational, and Customer Leadership —offering a structured framework to assess their effectiveness. By implementing the recommended metrics, SMEs can enhance managerial capabilities, foster innovation, and achieve strategic business objectives. These insights provide rigorous scholarly perspectives and practical models for engineering management and technical leaders to drive meaningful change and ensure organizational success in a competitive digital landscape. Keywords Digital Transformation, Digital Literacy, Engineering Managers, Small and Medium Enterprises (SME), Innovation, Dynamic Thinking, Industry 4.0 Technologies, Internet of Things, Workforce Transformation. Introduction Traditional commercial television took 13 years to reach 50 million households, internet service providers needed three years, and Twitter achieved this in nine months (Chui et al., 2012). Global industries are rapidly evolving to faster, cost-effective, high-quality methods to maintain a competitive advantage. Classic business models are being replaced by flexible ones due to Industry 4.0 technologies, including IoT, cloud computing, big data, AI, robotics, 3D printing, augmented and virtual reality, digit al twins, cybersecurity, and blockchain (Moreira et al., 2018). These technologies drive digital innovation, making supply chains efficient, automating processes, reducing infrastructure costs, and accelerating product and service delivery. According to Sc hallmo et al. (2017), digital transformation combines technologies, processes, and business models to create new consumer value, starting with product design and using data for efficient decisions. This transformation requires new workforce skills for appl ying Industry 4.0 technologies, analyzing data, and using AI to augment decision-making. Enterprises use digital technologies to improve operational effectiveness (Schallmo et al., 2018). Firms must reevaluate and reorganize technology, processes, and busi ness models to drive new value across the business value chain. There are 33.2 million SMEs in the United States, comprising 99.9% of all U.S. businesses (U.S. Chamber of Commerce, 2023). SMEs, defined as businesses with fewer than 250 employees, are the b ackbone of the economy and critical supporters of innovation. For SMEs to become digital companies, they need organizational readiness and digital capabilities to develop a digital business model (Uhl & Gollenia, 2016). The digital transformation process i s a radical technological project where managers play an important role (Kohli & Melville, 2019). Given their small size, revenue, and agility, engineering managers in SMEs are crucial for driving innovation and digital transformation. Unlike large firms, SMEs often lack a consistent cash stream for innovation and face funding",purdue.edu,Purdue University,United States,40.430028,-86.92642114650494
81,LEADERSHIP IN ENGINEERING AND BUSINESS DECISION-MAKING THROUGH DATA SCIENCE AND DATA STORYTELLING,@rice.edu,"Engineering leadership, business decision-making, data science, product development, data storytelling, narrative","Effective leadership in engineering has become crucial for driving innovation and achieving organizational success. Yet, new engineering leaders are expected to have an expanding set of skills necessary to lead their teams, make informed business decisions , and more recently , leverage the power of data science. This paper explores the intersection of engineering leadership and data science, focusing particularly on data storytelling as a catalyst for better business decision-making during the product develo pment process. This paper proposes an integrative data -driven decision-making framework that fosters creativity and collaboration in the face of technical challenges by drawing on principles of effective leadership in the context of the fourth industrial revolution. This framework combines rhetorical techniques in data storytelling, enabling leaders to transform complex decision problems into manageable situations by incorporating data with compelling narratives. Keywords Engineering leadership, business decision-making, data science, product development, data storytelling, narrative Introduction Modern businesses operate in an environment where sustainability, Industry 4.0 technology, and innovation are crucial for success (Lemaître, 2019; Sony & Naik, 2019). Integrating these three elements creates opportunities for engineers to help businesses navigate this complexity by playing a crucial role in decisions (Bell et al., 2011). To make effective decisions, engineers with leadership, decision -making, and data science competencies are needed both on teams and in management roles (Hernandez-de-Menendez et al., 2020; Day, 2022a). However, these decisions often depend on leaders’ ability to communicate data effectively, that is, to tell effective data stories (Kemp et al., 2023; Dessert  & Standaert, 2023). Thus, engineers and managers need approaches to business decision -making that integrate all of these factors , especially across the product development process . The main goal of this paper is to develop an integrative data storytelling model to improve the decision-making landscape for engineering leaders and managers. Leadership in Engineering During the 20th century, many general leadership theories were developed and studied, including the Great Man theory, Trait theory, Process leadership theory, Behavioral theory, Transactional, and Transformational leadership theory (Nawaz & Khan, 2016).  These leadership and associated management theories evolved to be more inclusive and adaptive to meet the demands of the 20th-century industrial revolutions and society (Taskan & Kubat, 2020).  As society became more complex so did leadership. To help address growing complexity, a key step in leadership theory was the transition from personal traits to learned competency-based models. Competencies are observable behaviors that lead to effectiveness in the workplace and the professional world (McClelland, 1998)  and include social, emotional, and cognitive skills and knowledge (Boyatzis, 2008).  The resulting researched competencies of e motional intelligence, systems thinking, and design thinking became exemplar 20th-century competencies for leadership and taught at leading business schools (Goleman et al., 2001; Senge, 2006; Aurenhammer, 2021).  Yet, as technology pushed on, society and the business world became even more complicated. The 21st century brought the fourth industrial revolution and the need for expanded leadership theories and competencies that incorporated Industry 4.0 technolog ies, such as artificial intelligence and data science (Oberer  &",rice.edu,Rice University,United States,29.716791450000002,-95.40478113393792
82,A STRATEGIC FRAMEWORK FOR MANAGING RECREATIONAL THERAPY INTERVENTIONS IN NURSING HOMES,@binghamton.edu,"Recreational therapy, Nursing homes, Strategic management","Recreational therapy (RT) plays a pivotal role in enhancing the quality of life for residents in nursing homes (NH) by addressing physical, cognitive, emotional, and social needs. RT promotes physical well -being through activities such as strength training, gait training, and flexibility routines. It supports cognitive maintenance with creative arts, puzzles, and trivia games, and fosters emotional well-being through music therapy, pet therapy, and community outings. Social interaction is enhanced via group activities, social clubs, and communal events which reduces isolation and depression. Effective strategies for RT interventions in NH require interdisciplinary collaboration, patient -centered care approaches, and ongoing evaluation and adaptation of interventions to meet the unique requirements and preferences of residents. Implementation steps incl ude training RT practitioners, integrating RT activities into daily schedules, and tailoring interventions to individual needs. Key success metrics include enhancements in physical mobility, cognitive function, emotional well-being, and social engagement. These metrics can be quantified by monitoring the frequency and participation rates of RT  activities, along with health indicators such as fall reduction , and feedback from resident satisfaction surveys.  This study uses literature review findings to develo p a strategic framework for managing RT interventions in NH to achieve beneficial outcomes. Keywords Recreational therapy, Nursing homes, Strategic management Introduction Recreational therapy (RT), also known as therapeutic recreation (TR), plays a pivotal role in enhancing the quality of life for residents in nursing homes (NH), offering advantages within a holistic approach to care that addresses physical, cognitive, emotional, and social needs ( Wilhite et al., 1999 ; Carruthers & Hood, 2007; Stumbo & Peterson, 2009; Datillo, 2015). Effective strategies for RT interventions in NH require interdisciplinary collaboration, person-centered care approaches, and ongoing evaluation and adaptation of interventions to meet the unique requirements and preferences of residents. By making the integration of RT into care plans at NH a priority, these institutions can optimize resident outcomes, promote well-being, create vibrant communities for enriching the lives of all who reside within them, and increase stakeholders’ satisfaction (Wilhite et al., 1999). RT serves as a catalyst for physical well - being by promoting strength, mobility, and flexibility through tailored activities, mitigating the adverse effects of sedentary lifestyles and age -related decline.  Further, RT contributes to cognitive stimulation and maintenance, by providing activities that challenge creativity, memory, and problem -solving skills, allowing NH  residents to experience a sense of accomplishment and reducing cognitive decline. Additionally, RT fosters emotional well-being by providing opportunities for self-expression, relaxation, and emotional catharsis; cultivating a sense of purpose and joy among NH residents; and reducing stress and anxiety ( Barca et al., 2009; Seitz et al., 2010; Aung et al., 2017 ; Creighton et al., 2017). RT is also known to serve as a social catalyst, generating meaningful opportunities for social interaction, companionship, and community engagement. These opportunities aid in combating feelings of isolation, loneliness, and depression commonly experienced within NH settings (Chen et al., 2014 ; Aung et al., 2017). This preliminary scoping study leverages scholarly literature to identify existing RT/TR practice models for collating strategic elements that could assist managers at NH in making effective decisions, in policy planning and development, and in managing RT interventions. This preliminary review paper highlights the significance of a composite framework (Exhibits 1a. & 1b.) that is useful for modeling effective strategies for RT interventions within NH settings and enabling some important benefits and outcomes. The study, however, is limited to a review of the current",binghamton.edu,State University of New York at Binghamton,United States,42.08779975,-75.97066065614858
83,SHARED LEADERSHIP EMERGENCE WITHIN DESIGN TEAMS,@uah.edu,"Leadership Emergence, Shared Leadership, Five-Factor Personality, Communication Styles, Coaching, Design Teams","Individual characteristics within design teams may be essential in determining leadership emergence. Our study aimed to explore these characteristics by examining leadership emergence during design team building exercises and exploring how individ ual traits such as personality, communication style, and response to group coaching might influence emergence. We also investigated the distinctions between appointed leaders and emergent leaders, recognizing that in times when an appointed leader needs he lp, another team member may step up and assume some of their leadership responsibilities, operating as an emergent leader within the team. The present study compares the differences between appointed and emergent leadership by their personality and communi cation styles; and hypothesized that group coaching was a valid intervention for increasing the likelihood of shared leadership dynamics. Our findings revealed that appointed leaders tended to be significantly more extroverted than emergent leaders on the personality scale. However, there were no significant differences between the two groups on other communication style. Additionally, we found that leaders were notably more likely to emerge from the post -coaching intervention. The findings on shared leader ship emergence behavior inform the development of theory and adoption of new managerial approaches to revolutionize and build systematic approaches to effective leadership interventions and prompts future research to further explore shared leadership emergence behaviors. Keywords Leadership Emergence, Shared Leadership, Five-Factor Personality, Communication Styles, Coaching, Design Teams Introduction Significant strides have been made in the methodological advancement of autonomous design teams through the study of leader emergence and the phenomena’s influence on performance outcomes. One can consider design teams in the context of engineering management, a multidisciplinary group of professionals that include engineers and other design specialists, who collaborate to develop, plan, and execute the design and technical aspects of an engineering project. Leaders of such teams may therefore be interested in identifying antecedents and be haviors that precede leadership emergence to stimulate the potential emergence of leaders for talent development or better understand how potential leaders might influence work teams and outcomes. In the context of managerial work settings, the term “leade rship” can be used as a broad-encompassing term to refer to the dynamic processes through which the influential individual(s) in a group exert a significant impact on overall work culture and strategy (Zhao et al., 2022). Leadership emergence refers to the degree to which a person not holding a position of authority could be perceived as a leader (Lee & Fahr, 2019). As is the nature of phenomena, more than one leader may emerge within a group even when another leader is present. Within traditional leadershi p structures with one appointed leader, more competent individuals may adopt additional leadership responsibilities and emerge as informal leaders (DeRue et al., 2015). This research lies within the interest of engineering management for current manag ers and entreats them to be conscientious of the antecedents (i.e., preexisting traits ) of emergent lea ders and their associated positive and negative consequences on team dynamic and performance outcomes. For instance, negative traits associated with a lack of functional skills, concern for the organization/members, honesty, and transparency can result in productive inefficacies, stagnated skill growth, and inefficient performance from the organization’s other members (Patel & Hamlin, 2017). In con trast, when in the presence of an effective leader, organizations observed significant increases in open communication and trust in addition to significant reductions in employee silence (Xu et al., 2023). A team’s performance can be strongly influenced by  the qualities (e.g., personality attributes, cognitive ability, etc.) and how they emerge as the team’s leader (Taggar et al., 1999). The current study aims to investigate the phenomena of",uah.edu,University of Alabama at Huntsville,United States,,
84,A SYSTEMS PERSPECTIVE AND VOSVIEWER NETWORK ANALYSIS OF FALL FATALITIES IN CONSTRUCTION,@colostate.edu,"Fall Protection, Construction, Systems Thinking, VOSviewer, Network Analysis.","Falls to a lower level consistently account for approximatel y 30% of work -related fatalities in the construction industry. Despite intensified regulatory, enforcement, and outreach efforts by the Occupational Safety and Health Administration (OSHA) and partners like the Center for Construction Research and Training  (CPWR) and the National Institute for Occupational Safety and Health (NIOSH), fall fatalities have remained unchanged. The authors reviewed the literature on falls in construction and systems thinking and construction and applied systems thinking methodologies and VOSviewer network analysis to explore these persistent challenges. The results reveal a limited focus on systems thinking for fall protection , primarily in the area of safety integration. Our findings indicate a substantial gap in applying systems perspectives to define th is problem, suggesting that r egulatory and outreach activities may be based on an inadequate understanding of the systems behaviors. The findings suggest a need for more robust systems-oriented research and management approaches for construction fall protection. Keywords Fall Protection, Construction, Systems Thinking, VOSviewer, Network Analysis. Introduction Falls to a lower level  in the construction industry are the cause of most work -related fatalities in the United States. 3,700 out of the approximately 10,700 construction fatalities from 2011 to 2021 were caused by falls to a lower level (CPWR, 2023) . Falls to a lower level is a detailed event or exposure category in the annual Census of Fatal Occupational Injuries (CFOI) that includes the following subcategories: fall from collapsing structure or equipment, fall through surface or existing opening, other fall to a lower level, and falls to a lower level, unspecified (BLS, 2024). In a review of over 23,000 fall incid ents in the U.S. construction industry over 20 years of Occupational Safety and Health Administration ( OSHA) data, Halabi, et. al. (2022) concurred with the U.S. Bureau of Labor and Statistics (BLS) data that 30% of all U.S. construction fatalities are caused by falls .  Exhibit 1 provides a ten-year history of fatal falls to a lower level annually using BLS data , falls to a lower level being the CFOI subcategory of the most impact to the construction industry based on the fatality data. Exhibit 1.  Annual Percentage of Fall Fatalities in Construction Caused by a Fall to a Lower Level . 0.00 20.00 40.00 60.00 80.00 100.00 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 Year %Fatal Falls to Lower Level",colostate.edu,Colorado State University,United States,40.570656650000004,-105.08539947634978
85,RELATIONSHIPS BETWEEN DETERMINANTS OF ORGANIZATIONAL COMMITMENT AND ORGANIZATIONAL CITIZENSHIP BEHAVIOR WITHIN UNIVERSITY STUDENT ORGANIZATIONS,@montana.edu,"Organizational commitment, organizational citizenship behavior, intrinsic rewards, extrinsic rewards .","This study investigated the relationship between organizational commitment ( OC) and organizational citizenship behavior (OCB) within university student organizations, addressing a gap in existing research. Building on Mottaz’s (1988) framework of intrinsic and extrinsic rewards as determinants of OC, this research delved into the unique dynamics of OC and OCB in diverse student organization types. Intrinsic (task based, meaning oriented) and extrinsic (social capital, involvement conditions, pay) along with person -organizational fit were examined within paid (university housing stu dent staff), pay -to-play (Greek life), and voluntary (student government) organizations. Through surveying student populations at two distinct institutions and employing multiple linear regression analysis, this study sought to investigate significant correlations between OC determinants and OCB across various organization types. The findings provide valuable insight on the predictive nature of specific determinants of OC on OCB, highlighting actionable recommendations for university student organization ad visors. Notably, a singular OC determinant correlation with OCB across all organization types was sought after to suggest the potential efficacy of targeted strategies for enhancing OCB. While conducted within a university setting, this study's implication s extend to business organizations as well, emphasizing actionable steps managers may take to increase OCB within their employees. Future research directions include exploring the efficacy of intervention methods aimed at influencing specific OC determinants, offering potential avenues for enhancing organizational performance and fostering cultures of engagement. Keywords Organizational commitment, organizational citizenship behavior, intrinsic rewards, extrinsic rewards . Introduction This paper aims to explore different determinants of organizational commitment (OC) and their relation to organizational citizenship behavior (OCB) across several types of  university student organizations (USOs). At the present time, in -depth research has been conducted pertaining to OC along with its outcomes and antecedents, but literature is limited regarding its linkage to OCB, specifically as it pertains to student involvement within USO’s. Both Meyer and Allen (1997) and Organ et al. (2006) have compiled an extensive amount of empirical data to highlight the positive correlations of OC and OCB with several work outcomes stemming from increased OCB such as decreased absenteeism, increased performance, greater senses of personal well-being and satisfaction, and overall organizational effectiveness. Though much of the research surrounds paid employees, other studies indicate that the variables to study work attitudes and OC are associated with similar outcomes for volunteers (Dailey, 1986). Furthermore, th e concept of OC as developed by Meyer and Allen (1993) was shown by Allen (2007) to be applicable within the university setting, though this research focused on commitment to the institution itself rather than specific student organizations. In the pres ent study, several determinants of OC  are examined based on an expansion of the work values and work rewards exchange perspective explored by Mottaz (1988). Mottaz highlighted congruence between work and personal values, intrinsic task rewards, and extrinsic social and organizational rewards to all have positive correlations with commitment. The relationship between these determinants, value congruence and rewards, and OCB will be explored with OC acting as a mediator. The USOs examined in this study will e ncompass voluntary, or a traditional student organization, paid, or a student-worker style organization, and a third type exhibited by Greek organizations",montana.edu,Montana State University - Bozeman,United States,45.6638859,-111.07928704602077
86,CRISYS COMMUNITY RESILIENCE FRAMEWORK AS A PRACTICAL GUIDELINE FOR DECISION MAKERS IN CASE OF NATURAL HAZARDS,@lamar.edu,"CRISys, Community Resilience, Data Analysis, Entropy Weight Method, Natural Hazard .","Natural hazards (e.g., floods, earthquakes) had significant impacts on global economies and societies. Effects of natural hazards have been intensifying due to climate changes. To better understand and evaluate the impacts of these events, a variety of com munity resilience frameworks have been introduced. These frameworks have various dimensions such as socio-economic, physical, and environmental dimensions that can help calculate and estimate the resilience score of a region. However, not all the framework s are easily applicable to a specific region. Thus, the aim of this study is to propose a custom framework named CRISys, based on the needs of a county, which was affected frequently by hurricanes in Texas. CRISys assesses and measures all the variables th at actively influence the socio - economic status of that county in Texas. The assessment of the variables was conducted by experts to apply the framework. Data was obtained from the US Census Bureau. Then, the Entropy Weight Method (EWM) was employed to compute the weight of each variable. Finally, the socio-economic total entropy resilience score was calculated. By revealing the resilience score, decision -makers will be able to plan and implement practical solutions to increase the total resilience in communities, leading to a decrease in recovery time and costs of a disaster. Keywords CRISys, Community Resilience, Data Analysis, Entropy Weight Method, Natural Hazard . Introduction Community resilience is defined as the ability of an ordinary community to prepare, plan, absorb and recover from an adverse event in timely and efficient way (Cimellaro, 2016). Exhibit 1 shows total performance of functional elements which operate normally in  an ordinary community which has been fallen suddenly by a disaster and will be recovered in recovery period and, Eq. (1) is mathematical representation of loss of resilience (LOR) and 𝑄0 is initial functionality, R(t) is total functionality at a given time, 𝑡0 is time of event occurred and 𝑡1 is time that system reco vered to initial state (Cimellaro, 2016). The adverse events can be natural hazard like hurricane, tornado, and earthquake or manmade such as transport accident, civil disorders, and power outage. Because of widespread nature of natural hazards, impacts of these events on the societies and economies are considerable (Pescaroli & Alexander, 2016). In addition, due to the climate change frequency and intensity of these catastrophic events are increasing considerably (Sarkodie & Strezov, 2019). For example, numerous structures sustained damage because of the combined effects of wave forces and debris impact during Hurricane s Katrina (2005) and Sandy (2012) in the US (Padgett, DesRoches, Nielson, Yashinsky, Kwon, Burdette & Tavera, 2008 ). Based on the National C enters for Environmental Information (NCEI)  Texas experienced more than 145 cases of disasters between 1980 and 2023, resulting in an average of over 3 catastrophic events annually within that geographical area (NCEI, 2023). Additionally, the cumulative cost associated with these natural disasters during the period spanning 1980 to 2023 exceeded 300 billion dollars, indicating an approximate yearly expenditure of 8 billion dollars  (NCEI, 2023). Exhibit  2a shows the frequency and Exhibit 2b demonstrates total cost of natural disasters in the US from 1980 to 2023 (NCEI, 2023). 𝐿𝑂𝑅 = ∫ [𝑄0 − 𝑅(𝑡)]. 𝑑𝑡 (1)",lamar.edu,Lamar University,United States,30.03889465,-94.07589293260585
87,COMMUNICATING THE INTENTION: A COMMUNICATION CHANNEL DESIGNED FOR EXCHANGING INFORMATION ABOUT INTENTIONS IN COLLABORATIVE SYSTEMS,@asu.edu,"Collaborative Systems, Communication, Decision-making, Game-Theory, Human Experiments","In collaborative systems, both technical and social factors influence decisions. While collaborative options may yield desired outcomes, a lack of understanding between parties can hinder collaboration. Effective communication facilitates information exchange and comprehension of partners' intentions, guiding designers towa rd collaborative decisions. This study examines the impact of a communication channel designed to share actors' collaboration intentions on the accuracy of information exchange and strategic decisions in a collaborative design process. The research uses secondary data from a human experiment involving a collaborative system design problem to assess the intervention's effects. The experimental procedure involves actors completing 30 paired tasks, earning or losing points based on joint decisions with their partners. Participants represent decision-makers from different car manufacturing companies. The experiment al data  includes 28 junior-year plus STEM undergraduate and graduate students completing paired decision-making collaborative tasks allowed to exchange verbal information and have an additional communication channel to share intentions . The usage of the communication channel is investigated using multiple statistical tests. Results indicate that actors share their intentions accurately  and honestly via the communication channel. Even in inaccurate cases, actors’ decisions shift significantly due to their partner's reported strategic intentions.  This research underscores the importance of communication for better management of collabora tive systems. Keywords Collaborative Systems, Communication, Decision-making, Game-Theory, Human Experiments Introduction Boeing, a leading aircraft designer and producer, manufactures only a few parts of its designs, while Apple, a top technology company, relies on partners to produce most of its products.  These examples illustrate that engineering has evolved from a cooperative to a collaborative process, making the management of collaborative systems critical. Collaboration is a strategic agreement between actors to work together in ways that surpass the capabilities of a single actor (Rechtin, 1992). Despite their significance, about half of collaborations fail (Kale, Dyer, & Singh, 2002). In collaborative design systems, outcomes depend not only on one's decisions but also on a partner's actions, making risk inseparable from the process (Avsar, Grogan, & Stern, 2022; Avsar, 2023). Even if collaboration promises higher gains, lack of understanding, insufficient common  knowledge, and the bounded rationality of the participants due to suspicion and distrust towards their partner can lead decision-makers to choose individual options (Zajac & Bazerman, 1991; Agarwal, Croson, & Mahoney, 2010). Enhanced communication is show n to increase successful collaborative outcomes (Agarwal, Croson, & Mahoney, 2010; Shin, Park, & Ingram, 2012; Rodan & Galunic, 2004; Adner & Helfat, 2003; Kogut, 2000).  This paper investigates whether actors use an information channel  accurately to communicate their strategic intentions, provided it is present in the collaborative system. The paper uses secondary data from a dissertation study  (Avsar, 2023) involving a human experiment on a collaborative system design problem. It investigates the eff ects of an intervention on outcomes, with participants representing decision-makers of different organizations aiming to increase their revenues through paired collaborative tasks. Participants can gain more by collaborating but face downside potential if it fails. Actors report their collaboration beliefs in each task  via a slider, and the communication channel provides information on the strategic intentions of both actors and the minimum required collaboration beliefs to choose collaboration.",asu.edu,Arizona State University,United States,33.4213174,-111.93316305413154
88,AN ECONOMIC ANALYSIS OF CHEMICAL VERSUS MECHANICAL APPROACHES TO LITHIUM-ION BATTERY RECYCLING: A CONCEPTUAL FRAMEWORK,@oregonstate.edu,"Lithium-Ion Battery, Battery Recycling, Mechanical Recycling, Pyrometallurgical","The rapid expansion of electric vehicles, portable electronics, and renewable energy storage systems has driven significant demand for efficient and sustainable recycling of Lithium -ion batteries (LIBs). For the initial process of separating a LIB cell, existing recycling methods mainly rely on chemical processes (hydro - or pyro-metallurgical method) to partially separate the components. Existing methods while effective for large -scale industrial recycling, are energy-intensive, environmentally polluting, and recovering limited valuable components, specifically lithium. A new method using mechanical approach to separate the LIBs into individual components for the initial recycling process has been proposed. Without chemical treatments or high energy for heat, the mechanical approach  separates LIBs into individual components, namely, anodes, cathodes, electrolytes, separator, and current collector, and allows for downstream recovery of critical materials such as Mn, Ni, Li, Co, Al, Cu, graphite, and PE or PP polymer. As the mechanical approach is fundamentally different from the chemical approach , an evaluation of the economic and environmental viability of the mechanical approach is needed. This study presents an initial framework as a foundation to compare the difference between the chemical and mechanical processes. Future work includes identifying further processes for material separation, standardizing batch sizes, quantifying inputs and outputs, and conducting economic analyses to derive insights. Keywords Lithium-Ion Battery, Battery Recycling, Mechanical Recycling, Pyrometallurgical Introduction The rapid growth of electric vehicles, portable electronics, and renewable energy storage systems has driven an increasing demand for efficient and sustainable battery technologies. Among these, LIBS have emerged as the leading choice due to their high energy density, long cycle life, and superior performance. However, the widespread adoption of LIBs has also led to significant challenges in terms of resource consumption and environmental impact, necessitating the development of effective recycling methods.  As technology progresses, recycling methods are anticipated to advance and become mandatory for all end-of-life batteries, given that only 10% are currently recycled or reused (Jorges et al., 2023). Traditional recycling methods for LIBs, such as pyrometallurgical technology, have been widely used in industrial settings due to their ability to handle large volumes of spent batteries. This high -temperature process facilitates the extraction of metals and other compounds but is also associated with significa nt energy consumption and environmental pollution. Despite its industrial applicability, pyrometallurgical technology faces limitations in efficiently recovering all valuable components, particularly lithium. In response to these challenges, innovative recycling technologies are being developed to enhance the efficiency and environmental sustainability of LIB recycling. One such advancement is the automated disassembly process designed specifically for pouch -type LIBs. This technology aims to improve the re covery rates of critical materials like lithium and cobalt while minimizing environmental impact and reducing recycling costs. The new automated disassembly technology is a machine -based process that efficiently disassembles and separates Lithium -ion battery cell components without using heat and chemicals. This technology is designed to maximize the recovery of valuable metals li ke lithium and cobalt, minimize environmental pollution, and reduce recycling costs.",oregonstate.edu,Oregon State University,United States,44.56305595,-123.28392337694638
