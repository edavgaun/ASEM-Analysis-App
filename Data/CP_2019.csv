,Title,email,KeyWords,Abstract,domain,Institution,Country,Latitude,Longitude
0,REFLECTIONS ON THE CHANGING WORLD OF EM PROFESSORS –PART I,@donkennedy.ca,"Virtual campus, professor evaluation, engineering education ","There is a saying that doctors make the worst patients. Perhaps EM professors are not looking internally to actively  affect the direction their careers are going. Major changes in how societies function can follow paths that are not  intentionally directed or can be based on decisions that are not fully researched to explore the possible outcomes.  Consider how the conversion to auto mation to replace manual labor is rapidly proceeding without a clear vision of  what the short term impacts are or what will replace the displaced jobs. The makeup of the attendees of ASEM  conferences has changed gradually over time. This, of course, follow s the introduction of new people, but also  shows up in changes to the types of jobs the long standing members now hold. A review of ASEM authors shows an  increasing number of non-tenure track faculty. The changing roles of professors and the expectations o f students  over the past half century are outlined. Duration of employment at any one institution has decreased. The methods of  evaluating performance have moved with the rise of the concept of student as customer. The goal of this paper is to  reflect on t hese changes in the world of academia and the potential long term consequences.  Are the students the  best evaluators of professor performance? The trends in academia are presented including a move away from  academic diversity and the commoditization of programs.  Keywords  Virtual campus, professor evaluation, engineering education  Introduction  The goal of improving the education system can be taken to be universal ly held . The key problem is how the  spectrum of opinions and lack of clear understanding of unintended consequences prevent a unified approach on  how exactly to change for the better. Peter and Hill (1970)  recognize this desire to improve the education system is  strong enough to frequently generate large donati ons of cash to fix the system. According to them, this typically  results in large infrastructure expenditures  on items such as new buildings or extensions for more classrooms  as a  way to spend the funding since reaching a consensus  on what else can be done  is near impossible to achieve . They  termed this as an organizational  edifice complex. The world has changed considerably since 1970 , but we  suggest  that the level of understanding on what to do to better manage education has not improved much.    A theme of many traditional management texts  is that the past is a reliable guide for decision making since  basic human behavior has changed little over the span of history  (Drucker, 2002). There are an increasing number of  arguments, however, that perhaps modern situations are creating systems and behaviors without a clear precedent to  guide us.  The innovations promoted by Frederick Taylor (1911) were generally based on studying one particularly  strong manual laborer whose work patterns  for lifting pig iron may be difficult to extrapolate to a team writing code  for a new video game.  Similarly, practices accepted as tried and true  in past decades  are now challenged for  relevancy in many fields such as advertising (Zyman & Brott, 2002) , career planning (Lang, Kern, & Zapf, 2016) ,  productivity (Kennedy, 2018), information and finance (Lewis, 2001).   Coinciding with these general changes, t here is also a major change impacting the careers of professors.  When certain practices are widely followed at a particular time in history , it is typical to  not explicitly record them",donkennedy.ca,,,46.3144754,11.0480288
1,"ENGINEERING EDUCATION, SKILLS AND INDUSTRY ALIGNMENT –COMPARATIVE ANALYSIS OF THE UK AND USA",@lsbu.ac.uk,"Engineering Education, Skills & Knowledge, Industry Alignment, Engineering Management. ","There is an ongoing debate on engineering education, future skills development and alignment of universities with  industry. This debate includes discussion on whether graduating engineers have the required skills and competencies  to make a positive impact in industry and the wider workplace. Academia is focused on maintaining the technical  standard of engineering education, while industry seeks to recruit engineering graduates that not only have a solid  grounding in the engineering fundamentals but also have effective professional skills, such as communication, team  working and project management skills. Additionally, there is a need to consider how engineers can harness innovation  and creativity as well as leveraging the emerging opportunities associated fr om digitization. In this regard there have  been a series of reports that have investigated this area and many such reports tend to be issued at the national level.  Therefore, this paper reports on a comparative analysis of studies and reports from the UK and USA that have focused  on engineering education, skills development and industry alignment.   This analysis has identified various insights  and keys areas to be developed in the context of the Engineering Management Body of Knowledge. The paper  concludes with recommendations on how the field of engineering management can be positioned to address the  challenges and opportunities that have been identified.  Keywords  Engineering Education, Skills & Knowledge, Industry Alignment, Engineering Management.  Introduction  Engineers need to have a full grasp of the technical competencies across traditional engineering science areas,  including numerical and engineering design skills as well as the ability to be effective in knowledge -driven  organizations through, for example, working as part of teams and on engineering projects. But will this be enough for  the engineer of the future? Indeed, in 2016 the World Economic Forum (WEF) estimated that by 2021, around one - third of skills (35%) that are considered important in today’s workforce will have changed. We are also potentially on  the cusp of a new industrial revolution and e ngineers continue to be presented with challenges and opportunities  associated with adopting new technologies, for example, those associated w ith Industry 4.0  (Liao et al., 2017).   Although do  today’s graduating engineers have the knowledge and skills to capitali ze on such technological  developments? Moreover, are  existing pedagogic models in universities adequate to support the development of  graduate engineers so they can harness these technologies, or do we need new approaches to teaching practices?   In regard to engineering education,  academia faces a number of  challenges, including the need  to ensure  professional and design skills can be ad equately integrated with discipline -specific content  in order to meet the  demands of both graduates and their employers ( Mitchell et al., 2019).  There is of course a need to ensure strong  coverage of the engineering fundamentals, provision of more real -world engineering design and operational areas,  such as quality engineering; in addition to more frontier oriented engineering areas as well as providing opportunities  for students to gain improved communication, team-working, critical and creative thinking and problem-solving skills  (Felder et al., 2000) . Moreover, many authors point to a mismatch between skills possessed by graduates and those",lsbu.ac.uk,London South Bank University,UK,51.4979,0.102
2,IMPLEMENTATION OF PERFORMANCE MEASUREMENT SYSTEMSIN NONPROFITS: QUALITATIVE CONTENT ANALYSIS,@pucpr.br,Implementation; Performance Measurement Systems; Nonprofits; Content Analysis. ,"The defining feature of nonprofit organizations is the legal restriction  generat financial profits. Work initiatives and  guidelines are instead geared towards social and non -financial issues. Amongst others, the development of services  that aid society, the main beneficiary of their activities, stands out. In this context, it is important to design  and  implement performance measurement and management systems that attend  stakeholders demands for information .  Nonprofits must also optimize their levels of competitiveness, mainly when raising funds, which often come from  governments. A Perf ormance Measurement System (PMS) contains indicators that measure the results of costs,  financial operations, productivity and user satisfaction. There is a growing list of performance tools developed for  use in the private sector but adapted for rollout in social organizations. This work develops a content analysis in a  sample of scientific paper,  the data was originally drawn from a previous systematic literature review, and the  present study focuses on identifying a  set of factors that influence s the imp lementation phase of measurement  system projects in nonprofits. The evolution of the results guides and aids the development of measurement systems.  This aspect lead to a set of recommendations that could improve success rates in implementing performance  measurement systems.  Keywords  Implementation; Performance Measurement Systems; Nonprofits; Content Analysis.  Introduction  The defining feature of a nonprofit  organization is restriction on financial profit, with work focused instead on  generating social value (Valentinov, 2011), which is achieved by developing measures that benefit society.   Nonprofit sector management models are grounded in non -governmental guidelines. Relevant examples of such  organizations are: professional institutes and associations, foundations and philanthropic institutions, cooperatives  and public administration departments. In most cases, civil society and government bodies are responsi ble for  overseeing the transparency of results regarding costs, expenditure and additional internal information (Arena et al.,  2015, Mehrotra and Verma, 2015). Common sources of financial income are governments and private companies.  As such, it is important for organisations to broaden their competitive advantages, in order to administer and raise  financial funds, thereby ensuring financial sustainability.",pucpr.br,Pontificia Universidade Católica do Paraná,Brazil,-25.4523677,-49.25132119969333
3,A MIXED METHOD STUDY OF INFRASTRUCTURE RESILIENCEEDUCATION AND INSTRUCTION,@westpoint.edu,"Infrastructure, resilience, education ","As the frequency and severity of natural and man-made disasters increases, the importance of improving the resilience  of complex infrastructure systems in an uncertain environment is increasingly critical. Proper training and education  are key components to addressing this issue, but it is unclear how and where modeling under uncertainty, infrastructure  systems management, and resilient systems are integrated into the standard undergraduate and graduate engineering  management curriculum. This re search uses a mixed method to determine whether and at what level engineering  managers receive instruction regarding the implementation of tools and techniques to improve infrastructure  resilience. A review of current courses and content informs a systems-thinking approach to resilience and investigates  how the topic of infrastructure resilience is being taught. The results of the study identify gaps in existing engineering  management curriculum with respect to the topic of resilience. The findings from these results can be used to by the  engineering management educator to provide coursework and training that can be used to lead teams that design, build,  analyze the resiliency of current infrastructure systems , or restore damaged infrastructure systems to th eir original  state.  Keywords  Infrastructure, resilience, education  Introduction  Critical infrastructure systems such as hospitals, transportation networks, and utility systems, are  becoming increasing  more complex and interdependent while at the same time there has been a significant increase in operational  uncertainty of these systems due to either natural or man- made disasters. Infrastructure resilience is the concept that  addresses this uncertainty though it has been defined in many ways by a host of experts across a vast cross-section of  disciplines. This research utilized its previous work on an integrative literature review to define resiliency  as “an  ability to prepare for, wi thstand, and/or recover from adversity, emergencies or failures in a timely manner and still  be able to function at least nominally while minimizing potential losses in the system” (Wilt, Long, & Shoberg, 2016).  Due to the complexity of these infrastructur e systems  and the various engineering and other disciplines  involved with the design and operation of a complex  infrastructure system , solutions to improve infrastructure  resilience require a multidisciplinary approach and makes the application of operational concepts of engineering  management towards understanding and improving infrastructure resilience more important to maintaining, restoring,  and adapting critical infrastructure to deal with disasters. It has been argued that engineering management programs  provide the leaders needed to manage these complex and interdisciplinary efforts  (Perry, Hunter, Currall, &  Frauenheim, 2017), so proper training and education of engineering managers in infrastructure resilience is critical to  enable them to successfully lead infrastructure resilience programs and projects .  However, at this time, it is unclear  how and where modeling under uncertainty, infrastructure systems management, and resilient systems are integrated  into the standard engineering curriculum.  This research uses a mixed method approach to determine whether and at what level engineering managers  receive instruction regarding the implementation of tools and techniques to improve infrastructure resilience. The   mixed methods research utilized a qualitative search of current courses in select schools with accredited engineering  management programs, either by the American Society  for Engineering Management (ASEM) or the Accreditation",westpoint.edu,United States Military Academy West Point,United States,41.3915,-73.956
4,DETERMINANTS TOWARDS A FRONTLINE SUPERVISOREFFECTIVENESS MODEL FOR ENGINEERING TEAM-BASEDORGANIZATIONS,@sun.ac.za,"Frontline supervision, Engineering Work-Teams, Effectiveness, Structural Modeling  ","The role of frontline supervisors is often neglected in engineering management research. Studies tend to focus on  senior management or treat management as a homogenous group. A model that conceptualizes the frontline supervisor  effectiveness in an engineering team -based environment  is proposed. It is envisioned that the study approach will  follow three iterative phases to develop and validate a  Frontline Supervisor Effectiveness Model. This paper reports  on the first phase of the research , whereby a conceptual model is developed and presented based on a systematic  review of the literature.  The study found five determinants of supervisory effectiveness and presents these  determinants as a structural model  to illustrate the hypothesized inter -relationships and recommends direction for  future research.   Keywords  Frontline supervision, Engineering Work-Teams, Effectiveness, Structural Modeling   Introduction  Engineering organi zations are faced with a challenge to cope with competition in  global markets while achieving  product quality, productivity and optimal use of resources. Essential to meeting this challenge is the use of work teams.  There has been a rise  in employing work teams across a wide range of industries. This trend  is associated with the  broader changes in the world of work and organizations responding to competitive challenges and organizational needs  of flexibility and adaptation (Delgado Piña, María Romero Martínez, & Gómez Martínez, 2008) . As noted by Gil,  Alcover & Peiró (2005), it is not surprising that research in a more diverse range of fields has increasingly focused on  the effectiveness of work teams in organizational contexts.  However, team -based systems in the engineering world ha ve posed a challenge for the management of such  organizations to provide the work teams with an organization al environment that supports their needs. The literature  about the management and the supervisory outcomes of these work teams is limited and is primarily based on the case  studies of manufacturing plants (Batt, 2004; Hertle, Siedelhofer, Metternich, & Abele, 2015). The frontline supervisor  (FS) is the person who works closest to the work team members and is tasked with the responsibility of directly  influencing the work team effectiveness. FS are the most significant point of leverage f or team-based organizations  since they work closest to the operating core and hence in high performing organizations, FS are key actors who play  important roles (Zhou & Liu, 2013). The literature pertaining to the role of the FS is however sparse.   This paper aims to collate,  review and synthesi ze available scholarly work on  the FS role  in engineering team - based organizations , identify those factors that determine their effectiveness and to explore the interrelationships  between those factors.   Frontline Supervision  This section pays special attention to frontline supervision by reviewing the terminology and definition of frontline  supervision, and by discussing the concept of effectiveness in the context of team-based systems.",sun.ac.za,University of Stellenbosch,South Africa,-33.8842684,18.62729953211983
5,ENHANCING LEAN PRODUCT AND PROCESS DEVELOPMENTCAPABILITIES USING CURRENT PRODUCTION VALUE STREAMS,@tramgroup.com,"Lean Product and Process Development, Value Stream Improvement ","Lean Product and Process Development (LPPD) proficiency represents the next frontier for many manufacturing  organizations in their quest for excellence. However, these firms needn’t wait for the next new product cycle to  practice LPPD capabilities.  The purpose of development is to create profitable operational value streams. Manufacturing organizations  use Value Stream Mapping to delineate value added process elements and waste, thereby identifying targets for  continuous improvement activities. Practitioners can then address these targets one at a time using the Toyota  Improvement Kata, the iterative practice of making hypotheses based on observations, and learning through  experimentation toward each successive target condition. However, continuous improvement activities sometimes  suffer in a manufacturing operation, when projects have a broad scope and where daily production issues receive  resource priority.  Manufacturing firms can simultaneously accelerate their improvement activities and enhance their  development capabilities by applying LPPD principles to current unprofitable value streams. The Toyota  Improvement Kata and LPPD are congruent; at the root of both is the socio-technical activity of creative problem  solving using scientific thinking.   This reflective case study illustrates how an auto parts supplier applied LPPD principles to solve an  ongoing production problem based on the premise that an unprofitable value stream is failure of the development  process. A superior solution was created and implemented quickly, and the organization was able to execute a  learning experiment in LPPD implementation in advance of a new product cycle.   Keywords  Lean Product and Process Development, Value Stream Improvement  Introduction  In a recent SlideShare presentation ( Rother & Liker, 2018) , Mike Rother and Jeffrey Liker reflected on what they  have learned in the 20 years since the publication of Learning to See , the seminal work by Rother and John Shook  that introduced Value Str eam Mapping (VSM) to the Lean Community  (Rother & Shook, 1999) . VSM gave  practitioners a method to graphically depict their operations so that they could clearly discern value added elements  from waste, for the purpose of improving their processes by increasing the ratio of the former to the latter. To  describe their desired lean condition,  practitioners could create a future state map of the operation, where value  added elements were retained and waste was minimized or eliminated. A chronic problem among practitioners,  noted by Rother and Liker in their reflection, became how to proceed from t he current state of operations toward the  desired future state, as proposed action plans were mired in uncertainty and usually involved many stakeholders  within the supply chain. The solution to this problem arrived ten years later with the publication of Toyota Kata,  which gave these same practitioners a method to infuse scientific thinking throughout their respective organizations.  Implementation uncertainty would be gradually eliminated through continuous iterations of knowledge building  experiments, each one a step toward the lean ideal state as illustrated by the future value stream map (Rother, 2010).",tramgroup.com,,,46.3144754,11.0480288
6,INTEGRATING SET-BASED DESIGN INTO THE DEPARTMENT OFDEFENSE ACQUISITIONS SYSTEM TO INFORM PROGRAMMATICDECISIONS,@uark.edu;,"Set-Based Design , Defense Acquisition, Decision Analysis, Model-Based Systems Engineering, Uncertainty ","Over the years, the Department of Defense (DoD) has implemented several significant modifications to its acquisition  process with the goal of producing timely and cost -effective systems.  These changes, h owever, have done little to  curb major design problems, delays and cost overruns to programs.  Many DoD acquisition programs use Point-Based  Design (PBD) approach es in system development,  frequently resulting in premature design decisions  resulting in  subsequent schedule delays, and cost overruns.  Delays and increased costs are a result of the time-consuming activities  undertaken to fix the selected PBD solution prior to the resolution of key technology and budget uncertainties.  Set - Based Design (SBD) is a concurrent system design and analysis alternative to PBD, which systematically resolves  program uncertainties early in the  design phase,  potentially reducing the need for costly and inefficient redesign  activities.  In application, SBD concurrently evaluates multiple system and sub -system design concepts, while  simultaneously resolving requirements  and design uncertainties.  Commercial manufacturing and defense related  industries have successfully employed SBD in product development (PD). This success suggests that a DoD feasibility  and integration assessment of an SBD process for PD of a large-scale DoD acquisition programs i s required.  This  research reviews current DoD  acquisition processes, provides a strategic framework for SBD integration into these  processes, and identifies critical integration challenges for  future research.  This paper concludes that integration of  SBD into major DoD acquisition processes is both feasible and economical, as well as a credible and defensible  methodology for making complex design decisions under uncertainty.  Keywords  Set-Based Design , Defense Acquisition, Decision Analysis, Model-Based Systems Engineering, Uncertainty  Resolution, Tradespace Exploration  Introduction  The United States Department of Defense ( DoD) currently invests trillions of dollars into weapon system research,  development, and acquisition  (United States Government Accountability Office, 2017) .  Responsibility for this  significant investment lies with an equally large and complex defense acquisition system; a system that has  periodically implemented significant changes to address the root causes of costly systemic problems and risks.  Since  the 1990s, the Government Accountability Office (GAO) has identified  DoD weapon system acquisitions as a  high- risk area.  The reason for this perpetual designatio n lies with in a history of significant  and unanticipated cost and  schedule growth, resulting in numerous Nunn- McCurdy cost breaches (United States Government Accountability  Office, 2013) .  To addre ss these continuing  issues, the DoD published Department of Defense Instruction ( DoDI)  5000.02 for the Operation of the Defense Acquisition System.  This document significantly increased emphasis on  affordability and trade -off analyses, with complementary systems engineering activity early in the acquisition life - cycle (Cilli, Parnell, Cloutier, & Zigh, 2017) .  The updated requirements contained in DoDI 5000.02, underscore the",uark.edu;,University of Arkansas,United States,36.0687,-94.1748
7,ECONOMIC FEASIBILITY OF THE RESIDENTIAL APPLICATIONS OFPHOTOVOLTAICS IN ALASKA,Missing,"Economic feasibility, residential application, photovoltaics, Alaska ","Photovoltaic (PV) is often considered a not -so-attractive renewable energy option in Alaska because of the limited  daylight and harsh weather during wi nter times, but many people are misinformed about PV systems in this region.  This study reviews the economic feasibility of the residential PV systems in Alaska. The economic evaluation in this  study looks specifically at a region of Alaska known as the “R ailbelt”. Within this region, an overview of the  residential electric rates, installation costs, the efficiency of PV systems and other characteristics that could impact  the economic analysis are discussed. Finally, a model that takes into account the vari ables noted above is used to  determine the most cost-effective size of a hypothetical residential PV installation. The model shows that if $18,753.08  was initially invested in a PV system, its net present value of the savings would be $6,749.55. This means you would  recover the initial investment and make an additional $ 6,749.55 and it appears that the PV system is a good  investment. The analysis used a hypothetical PV installation with loads that were based on the average usage of a  residential meter in ur ban Alaska. These type of loads and other assumptions made in the analysis may not apply to  every residential PV installation, but this analysis is for a typical residential installation and most of the data and the  results should be a good representation of what a residential installation would see. These numbers indicate that a  residential PV system makes economic sense.  Keywords  Economic feasibility, residential application, photovoltaics, Alaska  Introduction  The earth receives enough solar energy from  the sun in less than two hours to power all the world’s energy needs   (Tsao, Lewis, & Crabtree, 2005).  The sun provides the heat and light necessary for life as we know it to exist.  For  centuries people have searched for ways to harness this energy.  Thi s paper look s at the history of harnessing that  energy through photovoltaics (PV), how PV works, and how economically viable PV systems are in the urban areas  of Alaska.   But not a lot of people think the PV system is the best option in Alaska because it is cold and dark. However,  the electric rates in Alaska are higher than the national average by a significant margin. In addition, the cost of PV  systems has decreased  over the years. With electric rates in Alaska higher than the national average and the co st of  PV systems coming down, it makes one wonder if installing a residential PV system makes economic sense.   Photovoltaics is the conversion of light into electricity using semiconducting materials . Solar cells make up  the solar panels. These panels are then interconnected with wiring and the voltage is changed from DC, the voltage  that is generated in the solar cells, to AC by inverters. So solar panels, wiring, inverters, fuses, and a disconnect switch  are what typically make up the residential PV system we have today.  Following sections are structured as follows. Next section is a literature review, which illustrates the limited  analysis of the financial viability of integrating PV into the urban areas of Alaska. The next sections are the research  methodology and the economic evaluation of residential PV in urban areas of Alaska. The following section concludes.  Literature Review  The amount of literature and analysis on the financial viability of integrating resid ential PV into the urban areas of  Alaska is limited. T here are significant researches on international, national, and rural PV applications. T here is not",Missing,,,46.3144754,11.0480288
8,"HUMAN ERROR, THE CAUSE OF MAJOR INCIDENTS THATOCCURRED WITHIN THE OFFSHORE OIL AND GAS INDUSTRY",Missing,"Human error, Offshore Oil and Gas industry, Major incidents, Root Cause, Human error evaluation framework. ","Human performance and behaviour are viewed as contributing factors in most accidents within process plants.  If the  rate of accidents occurrences is to be reduced, Gambetti et al (2012) advises that human factors be better understood  and that understanding be broadly applied. The main objective of this research study is to investigate whether human  error is the cause of major incidents that occur red within the offshore oil and gas industry. The investigation is  conducted via a human error evaluation framework that is developed by the research team, specific to analysing  incident’s causes within the offshore oil and gas industry. The secondary aim of this research is to investigate whether  the propositioned human error evaluation framework is an adequate tool in conducting an incident investigation, with  the aim of finding the cause of the incident. A total of eight case studies are evaluated via a human error evaluation  framework in order to determine specific causes. The results indicate that most incidents that occurred within the  offshore oil and gas industry are due to specific factors, namely management systems; work environment and human  factors. The results from the evaluation indicates that management systems are accountable for 47% of offshore oil  and gas incidents, while work environment factors are responsible for 27% of incidents of offshore oil and gas  industry. Human factors is responsi ble for 27% of offshore oil and gas incidents. To successfully address human  failure issues, it is recommended that a human factors approach be taken by oil and gas organisations.   Keywords:  Human error, Offshore Oil and Gas industry, Major incidents, Root Cause, Human error evaluation framework.  Introduction  Organisations are regulated by following previously designed strategies and operate according to processes carried  out on the basis of resources available. These processes and strategies are complex systems that assimilate workers,  environment and plants. Carpitella et al (2018) emphasise that it is very crucial to mutually adapt and balance the  processes and strategies, because they assist in identifying near misses and prevent accidents and occupational disease  within the workplaces. The theory of human management system (HMS) is important under this issue (Carpitella,  Carpitella, Certa, & Benitez, 2018)  Choe (2015) cautions that it is neither convenient nor possible, to t otally eliminate human contribution to a  process, even though a high degree of automation is practised, such as in many manufacturing industries (Choe, Tew,  & Tong, 2015). Industries that produce high volumes may consider computers and machines  because they are more  reliable and faster in compared with humans Automation is considered more reliable and faster than humans, as it is  not affected by physical and psychological  factors such as stress health, mood and age  (Carpitella, Carpitella, Certa,  & Benitez, 2018).  Aim and Objective  Currently there exist several tools and methods that are used to investigate incidents within the offshore oil and gas  fraternity, all with the aim of determining the cau se of the incident. An approach that is considered to investigate an  incident is depended on the type of incident and consequence it has in terms of people, environment, asset damage  and the reputation of the organisation. The first objective of this study is to determine what methods are currently used  globally to investigate incidents, with an aim of establishing causes. The second objective is to develop a framework  that can be used to determine the causes of incidents within the offshore oil and gas ind ustry. The third part of this  research is to determine the causes of incidents that occurred within the offshore oil and gas industry. The forth part",Missing,,,46.3144754,11.0480288
9,EXPLORING INFORMATION LITERACY IN THE CONTEXT OF THEATTENTION ECONOMY: A HEURISTIC-BASED FRAMEWORK FORATTITUDE CERTAINTY,Missing,"Heuristics, certainty, information literacy, attention economy ","By nature of their immersion in the attention economy, digital natives are subject to persistent, pervasive priming and  due to the associated commoditization of time and relevance, are subject to making decisions in an environment of  higher cognitive loading and decreased motivation.  This emerging paradigm affects information literacy and  necessitates a reevaluation of the framework for the development of certainty.  This article describes a new framework  for understanding the development of at titude certainty within the attention economy  and discusses preliminary,  qualitative research examining decision making among digit al natives.  Data indicate attitude certainty appraisals  within this demographic are less consistent with systematic appraisals of previous models and more consistent with  socially influenced heuristic cues .  The heuristic -based framework (HBF) for attitud e certainty not only extends  current theory but also synthesizes multi -disciplinary research in an attempt to explicate these decision patterns and  strategies.  Data suggest many implications for theory including preparing engineering managers and business leaders  to build and manage digitally enabled cultures and as a basis for pedagogical intervention.   Keywords  Heuristics, certainty, information literacy, attention economy  Introduction  The rapid proliferation of digital communication, e -commerce, and social networking have enabled the increase in  both the amount of information available and the tools and processes for locating and assessing the veracity of that  information.  This poses new and unique challenges for engineering managers.  While the current body of knowledge  is rich in research on the systematic development of attitude certainty, it is underdeveloped with respect to the role of  the unique heuristic patterns of digital natives in the development of attitude certainty.  The problem is that credibility  researchers have embraced the implicatio ns of a web -enabled demographic, but despite a high degree of conceptual  isomorphism, there is little evidence of taking the next logical step to the development of certainty in this same  demographic.  This is concerning for two reasons:  (1) because heuristics are a pervasive and significant element of  human information processing and decision- making and (2) online information proliferation changes the frequency  with which we make credibility (certainty) decisions (Metzger & Flanagin, 2013) . Now more than ever, it is critical  to extend information literacy research on the use of heuristics to the development of certainty.  This study proposes  a framework that reflects the emerging paradigm regarding attitude certainty .  The heuristic-based framework (HBF)  for attitude certainty combines the principles of information literacy, heuristics and attitude certainty to elucidate the  decision-making trends and strategies of a demographic attempting to process information within a bounded rationality  and through the filter of the attention economy.  In addition to a brief review of the state of the current literature,  findings from a recent pilot study are presented to illustrate the  types of heuri stics that engineering students  within  this demographic use when determining certainty and how those heuristics support the proposed framework. We end  with a précis of the ongoing and future research needed to better understand the role and influence of cognitive  heuristics on the development of attitude certainty in the digital media environment.        A Review of the Current Research  Psychological and decision theory research has focused primarily on the development of attitude certainty through  appraisals of information accuracy, relevance, and legitimacy while communication and information science literature  has similarly focused  on the credibility of information, with an emphasis on believability of me ssages rather than",Missing,,,46.3144754,11.0480288
10,OPEC: SYSTEMS THINKING ON LOW OIL PRICE SITUATION,@ttu.edu,"OPEC, systems thinking, systems theory, oil price ","The Organization of Petroleum Exporting Countries (OPEC) was founded in 1960, and ever since, its fourteen   members have enjoyed its dominant supplier position with 43% of global production and 80% of the oil reserves.  The oil price reached a peak in mid -2008 when the West Texas Intermediate ( WTI) futures price was skyrocketing  to $150 per barrel, among fears of the supply shortages due to stunning growth rates of China and India. The OPEC  members and other producers benefited the most from such high price states. The high price did not sustain, and the  dynamics of the market shifted. In mid -2014, the WTI oil price plummeted to $40s per barrel, followed by a further  drop to the mid -$20s in early 2016. OPEC ha s been complacent with its production capability and price setting  roles. Now, both OPEC and non-OPEC oil producers find themselves in a series of downward price spirals, resulting  in government budget d eficits and heavy layoff situations in the global oil industry. This paper analyzes historical  data for crude oil production, demand and prices over the period of 2000 to 2018.  This analysis examines how  global oil producers could use systems thinking approaches in a response to the growing shale oil production and  cost structures of all the global producers. An examination of the behavior over time and the subsequent causal loop  diagram of the dynamics underlying the structures of the global system are pr esented. Potential impacts and  implications of the current state of the global oil market are explored.  Keywords  OPEC, systems thinking, systems theory, oil price  Introduction   Three major fossil fuels, coal, oil and natural gas, account ed for 80% of global energy consumption, with oil alone  for 33% of the consumption (Enger, 2015). The world oil market systems had been dominated by multinational oil  companies, known as the “Seven Sisters” – Jersey (currently Exxon Mobil), Socony -Vacuum (Ex xon Mobil),  Standard of California (Chevron), Texaco, Gulf, Royal Dutch/Shell and British Petroleum, and it was not until the  1960s that the world went through a decolonization stage, with the birth of many independent states (Yergin, 1992).   The Organizati on of Petroleum Exporting Countries (OPEC) came into existence in 1960 with five  founders, Iraq, Kuwait, Saudi Arabia, Iran, and Venezuela, and now has fourteen members with its head office  located in Vienna, Austria  (OPEC, OPEC Brief History, 2019 ). OPEC made its two objectives clear in its mission  statement: establish consensus petroleum policies among members to ensure stable and efficient supply, and secure  steady income with a fair return on investment. Since its foundation, OPEC has successfully stren gthened its  position: playing leading roles in the first oil price spike with the Arab oil embargo in 1973, and the second oil  shock from the Iran Revolution in 1978. Finally, the third oil shock took place in 1986, this time, oil price crashed  due to the big oil glut in the world (Yergin, 1992).  As of 2016, OPEC, as an international cartel, still maintained a strong position in the world oil supply,  producing about 35 million barrels of crude oil per day, or 43% of the world production, and holding 80% of  worldwide crude oil reserves (OPEC, Oil Market Monthly Report, April 2017). This oil production capability  enabled OPEC to exercise its bargaining power in the world oil market, by managing their member nations’  production volume, and thus influencing oil prices. In the 2000s, oil became an asset class, or commodity as an  investment, with the emergence of speculative activities that adversely affected the market systems. The WTI (West  Texas Intermediate) prompt futures price went up to USD150/bbl in the mid -2008, due to the concerns of global oil  shortages and some speculation.   The market in the first quarter of 2019 saw the WTI futures price hover around USD58.00/bbl. With the  price collapsing over the decade to a third of the USD150/bbl in the mid -2008, the oil revenues of OPEC members",ttu.edu,Texas Tech University,United States,33.59375255,-101.89959552302756
11,INCREASE IN THE SYNTHETIC RATE OF RETURN (TRS)EFFICIENCY INDICATOR OF AN INDUSTRY LEADER’SBUBBLE GUM PRODUCTION LINE,"@udem.edu,","Root Cause Analysis, OEE, Downtime, Process Improvement ","Globalization has given entry to increased world -wide competition, which has led companies to delve into cost- reduction strategies, mostly through the increase of productivity and efficiency. The present paper seeks to illustrate  the project that was carried out surrounding the low efficiency problem presented in an industry leader’s bubble gum  production line, measured through the TRS efficiency indicator (synthetic rate of return). To carry out the project, the  Atlas Methodology was designed, taking as a basis the methodological proposals of various authors around increasing  efficiency in the food and manufacturing industries.  Throughout the project an organizational diagnosis was carried out, five KPI goals were set, and four root  causes that originated the problem in question were identified. Additionally, six solution alternatives were designed,  using techniques such as design of experiments and software-assisted probabilistic simulation, the project resulted in   a 27% increase in the main KPI. Finally, the implementation and control phases’ results were presented, as well as  operational and financial benefits that laid the basis for the organization to remain competitive in a highly demanded  industry.  Keywords  Root Cause Analysis, OEE, Downtime, Process Improvement  Introduction  Understanding global tendencies to be more and more competitive, different aspects have been highlighted and thus,  become more and more important. Efficiency has been and is one of the most important parts when analyzing the food  industry. Quality standards have been set and the increasing rate of production, reduction of time frame to answer to  demand and the importance of taking advantage of time has brought to light the importance of being efficient in a  highly demanded industry. This paper seeks to illustrate the project that was carried out surrounding the low efficiency  issue in an industry leader’s bubble gum production line. To correctly diagnose the key issues and decide the solutions  that were going to be implemented, the Atlas Methodology was designed taking as a basis the methodological  proposals of various authors. Throughout the investigation, different approaches are studied, and their implementation  results are analyzed in terms on operational and financial benefits for the organization.  Literature Review   The OEE efficiency indicator has been extensively applied in the manufacturing industry as a measurement tool that  has significantly aided the increase of productivity by making equipment more effective. Companies have found value  in the use of this indicator mostly because it helps understanding a manufacturing line’s performance in three main  factors “by having a predetermined framework of the impact of m achine availability, performance & quality , OEE  provides the framework to track underlying issues and root cause” (Nakajima, S. 1988. p. 31). As stated by Nakajima,  the OEE efficiency indicator is a crucial tool when trying to perform a root- cause analysis  to comprehend the  underlying issues affecting a system’s performance. Not only does the indicator provide a segmented view of the  problem, but it also has a very simple calculation method which allows both operations and upper-management teams","udem.edu,",Universidad de Monterrey,Mexico,25.661,-100.4202
12,EVALUATING THE IMPLEMENTATION OF PREQUALIFICATION OFCIVIL ENGINEERING CONTRACTORS,@uj.ac.za,"Contractor, Evaluation, Prequalification, and Projects. ","Problems associated with contractor procurement processes often affect project outcomes. Contractors are among the  key role players in the construction industry in delivering projects in line with the key delivery outcomes of time,  scope, quality and cost. The aim of this research is to evaluate if prequalification can possibly contribute in the delivery  of civil engineering projects in South Africa, Gauteng Province. The study further identifies challenges, benefits and  efficiency of prequalification. The research methodology includes; an in-depth review of existing literature, literature  linked questionnaire for a pilot, main study and data analysis. The final questionnaire was distributed to the  Construction Industry Development Board (CIDB) registered civil engineering contractors. The results of the  questionnaire indicates that prequalification can improve project outcomes with regards to; health and safety, time,  cost, scope and quality in the order of impact. Findings further reveal that contractor’s common challenge is that  project success measures differ from one client to the other and therefore making it difficult to comply with all clients.  Prequalification has benefits as contractors are pre- assessed which then minimizes the risk for them and clients.  Criteria of prequalification also indicates that proper management of health and safety is an important attribute in the  management of projects. The study recommends that the linked and associated stakeholders should consider  prequalification to improve the delivery of projects.  Keywords  Contractor, Evaluation, Prequalification, and Projects.  Introduction  The delivery of good projects is largely dependent upon contractor’s skills, experience and competence of the team  (Aje et al., 2009).   Puri and Tiwari (2014), declare that a poor contractor selection model and processes may lead to  project failure. Egemen and Mohamed (2007) declare that contractor’s success and survival is mainly through bidding,  winning bids and making profit. Selection of bids therefore becomes critical for both contractor’s survival and project  success (Chou et al., 2013). The contractor selection process is then a critical step for the success of any construction  project (Palaneeswaran and Kumaraswamy, 1999).                Prequalification of contractors is a pre -tender process from which a list of capable contractors is compiled  (Hatush and Kitmore (1997). Molla (2013) further defines prequalification as a phase prior to the bidding process  through which bidder’s ability is assessed in line with specific requirements including a nd not limited to; financial  ability, portfolio of previous works and human resources experience.   Guided by the literature, a summarized road map diagram to prequalification is established as stated in Exhibit 1. The  client initiates the process in step 1; this is further guided by client’s needs for either, service delivery or infrastructure  development.  Structuring of requirements and the process of identifying bidders follows in step 2. Contractors would  then submit responses to clients for assessment.  Upon assessment a list of competent contractors is compiled which  then leads to a final stage 5 with a list of competent and prequalified contractors.  The aim of this research is to determine if prequalification can improve processes of contractor selection and  in turn improve delivery of projects. The prequalification process is as important as final bidder selection (Kog and  Yaman 2014).",uj.ac.za,University of Johannesburg,South Africa,-26.18493745,27.99979246435022
13,BLOCKCHAIN IMPLEMENTATION FOR SMART GRID RESILIENCE,"@uscupstate.edu,","Blockchain, Smart grid, Resilience, Risk, Vulnerability. ","Smart grids represent an unprecedented opportunity to meet current and future energy demands in a reliable, resilient  and environmentally friendly manner. Furthermore, through the deployment of smart grids, energy consumers can be  transformed into prosumers. Blockchain technology, which is a distributed information and communication  technology, has emerged as potential candidate technology that can enable decentralized smart grids. However, there  remains a lack of literature on the utility of blockchain technology in the realization of secure, flexible and resilient  smart grids. The aim of this study is two -fold: (1) to explore the role that blockchain tec hnology can play in the  deployment of smart grids and (2) to identify barriers to blockchain implementation in smart grids. Pertinent literature  on smart grids, blockchain and resilience is collected and synthesized to address the aims of the study. Additionally,  this research examines challenges and opportunities facing the integration of blockchain technology into smart grid s  and concludes with research implications as well as a potential path for future research.  Keywords  Blockchain, Smart grid, Resilience, Risk, Vulnerability.  Introduction  Modern society, to a large degree, depends on goods and services provided by a set of large complex systems typically  referred to as critical infrastructures . These systems are critical because they are essential for maintaining and  sustaining public well-being, safety, and economic prosperity (Gheorghe, et al., 2018). There is increasing interest in  the energy sector , which represents a critical infrastructure,  with respect to the realization of  secure, flexible and  resilient smart grids (Bologna et al., 2012; Clements et al., 2011; Egbue et al., 2016, Komninos et al., 2014; Rocchetta  et al., 2015).  Smart grids, similar to all critical infrastructure  systems, operate under conditions of uncertain ty with  respect to natural events such as earthquakes and hurricanes as well as man-made events such as acts of sabotage and  cyber-threats (Katina and Hester, 2013; Wang and Lu, 2013; Zio and Aven, 2011). Against this backdrop, it is easy to  see why there is  increased research on potential benefits of s mart grids (Fazio et al., 2014), risks in implementation  (Choo, 2011; Clastres, 2011; Hou et al. , 2011), parts/elements of s mart grids including design for next -generation  control centers (Zhang et al., 2010), optimizing distributed power systems (Rocchetta et al. , 2015) effects of plug-in- hybrid-electric vehicles (Hashemi-Dezaki et al., 2015), security issues (Amin and Giacomoni, 2012; Balaji and Ram,  2015; Baumeister, 2010; McBride and McGee, 2012), s mart meter (Yesudas and Clarke, 2013), standards and best  practices (Habash et al., 2013; Wang et al.. 2011), and classification of threats (Amin and Giacomoni, 2012; Clements  et al., 2011; Komninos et al., 2014). However, there remains a lack of literature on the utility of blockchain technology  in the realization of secure, flexible and resilient smart grids. The aim of this study is two-fold: (i) to explore the role  that blockchain technology can play in enhancing smart grid  resilience and (ii) to identify barriers to blockchain  implementation in smart grids and to determine areas for future work . For the purpose of this study, resilience is  defined as the ability of the smart grid to withstand, recover from, and reorganize in response to crises - man made or  natural events.  The rest of this paper is organized as follows: First, we provide an overview of smart grid literature in terms  of domains and major characteristics. Second, we provide a synthesis of the literature on blockchain technology  describing both potential benefits and barriers. Third, we provide a robust analysis of the literature on blockchain use  in smart grids and discuss associated challenges. Next, we discuss the links between blockchain, smart grids and","uscupstate.edu,",University of South Carolina Upstate,United States,34.9996,-81.9712
14,INDUSTRY 4.0 AND WATER INDUSTRY: A SOUTH AFRICANPERSPECTIVE AND READINESS,Missing,Introduction ,"South Africa has been classified as a water scarce nation with an average rainfall of 450mm per annum , this is 50%  of the global average. In the  21st century digital technolog y is enhancing data collection and analytics facilitating  proactive decisio n making and increase efficiencies . South Africa n municipalities are losing up to 36% of water  mainly due to pipe leaks and theft. A  significant challenge for the water section in the country. The current   challenges facing the global water industry are also not peculiar to the South Africa n water industry. It is expected  that industry 4.0 technologies w ill address some challenges facing the water industry. Th is paper presents a general  overview of the South Africa n water industry, the challenges facing the water industry and the position of S outh  Africa, among the water stress countries by 2040. The paper takes a close look at the Fourth Industrial Revolution  from a Water 4.0 point of view and identifies selected technologies for the water industry of the future. Based on  literature, the findings in this paper includes , the South Africa n water industry readiness for the water of the future  “Water 4.0”. This includes identifying limitations of  Water 4.0  technologies. This paper also aims to answer the  research question “Is South Africa ready for Water 4.0 paradigm shift –  moving from the traditional water system to  digitalize water system?”. Finally, t his paper presents recommendations for Water 4.0 and future work on Water 4.0  in South Africa.   Keywords: Water 4.0, Industry 4.0, South Africa, Water Supply, Water Digitalization, Readiness.   Introduction  South Africa (SA) is recognized as a water scarce nation with an average rainfall of 450 mm per annum. South  Africa receives almost 50% less rainfall than the global average of 860mm per year (Amis & Lugogo, 2018). Nearly  70% of SA’s Gross Domestic Product (GDP) is supported by water supply from the Limpopo province, Inkomati,  Pongola and Orange rivers, and these altogether is  two thirds of the land area (Department of Water Affairs, 2012).  The water infrastructure in South Africa is weighted an average of 39 years and the infrastructure is subjected to  ageing effects and further deterioration due to both externa l and internal stresses and other associated effects such as  poor maintenance and capital renewal of the water infrastructure. Increase in urban populations, greater levels of  development and worldwide climate change have resulted in an increasing water stresses in the years to come.   In the South African context, the Department of Water Affairs monitors and regulates the water supply and  resources, accounting for some 250 water scheme s.  Water availability faces three vital challenges as stated below  (Department of Water Affairs, 2012, Amis & Lugogo, 2018):    • Uneven spatial distribution and seasonality of rainfall (43% of the rain falls on 13% of the land).   • Relatively low stream flow in rivers most of the time, which limits the proportion of stream flow that can  be relied upon for use, and,   • Location of major urban and industrial developments remote from the country’s larger watercourses, which  necessitates large-scale transfers of water across catchments.  Water is a valuable natural resource for use of society and communitie s, and for powering the key  economic sectors of the country . These include  agriculture, manufacturing and food processing. Water requires a  sustainable approach, and this can be achieved by minimizing all the losses of th ese natural resources (Amis &  Lugogo, 2018). According to the Raju & Manasi (2017) as reported by United Nations 2006 report “Water use has  grown at more than twice the rate of population increases in the last century. By 2025, an estimated 1.8 billion  people will live in areas plagued by water scarcity, with t wo-thirds of the world’s population living in water stressed  regions as a result of use, growth and climate change” (National -Geographic, 2019). This is the challenge the world  is facing with regards to water distribution,  and water industry need s. Embracing innovative technologies such as",Missing,,,46.3144754,11.0480288
15,INDUSTRY 4.0: INNOVATIVE SOLUTIONS FOR THE WATERINDUSTRY,Missing,Introduction ,"Most water service providers are increasingly utilizing capacities of Internet of Things and Big Data for leakage  detection, water metering, planning, monitoring and distribution. The era of Industry 4.0 has brought about different  innovative solutions across various industrial sectors. Internet of Things (IoT) provides new solutions to the water  industry, improving water management, and reducing operational expenses as relating to water infrastructure  maintenance. A challenge in the wat er industry is the ability to turn the available data into insightful information,  permitting effective decision making. This paper aims to answer two research questions that is “what are the  innovative solutions that Big Data (BD) and Internet of Things o ffer the water industry” and “Is the Artificial  Intelligence Hierarchy of Needs (AIHN) applicable to the water industry?”. This paper reviews innovative solutions  in the water industry from an Industry 4.0 perspective, with a close look at the BD and IoT. The paper identifies the  key benefits of IoT -based technologies and how these technologies have started empowering the water industry,  especially, in the development of smart water management system. This paper presents the AIHN and its application  to the water industry, including data-science best practices. The paper further identifies the current challenges of BD  and IoT and in conclusion, proposes a simple semantic innovative solution that illustrates how different sensors and  BD, IoT and cloud technologies can assist the water industry to detect water leaks and pump issues at real -time via  instant information to both in-house and field water engineers/personnel.  Keywords: Water Digitalization, Industry 4.0, Innovative Solutions, Big Data and Analytics and AI Hierarchy of Needs  Introduction  The Fourth Industrial Revolution (FIR) era, also known as “Industry 4.0” has brought about digital transformation  across different sectors worldwide, such as the water sector. The water industry is entering the seaso n of “Big Data”  and this term is referred to as four V, i.e. Volume (the quality of the data), Velocity (the frequency at which the data  are being generated), Veracity (trustworthiness of the available data) and Variety (forms and sources of the data). In  today’s world, most water industries are moving away from traditional water solution s, i.e. business -as -usual  operations to new digital revolution of smart water management system using the Big Data and advanced analytics  technology to provide new insight s that  will improve the water management, water quality and the operational  efficiencies (Liner & Kenel, 2016). Industry 4.0 is setting the future of water industry in the right direction, because  the Big Data and Internet of Things are expected to revolut ionize the water sector and increase the business  productivity.   The water industry is very essential to human being s, plant s, animal s and the economy of a nation.  According to Raju and Manasi (2017) as stated by United Nations 2006 report “Water use has grown at more than  twice the rate of population increases in the last century. By 2025, an estimated 1.8 billion people will live in areas  plagued by water scarcity, with two -thirds of the world’s population living in water stressed regions as a result of  use, growth and climat e change” (National -Geographic, 2019). Currently, lots of countries in the world are facing  diverse water challenges, and there is a need to embrace the new innovative technologies of Industry 4.0 to  assist the  water sector to  improve, manage and distribut e the water using 21 st century “smart technologies” which are also  referred to as disruptive technologies.   The development of new technology has taken the central role across different sectors in order to increase  efficiency and improve performance and meet the customers’ requirement and specifications. Contemporary  Industry 4.0 technologies have been considered suitable for water industry and the digital technologies are  transforming the water sector. These technologies are Big Data, Internet of Things (I oT) and Cloud technology as  shown and described in Exhibit  1. These technologies are already transforming the traditional water management  system and providing the industry with new opportunities.",Missing,,,46.3144754,11.0480288
16,EXPLORING LEAN SIX SIGMA ACROSS A RANGE OF INDUSTRIES,@westpoint.edu,"Lean Six Sigma, Process Improvement ","Many organizations use Lean Six Sigma principles to improve their processes and systems to eliminate waste and  variation. These processes and systems specialize in manufacturing products to providing services. The objective of  this paper is to provide a basic understanding of the Lean Six Sigma methodology, its applications, and how these  applications differ depending the sector of industry or specific product. This paper explains the origins of Lean and  Six Sigma and the integration of the two methods. Furthermore, the paper will provide insight as to how Lean Six  Sigma is implemented differently throughout a variety of industry sectors. This idea will be expanded as we examine  the use of Lean Six Sigma in supply chain management, in military organizations, utilization of big data, and the  manufacturing process of Lithium-Ion Batteries. An examination of the diversity in usage of Lean Six Sigma in these  various industries will allow us to understand the different ways Lean Six Sigma can improve company's’ processes  that they rely on daily. These improvements can not only lead to less waste of mater ials used by the company and  variation, but also save the company revenue by creating effective and efficient systems, generating time and energy  towards other endeavors.    Keywords  Lean Six Sigma, Process Improvement  Introduction  Big Corporate Industries have implemented the Lean Six Sigma paradigm as a mean to resolve defects in process from  variation or waste. This revolutionary ways to reduce waste from lean thinking and variation from six sigma principles  has its origin in the Japanese production system. The Lean Six Sigma program is designed to improve the quality of a  process that is suffering from a lack of considerations. Issues in a process can stem from the process layout,  miscommunication between the business and voice of the customer.  Organizations are continually seeking ways to improve the quality of their products or services in order to  gain an advantage over their competitors and meet  customer needs. One tried-and-true method is the Lean Six Sigma  process. This process is a combination of the Lean and the Six Sigma methodologies. Eckes (2001: xi) states that Six  Sigma  is a “quantitative approach that fuels improved effectiveness and efficiency in an organization”. It is no secret  that deficiencies will affect most processes and might cause variations in the products. Individuals trained in the  methodology of Six Sigma identify an issue and generate solutions to improve quality. However, when did Six Sigma  start?  The focus on quality was introduced in the early 1900s in the wake of  the introduction of mass production  (Eckes, 2001). “The emphasis on quantity of goods and services superseded the emphasis on quality” (Eckes, 2001:  1). Americans were more accepting of goods that were not good quality (Eckes, 2001).   This paper includes four additional sections: a literature review, industry case studies, future challenges, and  a conclusion and future work section.  The literature review focuses on the origins of lean and six sigma and how  these two methodologies merge to create Lean Six Sigma.  The industry case studies section examines how different  industries to include supply chain, the military, and manufacturing have adopted lean six sigma principles.  The section  on future challenges examines how big data may play a role in lean six sigma and discusses the organizational  challenges any lean six sigma team faces.  Finally, the conclusion summarizes the findings and proposes future work  in this area.  Literature Review  This section present s a review of the origins of lean and six sigma  as individual methodologies and discusses how  industry has merged these into Lean Six Sigma to realizes the benefits of the individual methods.  Lean focuses on  eliminating waste and is a product of the Japanese automakers after World War II.  Their focus  on eliminating any",westpoint.edu,United States Military Academy West Point,United States,41.3915,-73.956
17,PLATFORM AND MISSION RESILIENCY THROUGH THE LENS OFSYSTEMS ENGINEERING ILITIES,@westpoint.edu,"Resiliency, Systems Engineering, illities. ","The concept of resiliency in engineered systems focuses on the system’s ability to adapt to a changing environment  and continue to provide value to the stakeholders despite disruptions to its operations.  The literature examines both  the mission resiliency of a system, its ability to continue to operate despite a disruption, and the platform resiliency,  the ability of a system to maintain value over an extended time.  Although resiliency is in itself a system attribute,  several other non -functional attributes lead to a system’s resiliency.  This paper examines several of the systems  engineering ilities and how they contribute to both mission and platform r esiliency of a system.  Attributes like  repairaiblity, maintainability, durability, and survivability all contribute to a system’s mission resiliency and its ability  to react to a disruption to system performance.  Whereas attributes like changeability, fl exibility, extensibility, and  versatility contribute to a system’s platform resiliency and ability to provide value throughout the system’s lifecycle.   Additionally, the paper describes several attributes that contribute to both the mission and platform resiliency of a  systems like adaptability, agility, and robustness.  Department of Defense (DoD) systems provide several examples  of systems that demonstrate both mission and platform resiliency based on these non-functional attributes that enable  them to react to disruptions over time.  Keywords  Resiliency, Systems Engineering, illities.  Introduction  The Department of Defense (DoD) faces a significant challenge as engineered systems increase in complexity while  at the same time face a changing operational environment that requires them to demonstrate resiliency to disruptions  in performance.  To compound this challenge, engineered systems not only need to demonstrate mission resiliency, to  mitigate disruptions in an operational context, but also platform resiliency, as these DoD systems may face several  disruptions to their performance over their system  lifecycle.  This paper applies a grounded theory approach to  examine the systems engineering ilities, or non- functional attributes, which may enable platform and or mission  resiliency in an engineered system.  With an understanding of what attributes may benefit a system in terms of  resiliency, systems engineers can potentially design these attributes into systems early in the design process.    The concept of resiliency in DoD systems is not new as engineers have accepted that DoD systems need to  react to a changing environment and have begun to develop engineered resilient systems that incorporate this into the  design of the system (Goerger, Madni, & Eslinger, 2014).  The literature also makes a distinction between the platform  resiliency and mission resiliency of a system based on the time and context of the disruptions to the systems  (Buchanan, et al., 2015) .  Additionally, work in the literature links various ilities to aspects of resiliency as a way to  describe resiliency as well as identify means to achieve resiliency in engineered systems (Enos, 2018).  This paper  examines how the various ilities, or non -functional attributes contribute to mission and platform resilience to  determine if different attributes are required to achieve these types of resiliency.   This paper is organized into four additional sections, a literature review, discussion on platform r esiliency,  mission resiliency, and a conclusion and future work section.  The literature review examines resiliency in engineered  systems, describes the grounded theory approach to understanding how non-functional attributes affect platform and  mission resiliency, and a description of the systems engineering ilities.  The section on platform resiliency discusses  how engineered systems demonstrate resiliency over time at the platform level, which ilities allow systems to achieve  this resiliency, and provides examples, like the B-52 bomber of DoD systems that have achieved platform resiliency  over their lifecycle.  The next section follows a similar outline but focuses on the mission resiliency of a system and  describes the non-functional attributes that lead to this type of resiliency for systems.  The final section of the paper  provide a conclusion to the work, summarizes key findings, and proposes future work in this area.",westpoint.edu,United States Military Academy West Point,United States,41.3915,-73.956
18,RESILIENCE MAPPING OF STRATEGIC WATER PLANS: APRELIMINARY SYSTEMS DYNAMICS MODEL,@ttu.edu;,"Resilience, resilience strategies, water resource management. ","In an attempt to make their systems more resilient to a plurality of pressures, it is not uncommon fo r municipalities  to formulate strategic water plans (SWPs).  Such plans are intended to mitigate uncertainty as well as ensure the  long-term welfare and prosperity of the communities they serve.  Current evidence suggests that these SWPs will  become critically important to a community’s continuity as water becomes increasingly scarce in both developed  and developing countries.  Resilience, however, is a complex target.  Despite its ubiquity across multiple domains  for the past several decades, questions regarding what is being preserved, for who/what, and for how long remain.   The answers to such questions have important implications for water resource managers.  In Part 1 of this paper, the  authors examine the SWP for a medium sized community in a semi-arid region of the United States and analyze it  through the lens of resilience.  Specifically, the authors match the interventions proposed in the SWP to commonly  prescribed resilience strategies.  In Part 2, the authors propose a causal loop diagram that will serve as the  foundation of a systems dynamics model intended to measure the efficacy of the resilience interventions canvassed  in Part 1.  The authors conclude Part 2 by identifying some assumptions and tensions discovered thus far.   Addressing these in-depth constitute the next steps in the research project outlined here.  The authors argue that the  thoughtful application of systems thinking and tools can help ensure the ongoing availability of this critical common  resource.  Keywords  Resilience, resilience strategies, water resource management.  Introduction  The City of Lubbock (TX, USA) has developed a Strategic Water Supply Plan (hereafter LSWSP) to provide a  “…’road map’ to guide the development and implementation of cost-effective and sustainable water supplies over the  next 100 years” (2018, p. 5) .  In crafting this plan, water resource managers are trying to offer a suite of options that  meet the demands of  both current and future stakeholders while planning for uncertainties associated with variations  in water supply as well those due to “variable climatic conditions” (City of Lubbock, 2018, p. 5) .  A significant goal  of the plan, in short, is to ensure that the Lubbock water system is resilient to a variety of stressors; both endogenous  and exogenous to the system itself.  Resilience, in this context, can be defined as a system’s ability to persist over time  in the face of stress.  More expansive definitions recognize that persistence over time may mean a return to the original,  pre-stress state of affairs or adaptation to a new state of affairs as a result of being stressed (Martin-Breen & Anderies,  2011; Quinlan, Berbes-Blazquez, Haider, & Peterson , 2016).  As a goal, resilience lends itself to the application of  systems thinking and tools.  More specific to this paper, the authors contend that a systems dynamics approach to  water resource management (WRM) can yield important insights as to whether a water system is resilient to a variety  of stressors.  The application of tools lik e causal loop diagrams can help identify leverage points in the system to  maximize intervention efficacy.   The authors begin by surveying some of the dominant resilience paradigms across disciplinary domains and  make a brief case for adopting a social-ecological systems (SES) approach to resilience in the context of WRM.  Part  1 continues with a discussion of several strategies prescribed in the literature to enhance system resilience.  The authors  conclude this part of the paper by comparing these resilience strategies to the suite of supply options developed in the  LSWSP.  This comparison creates a foundation for attempts to model the efficacy of interventions on the resilience  of a water resource system.  The authors continue this foundation building effort in Part 2 with the introduction of a  preliminary model of the dynamics model.  This model incorporates c urrent and potential water supply sources and  can be used to evaluate the supply packages viz. their impact on the resilience of the system.  Once completed, the",ttu.edu;,Texas Tech University,United States,33.5845,-101.8751
19,M,Missing,,,Missing,,,46.3144754,11.0480288
20,M,Missing,,,Missing,,,46.3144754,11.0480288
21,INDUSTRY 4.0 CYBER PHYSICAL SYSTEMS MODEL FORPRODUCTION OPTIMIZATION,@uj.ac.za,"Industry 4.0, Digital, Energy, Coal, Cyber Physical Systems ","The current approach to energy optimi zation at production facilities is highly dependent on sp ecialized skills, time  and delivers in a complex environment. The current paradigm for the energy calculation basis is not repeatable,  especially if components have changed. Production equipment, conditions and site specific variables make for an  additional challenge. In the age of technology, digitally integrated systems is the driver with business processes the  design basis. The development of a business process model or Cyber Physical representation of a business resolves  both the design basis but serves also as an opportunistic tool for optimization. This research focuses on developing a  comprehensive cyber physical representation of a production business. The model identifies various optimi zation  opportunities that are logically substituted based on a structured experimental protocol to find an optimized business  state. The results demonstrate the effectiveness of the model to predict energy consumption and optimization options.  The results are illustrative of a less intense model for energy determination.  Keywords  Industry 4.0, Digital, Energy, Coal, Cyber Physical Systems  Introduction  Energy is a considered a basic necessity in today’s global society(European Commission, 2017). It is essential for the  growth of an economy, promoting social development, availability of clean drinking water, use of devices such as  laptops and smart phones and access to the internet. However, energy production and usage is accountable for 67% of  global Greenhouse Gas (GHG) emissions(IEA, 2015). Anthropogenic GHG emissions are significant contributor of  global warming, with numerous global interventions in place to reduce the global temperature rise to below two  degrees Celsius.  Hence, energy demand reduction and energy production efficiency is a necessity.  Traditionally, energy pr oduction has been fossil fuel  based but has since m oved towards renewable  technologies of solar, wind and geothermal. This migration towards renewable energy resources, has not halted  operation of existing fossil fuel power plant nor the construction of new fossil fuel power plants. In South Africa 90%  of electricity generation is from coal combustion (Baker & Wlokas, 2015).  This high reliance on coal for electricity  production necessitates the optimization of the processes of the existing power plants to enable reduction in energy  demand and the associated GHG emissions.   A power plant operates by execution of business processes, which details the sequence of steps for execution  of a business activity (Bititci & Muir, 1997) . The business activity can be range from financial function of salaries  payment and tax management to operational functions of generating electricity and operating the waste water treatment  plants. Business process are adopt ed in development of a Cyber Physical model of a power plant, as it enables  digitalization of the actual operational processes of all business activities.   The Cyber Physical energy optimiz ation model is initially developed for the operational function of  generation of electricity as it is the process with the highest energy demand in the power plant. Industry 4.0  technologies and Cleaner Production techniques are applied in optimi zing the energy demand of the electricity  generation process.  Background",uj.ac.za,University of Johannesburg,South Africa,-26.18493745,27.99979246435022
22,INDUSTRY 4.0 SYSTEMS FOR LOGSITICS ENERGY OPTIMIZATION,@uj.ac.za,"Logistics 4.0, Industry 4.0, energy optimization. ","The global logistics paradigm has been subject to many research studies with various models developed. The key  focus is optimization, energy reduction, resource reductions and improved delivery times. Studies have focused on  the logistics network optimization, warehouse optimization, automation, global tracking and various other specialized  solutions. The need o f the hour is all things digit al, with a global focus on the F ourth Industrial revolution. The  integration and digitalization, inclusive of automation, is a key driver of digital. Cleaner technologies introduction is  also a fundamental aspect of Logistics systems. The authors collate all optimization techniques for logistics system  via a simulation toolset representing the business logistics activities, rendered via business processes. Business  Processes (BP) provide a logical engine for simulation as BP represent business activities at a detailed level, usually  at a level three . The research team build s a global logistics model, cent ered on business processes. The model is  designed to facilitate optimization option substitution with the ability to predict business states. The results provides  insights into global logistics optimization. The paper concludes with detailed scenario based results.   Keywords  Logistics 4.0, Industry 4.0, energy optimization.  Introduction  Logistics is of critical importance, contributing to the Gross Domestic Product (GDP) of a country due to delivery of  raw materials and finished goods, with finished goods ranging from petroleum products, pharmaceuticals and  food(Ceniga & Sukalova, 2015). The logistics industry is energy intensive(Dai & Gao, 2016), with logistics operations  contributing to 13% of global emissions (World Economic Forum, 2016) , hence e nergy demand optimization is of  critical importance at logistics enterprises driven by business sustainability, carbon taxes and emission penalties. The  logistics industry is  encountering environmental issues of fuel consumption and air pollution (S. Liu, Zhang, Liu,  Wang, & Wang, 2019) . It is predicted that global freight emissions will increase by 160% in 205 0, should logistics  enterprises continue with current operational practice (J. Y. Liu, Yuan, Hafeez, & Yuan, 2018). As emphasis on  sustainable operations is at the forefront, green logi stics is critical. Green logistics is defined as reducing the  environmental impact of logistics operations towards achieving a balance among environmental, social and financial  targets(S. Liu et al., 2019). A challenge of the logistics industry is lack of real time data, which impedes attainment of  green logistics  (S. Liu, Zhang, & Lihui, 2018; S. Liu et al., 2019) . As logistics enterprises become increasingly  digitalized, energy efficiency is expected to be inherent.  Industry 4.0 technologies have the pot ential to optimize  current logistics operational practice(Hofmann & Rusch, 2017). Application of Industry 4.0 technology of Internet of  Things (IoT) has the potential of reducing energy demand up to 30%(CGI, 2017).  IoT also addresses the issue of lack  of real time data(S. Liu et al., 2018; S. Liu et al., 2019) .  It is reported that autonomous trucks can reduce emissions  by 25 million metric tons(World Economic Forum, 2016). However, the focus of Industry 4.0 application in logistics  is limited at only 6% in comparison to 73% focusing on process/operations application as noted by the global survey  conducted by Deloitte(Deloitte, 2018).   A logistics energy optimization model centered on business processes is developed. The model re-engineers  existing business processes to include Cleaner Production technologies and practices a nd Industry 4.0 technologies  for optimized business processes that are energy efficient and  have lower Greenhouse Gas (GHG) emissions. The  logistics energy optimization model is demonstrated via a case study.",uj.ac.za,University of Johannesburg,South Africa,-26.18493745,27.99979246435022
23,POLITICAL RISK ASSESSMENT MODEL BASED ON THE IMPROVEDCATASTROPHE PROGRESSION METHOD,@tju.edu.cn,"infrastructure projects, political risk, catastrophe progression method, intuitionistic fuzzy sets ","Political risk has a strong influence on the investment in infrastructure projects of Chinese enterprises in the countries  along “The Belt and Road”. It is necessary to make assessment and judgment on the political risk in the early stage of  investment. This paper establishes an indicator system of political risk by referencing literature and the reports of  consulting companies. Then the author applies the catastrophe progression method to quantitatively evaluate the  political risk and optimizes the method by using the intuitionistic fuzzy set with IFWA operator and a new score  function while ranking indicators according to importance. On the basis of the study above, more objective and  effective political risk evaluation model is established. Finally, the author applies this model to Singapore and  Malaysia and verified its effectiveness through calculating and comparing the results. This study contributes to proving  reference for the investment decisions of Chinese enterprises.  Keywords  infrastructure projects, political risk, catastrophe progression method, intuitionistic fuzzy sets  Introduction  On March, 2015, Chinese government released the 《Vision and Actions on Jointly Building Silk Road Economic  Belt and 21st -Century Maritime Silk Road 》 and it pointed out that the facilities connectivity, i.e., infrastructure  interconnection, should be given top priority in the construction of “The Belt and Road”. Since then, the “B&R”  initiative has been further promoted and the enthusiasm of enterprise s to ""Going global"" has also been increased  continuously. The influence of Chinese enterprises on the international markets is constantly under improvement.  From 2015 to 2017, the contract value(calculated in billions of dollars) of the overseas contracted projects of Chinese  enterprises in the countries along the Belt and Road rises steadily, shown in Exhibit 1.  Although the initial results of “B & R” initiative has been achieved, the political environment in the countries  along the Belt and Road has becom e more complicated and political risk is difficult to judge and prevent due to the  complex geopolitical situation, political instability and religious or ethnic conflicts in the countries. In recent years,  the projects of Chinese enterprises have indeed caused the loss of property and personnel due to political risks. Serious  accidents and significant losses indeed took place in several projects of Chinese enterprises in recent years. For  example, the civil unrest in Libya and the riots in Vietnam brought s erious loss of property to Chinese -funded  enterprises (Meng & Dong, 2015).  And Malaysia cancelled three Chinese infrastructure projects costing more than  US$20 billion which were approved by the previous government. The occurrence of these events shows tha t once  political environments change suddenly, it may bring huge economic losses to enterprises and the events further reflect  the importance of political risks identification and assessment. Therefore, as the investment subject of the project and",tju.edu.cn,Tianjin University,China,39.107253299999996,117.17789778037583
24,A SYSTEMATIC APPROACH IN DECISION GOVERNANCE:KNOWING FROM THE EXISTENCE,@odu.edu,"Ontology, Knowledge Generation, Decision Governance, Human-Machine Systems  ","Decision governance in a joint human- machine systems allows application of human creativity alongside complex  algorithm and knowledge searches by machin es.  In a decision making critical situation, this joint venture requires  maximum certainty in order to overcome any mission failures.  However, current progress in machine intelligence as  well as existing research in  the artificial intelligence community  depends on the best practices and/or standards set  forth by individual organizations and government responsible for the advancement of AI or MI.  In absence of an  expert reference base or knowledge base, more precisely a universal system, we still rely on the information and  standards that differ from organization to organization and from government to government.  This paper seeks to  mitigate this systems gap by looking at a systematic approach in decision governance by developing various levels of  ontologies for human-machine systems.  In support of this proposed approach, a recent development of top ontology  is discussed that revealed the core terminology and their relationships within human-machine systems.  This existential  understanding even lays the foundation for various other ontological evolution.  Keywords  Ontology, Knowledge Generation, Decision Governance, Human-Machine Systems   Introduction  Ontology and its exploitation in the field of engineering management (Mahmud and Zahedi, 2018) enforces: (1)  identifying problem space from the existence level, (2) recognizing  all relevant domains necessary  to build the  taxonomic and axiomatic structure for clarifying the structure of knowledge, and resulting in (3) better understanding  about a domain of di scourse to overcome any  discernment.  Until now, decision governance in a human- machine  intelligence systems rely on the best practices and/or standards that differ from organization to organization and from  government to government, contributing to system s failure in complex mission critical situations  (Mahmud, 2018).   Therefore, systematic approach in the form of ontological analysis is necessary to eradicate decision governance  problems in any given decision situation.   Exhibit 1 (Mahmud and Cotter, 2017) summarizes the primary levels or types of ontologies based on the  scope that are found in the existing literature.  A foundational ontology is also referred to top or upper level ontology.  This essentially gives the foundation of subsequent ontology deve lopment.  The scope of a foundational ontology is  to specify the general or universal classifications or categories, relations, and axioms for a body of knowledge such  that these concepts are reusable across core reference areas of the body of knowledge.  Foundational ontologies are  rich in abstractness and consider on ly the seed or core categories.  These seed categories are general in concept and  are same across all core reference areas and all domains.  Compared to foundational ontologies, core reference ontologies further specify the concepts, relations,  axioms, and functions of an area of a body of knowledge with reference to the respective foundational ontology and  are reusable across domains.  Domain ontologies provide the particular concepts, relationships, functions, axioms, and  instances relevant only to a specific knowledge domain.  Task ontologies specify the vocabulary of terms used in  problem solving tasks that are common across domains within a core reference area.  Conversely, domain task  ontologies specify the vocabulary of terms used in problem solving tasks specific to a given domain.  Likewise, domain  methods ontologies specify specific methods vocabularies (data collection, design, testing, engineering, software  development, etc.) necessary to operationalize the domain.   Application ontologies, application task ontologies, and  application methods ontologies are further specializations of domain ontologies to represent particular know ledge  models within a given domain.  During the last twenty-five or so years, application ontologies have been developed",odu.edu,Old Dominion University,United States,36.8862699,-76.30972478839735
25,M,Missing,,,Missing,,,46.3144754,11.0480288
26,SUPPORTING TECHNOLOGY SELECTION VIA PORTFOLIOREADINESS LEVEL AND TECHNOLOGY FORECASTING,Missing,"Technology Readiness Level, Portfolio Readiness Level, Functional Dependency Network Analysis. ","Halil I. Ozdemir  C. Ariel Pinto  Resit Unal  Charles B. Keating  Colin Britcher  Old Dominion University  hiozdemir1@gmail.com; cpinto@odu.edu; runal@odu.edu; ckeating@odu.edu;  cbritche@odu.edu    Abstract   Today’s complex technology end engineering projects usually have a long life cycle. In order to provide better  capabilities throughout the life cycle, engineers need to include both mature and immature technologies and  subsystems. Several combinations of these technologies and sub-systems might offer similar properties for the same  design. Technology Readiness Level (TRL) is traditionally used to compare two or more technologies for the same  purpose. TRL is also used to assess the development risk of the technology and can provide insight into overall system  development risk when several technologies under development are considered. A novel approach is proposed in this  study to address this need, Portfolio Readiness Level (PRL) which uses a modified Functional Dependency Network  Analysis (FDNA) approach to calculate a single value to represent the maturity of the design for a specific combination  of technology and sub-systems. With the help of a TRL based technology maturity forecasting, engineers can predict  when certain technologies will be available. Then, PRL metric and technology forecasting can be used to make a better  decision to select the optimum technology combination for the design. PRL and technology forecasting can also be  used to monitor the overall progress of the portfolio over time. In contrast to TRL being an integer value, PRL is  defined as a real number. Although non-integer TRL values do not have real-world meaning, it serves as a means to  compare the combinations of technologies for the designed system and to monitor the portfolio maturity progress over  time.  Keywords  Technology Readiness Level, Portfolio Readiness Level, Functional Dependency Network Analysis.  Introduction  New system development inherently includes several risks, both internal and external. One major  risk is associated  with the process of selection of the technologies for the designed system. While several technologies might be  employed to provide the required capabilities, engineers tend to select newer and immature technologies for achieving  better performance levels. However , including immature technologies increase the development risk of the overall  program. In order to define a common understanding of the maturity of a technology, a template was developed by  NASA, “Technology Readiness Levels” (Mankins, 1995) . The approach has been widely accepted and used by  government institutions and commercial companies, especially in the aerospace domain (El-Khoury, 2012; Hay,  Reeves, Gresham, Williams -Byrd, & Hinds, 2013; Robinson, Levack, Rhodes, & Chen, 2009) . In 1999, the US  General Accounting Office (GAO) recommended the use of Technology Readiness Levels (TRL) by Department of  Defense (DOD) in order to manage the transition of developing technologies into weapon systems and DOD adopted  a modified version of TRL metric for its weapon system acquisition policy in 2001 (Mankins, 2002).    While TRL is a widely adopted approach to define the maturity of a single technology and very useful in  comparing two or more technology options, it  is not intended to represent the maturity of an overall system. TRL is  also an indirect metric to define the development risk of individual technology, the higher the TRL, the lower the  development risk and vice versa. The effectiveness of TRL in defining the development risk of technology motivated  researchers to develop a similar approach to define the development risk of the overall system. Several studies focused  on the system level technology maturity (Kujawski, 2013; Lee & Thomas, 2000; McConkie, Mazzuchi, Sarkani, &",Missing,,,46.3144754,11.0480288
27,FLOOD MANAGEMENT DEEP LEARNING MODEL INPUTS: AREVIEW OF NECESSARY DATA AND PREDICTIVE TOOLS,@mst.edu;,"Flood Management, State-of-the-Art Matrix (SAM) analysis, Deep Learning ","Current flood management models are often hampered by the lack of robust predictive analytics, as well as  incomplete datasets for river basins prone to heavy flooding. This research uses a State-of-the-Art matrix (SAM)  analysis and integrative literature review to categorize existing models by method and scope, then determines  opportunities for integrating deep learning techniques to expand predictive capability. Trends in the SAM analysis  are then used to determine geospatial characteristics of the region that can contribute to flash flood scenarios, as well  as develop inputs for future modeling efforts. Preliminary progress on the selection of one urban and one rural test  site are presented subject to available data and input from key stakeholders. The transportation safety or disaster  planner can use these results to begin integrating deep learning methods in their planning strategies based on region- specific geospatial data and information.  Keywords  Flood Management, State-of-the-Art Matrix (SAM) analysis, Deep Learning  Introduction  The Federal Emergency Management Agency (FEMA) reported that 98% of counties in the United States  were  impacted by flooding events between 1996 and 2016 (FEMA, 2019). Potential flood cost evaluations depend upon the  extent of the flooding , subjective evaluation of personal property, and the size of the home  among others variables.  The cost of the total loss to a single residential dwelling can range anywhere from thousands to hundreds of thousands  of dollars (FEMA, 2017). In early 2019, parts of Iowa and Nebraska were devastated by floods. Official cost estimates  have not been published, but preliminary evaluations from state governments suggest billions of dollars in damage.  These costs present a daunting challenge to the United States economy with respect to infrastructure damage, loss or  partial damage of residential dwellings, and loss of crops  to name but a few.  Disaster managers are tasked with  breaking down these cost estimates and determining em ergency response strateg ies in a timely manner with finite  resources. An important but often over-looked dimension of flood costs are the indirect costs associated with road  closures. Before indirect costs can be calculated, a highly accurate and spatially resolute flood prediction model must  be developed to identify the extent of road closures. This work provides a preliminary review of flood prediction  studies to determine trends in model inputs and data sources for use in developing a flood prediction model.   Flood prediction is a complicated task that has become the subject of increased research focus as the  frequency and cost of flooding events continues to increase. Deep learning has emerged as a sophisticated technique  to solve complex problems, but has limited application in hydrological studies (Hu et al., 2018). This methodology is  a subfield of machine learning where computation models comprised of multiple layers learn representations of the  data (LeCun et al., 2015). While deep learning has emerged as a premium candidate for flood prediction efforts, the  term has become a catch -all term in artificial intelligence literature. Therefore, it is imperative that methods be  reviewed and compared to determine the optimal choice subject to sufficiently robust and granular dataset availability.",mst.edu;,Missouri S&T,United States,37.9537,-91.7756
28,GENDER DIFFERENCES IN PRACTITIONERS’ PREFERENCES FORSYSTEMS-THINKING SKILLS,@msstate.edu;,"systems thinking skills/preferences, gender, complex systems, multi-group structural equation modeling. ","The exponential enhancement of technology embedded in interdependent systems has led to increased difficulty and  complexity in problem -solving and decision -making in any system  of systems domains, including healthcare,  infrastructure and utility networks, business structures, military combat systems an d others.  Systems thinking (ST)  paradigm offer a shift in the worldview into how complex systems are perceived, assessed, managed, and governed.  Addressing problems in complex systems need not only technical knowledge but also consideration for inherent  individual differences, including differences in gender. This study compares the differences in systems  skills/preferences across genders using multi-group structural equation modeling approach. The paper concludes with  the discussion of results, limitations of the research, and directions for future studies.   Keywords  systems thinking skills/preferences, gender, complex systems, multi-group structural equation modeling.  Introduction  Systems thinking allows practitioners to look at the complex systems problems as a series of interconnected elements  as a whole. These problems are complex in nature due to social, political, technical, and economical factors. Failures  in the complex systems can result from non -technical reasons as well as technical causes and can be addressed by  individual differences such as gender, where individuals are an essential contributor to the failure. The complex nature  of a business structure challenges practitioners to achieve effective and robust decisions. Solutions to complex system  problem domains should focus more on satisfying solutions that will lead to effective and acceptable results (Jaradat  Adams, Abutabenjeh,  & Keating , 2017). Therefore, to better m anage the complex systems problems, a more  ‘systemic’ approach should be employed (Jaradat, Keating, and Bradley, 2018; Hossain and Jaradat, 2018; Hossain,  Nur, Hosseini, Jaradat, Marufuzzaman, & Puryear, 2019; Stirgus, Nagahi, Ma, Jaradat, Strawderman, & Eakin, 2019).  A more systemic viewpoint allows practitioners to analyze the interconnections between different aspects of complex  problems in a better way. In order to apply ST  to complex systems problems, there is a need to find a team of  practitioners capable of efficiently addressing complex systems problems. The team member should have an adequate  level of skills and preferences to understand and navigate organizational/managerial, human/social, and  political/policy dimensions of complex problems (Ackof, 1994, 1995; Checkland, 1999; Hossain, Nagahi, Jaradat, &  Keating, 2019; Lawrence, Hossain, Nagahi, & Jaradat, 2019). The context of ST and the extent  to which it differs  across genders, requires a closer attention. The main goal of this study is to investigate the impact of gender on the  practitioners’ level of ST skills/preferences. In a nutshell, the contribution attempts to demonstrate the classifications  of  ST skills/preferences based on genders, and how this difference impact complex system attributes.  Literature Review  The current body of knowledge is filled with different theoretical and empirical studies that concentrate on the  relationship between systems approach and thinking styles with gender differences. For instance, Sladek et al. (2010)  investigated the relationship between gender differences of healthcare workers in thinking disposition. They found  that male healthcare workers have more tendency toward rational processing than the female sample, whereas females  have more tendency to experiential processing than the male sample. Stephens (2013), in her book “Ecofeminism and  systems thinking,” investigated the relationship between critical ST and gender differences. She developed a systemic  framework called feminist-ST to provide some guidance for practitioners to pay more attention to gender differences  in project design, social policy, project management fields, and other areas. McConkey (1992) emphasized in",msstate.edu;,Mississippi State University,United States,37.9537,-91.7756
29,EXPLORING THE ROLE OF PEER INFLUENCE IN STUDENT’SDECISION BETWEEN ONLINE AND FACE-TO-FACE CLASS,@oregonstate.edu;,"Peer Influence, Student’s Decision, Online Class, Face-to-Face Class ","Online class is more widely available to students. Even though there are studies that examine the factors that affect  students’ choice for online classes, none of the studies had examined the effect of peer influence on class-mode choices  when both online and in- person class is available to the students. Most of the studies that investigate peer influence  focus on factors that affect adolescents and college student’s choice in areas such as smoking, drinking, and risky   behaviors. Existing studies also assumed that their subjects understood what peer influence is and never provide the  definition of peer influence. The objective of this study is to define peer influence in the context of student’s decision  between online and face-to-face class. A literature review on peer influence studies will be performed to identify the  factors and variables to be included in the study. A definition of peer influence and the associated factors that  contributed to peer influence will be identified.  Keywords  Peer Influence, Student’s Decision, Online Class, Face-to-Face Class  Introduction  Online classes are becoming more available to on -campus students, and on-campus students are increasingly taking  online classes due to time, schedule c onflicts, or lower tuition. Existing literature has not explored the effect of peer  influence on student’s decision in class selection when both types of courses are available to students. If the student’s  decisions are not being predicted before class registration, it may lead to class capacity issue. For example, one course  may have both an online class and face -to-face class, one mode of class may have already at capacity, but another  mode of class may have very few registrations. When the class capacity  issue occurred, it may lead to the waste of  resources and economy. The capacity of the face- to-face class is finite because it is limited in classroom capacity,  teaching quality, and the allocation of educational resources. Although the online class has its capacity, it can become  more flexible because it has fewer restrictions on external factors than the face-to-face class. Under the bad predicted  circumstance in student’s decision, we can assign students into the online class option when the capacity of the face- to-face class is full. If we can forecast appropriately student’s decision between online and face- to-face class, it will  help online educators scheduling online and face -to-face class in order to reduce economic and resources waste in  universities. In order to avoid this situation, it may help to explore the influence factors of peer influence in student’s  decision between online and face-to-face class. The objective of this study is to explore the influence factors of peer  influence in student’s decision between online and face-to-face class. An influence factors conceptual model will be  established through this study to observe how the peer influence affect the student’s decision in online versus on - campus course selection.  Three types of factor s including objective factors, subjective factors, and peer influence  factors will be defined following the conceptual model.  The study findings should provide useful direction to   schedulers who are responsible for scheduling online courses and face-to-face courses, online educators, and students  in universities.",oregonstate.edu;,Oregon State University,United States,44.554,-123.254
30,AN ANALYSIS OF THE STATE-OF-THE-ART ON CALIBRATIONTECHNIQUES FOR REPLICATES OF SYSTEM DYNAMICS MODELS,@ttu.edu,"Replicability, model robustness, systematic review ","System Dynamics (SD)-based simulation is gaining ground as simulation itself becomes increasingly embedded in  the decision-making process. Given the wide availability of simulation software like Vensim and Simulink, complex  systems can now be constructed, deconstructed, and replicated with ease unlike in the past. The concomitant increase  in the need to calibrate SD models has not been addressed sufficiently in the literature, however, with a majority of  the existing research efforts being expended towards the creation of new models based on available data. Vensim, for  instance, has a model calibration tool referred to as ‘Reality Check’ (RC) that focuses on calibration in regard to point  estimates. It is limited in that it does not provide a protocol of calibration and therefore its calibration effectiveness is  debatable. In fact, when applying RC to a model replicate, two problems emerge : (1) availability of historical  information that the original was modeled on and (2) introduction of unwanted errors into the model by the RC process.  To lay the foundations for an informed approach to calibration of model replicates, this work perform s a systematic  literature review of calibration techniques . The results suggest that cross-pollination of ideas from diverse fields of  research can richly inform a robust approach to calibration of SD model replicates.   Keywords  Replicability, model robustness, systematic review  Introduction  The adoption of System Dynamics (SD) to model and simulate complex real -world systems has seen significant  growth both in the industry and in academia across varied scientific disciplines. That SD simulation has been used to  study the effects of economic policies in a national innovation system (Walrave and Raven, 2016), water management  (Stave, 2003; Zarghami et al., 2018), education (Warren and Langley, 1999), team performance (Chinda, 2007), and  economics (Niosi, 2010) illustrates the diversity of its application. The two studies that form the bedrock of this study  are the ones by Elizondo -Noriega et al. (2018) and Visawan and Tannock (2004) . Both studies concern the field of  quality management (QM) and specifically how certain production practices could affect a firm’s product quality and  profitability. In fact, in the QM field, it is identified there is a model with the potential to be a suitable platform to  perform dynamic hypotheses.   Visawan and Tannock (2004), whose model is referred to as the VT model in this study, simulated the effects  of investments in defect prevention (P) and appraisal (A) activities with the aim of reducing product failure -related  costs (F) . Elizondo-Noriega et al. (2018)  identified the VT model to be the most comprehensive model of a  manufacturing firm in extant literature and also that it had been not been taken up for further research since it was first  published. The lack of pervading availability of low-cost simulation software at the time was identified to be a reason.  In a subsequent work, Elizondo- Noriega et al. (2019) replicated the VT model with the intent of making it easily  accessible to other researchers, but found that their replica exhibited a  considerably different value fo r a critical  variable (the net present value of profit or profit NPV) with respect to the original model’s values (see Exhibit 1 for  the original model values). They also noted that the historical records upon which the VT model was created was not  provided by the VT model’s authors.",ttu.edu,Texas Tech University,United States,33.59375255,-101.89959552302756
31,AN IMPROVEMENT IN ROBUSTNESS OF A SYSTEM DYNAMICSMODEL FOR SIMULATING COST OF QUALITY IN MANUFACTURINGOPERATIONS,@ttu.edu,"Simulation, model correction, model improvement, ","The use of System Dynamics to model, understand, and predict the behavior of complex systems has grown steadily  over the last two decades . One complex phenomenon that has received considerable attention of researchers in the  System Dynamics  discipline is the Economic s of Quality , specifically the Cost of Quality , in manufacturing  organizations. The Cost of Quality  is a composite of various costs associated with  activities concerning defect  prevention, appraisal, and both internal and external failure. There are at least five different studies that model Cost  of Quality in an organization via System Dynamics, and of them, Visawan and Tannock’s model provides the most  comprehensive description of a manufacturing facility. However, other studies on the Visawan-Tannock model have  identified an inherent flaw in the model in that it accepts one large investment intervention toward defect prevention  activities to attain six-sigma-levels of operations: an obviously unrealistic behavior. This study proposes a correction  to this identified flaw through the addition of an extra module to the Visawan and Tannock’s  model that has been  tested for compliance with the reported values in the literature.   Keywords  Simulation, model correction, model improvement,  Introduction  Since the beginning of the quality management (QM) movement almost 80 years ago, organizations have increasingly  absorbed and implemented one or more types of QM initiatives. According to Weiler (2004) and Sadeghi et al. (2018),  attainment of strategic objectives through the implementation of QM initiatives is an exercise in constant learning and  adaptation. They stated that previously held notions about QM as being static and focused solely on defect reduction  represent obsolete paradigms, which are not necessarily incorrect but are limited in scope. Cole and Matsumiya (2007)  pointed out that firms need to scope  the end objective of their QM initiatives in advance; they noted that for some   firms, QM could be quality control whereas for others it could be defect  reduction in production-related activities  (a.k.a. quality improvement).    The modern QM paradigm states that a proper QM initiative implementation should factor in not just one  part but the entire supply chain—suppliers, organization, and customer—to enhance a firm’s capabilities and attain  higher organizational productivity (Schneiderman, 1986 ; Juran and Gryna, 1998). This modern QM paradigm is  consistent with Sumanth’s (1984) interpretation of and equation for total productivity (Equation 1), which emphasizes  factoring the whole as opposed to one or more of a system’s parts . Also, this new QM paradigm, drawing a parallel  from the established positive relationship between quality and productivity ( Lee, 1997), suggests five general  strategies to increase productivity and thereby quality (Exhibit 1). These strategies could be realized using different  types of process-centric innovation to affect the composite input (𝐼𝐼𝑇𝑇𝑇𝑇𝑇𝑇) or output (𝑂𝑂𝑇𝑇𝑇𝑇𝑇𝑇). For example, strategy No. 4  in Exhibit 1 can be implemented by employing a combination of target and kaizen costing techniques and influencing  what Cooper (1995) refers to as the “survival zone” in a market. Survival zone is a specific region defined by the Cost- Functionality-Quality axes that is characterized by values of the three attributes within an allowable, attainable range.  Operating within this range of values allows a firm to  compete against stronger competitors regardless of its own",ttu.edu,Texas Tech University,United States,33.59375255,-101.89959552302756
32,STRATEGIC PLANNING FOR GOOGLE'S AUTONOMOUS VEHICLETECHNOLOGY BASED ON PATENT ANALYSIS,@pdx.edu,"Self-driving technology, Patent analysis, SWOT analysis, Social Network Analysis, Waymo’s car ","It would be reasonable to indicate that autonomous vehicle technology significantly affects the traditional automotive  industry and other related industries. However, it is much more challenging to make a complete transformation of this  effect than moving from the electric car. The study includes investigation of different perspectives with S WOT  analysis for the autonomous driving impact. The research combines Patent analysis and Social Network Analysis  (SNA) to devise an essential tool for strategic planning to reveal the implicit R&D partnerships and explicit strategies  in the company level.  The case study shows that the competitive and complementary interactions influence the  formation of partnerships in the market. This study shows that the visualization in a sophisticated network setting  provides abundant and unbiased analysis to high-quality decision-making. Based on the case study of Google’s self- driving company Waymo, this study finds that Waymo’s car should keep the best R&D for customer -oriented  technology so that it can maintain continuous cooperation. Secondly, one should identify niche areas before the large- scale transformation, such as public transport; disable people usage; for campus or indoor-closed area use. Thirdly,  Waymo shall provide users and collaborators self -driving car solution for sustaining ecosystem to expand to rea lize  the economies of scale. The last but the most important is focusing on the R&D activities in critical technologies to  achieve more core patents.  Keywords  Self-driving technology, Patent analysis, SWOT analysis, Social Network Analysis, Waymo’s car  Introduction  Not every emerging technology may become an advanced and mature industry. Such technologies should be accepted,  preferred, and adapted by people. Then, it is necessary to develop the product with the continuous innovation of the  product that the technology converts and to create the supply capacity that this demand can meet to change something  in a mature industry. There is a broad agreement in the car industry that autonomous vehicles are the future, as verified  by significant research and dev elopment (R&D) investments by automotive players and tech giants alike how to  examine it for success. Autonomous vehicle technology also seems to affect the traditional automotive industry and  other related industries. However, it is much more challenging to make a complete transformation of this effect than  moving from the electric car. The group intends to investigate the impact of autonomous driving in technology, market,  legalization and infrastructure perspectives, as well as elucidate quantitative analysis as a vital tool for strategic  planning in company level, provide the overview of the technologies, identify potential competitors along with  partnership, and track the evolution of a landscape relative to possible strategy.  Literature Review  Different perspective in Self-driving technology  One should indicate that autonomous driving is recognized as the future of transportation systems. Companies like  Google are leading the innovation to bring fully autonomous and commercially feasible vehicles to the market. Many  automotive firms, including Ford and Tesla, are competing to be the first to bring viable and affordable self -driving",pdx.edu,Portland State University,United States,45.51181205,-122.68493059820187
33,OPPORTUNITIES AND CHALLENGES FOR RURAL BROADBANDINFRASTRUCTURE INVESTMENT,@mst.edu,"Rural Broadband, State-of-the-Art Matrix, Strategic Planning, Infrastructure ","Insufficient internet access is holding back local economies, reducing educational outcomes, and creating health  disparities in rural areas of the U.S. At present, federal and state funding is available for rural broadband infrastructure  deployment, but existing efforts have not invested in analytical work  to maximize efficiency and minimize cost . In  this study, we use a state-of-the-art matrix (SAM) to identify key challenges and opportunities facing rural broadband  infrastructure from previous research and government reports. We focus on six themes: (1) technology, (2) hardware  costs, (3) financing, (4) adoption, (5) regulatory/legal, and (6) management. We highlight key issues to be addressed  by both private and public decision -makers to effectively manage broadband investment as well as engage  stakeholders to improve access and adoption. Much of the challenge for rural broadband infrastructure is related to a  low return on investment due to high capital costs and low population densities. However, there are many innovative  approaches to overcoming this barrier from technical, policy, and social perspectives. Unfortunately, adoption and  management are understudied and would benefit from additional research to design effective decis ion-making tools  and programs. From a systems perspective, solutions that leverage tools from a diverse set of perspectives, rather than  purely focusing on technology deployment, are more likely to be sustainable in the long -term. We outline an agenda  for future work based on the needs of rural communities as well as local and state governments.         Keywords  Rural Broadband, State-of-the-Art Matrix, Strategic Planning, Infrastructure         Introduction  High-speed rural internet access is associated with i ncreased incomes and reduced unemployment via increased  opportunities for remote work and the ability to expand brick and mortar enterprises online (Whitacre et al., 2014). In  fact, econometrics analysis suggests that  a 10% increase in fixed broadband access increases GDP in developed  countries by a pproximately 1.2% (Qiang et al., 2009). Consequently, governments around the world have invested  funds to deploy broadband infrastructure in underserved areas.  In addition to increasing access, rural broadband ef forts aim to improve the quality of service by providing  advanced capabilities. The U.S. Congress defines “advanced telecommunications capability” as that which allows  users to “originate and receive high -quality voice, data, graphics, and video” services (47 U.S.C. 1302, 1996) . The  U.S. Federal Communications Commission (FCC) has established download/upload speed benchmarks of 25 Mbps/3  Mbps for fixed services and 10 Mbps/3 Mbps (median) for mobile services (FCC, 2018). Beyond economic benefits,  improved broadband services can improve health outcomes by increasing access to telemedicine in rural areas that are  far from a doctor or hospital as well as education outcomes by allowing students to access online learning resources  at school.   However, a recent st udy by the FCC shows that rural and tribal communities still lag behind in broadband  deployment. In rural areas, only 68.6% of Americans have access to b oth fixed and mobile LTE broadband services",mst.edu,Missouri University of Science and Technology,United States,37.9532435,-91.77426666814159
34,DEVELOPING CAUSAL RELATIONSHIPS FOR THE PERFORMANCEMEASUREMENT IMPLEMENTATION PROCESS,@ttu.edu,"Performance Measurement, Implementation, Causal Loop Diagram, Success Factors  ","In recent years, performance measurement (PM) has continued to gain increased interest from academic researchers  and industry professionals as a means for improving productivity and performance. Despite the increased use of PM,  evidence from the literature suggests that many of the initiatives are not successful. Scholarly research also suggests  that PM initiatives fail at the implementation phase, as this is where most of the challenges are seen, which may create  barriers that lead to ineffective systems. Therefore, by improving the implementation process, the chances of success  for PM systems are increased. By analyzing  interrelationships and interpreting the effect of the success factors, this  can drive implementation success. A causal loop diagram (CLD) can be used to represent the relationships between  the variables identified to give a better understanding of the process. So, establishing the interactions between the  factors that affect the implementation can give an insight into executing successful systems. This study generates a  CLD from a regression analysis developed through an initial investigation of variables that affect implementation  success. Survey data from initial investigation was based on 124 responses from medium-sized organizations across  different industries. The CLD shows that success factors have a significant positive effect on PM implementation.  This paper develops a CLD that indicates causal r elationships of variables that affect implementation success which  can be used as the basis for future work. Using the results of this study, practitioners can leverage on the information  to establish strategies that effectively enhance their processes.  Keywords  Performance Measurement, Implementation, Causal Loop Diagram, Success Factors   Introduction  The performance measurement (PM) system is becoming popular as more organizations are adopting approaches that  seek to enhance their processes, people and performance to thrive in the current business environment  due to  globalization (Nudurupati, Bititci, Kumar, & Chan, 2011) . As PM systems have evolved over the years, researchers  and practitioners continually identified PM approaches as appropriate techniques to improve the effectiveness and  efficiency of processes, people or product s as they provide feedback on measurement , enable accountability in the  system and in crease strategic alignment  of goals and objectives (Bourne, Mills, Wilcox, Neely, & Platts, 2000; de  Waal, 2002; Marr & Gray, 2012). This is also why the evolution of PM systems has seen a shift from assessing only  financial measures to including non -financial measures to allow for improvements that contribute to the general  success of the organization  (Kennerley & Neely, 2002) . Therefore, PM can  be used for management processes  including strategic planning, organizing, allocating resources, directing and controlling to enhance productivity, and  sustainability measures that support  managerial decision-making processes (Bititci, Bourne, Cross, Nudurupati, &  Sang, 2018; de Waal, 2002).",ttu.edu,Texas Tech University,United States,33.59375255,-101.89959552302756
35,A GEOMETRICALLY-BASED METHOD FOR EFFICIENT MANY-OBJECTIVE DECISION-MAKING,@umsystem.edu,"Pareto frontier, Pareto efficient set, many-objective decision-making, geometric presort, ideal point comparison ","Practitioners of the systems engineering discipline are increasingly asked to make decisions from large sets of  alternative solutions while considering the conflicting interests of diverse system stakeholders. Formulated as many- alternative, many -objective optimization problems, a posteriori methods are often applied to these scenarios to  determine the solution alternatives that are objectively best perfo rming according to the diverse stakeholder  preferences. Frequently operating under computational and temporal constraints, decision-makers are often forced to  consider fewer alternatives or incorporate a smaller number of stakeholder preferences due to the  inefficiencies of  current a posteriori methods. Utilizing a geometric comparison to the  ideal point of the solution-space, a method is  proposed that seeks to reduce the computational and temporal expense of determining the set of objectively superior  solutions. In a numerical comparison to current methods, the proposed was shown to exhibit improved efficiency  across a range of many -objective test -classes. Equipped with these efficiency allowances, systems engineering  decision-makers can consider more alter natives and a greater number of stakeholder preferences without violating  computational or time restrictions. These liberties enable a more complete and tailored search of the solution -space,  permitting the identification of more thoroughly vetted and scrutinized objectively superior engineering solutions.  Keywords  Pareto frontier, Pareto efficient set, many-objective decision-making, geometric presort, ideal point comparison  Introduction  The systems engineering discipline frequently demands its practitioners make decisions from large sets of alternative  solutions while serving the conflicting interests of diverse stakeholders ( Crawley, Cameron, & Selva, 2016 ).  Sponsoring this demand has been the increased employment of model -based systems engineering. This technique  allows systems designers to develop an ever-greater number of solution alternatives quickly, while avoiding many of  the inhibitive costs associated with traditional system development approaches ( Ramos, Ferreira, & Barcelo, 2012).  While this increased exploration of the solution -space has facilitated marked advancement in creativity and  innovation, it has greatly increased the burden associated with systems engineering decision-making. Decision-makers  are now expected to consider a  large number of solution candidates in justifiably selecting the preferred alternative  (Crawley, Cameron, & Selva, 2016). Further complicating the selection process are the alluded diverse interests that  nominated system solutions must serve. As engineeri ng endeavors become more complex and global in scale, the  parties contributing to a system’s creation, and those expecting service from its enaction, greatly increase in number  (Leybourne, Kanabar, & Warburton , 2010). These stakeholde rs often house conflicting interests and dissimilarly  perceive system value, creating scenarios where different alternatives are the preferred solution of different interest  parties. Consider the simple example of two stakeholders interested in the development of an airc raft. The first  stakeholder may desire the vehicle have as large a carrying capacity as possible,  while the second may desire the  craft’s fuel economy be maximized. Because of the noncooperative nature of the desires, it is unlikely that a single  solution is the globally preferred choice of both stakeholders. As the number of conflicting stakeholders increases, the  likelihood that a universally preferred alternative exists decreases (Marler & Arora, 2004) Instead, the decision-maker  will likely be faced with a set of alternatives that are variably attractive to different stakeholders in accordance with  their respective conflicting preferences.  The described scenario, characterized by a high -volume of solution candidates and diverse stakeholder  preferences, is indicative of a many -alternative, many-objective optimization problem. This class of optimization  problems is defined by the use of many (more than 3; whereas a multi-objective problem has 2 or 3) objectives in the  selection of alternatives from a set of many candidate solutions (IEEE, 2018). In solving many-objective optimization  problems, two method classes are used. The first method class, a priori methods, requires preference information be",umsystem.edu,University of Missouri System,United States,38.9404,-92.3277
36,M,Missing,,,Missing,,,46.3144754,11.0480288
37,WATER RESOURCE MANAGEMENT AND THE PITFALLS OFPRIVATIZATION: A CAUSAL FEEDBACK STRUCTURE FORCOMMODITIZED WATER AND THE MANAGEMENT OFUNINTENDED CONSEQUENCES IN PRIVATIZATION,@ttu.edu,"Water resources management, commodification, privatization, ethics, sustainability ","As the development and exploitation of earth’s water resources accelerates ahead of population growth and  quality of life our ability to develop water resource management frameworks that economize consumption without  creating unintended consequences will determine whether we witness a triumph of c ollective action or a deadly  tragedy of the commons in this century.  This work explores the indirect outcomes that may follow the privatization  of water in a free market system .  A lthough concerns are justified it has been shown that the essential element s of  privatization – rivalry and excludability –  must exist in order to manage consumption and control externalities .     Balanced free markets proficiently maximize economic growth and profitability but  these may come at the expense  of other non -market considerations such as economization, sustainability, and social justice.  The causal feedback  structure proposed herein captures the tragedy of the commons effect that typically dominates water resource  management and develops a new framework that can begin to reverse the standard outcome.  The new framework is  embedded into an expanded tragedy of the commons archetype and is useful for predicting both water’s market  behavior and its potential for economization while managing externalities.  This contentious issue is important to  water resource managers on the basis of its technical management significance and because many experts predict that  freshwater access will be a leading cause of conflict in the 21st century.  Keywords  Water resources management, commodification, privatization, ethics, sustainability  Introduction  In 1995, Ismail Serageldin, the former president of the World Bank, famously said, ""If the wars of this century  were fought over oil, the wars of the next century will be fought over water .” (Serageldin.org, n.d.) No one would  argue that burgeoning population growth and water scarcity leads to conflict but some would argue that water stress  leads to treaties more often than to war. (Postel & Wolf, 2001) Whichever perspective prevails it is clear that this  century will witness either the greatest  ever “tragedy of the commons”  (ToC) (Hardin, 1968) or else of mankind’s  foremost success in collective action.   A win here will take the form of  collective action that preserves or enhances  the bounty of the water commons without unacceptable stakeholder effects.  This can be measured as the volumetric  equivalent of a person’s reliable access to embedded, virtual, an d direct freshwater; whether this liquid wealth  increases or decreases.   Individuals, however, are not the only stakeholders to consider.  The vitality of local  environments, communities, and individuals should also be protected and, preferably, without sapping the vitality of  commercial and industrial water sectors.  It is easy to remain ethically connected to people and the environment in writing, but market forces often  show a deafness towards  ethically based,  non-market responsibilities that are not intrinsic to the business cycle.   Laissez-faire capitalism, the chief of free market economic models, solves the classic problem of economic production  and resource distribution by empowering the individual through private ownership and by proliferating trade through  open competition based on the profit motive of producers.  Indeed, capitalism’s efficiency in maximizing profits and  rate of return is unchallenged but its structural motivation towards the ethical treatment of non-economic stakeholders  has a dubious record.  Non-mandatory ethics – those that are not codified into law – rarely improve the bottom line.    Unless they have been translated into regulatory directives, e thical concerns are under prioritized in market  strategy and there is little traceability between business -as-usual and ethical accountability.  Blindly complicit to  human rights violations is the industrialist who fails to pay a livable wage to his workforce when he could easily afford  to simply because his industry’s wage baseline is driven downwards by competing industrialists who presently pay",ttu.edu,Texas Tech University,United States,33.59375255,-101.89959552302756
38,GENDER BIAS IN STEM EDUCATION: IMPLICATIONS FOR SMALLACADEMIC INSTITUTIONS,@jefferson.edu,"Gender bias, higher education, STEM ","Current research on gender bias in STEM education indicates that non -male students are more likely to experience  unfavorable gendered biases from their peers and faculty than male students. Much of this research treats gender as a  binary female-male system and primarily focuses on large, research institutions or data from national surveys. Our  research intended to study gender bias in a manner inclusive of all genders, quantify the perception of it among  students, and understand the manifestations of such biases. Additionally, this study examined possible strategies to  minimize students’ experiences with gender bias. The investigation took place at Little College during the 2017-2018  academic year. It was hypothesized that non-male students would perceive gender bias at a heightened rate, compared  to their male counterparts. Results from this study indicate that non -male students at Little College perceive gender  bias at a significantly higher (p<0.05) rate than their male peers.  The study examined a niche area within STEM education, and, while it does address a gap in the literature,  contextual implications may only be relevant for institutions with similar profiles to Little College. However,  anecdotal data from students experiencing gender bias provides essential insights into the consequences of gendered  biases in any educational context, regardless of similarity to Little College. The findings presented in this document  should enable Little College and similar institutions to make informed modifications to their practices (curricular and  non-curricular) to foster a more inclusive educational environment.  Keywords  Gender bias, higher education, STEM  Introduction   In 2016, the NSF reported a disproportionately high number of men, compared to women, enrolled in engineering,  computer science, and physical science higher education programs; the same report reflected even fewer women  working professionally in these fiel ds (National Science Foundation, 2016) . While the question of why the gender  ratios within STEM do not reflect those of the general population remains a hotly debated subject, the fact of  disproportionate representation within the field poses a concern in and of itself. Strong and consistent representation  of men in these areas of STEM creates cognitive norms of who the individuals working in the realms of engineering,  computer science, and the physical sciences should be, making individuals in these spaces prone to harboring gender- based biases (Moscovici & Gerard, 2001).  Gender bias is understood as an explicit or implicit partiality, based on the gender or perceived gender of an  individual. Though harboring the bias itself does not necessarily lead to discriminatory action, those who harbor biases  are more prone to expressing these gender biases in their actions. Manifestations of gender bias ultimately have the  ability exclude individuals  from various professional, social, educational, or political opport unities. As such,  understanding how gender bias manifests within various institutions plays a critical role in  fostering the behavioral changes capable of eradicating gender bias or alleviating its consequences.  The intent of this research was to study gender bias, in the context of a small, private STEM-focused  institution of higher education, specifically at Little College.  Little College is a private STEM college  with a 75%  male, by sex, student body of 2,200.  This research sought to quantify the percept ion of gender bias among students  and anecdotally understand the manifestations of such biases. Additionally, this study examined possible strategies to",jefferson.edu,Thomas Jefferson University,United States,39.9489114,-75.15805656266755
39,DEVELOPMENT OF COST ALLOCATION MODEL FOR DESIGN OFSUSTAINABLE LOGISTICS OPERATIONS,@sdsmt.edu,"Sustainability Paradigm, Cooperative Games, Collaborative Transportation ","Collaborative shipping in the area of sustainable logistics is a phenomenon wherein companies work towards  identifying opportunities for shipment consolidation in order to reduce supply chain transportation costs. Collective  participation in shipping of goods and services promotes a sustainable freight operation by reducing the number of  trips made by a firm’s traditional deliv ery vehicles. This in turn contributes to lower carbon emissions, reduced  congestion and increased highway safety on roadways. However, a fair cost -sharing agreement is prerequisite to a  successful cooperative effort between companies with often competing objectives of achieving the highest savings  attainable for an agreed upon cost-share amount. The proposed study will examine implementation of a game theoretic  cost-division concept to show efficacy of maintaining sustainable operations. Savings realized by a company in a cost- sharing agreement will be represented by the difference between the amount allocated to the company for engaging  in combined shipping and their corresponding stand-alone transportation cost. An allocation of total joint shipping  cost will be obtained by  means of fair distribution of  savings among companies. More importantly, the proposed  allocation scheme possesses the capability to meet and exceed  the social dimension of the negotiation process in the  form of numerical computation. Me aning, the arbitration behavior exhibited by logistics managers of respective  companies is depicted by a series of systematic iterations involving redistribution of savings across multiple possible  allocations. The procedure terminates upon convergence to a single point allocation that promotes efficient resource  utilization among stakeholders.  Keywords  Sustainability Paradigm, Cooperative Games, Collaborative Transportation  Introduction   Significant rise of greenhouse gases (GHGs) in the earth’s atmosphere as a result of rapid industrialization continues  to be a  matter of great concern to climate scientist and engineering managers  working for technical organizations .   Climate change as a result of global warming  has become the defining issue of th e 21st century within the trading  sectors of the world economy. Growing amounts of scientific literature show increased emissions of GHGs connected  with commercial activities as a major contributing factor to climate change (Socolow, Andrews, Thomas & Berkhout,  1997). This has motivated the business community at the executive level  to make environmental positive  decisions  with regards to capital infrastructure investments pertaining to commercial activities for long term preservation of the  earth’s ecos ystem. Therefore, business es throughout the world  are reimagining standard operating practices and  procedures with the goal of discerning optimal strategies to minimize release of industrial waste and operate machinery  whilst emphasizing conservation of environment. More so, the well-known three pillars of sustainability framework  that has provided a generic and base level guideline for designing engineering operations has been implemented in a  partial manner (Lems, Van der Kooi & De Swaan Arons, 2002) .  The idea of conducting sustainable operations  is  based on the principle that an activity  should be designed so that the  long-term functioning would not impact the  community and the environment  in a negative manner . However, systematic integration of social, economic and  environmental factors into a firm ’s strategic plan continue s’ to remain elusive especially in industries engaged in  production of technical products . The framework of sustainability  has garnered a renewed attention among  engineering mangers se arching for  a new paradigm for handling day -to-day operations . The social  pillar of the  framework deals with structuring business process es that result in workforce development and in equal meas ure  benefit the local populace  within which the operation is being undertaken, or where the company is headquartered.  The economic pillar of the framework ensures that the operations of the company are profitable and lead to generation  of reliable goods and services for end users. The environmental pillar warrants that the company facilitates operations  in such a way that results in minimization of net carbon footprint. This framework is well documented in the literature,",sdsmt.edu,South Dakota School of Mines and Technology,United States,44.0731,-103.2063
40,"IMPROVING MANUFACTURING OPERATIONS USING LEANPRINCIPLES AND PRIORITIZING PROJECTS: SUCCESS FACTORS,PITFALLS AND CHALLENGES",@newhaven.edu,"Lean Manufacturing, Project Prioritization, Continuous Improvement, 6S. ","Improving operations has been essential for manufacturing companies in gaining competitive advantage especially  when the industry was heavily geared towa rds adopting lean principles. In the age of smart factories, implementing  improvement projects to achieve a better performance is no longer a matter of choice but a necessity for company  competitiveness. While success in any single project is of utmost imp ortance, selecting the right project to start the  improvement initiatives is as equally important. Therefore, prioritizing projects is a critical and necessary step for  any manager to ensure better outcomes. This paper presents a case study involving a large manufacturing company’s  3-months intensive efforts targeting product and process improvement. Several projects focusing on various areas in  the manufacturing process have been defined, and lean and statistical process control (SPC) tools were chosen to  support improvement activities.  Selecting the order of implementation and the changes that had to be made along  the way provided invaluable input in framing success factors, pitfalls and challenges in prioritizing improvement  projects in traditional manuf acturing plants. These elements and the impacts of the decisions made are depicted  through detailed descriptions of two projects. The first project was about production layout, and the second project  targeted tooling process. In both improvement efforts, lean methods were used primarily.  Keywords  Lean Manufacturing, Project Prioritization, Continuous Improvement, 6S.  Introduction  Investment in technology is on the rise as the industry is moving into an era of smart manufacturing ( Kang, Lee,  Choi, Kim H, P ark, Son, Kim B.H., & Do Noh; 2016). The technologically advanced companies are implementing  more and more Industrial Internet of Things devices, and using data analytics to guide their processes (Munir,  Baumbach, Gu, Dengel, & Ahmed, 2018) . Nevertheless, there are still a large number of manufacturing companies  operating with traditional practices. In the age of smart factories, implementing improvement projects to improve  operations and achieve a better performance is no longer a matter of choice but a ne cessity for these companies to  remain competitive. While success in any single project is of utmost importance, selecting the right project to start  the improvement initiatives is as equally important. Therefore, prioritizing projects is a critical and nec essary step  for any manager to ensure better outcomes (Pennypacker & Dye, 2005).  There are many factors that affect the prioritization process including the product type, volume and variety  produced. This study focuses mainly on high volume and high variety assembly production that typically suffers  from a large number and frequent change of setups. Lean has been a proven methodology in such settings by cutting  down wait times, setup and travel times, and simplifying work (Chen & Erdil, 2015; Roriz, 2017).  Project Prioritization Process is a structured activity which aims to generate a project portfolio that is  aligned with company goals and to increase project success by taking into account the available resources. This  project portfolio not only includes resource allocation plan for each project, but also provides the order of execution  of each project.  The order sequence generated is based on a number of criteria such as financial, technical, resource  related, etc., and aims to ensure the highes t efficiency of the overall portfolio (Purnus & Bodea, 2014). A good  project prioritization process will allow to “right size” the portfolio while having a clearly prioritized list of projects,  which will ensure that resources are more effectively allocated during implementation.  In this study, a project prioritization framework based on lean principles was employed to ensure that  project outcomes were built upon each other. In the following sections, first this prioritization framework is  described, then t he projects executed are briefly presented. Finally, the lessons learned during implementation are  explained.",newhaven.edu,University of New Haven,United States,41.29091365,-72.96263883692575
41,A METHODOLOGY FOR DESIGNING ENDURING HUMAN ACTIVITYSYSTEMS,@oregonstate.edu,"Enduring organizations, organizational adaptiveness, process improvement, human activity systems ","With the advent of the fourth industrial revolution,  engineering organizations face the challenge of increasing  productivity, while at the same time inc orporating and adapting to new technologies  without increasing resource  utilization. To be effective, organizations must rely heavily on their ability to quickly change organizational priorities  while aligning seamlessly all their operations to the new priorities. Although there are many methods that suggest best  practices for designing and implementing culture -based organizational change, current research lacks a holistic  method. Further, current methods do not emphasize the need for cultural change while also designing for the  entire  human activity system. We propose that such balance is best achieved through the design of enduring human activity  systems that promote a culture of adaptiveness across the entire organization.  In this research, the authors pr esent a  proposed methodology that uses the concepts and methods of continuous improvement initiatives to design and  create a culture of adaptiveness  within an organization. The application of this methodology is illustrated through a  case study with the Division of Finance and Administration at Oregon State University. The case study illustrates how,  through the implementation of the methodology , the Division of Finance and Administration  at Oregon State  University is creating a culture of adaptiveness. This research is relevant to engineering managers because it will set  the foundation for engineering managers to foster research into the creation of enduring human activity systems.  Keywords  Enduring organizations, organizational adaptiveness, process improvement, human activity systems  Introduction  As engineering organizations continue to face rapid technological change, they must seek innovative ways to adapt to  these changing environments in order to remain competitive in their respective business markets. Bahrami (1992, p.  33) suggests that this change has forced organizations to “move away from monolithic and rigid organizational designs  which were geared for repetitive transactions and routine activities” towards “flexible and agile organizational forms  which can accommodate novelty, innovation, and change”.  To help manage this t ransformation, there has been an  emergence of methods and best practices for approaching and implementing organizational change. Organizational  change can be best characterized as a transformation of an organization from its current state to a future state (Beckhard  & Harris, 1987)  with a particular focus on large -scale operational and strategic changes (Dunphy & Stace, 1990) .  Popular methods or best practices for implementing such changes have ranged from the simplistic three -step model  included in  Lewin’s Change Model (Lewin, 1958)  to the McKinsey 7 -S Model (Peters & Waterman, 2012)  that  balances both the complex social and technical aspects of organizational change.  In recent years, the most widely  recognized method for organizational transformation is Lean manufacturing, often associated with the success of the  Toyota Production system, which is primarily applied in a manufacturing setting.    As the need for organizational change has continued to grow, there has been an increase in research towards  evaluating the success of the various methods for organizational change. In reviewing the literature on this topic, there  are two emerging characteristics of organizational change that have been identified as being crucial to a successful  transformation. The f irst characteristic is a focus on people. In a literature review on Lean implementation and  organizational transformation, Yadav, Nepal, Rahaman, and Lal (2017) highlight a consensus among publications that  people are central to the Lean transformation. Based on their literature review, they also conclude d that the  management and development of organizational culture is crucial to the success and survival of the Lean  transformation. Conti (2010, p. 888)  defines organizational culture as the “DNA of the human social systems,  reflecting the ensemble of values, beliefs, history, traditions, way of thinking, and doing all of which link members of",oregonstate.edu,Oregon State University,United States,44.56305595,-123.28392337694638
42,PRODUCT AND TECHNOLOGY (INNOVATION) DIFFUSIONECONOMICS’ TIME RELATION TO ABANDONMENT,@swri.org,"Technology, Diffusion Time Value, S -Curve, Technology Diffusion , Innovation Diffusion, Technology and "," The pace of business is naturally accelerating due to technology  and innovation advancements; as such, to  maintain relevance and a competitive advantage an organization must understand and use time wisely.  Thus, the  exploration of product/technology (innovation) diffusion economics, and its relationship to time has great value to  decision makers within an organization.  Previous research demonstrated via economic impact that when a technology  or innovation has a fast diffusion rate, an organization’s decision-makers should endeavor to make quicker decisions  when compared to a technology or innovation with a slower diffusion rate.  Expanding on this research, the Diffusion  Time Value, a standardized economic measure referenced to units of time, is used in this paper to explore the economic  importance of understanding a product/technology (innovation) diffusion stages in relation to its abandonment point.   This framework provides knowledge for an organization’s decision makers to make better decisions in relation to  time, for the understanding and use of time within an organization can be used as a competitive advantage for growth.  Keywords  Technology, Diffusion Time Value, S -Curve, Technology Diffusion , Innovation Diffusion, Technology and  Innovation Abandonment   Introduction  In a proactive environment, when an organization chooses  to abandon technolog ies, it is to either maximize  profits/growth or to minimize its losses through the management  of its limited resources  (Parvin Jr & Beruvides,  2018).  Thus far , the arena of technology (innovation) abandonment is far less developed than that of technology  (innovation) adoption in engineering management (Greenwood, Agarwal, Agarwal, & Gopal, 2016) .  Parvin Jr and  Beruvides (2018), in an effort to explore  factors impacting abandonment, demonstrated a conceptual link between a  technology’s diffusion rate and its value (economic impact).  This work was further expanded in 2019 to explore the  characteristics and implications of the Time Value of Diffusion, term Diffusion Time Value (DTV), in  terms of  technology (innovation) abandonment (Parvin Jr & Beruvides, 2019).  The value per unit time of DTV represents the  potential gains/losses of abandonment, consequently indicating  an economic impact of delaying or accelerating the  abandonment of a technology.   Hence, implying that as a technology diffusion rate increases a decision maker should  endeavor to make quick decisions in order to maximize gains or minimize los ses (Parvin Jr & Beruvides, 2019).  In  this paper, the characterization of a technology’s diffusion stages, in relation to a technology’s abandonment point, is  explored in an attemp to further add to the framework of technology abandonment knowledge; thus enabling decision  makers to make better abandonment decisions concerning time.           Background  This paper is the latest of three concatenated research exploration endeavors examining technology  and innovation  abandonment.  Operational definitions give communicable meaning to spoken and written words when applied in a  specific context of transferring information and knowledge, forming a ""common language"" between individuals and  groups (Deming, 2000).  Thus, enabling the efficient transfer of knowledge between individuals and groups.  Toward  this effect, the previous research findings and relevant background central to the understanding and interpretation of  this research are presented herein.",swri.org,,,46.3144754,11.0480288
43,EVOLUTION ANALYSIS OF KNOWLEDGE NETWORK IN PROJECT-BASED ORGANIZATIONS,@126.com,"Project-based organizations, knowledge network, network evolution, social network analysis ","In project-based organizations, the knowledge activities among the participants intersect with each other, forming the  knowledge networks. It is necessa ry to analyze the characteristics of knowledge networks to ensure the smooth  completion of the project. This paper builds a knowledge network evolution process for project -based organizations  in the engineering industry. To better simulate the evolution pr ocess and identify the network features, the social  network analysis method is used to analyze a case. The results show that the participants and network characteristics  are continuously changing. This paper provides a tool for analyzing the overall dynamic knowledge network in project- based organizations.  Keywords  Project-based organizations, knowledge network, network evolution, social network analysis  Introduction  Project-based organizations are being more and more popular to cope with fierce competition. For these organizations,  knowledge is one of the most critical resources to improve project value (A. Ekambaram et al., 2018). Project -based  organizations involve multiple parti cipants. Knowledge transferring among participants forms the knowledge  network. The smooth operation of the knowledge network ensures that project participants can obtain the required  knowledge resources on time. In the context of the knowledge economy, it  is of great practical significance to   emphasize the knowledge cooperation of participants  and analyze the evolution process of knowledge networks in  project-based organizations.  The knowledge network in project- based organizations is not static. As the pr oject progressed, the  participants change, and the network evolves gradually. However, there are few empirical articles on the evolution of  knowledge networks (Xinyu Li, 2017). Most previous research focus es on the influencing factors of knowledge  sharing (Pemsel S. et al., 2012) or the game between participants (Mohsen T. et al., 2019), ignoring the overall  characteristics of the knowledge network. In other words, the knowledge network is always in a dynamic change, but  the existing analysis only stays at a static level. There are also limitations in the research dimensions. Research on  knowledge management can be related to knowledge, knowledge activities, and participants. However, most of the  existing research on knowledge networks focus on the first two levels. Scholars divide knowledge into different types,  such as tacit knowledge and explicit knowledge (Yong Sauk Hau, 2013). Alternatively , they study how to promote  knowledge sharing (Tong Qiao, 2019). Some scholars suggest that understanding ""who"" is also very important. Arend  et al. (2014) emphasize the importance of identifying participants of project -based organizations. In summary, there  is a gap between the overall dynamic evolution analysis and the static transfer analysis.  From the documents and contracts signed at different stages, real data can be obtained to quantify the  evolution of the knowledge network. Data collection is the starting point for social network analysis (SNA).  It is  possible to analyze the characteristics of the knowledge netw ork at different stage s from data and indicators. These  analyses can serve as a basis for guiding future project implementation. The shortcomings in the current knowledge  management field mainly include: (1) analyzing the knowledge transfer in the project-based organization from a static  perspective and ignoring the dynamic evolution; and (2) ignoring the identification and analysis of the network  participants. To solve these problems, we introduce a social network analysis method and use it as a tool to evaluate  the evolution process of the knowledge network in project- based organizations. Our goal is to address the research  challenges mentioned in this article. The paper is organized as follows. Section 2 summarizes the existing literature  and analyzes the relationship between knowledge network, knowledge sharing and social network analysis. Section 3  moves forward by proposing a methodology to analyze the characteristics of the knowledge network at different",126.com,,,46.3144754,11.0480288
44,"AN INTEGRATED, SYSTEM-ORIENTED PROCESS IMPROVEMENTMETHODOLOGY FOR THE CONSTRUCTIONINDUSTRY: APPLICATION TO A COMPANY IN AFGHANISTAN",Missing,"Process improvement, lean manufacturing, vale stream map, cost effective analysis, construction industry ","Organizations need to manage, combat, and cope with external and internal pressures. These pressures are excessive  in the industries with low profit margins but complex operations and production management processes. Construction  industry is one of those industries. Challenges are more severe for construction companies operating in countries with  poor economies such as Afghanistan. This paper explores the major challenges that the construction businesses have  been facing since 2004 in Afghanistan.  Afghanistan enjoyed high economic growth rate between 2004 and 2014, but it declined to -6.79 percent at  the end of the fourth quarter of 2015 (World Bank, 2018). In such a struggling economy, surviving is a lifelong  challenge for mos t construction companies . Unfortunately, once famous for their quality work, credible Afghan  construction firms failed to survive. Despite the compound damaging impact of these failures, Afghanistan is still  investing in building its infrastructures and has been partnering with the private sector through Public Private  Partnerships (PPPs).   In our research efforts, we found out that extensive project delays have been the major cause of construction  business failures. By  developing a system -oriented process improvement methodology and applying lean  manufacturing principles and tools, this study focuses on how to reduce the delays and decrease unit cost of operations  and production. This paper also proposes investing in national-level research initiatives about the management of the  PPPs that will have large positive impact on the economic status of Afghanistan and U .S. tax payers who contribute  $45 billion annually to stabilize the country.  Finally, the study recommends extending this approach to other business processes and other companies in  the construction industry to gain further advantages and ultimately guarantee business survival and growth. It proposes  the engagement of government in supporting construction firms to overcome constraints such as insecurity, corruption,  lack of skilled workforce and construction standards.  Keywords  Process improvement, lean manufacturing, vale stream map, cost effective analysis, construction industry  Introduction  As far as continuous process improvement is concerned, there is always room for refining business processes. Besides,  owners and senior managers always seek ways to improve productivity, maximize assets utilization and finally  increase profit margins. They invest time and money to beat their lower -priced competitors without compromising  quality. Unfortunately, in Afghanistan , construction contractors have underrated investing in business process  improvement.   This paper explores the underlying reasons that have led c onstruction companies in Afghanistan to fail in  surviving and/or building according  to the industry standards. The focus of the paper is to highlight the return on  process improvement investments. We have limited the scope of this study to investigating one critical process in a  construction company headquartered in Afghanistan  in order to manage the boundary of our work. It is, however,  noteworthy that the developed and implemented methodology and analysis in this study can be generalized and applied  to other business processes and other companies in the construction industry to gain further advantages and ultimately  guarantee business survival and growth.  The above-stated process is the “Building Material Delivery to Construction Sites”. This process was selected  based on the results of a survey we conducted. This process is usually wasteful. It also involves various cross - functional teams such as procurement, finance, logistics and project management. Therefore, we selected this process",Missing,,,46.3144754,11.0480288
45,LIFE CYCLE ANALYSIS OF ELECTRIC AND GASOLINE CARS,@csun.edu,"Life cycle analysis, Electric Vs Gasoline Cars, Sustainability of Electric Cars, Cost and Environmental analysis of ","In the quest of finding better mobility solutions to the currently available alternatives, automobile companies are  investing billions of dollars in man ufacturing all-electric cars to save fuel, reduce lifecycle emissions , particularly  once the vehicles are in use by the end user  and thus ultimately saving the planet  from the untoward effects of  emissions caused by cars . This paper investigates  the total cost of ownership for customers and emissions  over the  life-cycle of electric vehicles and gasoline cars. The  primary focus of this paper is to  look at both the upstream (or  production) emissions and the downstream emissions (once the automobile is being driven by the end user)  for each  type of vehicle. Additionally, there will be an insight into direct and indirect effects that the upstream and downstream  processes have on the triple bottom line, i.e., the environmental, social and economic impact.    Keywords  Life cycle analysis, Electric Vs Gasoline Cars, Sustainability of Electric Cars, Cost and Environmental analysis of  Automobiles.   Introduction  Even though the United States of America is no longer a participant in the Paris Climate change mitigation agreement,  the challenge of climate change is growing day by day. No country is an exception to this change. Overall global  warming is a threat to th e planet, and one of the significant causes behind global warming is emissions from  automobiles ( “Car Emissions and Global Warming,” April 2019 .). This threat of global warming is the primary  motivator behind the change process of shifting from conventional gasoline engine cars to hybrids and eventually all- electric vehicles.  Even though electrification of cars started with Toyota Prius there are other companies which  increased the popularity of electric cars.  In this regard it is interesting to note that a comparatively new company in  the automobile industry has initiated the change process , which is Tesla. This company started with all -electric cars  and have made electric cars mainstream; thus,  making it more acceptable to the vast customer bas e in the United  States. Using an electric vehicle is no longer a rare thing; instead , quite the contrary, owning a Tesla is considered a  symbol of pride in several states in the US . This trend is pushing all the automobile manufacturers from across the  world to introduce all-electric car. Therefore, even if electric cars are not homogeneous, for the limitation of space  ,this paper will focus on  manufacturing complexity of all electric cars ( and not hybrids, plugin hybrids or semi electric  vehicles). However, to modify existing assembly or factories to produce electric cars is a challenge for most of the  automobile companies. It does not only affect the manufacturing facility but results in changes that have to be made  throughout the supply chain.  Also, from a customer’s point of view , electric vehicles are comparatively expensive  because rare earth elements are involved in the production of EVs. These elements are available in limited quantity in  nature. Hence for a buyer, electric cars are always going to be more expensive compared to gasoline vehicles because  of the production cost until the manufacturing technology evolves completely (Gilboy, n.d.).   The fundamental reason behind this study is to understand the effect of electric cars on the triple bottom line  of the business, which is people (for working conditions of labors involved in mining of rare earth elements), Monitory  profit (for total cost of ownership for customers)  and planet (in terms of overall carbon footprint and environmental  damage). Speaking of people or customers currently, the major challenge with an electric vehicle is the range and  infrastructure for charging. Charging time and battery technology is improving with all new supercharging and Nickel- Cobalt-Manganese anodes technology (“Electric Vehicle and Battery Metal News - | Zero Hedge | Zero Hedge,” n.d.",csun.edu,"California State University, Northridge",United States,34.2455346,-118.52632210641266
46,DEVELOPMENT OF SMALL BUSINESS BIDDING STRATEGIESUTILIZING MARKOV CHAINS,@westpoint.edu,"Markov chains, bidding strategy, program management ","For small businesses, choosing which and how many contracts to bid on requires the consideration of many complex  and interrelated factors.  A portfolio bidding strategy compares all possible work, the willingness of a company to  complete work for a set price, the predicted profit, the likelihood of being granted the contract, and the relative  attractiveness of the work itself.  In addition to the immediate monetary gain of a singular contract, businesses would  be prudent consider the potential client lifetime value, the level of resource commitment which limits flexibility for  future bidding opportunities, the importance of adherence to core business competencies, and the sunk costs related  to developing bids.  Viewing the strategy through client lifetime value, small businesses judge the potential for follow- on contracts with the same client and consider the value of that relationship in totality.  Long term relationships reduce  the burden of attracting new work and restrict flexibility to chase emerging opportunities and the development of new  skills and competencies.  Given these considerations, the problem of deciding on a long- term bidding strategy limited  by capacity is neither easily simplified nor deterministic.  Rather, this strategy must include the possibility that bids  are lost or that assumed future work does not materialize.  This paper seeks to apply Markov chain analysis to compare  bidding strategies to inform small companies as to which bids to write for optimal portfolio composition over a  specified time horizon considering the type of industry, number of peer competitors, and their long-term goals.  Keywords  Markov chains, bidding strategy, program management  Introduction  Leaders of small businesses face many challenging decisions throughout the life cycle of their company.  The most  basic challenge is balancing limited resources to maximize the profitability of the company.  Stated that simply, it  undersells the complexity of that task.  At the beginning of the lifespan of a company, leaders are pressured to not  only make the company financially viable, but also make it profitable in  a short period of time.  These leaders must  balance this pressure with the costs associated with creating and submitting bids in addition to ensuring the long-term  goals of the company are met.  Therefore, leaders of small and young businesses need to find the right balance of contracts to bid on.  Beyond  the cost of developing a bid and the potential profit, there are other considerations which can be industry dependent.   One obvious fact is that no two contracts are the same with regards to profitability,  manpower requirements, or  lifespan.  Similarly, each contract may require unique competencies.  In addition to the various attributes a contract  may have, the process of understanding which to bid on is complicated by the fact that winning a contract has a degree  of uncertainty involved.  If leaders knew exactly which contracts they would win, there would be no reason to bid on  anything else.  Rather, the stochastic nature of the process requires leaders to bid on multiple contracts with no  guarantees of w inning any let alone all.  The effects of the uncertainty are amplified across years as the types of  contracts won each year informs the reputation of the company and which competencies they strengthen.  In other  words, winning a contract which requires specific competencies makes it more likely that future contracts will require  the same.  The result is that the midterm goals of the company dictate the bidding strategy years prior.  Viewed from  another perspective, the company also tries to minimize their chance of failing or folding during their planning horizon.  Literature Review  Small businesses constitute a vital component of the economy in the United States.  As recently as 2008, they  accounted for a non-trivial 46 percent of the private, non -farm gross domestic product (Kobe, 2019).  In addition to  their direct contribution to the economy, small businesses are valued for their ability to create job opportunities and  to incubate innovation.  Unfortunately, starting a small business involves a risk for business owners and investors.",westpoint.edu,United States Military Academy West Point,United States,41.3915,-73.956
47,PREVENTING MEDICATION ERRORS USING LEAN AND SIX SIGMA,@newhaven.edu,"Lean, Six Sigma, Medication Error, Healthcare ","Medical errors are the third leading cause of deaths in the United States . One category of medical errors is  medication errors, which are failures in th e medication delivery process that results in or has the potential to lead to  harm to patient. Medication errors are associated with significant financial and medical consequences, thus receiving  attention of healthcare managers. The cost of medication err ors to the U.S. healthcare industry is $42 billion  annually. Medication errors could happen at any stage of the process including prescribing, transcribing, dispensing,  administering and monitoring. Lean and Six Sigma are two proven process improvement met hodologies which have  been adopted by the healthcare industry. Their application areas in healthcare are increasing continuously. Literature  provides examples of Lean and Six Sigma implementation to reduce medication errors, which consist of mostly  single case reports and literature review articles. These studies support that Lean and Six Sigma are applicable in  reducing medication errors. However, an understanding of the nature of the medication errors and any contributing  factors to guide Lean and Six Sigma efforts can further increase the effectiveness of their implementation. This  paper presents a study of Lean and Six Sigma implementation based on the classification of medication errors,  whether errors occur in planning of an action or in its execution.   Keywords  Lean, Six Sigma, Medication Error, Healthcare  Introduction  250,000 deaths per year are estimated due to medical errors making medical errors the third leading cause of deaths  in the United States (Makary & Daniel, 2016). Medical error is defined as the preventable adverse effect of medical  care, whether or not it is evident or harmful to patient ( Grober & Bohnen, 2005). There are several ways in which  medical errors can occur. It can be related to issues such as  inaccurate laboratory testing, adverse drug reaction,  surgery, failure of the medication devices, and medication errors (Carver & Hipskind 2019). A medication error can  be defined as the preventable event which occur due the failur e in the treatment process  with potential to harm the  patient. The U.S. National Coordinating Council for Medication Error Prevention and Reporting, an independent  body of several national organizations, defines medication error as “The preventable event that may cause or lead to  inappropriate medication use or patient harm while the medication is in the control of the health care professional,  patient, or consumer. Such events may be related to professional practice, health care products, procedures, and  systems, including prescribing, order communication, product labeling, packaging, and nomenclature, compounding,  dispensing, distribution, administration, education, monitoring, and use ” (NCCMERP, 2019). Medication errors are  a common global issue and are  being recognized at all parts of the world (WHO, 2016).  Medication error s cause  7,000 deaths and 2 million serious adverse drug reactions each year in the U.S. alone (Trakulsunti & Antony, 2018).     Lean and Six Sigma, originated in the manufacturing  industry, are  powerful continuous improvement  methodologies that also have found applications in healthcare. Lean is a philosophy which provide s systematic  approach in minimizing waste and non -value added activities from the process. Healthcare applications of lean  typically focus on patient safety  and quality of care. Six Sigma is a data driven methodology used to reduce  variation within a process.  Lean Six Sigma (LSS) is a new generation methodology that combines tools from both  approaches. This paper discusses how LS S tools can be used to reduce medication errors, specifically their  likelihood of occurrence. In the following sections, first classification of medication errors  and then application of  lean six sigma tools to reduce medication errors are described.   Literature Review   Literature provides many examples of  single case LSS  studies in addressing medication errors  such as deriving  improvements from Lean Six Sigma to reduce parenteral medication administration (van de Plas, Slikkerveer, Hoen,",newhaven.edu,University of New Haven,United States,41.29091365,-72.96263883692575
48,PAYMENT RESPONSIBILITY SCHEMES BASED ON COOPERATIVEGAME THEORY FOR COMPANIES PARTICIPATING IN JOINT DEBTMANAGEMENT PROGRAMS,@sdsmt.edu,"Linear Programming, Game Theory, Financial Markets ","Debt financing is an important financial instrument used by companies to borrow money in order to acquire an asset.  However, companies unable to service their debts must take steps towards regaining financial health by committing  themselves to a conservative austere debt restructuring plan. One such plan is involvement of distressed companies in  a Joint Debt Management (JDM) program. A typical JDM program involves restructuring by way of consolidation of  existing debt by engaging in a strategic collaboration with other companies having debts of similar size. A JDM  program utilizes the concept of debt pooling which comprises of appropriating a specific amount from a creditor that  is equal to the sum of all existing debts from several debtors or companies. The benefits of being party to such an  agreement include significant reduction in single monthly payments made by participating companies to the creditors  as opposed to the amount paid in service of their individual stand- alone debts. Advantages of JDM program include  faster repayment of debt and stronger bargaining potential of companies to garner favorable payment terms such as  low interest rates. The proposed study will be to establish a fair and rational mechanism for the companies to share  the cost of a single payment being made in service of the new joint debt deal negotiated with the creditor. The study  will motivate use of cooperative game theory concepts as a plausible approach for allocation of payment  responsibilities among companies who have agreed to pay their debt obligations in a cooperative manner.  Keywords  Linear Programming, Game Theory, Financial Markets  Introduction  Debt is an amount owed by one financial entity who is referred to as a borrower or debtor, to another entity, the lender  or creditor. Debt on a balance sheet of a company is reduced by making series of payments using monetary and non- monetary financial instruments. As an initial focus, the form of debt examined in this paper will be of the type wherein  liability gets accrued by companies on a balance sheet as a result of failed repayment on loans taken out for a specific  business purpose. In 2010, U.S. businesses placed $150 billion in debt with collection agencies, out of those, agencies  were able to collect just $40 billion of that total. On delinquent debt, the industry averaged a 20% collection rate which  was a decrease from 30% a few decades ago (Stanley 2018). Moreover, the 2008 financial crisis drew attention to the  sensitivity of small and medium enterprises to withstand market shocks (Lee, Sameen & Cowling, 2015). Generally,  companies in an early stage of growth apply for large sums of loans in order to spur commercial operations as part of  a comprehensive strategy to  invest in procurement of requisite land, labor capital and human resources. Successful  companies are able to  service their debts by generating adequate cash inflow as a result of profitable operation s.  However, few companies fail to create enough funds and consequently are prone to having significant debt on their  balance sheets.   For the latter set of companies, debt management program (DMP) serve as an important lifeline. Banking institutions  use debt restructuring mechanisms to identify potential opportunities to streamline and renegotiate existing contract  obligations. DMPs allow financial mangers a new set of favorable terms with an end goal of stimulating repayments  on debt. Out of many possible strategies, one option is the pursual of a special process known as debt consolidation.  This approach is one of numerous financial rescue measures that  a company takes advantage of  when faced with  severe financial distress with the prospect of impending default. The proposed paper will discuss the concept of debt  restructuring, or debt refinancing with a special emphasis on debt consolidation. The intent of this approach would to  be present the afflicted entity with a viable option to lower risk of further debt accumulation by sharing their financial",sdsmt.edu,South Dakota School of Mines and Technology,United States,44.0731,-103.2063
49,PRIORITIZATION FOR RESILIENCY TO HILF POWER SYSTEMEVENTS,@ttu.edu,"High-Impact Low Frequency, Electric Power, Resiliency, Power Systems, EMP ","The response to High Impact Low Frequency (HILF) events in power systems has been the subject of numerous  researchers.  Events of particular interest include Electromagnetic Pulse, Geomagnetic Disturbances and Cyber  Attacks.  In order to achieve resilient outcomes following an HILF event, mitigation actions will be required at various  facilities within different infrastruct ure sub-systems. The selection of facilities for mitigation actions may occur in  isolation or using inter-infrastructure prioritization.  Multiple attributes are often used to order the various alternatives  in ranking problems; however, both hierarchical or network -based approaches may be applied.  The Analytical  Hierarchy Process (AHP) uses pair -wise comparisons for alternatives to estimate criteria weights and resulting  rankings.  Alternatively, the Analytical Network Process (ANP) uses clusters and nodes  to facilitate more complex  structures. This paper provides a comparison of resiliency outcomes resulting from AHP and ANP methods  and  provides a framework for analyzing outcomes in emergency management in power systems .  Selection of the most  effective prioritization method will assist emergency managers and infrastructure operators in optimizing resiliency  outcomes.  Keywords  High-Impact Low Frequency, Electric Power, Resiliency, Power Systems, EMP  Introduction  The study of emergency operations encompasses a number of high reliability organizations.  Overtime approaches to  disaster management transitioned from recovery to preparedness.  Preparedness often entails the study of mitigation   and recovery techniques based on perceived outcomes.  The electric power delivery system has also followed this path  of disaster preparedness; however, emerging threats associated with High -Impact Low Frequency (HILF) scenarios  are gaining increased  scrutiny from government, researchers and industry practitioners .  This paper extends the  framework put forth by Easton, Beruvides and Jackman (2017) , which outlined a method for modeling protracted  electric outages. On March 26, 2019 an Executive Order was issued by the President of the United States initiating a  series of actions related to the study of Electromagnetic Pulse (EMP) attacks on the United States of America.  The  Executive Order details actions including identifying national critical functions and associated priority critical  infrastructure at greatest risk from EMPs; improving understanding of EMP effects; evaluating approaches to mitigate  the effects of EMPs; strengthen ing critical infrastructure to withst and the effects of EMPs; and improv ing national  response to EMP events.  This Executive Order was followed by a public release  from the Electric Power Research  Institute (EPRI) on April 30, 2019 summarizing a three -year research effort related to Electromagnetic Pulse effects  on power system infrastructure.  A High-Altitude Electromagnetic Pulse (HEMP) results when a nuclear weapon is  detonated approximately 19 miles above the earth’s surface.  The resulting EMP has the potential to damage electronic  devices and disrupt power system operations.  As EPRI states “[a] properly functioning electric gri d is critical to  national security and society, and its potential loss for an extended period (months t o longer) could severely impact  both.” (EPRI, 2019)  An EMP event has the possibility of effecting multiple states simultaneously creating regional  challenges.  Emergency Managers and power system practitioners  would be forced to respond to a unique set of  challenges should such an event occur.  “Until the transmission system is appropriately hardened against the potential",ttu.edu,Texas Tech University,United States,33.59375255,-101.89959552302756
50,A STUDY ON THE FACTORS OF PUBLIC SATISFACTION WITHENVIRONMENTAL GOVERNANCE OF GOVERNMENT,@tju.edu.cn;+997033328,"environmental governance of government, satisfaction, sustainable development ","Environmental governance is not only related to the quality of people’s life, but also about the sustainable  development. In recent years, public satisfaction with environmental governance of government has gradually become  a key issue that researchers concern. This study aims to construct a theoretical model of hypotheses about the factors  of satisfaction with environmental governance of government. We conduct a review of literature and theories, which  are about the effects of public expectation and perceived quality on the satisfaction with environmental governance as  well as  the effects of  individual socio-economic status, macro economy and pollution on  public expectation and  perceived quality. These hypotheses finally form the theoretical model. This study can help us to understand the factors  of government’s environmental governance satisfaction from the micro and macro levels, and make contributions t o  sustainable development in environmental governance.  Keywords  environmental governance of government, satisfaction, sustainable development  Introduction  Pollution has become a major challenge for sustainable economic and social development. Because environmental  governance has the characteristics of public goods, the government plays a very important role in environmental  governance. In addition, with the increasing negative impact of pollution on people's lives and welfare, the public's  awareness of environmental protection has been continuously improved, which puts forward higher requirements for  the environmental governance of government. In 2018, China's first environmental tax law was officially implemented,  and the environmental governance of government has become more standardized (Chen & Yang, 2018). In the process  of promoting the modernization of governance system, the improvement of public satisfac tion has become an  important goal pursued by government. Public satisfaction is a psychological content of the public with their need and  aim, when they experience public administration and service (Zheng & Lu, 2012). Understanding the factors of public  satisfaction with environmental governance of the government is conducive to promoting environmental governance  of government and sustainable environmental development.   Previous studies on the factors of environmental attitudes mainly focus on individual fa ctors and external  conditions. Individual factors include age, gender, income, education, political ideology etc. The researchers are  committed to comparing the direct or indirect effects of various factors on environmental attitudes (Jones & Dunlap,  1992; Onel & Mukherjee, 2014; Cruz & Shannon, 2017). In addition, more and more studies take external conditions  into consideration, including economy and pollution (Guagnano et al., 1995; Bechtel et al., 2006; Wang & Liu,2017).  At present, there are few studies focusing on public satisfaction with environmental governance of  government. The government takes the main responsibility in regional environmental governance. The quality of  government’s environmental governance is directly related to the credibility of the government, which has a cohesive  effect on society.  For the analysis of the public satisfaction with environme ntal governance of government, c ustomer  satisfaction model can be used for reference. It is a customer-based measurement system that evaluates the quality of  products and services provided by the company, including the American Customer Satisfaction Index (ACSI), the  Swedish Customer Satisfaction Barometer (SCSB), the European Customer Satisfaction Index (ECSI), etc. The most  influential model is the ACSI. Based on the ACSI, the United States proposed a public satisfaction model applicable  to most public departments , which has become an important tool for performance evaluation of government  departments and has been widely used. This model usually consists of five latent variables. Public satisfaction is the",tju.edu.cn;+997033328,,,46.3144754,11.0480288
51,AN UNDERSTANDING OF ARTIFICIAL INTELLIGENCEAPPLICATIONS IN THE AUTOMOTIVE INDUSTRY VALUE CHAIN,@csun.edu,"Artificial Intelligence, AI applications, Automotive Industry, Value Chain, Supply Chain. ","Artificial intelligence (AI) is a field of human interest since the 1950s. In recent years, it has gained  widespread  attention due to the needed underlying technologies now available. AI technology is based on neuronal networks that  require large amounts of data and fast computation to process learning algorithms, which help organizations greatly  in their decision-making processes.   This paper explores AI applications in the automotive industry of the future with respect to the automotive  value chain. The applications of AI are analyzed for all the subprocesses in the automotive value chain, which include:  Research and Development, Procurement, Logistics, Operations, Marketing, Sales, and Connected Customer. The AI  applications for each sector are investigated in terms of risk and impact on businesses in the automotive sector . This  helps to identify, from a n organizational perspective, the most applicable areas of AI t echnology in the future  automotive industry. The recommendations made at the conclusion of this paper  include explanations of how the AI  application has to be made as part of the automotive val ue chain and the expected benefits of implementation.  In  addition, the findings are summarized in a table in the recommendations section, which shows the possible application  areas of artificial intelligence in the automotive industry value chain along with the benefits and risks of the use-cases.  Keywords  Artificial Intelligence, AI applications, Automotive Industry, Value Chain, Supply Chain.  Introduction  For a long time, the idea of replicating human cognitive processes through computer algorithms was primarily part of  academic research laps and science-fiction movies. John McCarthy, one of the godfathers of artificial intelligence (AI)  defines it as “The science and engineering of making intelligent machines, especially intelligent computer programs”   (McCarthy, 2007). AI can be described as a field of computer science which seeks to replicate human problem-solving  approaches, incorporating the core skills of perception, understanding, and learning based on complex sets of data to  perform human-like actions (Elements of AI, 2019)  In recent years, AI and its applications have gained increasing  attention, as some basis for using this technology more effectively is provided by cheaper memory space, faster data  transmission, and the flood of data coming along with digitalization. Nowadays, AI is already implemented in a lot of  our favorite smartphone apps and websites . Large tech companies like Google and Amazon use it to analyze their  customer data and offer personalized services. Additi onally, there are numerous start-ups being built on ideas based  on AI technology.  How can this new technology be used in companies, which still have their main focus on the  manufacturing of physical products?   This paper shows possible application areas of AI and m achine learning (ML), a subset of AI, along the  automotive value chain. In order to get a better picture of today’s automotive industry, the value chain and its structure  are generally explained in the first place. Subsequently, the current trends in the automotiv e value chain are  highlighted. To view the possibilities, benefits, and risks of applying AI technology along the automotive value chain,  the applications are then classified under the fields of R&D, Procurement, Logistics, Operations, Marketing, Sales and  After Sales, and Connected Customer.",csun.edu,"California State University, Northridge",United States,34.2455346,-118.52632210641266
52,A RESEARCH PATH FOR EXPLORING MATHEMATICALAPPROACHES TO DETERMINE OPTIMAL ORGANIZATIONALSTRUCTURES FOR SYSTEMS ENGINEERS,@uah.edu,"Systems engineering, systems engineers, roles, organizational structure, value. ","Systems engineering involves the application of analytic al and mathematical skills for holistically supporting the  development of systems and problem -solving. Systems engineers assist in  the development of systems within the  allotted budget and schedule . However, vagueness exists concerning the exact role of a systems engineer, and at  present, no standard definition exists for the position of a systems engineer. Presently, systems engineering positions  are created and roles ar e assigned based on heuristics, which may not necessarily be the optimal way to extract  the  complete potential out of systems engineers. This begs the question, “Can a mathematically sound method be derived  to obtain the optimal systems engineering organizational structure, such that the contribution to organizational value  made by systems engineers is maximized?” The main aim of this paper is to lay the foundation for the mathematically  grounded determination of the optimal systems engineering organizational structure, based on organizational context.  The optimal structure includes the correct assignment of roles, the correct number of systems engineers, and the levels  of positions for systems engineers. This paper establishes the pathways between systems engineers and organizational  value. Additionally, this paper leverages roles defined in past studies and discusses suitable mathematical frameworks  for establishing optimal organizational structures for systems engineers.  Keywords  Systems engineering, systems engineers, roles, organizational structure, value.  Introduction  The development of complex systems is faced with numerous challenges, including the prolonged times as sociated  with their development and the tremendous financial losses. The DoD incurs losses of approximately $200,000,00 per  day due to schedule delays in the development of  systems (Maddox, Collopy, & Farrington, 2013) . The increasing  complexity associated with systems, be it in terms of couplings that exist within the system, millions of lines of code  written for system software, or the multiple teams comprised of thousands of individuals, brings with it extreme risks  and coordination problems.    Systems engineers support system development throughout their life cycle . A qualified candidate for a  systems engineering position should have a holistic view of the system.  Systems engineers play multiple roles that  cater to different phases of the system life cycle, from the conceptual stage to the end -of-life stage. Apart from  overseeing the overall system, a systems engineer’s position may also call for assisting in domain-specific applications  (such as aerodynamics, propulsion, etc.).The systems engineers act as interfaces between different teams.  They also  assist in the development of requirements, architecting the system, testing, verification and validation, among others.  Often times, systems engineers take on managerial roles as well. The roles that are associated with systems engineers  are highly varied.   Effective systems engineering is important to reduce the  problem of cost overruns plaguing many modern  systems. Systems engineering (SE) is crucial to problem and risk management, and effective systems engineers form  the backbone of organizations. Emphasis needs to be placed on the correct organizational structure for systems",uah.edu,University of Alabama at Huntsville,United States,34.7252,-86.6405
53,MANAGING HINDRANCE STRESSORS IN AN ENGINEERINGMANAGEMENT ENVIRONMENT,@vectorpm.com;,"Organizational Project Management, Engineering Management, Strategic Management, Systems Thinking, Hindrance ","The daily focus of many Engineering Management (EM) practitioners is in constant sway between operations and  projects. Operational matters require solutions that relate to efficiency and effectiveness while project issues, mostly  without deference, requires solutions that just get the job done.  The requirement for switching between two such disparate mindsets can be a major hindrance stressor,  especially when the resolution of multiple issues requires a number of solutions to be simultaneously planned and  executed. Controlling of this environment may be further complicated by inconsistent monitoring mechanisms, often  due to separate project and operational systems.  Strategic Management (SM) is the silver thread that ties these two disparate world views together, allowing  the Engineering Manager to retain a consistent approach to successful management of operations and projects.  However, for this thread to be visible, the operational manager needs to lift his or her head out of the trees for long  enough to be able to discern the complexity and inter-relatedness of the forest.  The current research therefore proposes a model for the combi ned use of OPM and Systems Thinking as a  means for implementing Strategic Management, with the goal of empowering the Engineering Manager to maintain a  homogeneous mindset while overseeing the contiguous implementation of both subtle operational and bold p roject  solutions, through effective management of the hindrance stressors associated with such activities.  Keywords  Organizational Project Management, Engineering Management, Strategic Management, Systems Thinking, Hindrance  Stressors.  Introduction  Stress in the workplace is considered the result of exposure to specific stressors, which have been found to surface  when people encounter difficulty or anxiety in the execution of their responsibilities (Stranks , 2015). Work stressors  are a function of wo rkplace characteristics  and are often specific to an organization or an industry (Karasek &  Theorell, 1990).   The field of Engineering Management (EM) is defined as the “art and science of planning, organizing,  allocating resources, and directing and contr olling activities that have a technological component” (ASEM, 2015.)   The typical EM workplace has both project and operational functions which come together at the de sk of the  Engineering Manager (or just m anager, for the purpose of this research) who nee ds to make decisions relating to  escalated issues and risks arising from these disparate sources. Lazarus (1966) noted that stress occurs when a manager  believes the demands of a work situation to be such that it is beyond their ability to cope and accordi ng to this view  stressors are the stimuli that produce stress, with symptoms such as anxiety and exhaustion, following in short order  (Jex, 1998). Among the greatest workplace stressors have been found to be a feeling of “lack of control” and random  interruptions (Landy, Quick & Kasl, 1994) and these are both typical of an environment where project and operational  matters converge. The current research proposes a model for the management of stress arising in such an environment,  based on the contextual application of a proven method for hindrance stress management.  Management Stress   Work-related stress has been found to lead to physical illness, psychological distress and mental illness (Bui, K. et al,  2016); moreover, the American National Institute for O ccupational Safety and Health (NIOSH) has identified  psychological disorders as one of the ten leading work-related diseases and injuries (Sauter, Murphy, & Hurrell, 1990).",vectorpm.com;,,,46.3144754,11.0480288
54,AN ASSESSMENT OF EFFECTIVENESS OF COMMUNICATIONWITHIN ENERGY INFRASTRUCTURE PROJECTS,@gmail.com;,"Project success, project communications management, project stakeholder management, change management, ","Effective communication is  an important factor in  project success and a lack ther eof may even result in project  failure, with a negative  resultant effect on strategic organizational goals. The key objective of this research was to  assess the effectiveness of internal communication during the development of energy infrastructure project s at a  national electricity utility’s t ransmission section, specifically to understand the communication gaps that exist and  how best to address them.  In this case study, existing project communications processes were measured against the key requirements  for effective communication and project stakeholder management in a project environment.  The results of the study  assisted in the identification of critical gaps in the communication process and form the basis of recommendation for  provision of a standardized framework to improve the effectiveness of project communications  and elements of  stakeholder identification, prioritization a nd engagement  in the transmission projects department of a national  electricity utility.  Keywords  Project success, project communications management, project stakeholder management, change management,  project management maturity.  Introduction  Overview  As difficult as it may be to implement, the busyness of today’s working environment  has forced effective  communication to become  a critical  success factor in project environments.  In fact, some see it  as the most  important part of project management success; a factor driven by people in conjunction with  processes. Although it  is generally assumed that ineffective communication is generally the fault of the project team, in m any cases,  communication failures are potentially a result of mistakes by all stakeholders  in effectively communicating their  needs and requirements. (Cervone, 2014)  During the project life cycle project management principles are not only applicable to the project manager  by title but  is vital for any person who manages a sub -project or a project  stage or workstream . M uch of the   literature indicates communication skills as being the single most important skill a project manager could possess  and confirm effective communication as a key factor to project success (Cervone, 2014; Pinto & Slevin, 1987; Qian  & Zhen-hua, 2010 ; Roberts, Cheney &  Sweeney, 2002 ; French & Layzell, 1998 ; Hanakawa, 2004; see also  Muszynska, 2017; PMI, 2013a; Zulch, 2014; Molena & Rovai, 2013; PMI, 2013b).  Background  South Africa’s public electricity utility was established in 1923 as the Electricity Supply Commission (Eskom) and  generates approximately 95% of the electricity used in South Africa and approximately 45% of the electricity used  in Africa. Eskom generates, transmits and distributes electricity to ind ustrial, mining, commercial, agricultural and  residential customers and redistributors. Additional power stations and major power lines are being built to meet  rising electricity demand in South Africa, placing  an organizational focus on the management of engineering  infrastructure projects (Eskom, 2017).  The key objective of the current research is to assess the effectiveness of internal communication during the  development of infrastructure projects at Eskom Transmission  division and to understand the com munication gaps  that exist which ultimately hinder project success. The current research is limited to assessing the effectiveness of",gmail.com;,,,46.3144754,11.0480288
55,MANAGING CHANGE DURING SYSTEMS IMPLEMENTATION IN ANENGINEERING ENVIRONMENT,@gmail.com;,"Change management, Customer Relationship Management. ","The management of organizational change and the implementation of Customer Relati onship Management (CRM)  systems go hand in hand when it comes to managing the pressures of changing customer needs, rapidly increasing  competition, technological developments, evolving work forces and emerging government regulations.  Despite historic records indicating high failure rates in CRM implementation projects, organizations continue  to be forced to move from product orientated business strategies to customer focused business strategies. Using  descriptive case studies, an engineering company with a large market share and geographical monopoly was  researched to identify key success factors in the people management required to successfully manage organizational  change, including an evaluation of the influence of management support and customer focused cultures on such efforts.  The current research provided insight into existing change management practices as well as the ability to  identify key success and failure factors in the management of change in environments where mandatory change is  accompanied by systems implementation.  Keywords  Change management, Customer Relationship Management.  Introduction  Global and regional trends have combined to create a milieu where businesses strategically  aim for profitability in  increasingly competitive environments, with the knock -on effect of having to continuously re-plan and amend   operational goals to overcome the strong rivalry now present in the business world. (Bonsu, 2014); (Barnard & Stoll,  2010). Because these changes are implemented through projects, the importance of p roject management as strategic  enabler has increased due to these evolving environments, globalization, new challenges and specialization (Pastuszak,  Chadam, Phusavat, & Polkowska, 2013).  Motives of managerial change may be to increase the profits and promote growth, to increase efficiency and  reduce costs, to develop into a more business orientated organization and to ensure the continued existence of the  organization (Samuel, 2013). Driven by these needs, p roject structures have been put in place to ensure companies  remain afloat, knowing that change is imminent.  Numerous philosophies and models exist, showing how to manage organizational change but more than sixty   percent of such initiatives have failed. For th is reason, the cur rent research will  focus on  understanding this  phenomenon better (Farmer, 2014; McKinsey & Company, 2008).  Change is a result of project implementation and the success of a project is determined by how it is managed.  The project social system has been repeatedly neglected in the past and has become key in the achievement of project  success. (Choi, 2011; Cicmil, 1999; Gardener, 2009; Hornstein, 2014; King & Griffith-Cooper, 2007; Piderit, 2000;  Rossmore & Levine,  1993).  To this end, m anagement of change now concentrates on the  planned changes in  organizational structures and the need for human resources to adjust to their changing circumstances. Characteristics  like resistance to change, communication and organizational culture have been identified as  essential in the change  process (Knipe & Van der Waldt, 1999).  It has also been shown that deficiencies in the preparation and / or execution stages of the change process are  the key reasons for experiencing challenges during change ( Gill, 2002 ; Hoag, Ritscha rd, & Cooper, 2002). The  absence of a legitimate system of execution and oversight of organizational change are two further reasons for failure  (Armenakis & Harris, 2002; Burnes, 2009; Gilley et al., 2009).",gmail.com;,,,46.3144754,11.0480288
56,RISK AND THE PROGRAMMATIC COST-TIME S-CURVE,Missing,"Risk, Subjective Probability, Objective Probability, Subjective Time, Cumulative Risk, Information Theory, Risk ","The relationship between risk and project expenditures over time is revealed through the accepted programmatic S - Curve, which monotonically depicts the highest rate of spending in the middle of the project and the lowest  at the  beginning and tail end. As a new project proceeds from inception to completion, the risk of programmatic failure  decreases as work is performed, measured in monetary terms over time. The shape of the S-Curve has been described  qualitatively and quantitively; however, this research provides a philosophical, behavioral, and analytical foundation  which can then ultimately be applied to the quantization of programmatic risk. Although usually conflated, the  differences inherent to subjective and objectiv e probabilities will form the basis of a model developed from an  understanding of uncertainty (entropy). This analysis will provide engineers and scientists with the critical issues and  trade-offs inherent to the management of the economies of programmatic costs.  Keywords  Risk, Subjective Probability, Objective Probability, Subjective Time, Cumulative Risk, Information Theory, Risk  Quantization  Introduction  In the days of sailing ships, and long before the advent of GPS, there were two times when a crew knew their position  with undoubted certainty: upon their departure and their arrival. During the long voyage, navigators would endeavor  to estimate position using deduced reckoning, with refinements provided by lines of position to the sun, moon, and  stars when the weather supported it; however, the ir tools were crude and the ir estimates were often fatally poor,  especially before John Harrison’s chronometer (Sobel, 2005). Sometimes winds and seas were favorable, but a ship  entering the doldrums could exhaust its resources without making way for weeks. The total risk of not making the  final destination was greatest upon departu re as all hazards lay ahead, but the uncertainty of success was greatest at  some point during the transit. By this, one can understand the interconnected relationship of risk and uncertainty.   Similarly, for program or project management , the two points a t which there are no uncertainty are at start and at  completion, with the greatest uncertainty found during the effort. The standard cost -time S-Curve represents this  changing uncertainty through its slope: zero at the ends and at a maximum somewhere in the middle. So, like a great  sea voyage, charting risk and uncertainty for a project changes over time. The question then is, why does it change the  way it does?  W. Edwards Deming states that “management is prediction ,” which is precisely the goal of r isk management—to  scientifically predict the future (Deming, 1994, p. 101). With knowledge of the behavior of a project over the course  of its voyage, predictions can be made. However, merely assuming that prior (a posteriori) patterns will hold for the  future without an understanding of the underlying principles creates an opportunity for disaster due to an unpostulated  unknown, resulting in misguided decisions  just as superstitious sailors made using errant perceptions a century ago  based  upon generally-assumed harbingers of bad luck, like seeing an albatross or finding bananas or a black cat aboard  their ship. Knowledge of historical patterns and the theory behind them are required for understanding system  behavior.  This paper applies system theory and consider s project management as an organic open system , where cost is  analogous with nutritional energy or fuel, with predicable behavior based upon human perception of probability and  time; after all, projects are managed by people. In applying these theoretical principles, a proposal for a common unit  of programmatic risk in terms of dollar-years is revealed, which captures the interaction between cost and time at the  system level.",Missing,,,46.3144754,11.0480288
57,THE LANGUAGE WE USE TO DESCRIBE MALE AND FEMALECADETS AT THE UNITED STATES MILITARY ACADEMY,@mail.mil,"Text Mining, Evaluations, Human Resources, Periodic Development Reviews (PDRs) ","The United States Military Academy (USMA) uses Periodic Development Reviews (PDRs) as a systematic means for  evaluating the leader development of individual cadets within the Corps of Cadets.  PDRs provide developmental  feedback to the cadet from various evaluators (instructors, peers, subordinates, and superiors) at various times  throughout their 47 -month experience to aid the cadet in developing a self -improvement plan to maintain noted  strengths and to improve areas of deficiency.  Evaluators assess cadets  based on character, presence, intellect,  leadership qualities, and development skills by using a 5-point rating scale ranging from unsatisfactory to exceptional  and then by providing comments related to the evaluated attribute.  Recent research has found that success and failure  in each gender is often described using different adjectives.  Typic ally, men are describ ed as technical and logical  while women are described as organized and compassionate  (Smith 2018).  This study utilizes term frequency and  inverse document frequency to examine the different ways that we describe success among different genders of cadets  by conducting text analysis on ratings and comments from PDRs completed in the last year.  The results from this  study aims to help USMA further understand if any unintentional bias exist towards any gender or group of cadets  through the language used in PDRs.  This analysis also sets an additional benchmark for the continued development  of evaluation processes in other contexts.       Keywords  Text Mining, Evaluations, Human Resources, Periodic Development Reviews (PDRs)  Introduction  The United States Military Academy at West Point is a 4 -year undergraduate institution with an approximate  enrollment of 4,400 cadets.  Its mission is “to educate, train, and inspire the Corps of Cadets so that each graduate is  a commissioned leader of character committed to the values of Duty, Honor, Country and prepared for a career of  professional excellence and service to the Nation as an  officer in the United States Army  (United States Military  Academy, 2018) .”  The academy achieves this mission through execution of four leader development programs:  character, academic, military, and physical.  The West Point Leader Development Systems (WPLDS) - is a 47-month  purposeful integration of individual leader development experiences within the culture of character growth and  promotes the internalization of the ideals of “Duty, Honor, Country” and the Army Values .  West Point’s Character  Development Strategy aims to develop five facets of individual character –  moral, civic, social, performance, and  leadership.  The United States Military Academy utilizes Periodic Development Reviews (PDRs) to track the  development of cadets  across these facets of character through rating s by himself/herself, subordinates, peers,  instructors, and tactical officers.  PDRs provide both quantitative and qualitative feedback to the ratee.  Raters evaluate  ratees on 23 attributes and competencies that support West Point’s Character Development Strategy using a one to  five rating scale and then provide comments .  The purpose of this research is to ex plore the language used in the  qualitative comments provided across ratings, year groups of cadets, gender, and rater type.   Previous Research  A similar study at the United States Naval Academy examined word frequencies in peer evaluations of midshipmen  and found that while raters objectively evaluated men and women the same, many differences existed in subjective  ratings.  Amongst 89 attributes evaluated in that study, there were equal numbers of positive att ributes for men and  women, but significantly more negative attributes assigned to women.  The word “arrogant” appeared most often as a  negative attribute for m en and “inept” appeared most often as a negative attribute for women.  Though  objective",mail.mil,,,46.3144754,11.0480288
58,WORLD CLASS MANUFACTURING: A STEEL INDUSTRY CASESTUDY,@uj.ac.za,"Key words: World Class Manufacturing, Cost, Quality, Reliability and Case Study ","The steel industry is faced with a challenge to remain competitive and cutting edge. This is mainly due to the  decline of steel demand over the last decade. The low steel demand creates a competitive environment that requires  companies such Company Y to produce the steel at lower cost, on-time and at the right quality.  Company Y is a  multinational steel company with operations around the world including South Africa and Germany. This research  paper uses a comparative case study method specific to World Class Manufacturing (WCM) to improve quality,  cost and reliability between Company Y Germany (Site B – with WCM) and Company Y South Africa (Site A –  Without WCM) sinter-making plants.  The comparison study finds that Site A lost just above 30 million rand due  to the lack of efficiency (i.e. low optimisation on raw material and fuel rate). In addition  Site A has 15% more  defective material and lower plant reliability with total unplanned stoppage time of 519 hours. The key solutions  to close the gaps of the drivers of cost, quality and reliability between Site A and Site B are  the following:  implement raw material management system to ensure the by-products are used, create a quality plan that manages  quality from supplier to end product and implement autonomous maintenance.  Keywords  Key words: World Class Manufacturing, Cost, Quality, Reliability and Case Study  Introduction  In recent years, the steel industry has been under enormous pressure due to the declining global steel demand (The  Economist, 2015). The low demand can be attributed  to the 2008 global financial crisis and the  substitution of  steel by other materials. After the 2008 global financial crisis the steel demand dropped drastically. After the crisis  the Chinese government began to stimulate their steel market internally, by  increasing infrastructure  developments, which saw a high increase in steel demand for China domestically. The Chinese  steel demand  began to slowly decline, leading to an over capacity. This led to the current global over supply of steel. The high  supply and low demand drives steel prices down, which results into low business profitability.  The lower steel  demand has created a competitive environment for global steel manufacturers to trade in. The low er demand  encourages the steel industry to perform at optimum level with respect to cost and quality. The steel industry was  traditionally an industry that did not focus on high efficiencies due to the high demand of steel. The new  competitive market is the main driving force for the improvement change s by steel manufacturers, to improve  their efficiencies to achieve optimum cost and quality. This enables the steel producers to maintain and grow their  market share (Olmez G.M, Dilek F.B, Karanfil T and Yetis U, 2016). Steel consumers have become more  demanding in the quality of the material due to the vast options that exist in the market. The steel industry is  battling to meet these consumer demands due to their aged steel plants, which has led to low plant performance   resulting in the increase in production cost and poor product quality.   For organisations such as Company Y South Africa, to remain competitive, the organisation has to adopt  improvement strategies or systems to improve operations (quality, reliability) a nd business (cost) performance.  This research focuses on the use of World Class Manufacturing (WCM) as an engineering system that can be  deployed to improve quality, cost and reliability in the steel industry. The research will be a comparative case  study of Company Y Germany, with fully implemented WCM operations and Company Y South Africa that has  trialed the following systems; Six Sigma, Lean Manufacturing, Total Quality Management (TQM) and Total  Productive Maintenance (TPM). The research aims to identify the following;  • The global best practice standards for implementation of World Class Manufacturing,   • The gaps in operational and business excellence between Company Y South Africa and Germany and  global best practice, and   • Provide solutions to close the gaps",uj.ac.za,University of Johannesburg,South Africa,-26.18493745,27.99979246435022
59,A CASE STUDY FOR PATIENT WORKLOAD ANALYSIS OF ANOUTPATIENT CLINIC,@mavs.uta.edu;,"Patient Satisfaction, Waiting Time, Workload, Level-Loading, Resource Scheduling, Efficiency, Appointment ","A healthcare clinic, like other service-based businesses, requires effective personnel resource planning to achieve its  objectives. In addition to other aims, the plan serves two purposes. First, it communicates what the roles and  responsibilities are for the team members, and second, it  can serve to evaluate areas for possible improvement. This  paper reports on a study that analyzes a tactical personnel resource schedule plan, which is called ‘game plan’ by clinic  team, for a general internal medicine outpatient clinic. The game plan is distributed every morning to the clinic’s  healthcare providers and staff to provide them with a better understanding of the schedule, workload, responsibilities,  contact information, and absentees and coverage for the day. This study was undertaken to deve lop to identify areas  for possible improvements. Three months of daily game plans were analyzed. The analysis included planned patient  throughput per physician, for each of the clinic’s four ‘Pods’, and differences in physician workload for each day of  the week. Significant differences were noted in the throughput for the individual physicians, between the four Pods,  and during different days of the week. Some of the Pods and physicians had significant variances in throughput. In - depth analysis indicated that how the scheduling is performed and individual physician approach to patient care are  the main causes for existing variances. The paper concludes by noting areas for future work.  Keywords  Patient Satisfaction, Waiting Time, Workload, Level-Loading, Resource Scheduling, Efficiency, Appointment  Scheduling.  Introduction  The concept of “Just -In-Time” is well known in the manufacturing domain. This concept can also apply to other  domains such as healthcare. While high- volume manufacturing activities are exp ected to have accurate duration  estimates and tight variances, many healthcare service activities have large variances. This is because of the unique  nature of healthcare in which humans both provide as well as receive services. There are also differences in  consequences of errors between the manufacturing and healthcare domains. While a minor error in production may  result in economic loss, a small mistake in healthcare may result in human harm.   This study aims to improve the patient care of a clinic by analyzing the workload for an outpatient general  internal medicine clinic. Workload generally refers to the amount of work assigned to humans, machines, or any other  resource. Workload management can be defined as an approach to plan and control the resource allocation and  utilization. One way to improve workload is to reduce and/or remove waste and inefficiencies. The ultimate goal of",mavs.uta.edu;,The University of Texas at Arlington,United States,32.705002,-97.12278
60,OPTION GAMES FOR INVESTMENT DECISION IN THE POWERMARKET,@unal.edu.co,"Power market, competitive market, Real options, Games theory, Option Games, Uncertainty.  ","Starting three decades ago, several countries worldwide decided to restructure their power markets. This restructuring  brought positive aspects such as efficiency improvements and the incorporation of fresh private capital. However  investment decisions face more risk and uncertainty than in the previous monopoly models. For this reason,  researchers have been concerned with developing tools to adequately model the agents’ investment decision. Most of  these tools have flaws, so it is necessary to combine techniques that take into account both the risk that investors face  and expected reactions from competitors. Therefore, the purpos e of this work is to show the relevance of using  techniques that combine real options and game theory in competitive environments with risk and uncertainty. Real  options games are a good tool to understand the complex nature of the investment behavior of power companies in  competitive markets.  Keywords  Power market, competitive market, Real options, Games theory, Option Games, Uncertainty.   Introduction  At the beginning of the electricity industry, most utilities were integrated monopolies. Companies where  either  investor (mainly in the USA) or publicly owned. Since the 1980s, many power markets shifted from traditional  environments to competitive environments (Shivaie & Ameli, 2015) . However, pure competitive power markets do  not exist in practice because by nature there is a tendency to have a concentration in reduced numbers of firms (S. X.  Zhang, Chung, Wong, & Chen, 2009) , in other words, it is organized as an oligopoly market (Lopez, Baum, Olsina,  Blanco, & Rehtanz, 2017) . Then the action of one of the agents can dramatically influence market variables. In the  new economic models, profit maximization is more important than cost minimization.  Given the above, the power  market has to include in its risks the behavior of competitors, in addition to other risks such as fuel availability,  demand, etc. The investors must be very careful in their decision -making process specifically related to expansion  plans in generation. In recent years, several papers have been published (Alizadeh & Jadid, 2015; Fitiwi, De Cuadra,  Olmos, & Rivier, 2015; Fosso, Gjelsvik, Haugstad, Mo, & Wangensteen, 1999; Gil, Aravena, & Cárdenas, 2014;  Maceira, Marzano, Penna, Diniz, & Justino, 2015; Phupha, Lantharthong, & Rugthaicharoencheep, 2012; Rouhani,  Varamini, & Nikkhah, 2013; Zeng et al., 2013)  aiming to develop methodologies that can be used for making  generators' expansion decisions.   For this reason, (Botterrud, Ilic, & Wangensteen, 2005) proposed Game Theory (GT) for generators’ strategic  decision and (Smit & Trigeorgis, 2004) use of Real Option (RO) for uncertainty environmental. So, this work purpose  is to show the importance of using a hybrid tool such as Option Games (OG) that combines GT  and RO to properly  model uncertainties and competitive environments. This paper is organized as follow. Section 2 describes the  methodologies for new investment decision making in power markets. Section 3 and 4 describes OP and GT. Section",unal.edu.co,Universidad Nacional de Colombia,Colombia,4.63874255,-74.08523751358481
61,"SYSTEMS APPROACH TO INCREASING THE NUMBER OFENGINEERS, ESPECIALLY WOMEN, BY IMPLEMENTINGCURRICULAR AND CO-CURRICULAR BEST PRACTICES.",@sdsmt.edu,"Women in Engineering, Scholarships in STEM, System Analysis, Retention ","Women comprise 17-21% of engineering enrollment depending on discipline and only represent 12% of the practicing  engineers within the United States.  The entire social and education system from childhood to the working environment  plays a part on these low representation of women in engineering.    At South Dakota School of Mines and Technology that was below the national level in female engineering  enrollment, a National Science Foundation scholarships in STEM (S-STEM) program was started in 2010.  The focus  was on intellec tual diversity and building cultural awareness within the university as a mechanism for supporting  student differences, particularly for underrepresented groups such as women.  Gains were made at the university, and  the original program has been expanded t o include additional engineering majors and to support best curricular  practices, including addressing intellectual differences.   This research analyzes the systems that cause the low participation of women in engineering and discusses  the preliminary results of the S-STEM program that attempts to change the system to increase the number of women  in engineering.  Components of the program include curriculum modification, network events, industry plant trips, lab  events, outreach activities, Engineering Projects in Community Service (EPICS), and an awareness of systematic  barriers that discourage women from persisting in STEM fields.  Preliminary data on intellectual diversity, Small  Group Instructional Diagnosis (SGID), scholar focus groups, and growth in student self-efficacy beliefs as a result of  the program are also discussed.  Keywords  Women in Engineering, Scholarships in STEM, System Analysis, Retention  Introduction  Of the many engineering disciplines, only a handful have seen greater than 30% bachelor degree graduation rates  among women.  These disciplines include environmental, biomedical, biological and agricultural, chemical, and   architectural engineering (Yoder, 2016). When including all recognized engineering disciplines, women comprise 17- 21% of engineering enrollment, yet only represent 12% of the practicing engineers within the United States.  Recent  pushes from industry make it clear that industries are recognizing the value a more diverse workforce.  Companies  that are more diverse in ethnicity, experience, and gender are 45% more likely to have market share increase in the  last year and 70% more likely to capture a new market (Hewlett, Marshall, & Sherbin, 2013).  Most studies that investigate why the female participation in engineering is so low investigate how retention  can be improved at the university level or why women leave the workforce.  It may be desirable to examine the entire  system to understand the factors of why women leave the workforce at different levels in their careers.   This research analyzes the systems that cause the low participation of women in engineering and discuss es  the preliminary results of a scholarships in STEM (S-STEM) program that attempts to change the system to increase  the number of women in engineering.  Components of the program include curriculum modification, network events,  industry plant trips, lab events, outreach activities, Engineering Projects in C ommunity Service (EPICS), and an  awareness of systematic barriers that discourage women from persisting in STEM fields.   Preliminary data  on  intellectual diversity, Small Group Instructional Diagnosis (SGID), scholar focus groups, and growth in student self- efficacy beliefs as a result of the program will also be discussed.",sdsmt.edu,South Dakota School of Mines and Technology,United States,44.0731,-103.2063
62,TEMPLATING IN THE ARTS – A TEMPLATE FOR ENGINEERS,@uah.edu,"Templates, design science, process model, knowledge transfer. ","As the pace of new technology development increases, the availability of adaptable, easy to use training and  development tools becomes increasingly important. This development impacts fields such as engineering, with large  scale complex engineered systems growing in complexity , and fields such as the arts , that are adapting new  technologies for artistic expression. One tool to improve conceptual design efficiency is templates. Templates are one  of the most readily available and widely accepted knowledge transfer tools in use today. By looking to outside sources  that excel at using templates to rapidly create innovative designs, such as the fashion industry, engineers may be able  to create more effective templates for a variety of applications across multiple disciplines. In this paper, a preliminary  literature review on templates used in management, engineering, and artistic disciplines is performed. Relationships  between the arts and engineering are explored. Template types are categorized and templating techniques across  multiple disciplines are analyzed. Similarities in templating techniques are observed across disciplines. This research  may lead to improved efficiency and reduced costs in engineering design.  Keywords  Templates, design science, process model, knowledge transfer.  Introduction  With technology becoming increasingly integral to daily life, engineers tasked with creating and maintaining large  scale complex engineered systems (LSCES) are faced with significant challenges. As Lehman points out, “new  capability, often not recognized during the earlier life of the system, is superimposed on an existing structure without  redesign of the system as a whole.” This produces a never -ending maintenance cycle and leads to increased costs  (Lehman, 1980). Companies across industries have developed adaptable requirements for new systems in an attempt  to mitigate this problem; research into the creation of these systems however is lacking (Agarwal & Tiwana, 2015).  Leveraging experience is crucial for engineers creating adaptable systems to avoid duplicating fundamental  processes during system design. Experience must be earned, or communicated between engineers.  This may prove  difficult in the coming years, as a significant amount of institutional knowledge is at risk of disappearing with large  portions of the workforce nearing retirement age (Paullin, 2014). These concerns are not unique to engineering. Many  industries, such as fashion design, face similar challenges (Sull & Turconi, 2008).  Templates are a tool used to assist in the knowledge transfer process. Templates have been proven to increase  project efficiency , when successfully applied (Jensen & Szulanski, 2007) . Templates, defined by this paper as  knowledge transfer artifacts that provide a basis for new design, are ubiquitous and appear to have no single definition.  Every industry within the scope of this study appears to have a unique understanding of what constitutes a template.  By taking a design science approach to template development, systems engineers may be able to create more effective  knowledge transfer artifacts  (Hevner, March, Park, & Ram, 2004) . This could increase project efficiency (Hevner,  March, Park, & Ram, 2004) and alleviate the loss of crucial institutional system knowledge (Engström, Storey, Höst,  Runeson, & Bjarnason, 2017).  In this paper, a preliminary analysis of template use across five professional disciplines: engineering, systems  management, literature, fashion design, and fine art is conducted. Five template types are identified and defined in a  unique classification scheme  based on use within the  examined projects. Templating techniques among industries,  defined for this paper as the ways in which tem plates are applied, are examined and compared . By looking at how  other industries, such as the arts, define and use  templates, engineers may be able to develop knowledge transfer  artifacts that incorporate a greater range of institutional knowledge, easing  foundational design challenges for  adaptable systems.",uah.edu,University of Alabama at Huntsville,United States,34.7252,-86.6405
63,TOWARDS A MODEL OF STRATEGIC CONSIDERATIONS IN PRICINGDECISIONS,@uah.edu,"Pricing, hypothesis generation, judgment, decision making, affordability. ","The cost of a system is a crucial piece of  any system’s value. Unfortunately, modeling and predicting that cost can  present several challenges. The cost  of a system is not only the product of characteristics of the system itself, but it  also depends on potentially several pricing decisions. These pricing decisions may incorporate strategic considerations  that would not be seen from a typical engineering a nalysis. The price charged for a product is not only changing the  product’s price, but potential customers’ perceptions of the company as well. This paper explores a unique application  of a cognitive model of hypothesis generation in modeling the impact of pricing decisions on future value-for-money  judgments. What an individual thinks a product may be worth is based upon the information available to them, which  includes not only data directly related to the system itself, but also knowledge gained from previous interactions with  the producer. In this instance, the previous five interactions inform judgments regarding the value -for-money of the  following interaction. This simplified model represents an important step towards modeling the impact of human  judgment on strategic pricing decisions of engineered systems.   Keywords  Pricing, hypothesis generation, judgment, decision making, affordability.  Introduction  Understanding the cost of a system is an essential part of determining potential value, but understanding and accurately  predicting cost can be challenging. Affordability analysis can be seen as a way to gain a more nuanced view of how  cost impacts the success of a project, with many definitions including some sort of relationship between performance  and cost (Kroshl & Pandolfini, 2000; Mavris & DeLaurentis, 1998; Redman, 2012; White, Mesmer, & Collopy, 2019).  While including performance aspects may, indeed, shed more light on the topic than a cost analysis alone, it does not  escape the limitations of the cost models themselves. In space systems, traditional cost models have been shown to  have significant error for predicting the cost of future systems (Keller, Collopy, & Componation, 2014). Clearly, these  models are not perfect; improving the prediction of cost will require accounting for factors that are too often ignored.  The cost of a system is not simply a characteristic of the design itself, but is also the result of several cascading  pricing decisions. These decisions not only affect the profit for the current system, but can have far-reaching impacts  on reputations and relationships. Decisions made at one moment can change the environment in which future situations  may take place. In addition, the decisions made by competitors also affect the environment in which these decisions  are being made. Before a method for predicting costs can be developed, the broader impact of pricing decisions must  be explored.  Contributions  This paper provides a unique application of hypothesis generation modeling to subjective value judgments. Modeling  these judgments is essential for comprehensively modeling the outcomes of pricing decisions. Better understanding  of the effects driving pricing outcomes not only enables better pricing decisions, but potentially enables more accurate  cost forecasting.  Background  One key way that pricing decisions may impact other decisions is through the value judgments of potential customers.  What an individual thinks the system may be worth is based upon the information available to them, which includes  not only data directly related to the system itself , but also as pects such as the company’s reputation and previous  experiences with them. Social capital (Adler & Kwon, 2002) is a social science concept that relates to the goodwill",uah.edu,University of Alabama at Huntsville,United States,34.7252,-86.6405
64,ART+ENGINEERING: ENABLING INCLUSIVE AND CONSEQUENTIALTECHNOLOGICAL DESIGN,Missing,"Diversity and Inclusion, New Product Development, Visual Arts, Engineering Management Graduate Education  ","Not only is technology being more deeply embedded in our lives and our daily activities; but  it is also being called  upon in responding to some of socie ty’s greatest problems. While technological solutions hold much promise, the  complexity of these challenges implore the engineer to grapple with both technical considerations and the often more  consequential social, political, and cultural implications of their design and eventual deployment. Visual art, as a  methodological intervention, could offer promise in aiding the graduate engineering management (EM) student to  more deeply reflect on their design decisions and their a ssociated implications/repercussions.  A recent Artsy article  titled “Looking at Art Could Help Med Students Become Better Doctors” highlights a study that suggests that engaging  with the visual arts improved the capacity of medical students for personal reflection ; particularly, their “ability to  understand a situation from different points of view, to empathize with another person’s dilemma, and to acknowledge  different ways of thinking.” It is hypothesized that similar impact could happen in aiding the engineering manager  within the context of more inclusive and consequential product and technological design.  Through a review of some  exemplar Art+Engineering initiatives, this paper proposes three (3) pathways for exploration in supporting graduate  engineering management (EM) programmatic integration .  These strategies include: Embedded Artist or  Programmatic Artist in Residence ,  Art+Engineering Academic Track within the Graduate EM program , and  Art+Engineering Experiential Learning Opportunities.   Keywords  Diversity and Inclusion, New Product Development, Visual Arts, Engineering Management Graduate Education   Introduction  Not only is technology being more deeply embedded in our lives and our daily activities; but, it is also being called  upon in responding to some of society’s greatest challenges (http://www.engineeringchallenges.org/ ).  In meeting  these challenges, it is important that engineers and engineering managers think and act, more holistically, in  designing technological solutions of benefit to ALL of humanity.  Unfortunately, often as a function of a lack of  diversity in viewpoints, beliefs, and values of those privileged to engage in these often-grand engineering exercises  (i.e. western educated, white and/or Asian, middle/upper middle-class, heterosexual cisgender men), a more  homogenous and thus biased view of humanity often emerges.  This narrower lens of perspective not only constrains  the design exploration but could foster technological solutions that are exclusive; devoid to the considerations of  socioculturally diverse groups.  While an unintentional impact of the engineer’s decision-making, the consequences  can be profound.  “The choices that get made in building technology then have social ramifications.” states Stanford Professor  Mehran Sahami (Singer, 2018).  Exclusionary practices, patterns, behaviors, and norms are being ingrained within the  “doing” of engineering design (e.g. processes and practices) that, while unintentional, may lead to the deployment of  technological solutions that do more harm than good.  This is no better evidenced than in the mounting and disturbing  evidence that exposes the existence and propagation of bias in Artificial Intelligence (AI) products and technologies,  prompting many experts to state that, “We’re in a diversity crisis” (Snow, 2018).  In addressing this mounting crisis,  Nicol Turner Lee , states in her March 2019 congressional testimony, t he “tech sector must be more proactive in  developing solutions that reduce, or better yet, eliminate bias from newer and emerging technologies in part through  employing tools that ensure that cultural biases are identified upfront and checked throughout the process” (Hearing  on “Inclusion in Tech: How Diversity Benefits All Americans”, 2019)  It is hypothesized that engaging the visual arts, as a means for reflexivity in practice, could serve as a  means by which to aid the engineering/technology manager as designer to more deeply reflect, more inclusively (i.e.  designing such to take into account the full range of human diversity) and consequentially (i.e. taking the time to  pause to think through the potential outcomes of a given design decision or direction)",Missing,,,46.3144754,11.0480288
65,USING NEWS CYCLES TO EXPLAIN TRENDS IN CRUDE OIL SPOTPRICES,@mavs.uta.edu,"News corpus, Neural Network, crude oil spot price  ","Traditionally, numerical features such as stock movements, market futures, refinery stocks have been used to predict  or explain trends in crude oil spot prices. Even adverse events and Geo-political scenarios have been used to a certain  extent to explain trends in crude oil spot prices. Text-based features are an area that have not been explored fully yet.  With the increase in availability of news corpus data and advances in text mining and analysis methods, news cycles  may prove an important factor in explaining crude oil spot prices. This paper is an exploratory first step in using freely  available news corpora data to explain trends in crude oil spot prices over time. The success of the methods explored  here may lead to a more robust system for including text-based features as part of future forecasting models.  Keywords  News corpus, Neural Network, crude oil spot price   Introduction  Crude oil spot prices indicate, among other things, the health of an economy, on -hand inventories, and supply and  demand scenarios. Understanding and predicting spot prices is also important for futures trading and many models  have been employed for this particular task. Akin to other futures we think that there might be a relationship between  crude oil spot prices and the news cycle. This research is an exploratory first step in this direction.   In this work, Wall Street Journal news corpus was used to gauge the positive, negative, or neutral sentiment  of the news cycle and use that to predict crude oil spot prices. The theoretical model (and rationale), data used, results,  discussion, and the future direction for this work are laid out in the subsequent sections of this paper.  Related Work  Forecasting crude oil spot prices have been done using methods that may be broadly classified into three groups: time  series forecasting, econometric methods, and multivariate methods. A more detailed literature review m ay be found  in Natarajan and Ashok (2016).   Time series methods use historical time series data to make one- step ahead or multi -step ahead forecasts.  These methods just use the historical series of crude oil prices and n o other variables. The most commonly used  method in this category is the ARIMA (auto regressive integrated moving average) group of methods. There may be  modifications like using just AR and MA or adding a seasonality component to make it SARIMA. (Moshiri &  Foroutan, 2006; Mostafaei & Sakhabakhsh, 2011; Komijani, Naderi, & Alikhani, 2014; Zou, Yu, & He, 2015)   Econometric models use a few variables to explain the variance in crude oil prices. Econometr ic models  usually use regression and include economic variables. There have been some attempts at using machine learning  methods, but they are mostly linear methods.  (Dahl & Erdogan, 1994; Decker & Wohar, 2005; Mer ino & Albacete,  2010)",mavs.uta.edu,The University of Texas at Arlington,United States,32.705002,-97.12278
66,M,Missing,,,Missing,,,46.3144754,11.0480288
67,M,Missing,,,Missing,,,46.3144754,11.0480288
68,MANAGING DATA ANALYTICS INITIATIVES THROUGHUNSTRUCTURED PROCESSES,@gmail.com,"Data Analytics, Big Data Analytics, Unstructured Business Process, Industrial Internet of Thing s. ","The number of organizations using connected devices has been steadily increasing with the widespread application of  the Internet of Things (IoT). As a result, the volume of stored data, available to be analyzed, has also grown  significantly. With the popularization of machine learning and data mining algorithms, and the adoption of powerful  data analysis software, organizations have shown a growing interest in developing processes to collect, refine, process,  analyze and display data. However, most of the d ata analysis processes that are conducted are too prescriptive.  The  analysis is usually only suitable for one specific type of task (e.g. mining the most frequent occurrences of quality  problems in the deliverables of a project data log) and not suitable to be applied in a more general context. Adaptation  to a more uncertain objective is needed, in which different sources of data and different algorithms need to be  combined to produce insights (e.g. defining what actions had the best outcome in treating quality problems in the  projects of an organization). This work proposes, based on the data analytics and process management literature, an  unstructured, non -prescriptive process to manage data analytics initiatives that overcome these difficulties. The  process includes suggested activities, tools, and algorithms that are related through a set of loosely linked rules, making  the process more flexible and adaptable to different situations. An illustration of the process in the context of energy  management of an industrial organization is provided.  Keywords  Data Analytics, Big Data Analytics, Unstructured Business Process, Industrial Internet of Thing s.  Introduction  Currently, with the development of new technologies as the Internet of Things (IoT), Cyber Physical Systems (CPS)  and Big Data Analytics (BDA), the volume of data has increased significantly. The development of machine learning  and data mining algorithms software has supported organizations to collect, refine, process, analyze and display data.  However, most of the data analysis processes that are conducted are too prescriptive.  The analysis is usually only  suitable for one specific type of task (e.g. mining the most frequent occurrences of quality problems in the deliverables  of a project data log) and not suitable to be applied in a more general context. Adaptation to a more uncertain objective",gmail.com,,,46.3144754,11.0480288
69,A METHODOLOGY FOR VISUALIZING AN ORGANIZATION’SINFORMAL COMMUNICATION NETWORK,@afit.edu,"Organizational Networks, Network Diagrams, Visualization, Teams, Communication Networks , Process ","We depend on networks of people to realize our objectives.  What one person knows is important, however,  each person they know represents access to distributed knowledge.  Networks reveal the shape of this distribut ed  knowledge.  Performance of the individual, and by extension the organization, is influenced by this network.  Relevant  to engineering management, literature indicates that the establishment of networks influences performance in technical  industry settings.    Workforce networks vary in complexity, scope and rate of change.   The numbers of unique nodes and  connections serve as a gauge of complexity.  The scope of the network is not limited to a division or firm, connections  can extend to key business partners.  Beyond complexity and scope, workforce turnover trends make these networks  increasingly dynamic.  Balancing complexity, scope and rate of change in the phenomenon of interest, we have sought  a tool that is amenable to low cost reapplication over time.  We present a method to rapidly visualize a given employees communication network, a window into who  they know.  We discuss our data source, tool, example visualizations and possible applications. We leverage data that  is persistently gathered and  readily available in email log files.  Through processing with an open source software  tool, we are able to generate visualizations and descriptive statistics.  Two example networks are provided along with  assessments to illustrate insights from this visualization.  Finally, practical applications of this method are considered.  The method presented here is a first step,  additional research is required to understand the interactions between  network characteristics and performance.    Keywords  Organizational Networks, Network Diagrams, Visualization, Teams, Communication Networks , Process  Improvement, Tool, Email   Introduction  There are a number of ways to characterize the structure of an organization, the most common being that of the  hierarchy or organization chart.  Where the hierarchy is analogous to the backbone of an organization, informal  networks are the central nervous system. When characterized in a visual format called a network diagram, informal  networks can reveal the information flows and groups that underlie an organization’s activity and performance.  This  view provides insight into how the work gets done (de Toni & Nonino, 2010).  Exhibit 1. Visualization of an informal network, represented with a network diagram",afit.edu,Air Force Institute of Technology,United States,22.798225100000003,120.27882504037152
70,THE ROLE OF ORGANIZATIONAL RESILIENCE ACROSS THE CYBERATTACK LIFECYCLEVT MAK,@mak.com,"Cyber resilience, cyber attack lifecycle, organizational resilience, resilience engineering.  ","The rapid increase in the variety and complexity of cyber attacks continues to challenge the ability of organizations to  protect themselves from losses due to cyber intrusion. With this increase has also come an increase in standards,  frameworks and tools in order to combat such risk.   Organizations invest billions of dollars each year to obtain  sophisticated software tools, specialized hardware and high ly trained subject matter experts in order to improve their  cyber protection position.  The challenge for organizations is finding ways to navigate through the many protection  options to guide their investments towards organizational cyber resilience.  Res earch in resilience characteristics can  provide strategies for addressing the actions of advanced persistent threats (APTs) and the cyber tactics, techniques  and procedures (TTPs) they implement.  This paper will provide a mapping of the resilience characteristics needed  across all stages of the cyber attack lifecycle.  Specific cyber attack examples are used to demonstrate the application  of these resilience strategies.  Keywords  Cyber resilience, cyber attack lifecycle, organizational resilience, resilience engineering.   Introduction   The cost of cyber -breaches is far reaching as the data privacy of millions worldwide continues to be compromised  (Linkov & Kott, 2019).  Over the past 5 years cyber breaches have increased by 67% and the cost per breach increased  72% to an average of $13 million dollars per case (Accenture, 2019). Additionally, organizations are challenged with  how to guard against Advanced Persistent Threats (APTs) where in some cases a cyber-breach is not discovered until  years after the initial intrusion where data was compromised over a long period of time without detection (Accenture,  2019).  With so much at risk, regulations such as the General Data Protection Regulation (GDPR) set forth by the  European Union and the California Consumer Privacy Act (CCPA) in the United States have strict standards to help  ensure the protection of information (Mendoza, 2019).  Regulatory agencies for data protection and privacy are  beginning to hold executives and their organizations accountable for the subsequent impacts of cyber-breaches as the  impacts can affect national security, the economy and society as a whole.  Organizations that experience a breach and  are found to fall short with compliance to regulatory standards can experience deep fines (Mendoza, 2019).  For  example, recent data privacy breaches have resulted in multi-billion dollar fines (Isaac & Kang, 2019).   Organizations are challenged with how best to sift through regulatory requirements and choose the right set  of standards, guidelines, frameworks and tools to reduce their risk.  For example, GDPR and CCPA both have strict  regulatory standards for the protection of personal information.  However, they both differ in their definitions and  requirements adding layers of complexity for organizations that must comply with both (Mendoza, 2019).  The United  States Department of Defense (US DoD) has developed a strict set of guidelines for protecting organizational and  operational systems from cyber attacks and intrusion ( Ross, R., Dempsey, K., Viscuso, P., Riddle, M., & Guissanie,  G., 2018).  This includes associated standards defining the requirements that need to be followed for systems and  facilities to be certified and allowed to operate (Force, 2018). Carnegie Mellon University (CMU) CE RT has  developed a framework for assessing operational resilience management based on implemented goals and practices  (Caralli, R.A., Allen, J.H., White, D.W., Young, L.R., Mehravari, N., and Curtis, P.D., 2016 ).  The cybersecurity  industry has created a variety of tools and services to help organizations implement their cybersecurity programs. With",mak.com,,,46.3144754,11.0480288
71,ASYNCHRONOUS COURSE DESIGN 101,@unl.edu,"Online education, online course design, asynchronous, interactions, syllabus, navigation, backward design.  ","The face of higher education is changing rapidly. Institutions of higher learning are expanding their mainstream  programs and course offerings to include online options for several reasons,  including enrollment, revenue growth,  and demand from millions of working adults whose educational needs are not met with traditional face-to-face classes.   Creating a course using backward design pedagogy is important  for both face -to-face and online delivery formats.  While sound course design, development, and delivery are critical to effective teaching and learning in all delivery  formats, they are of particular importance in an asynchronous  environment due to the geographic distance  between  learners and faculty . Several factors which directly impact student success  in an online course  are syllabus quality;  course layout; ease of navigation; interactions of learners with facu lty, with content, and with other learners; and the  instructor’s online presence and ability to build an online community for the learners. This paper highlights practices  associated with successful online courses  and recommends strategies for design and delivery based on a course  evaluation rubric used by Quality Matters, which is an organization dedicated to creating effective online and blended  courses. Faculty must clearly communicate the purpose and structure of the course and help students get started in the  course; communicate expectations for online discussions, email, and other interactions ; explicitly identify minimum  technology, computer skills, and prerequisite knowledge; create a sense of community and belonging for the students  through instruction and interactions with faculty, content, and other l earners; and evaluate learning with sequenced,  varied, and appropriate assessments.  Keywords  Online education, online course design, asynchronous, interactions, syllabus, navigation, backward design.   Introduction  The origins of fully  online education dates back to mid-1980s, but it has rapidly gained popularity in recent years.  Lederman & Lieberman (2019) state that more than 20 institutions  from coast to coast  have made announcements,  either publicly or quietly, that  they are embarking upon ambitious online learning initiatives . These institutions are  individual flagship schools, part of the state university systems , and public universities. A few of the reasons which  may explain this phenomenon are: enrollment or revenue growth, serving millions of working adults, reclaiming state  residents who left the system to study online elsewhere, and capitalizing on the flexibility of time and space that online  education affords learners of all ages.  In a meta-analysis, Means, et. al. (2009)  reported that on average online learners performed better than on - ground students. Yet, online courses have 10% to 20% higher failed retention rates than  traditional courses ( Bawa,  2016). As online programs become part of the mainstream educational options offered by institutions of higher  learning, course design must be carefully considered  to improve retention rates and to continue and maintain the  superior performance by online learners.  The merits of backward course design is well documented in teaching and learning literature and emphasizes  that effective course design would include the following: a) identify desired results, b) plan learning experiences and  instruction, and c) determine acceptable evidence that studen ts have achieved those results ( Ko & Rossen, 2017;  Bernstein, et. al. , 2006; Wiggins & McTighe, 2005). While this pedagogical perspective is valid and necessary for  both online and face -to-face learning, an online course must also meet certain  criteria to ensure high  potential for  student learning. Online courses must respond to several social, motivational, and technological issues from  perspectives of both learners and faculty (Bawa, 2016). Therefore,  sound course design, development, and delivery  remain of utmost importance to ensure student success in achieving learning outcomes.   Quality Matters (QM) is an organization devoted to online and blended course design. In evaluating a course,  QM uses a rubric which includes eight general standards and 42 specific review standards. Grounded in more than 26  years of online development and teaching experience, in 2017 the author completed two certifications in, a) applying",unl.edu,"University of Nebraska, Lincoln",United States,40.8205941,-96.70260581368638
72,FORECASTING TECHNOLOGY TRENDS OF THE GAP BETWEENSCIENCE AND TECHNOLOGY: THE CASE OF SOFTWARE AS ASERVICE E-COMMERCE,@pdx.edu;,"Technology trends, Technology forecasting, Technological Trajectory, Text Mining, E -commerce, Software as a ","Identifying technology trends can be a key success factor for companies to be competitive and take advantage of  technological trends before they occur. This paper uses text mining techniques along with expert judgment to detect  and analyze the near -term te chnology evolution trends in a Software as a Service case study.  The longer -term  technology development trend in this case is forecasted by analyzing the gaps between science and technology. This  paper contributes to forecasting  technology methodology in software as a services technology..  Keywords  Technology trends, Technology forecasting, Technological Trajectory, Text Mining, E -commerce, Software as a  Service, SaaS, Patent Citation.  Introduction  The aim of this study is to apply text mining and citation analysis of scientific papers and published patents in Software  as a Service (SaaS) technology to reveal the technology trends in this industry and apply it as a technology forecasting  approach. Forecasting the trend of technologies creates potential o pportunities for the companies in the industry and  for governments at international competition. In current years, it’s been revealed in different research and development  projects that patents and scientific papers contain considerable amount of important  information about developed  technologies. (Kim & Bae, 2017) identifying technological trends and acting upon can give enterprises and countries  a strategic edge which result in more progression in the society and an advantage in global competition. (Li, X ie,  Daim, & Huang, 2019) most critical decision makers are aware of the importance of being ahead of competitors in  detecting and taking advantage of technological trends particularly in our current knowledge economies. Therefore, if  organizations, either profit or non- profit, want to gain sustainable competitive advantage they need to move early in  identifying emerging technologies and pursue the continuous process of innovation which will result in their  competitiveness and development.  Literature Review       In the era of big data and artificial intelligence, the computational capacity and abundance of data and information  has been increasing. For that, scientific research has access to the powerful tools to dig deeper into the fruitful sources  of data. That helps to understand the future scenarios of scientific and technological trends. Scientific papers and  patents are important containers of information about technologies that can be exploited by novel techniques to grasp  what are patterns of technolog ical trends. Some methods like text mining and patent analysis allow researchers to  investigate technological documents and mine for useful information in a systematic way. (Madani & Weber, 2016)",pdx.edu;,Portland State University,United States,45.5111,-122.6833
73,REVERSE HIERARCHAL LEARNING APPROACHES INENGINEERING EDUCATION: INFERENCES AND ETHICALCONSIDERATIONS,@csun.edu,"Community service, diversity, engineering education, ethics, hands on learning, reverse hierarchal learning, service-","Engineering education programs are rapidly changing due to shifting societal needs. Recent graduates may have the  academic knowledge but lack  the experience required to work as an effective 21st Century engineer. To meet such  challenges, a top -down reverse hierarchal approach that helps produce a learning environment where students learn  from each other is proposed. A freshman student is paired  with a senior student and then sent to a community -based  organization for an internship. The freshman-senior team, accompanied with a community-based employee, work on  solving engineering problems. While the curriculum prepares students academically, this approach combines service- learning activities into beginning engineering courses, as well as capstone courses.   Initial findings of the proposed approach are reported. The author performed a random experiment on students who  were directly selected from a population of freshman and senior level students. Progress of students who were paired  and sent to a workplace and that of others who stayed on campus without an internship are compared. Enabling senior  level engineering students to mentor freshman level s tudents proved to be effective in promoting learning and  enhancing retention.   The ethical responsibilities that academic institutions and the workplace have in implementing this approach are  discussed. Possible impacts on education, experience and gender interaction are explored. The students' perception of  how the community-based organization may influence their individual values is assessed as well. Results show that  individual ethical values are influenced by the student’s academic level. These values are also influenced by the  amount of time spent at the community-based organization.  Keywords  Community service, diversity, engineering education, ethics, hands on learning, reverse hierarchal learning, service- learning, social values.  Introduction  Previous research suggested that learning where diversity is emphasized generally have positive effects on college  students’ cognitive development. In a recent study of over 3,000 first -year students at 19 institutions, it was reported  that students who to ok at least one course where diversity is emphasized, have greater gains in their general interest  in ideas and effortful thinking than those who take no such courses. Prior observations reveal that students from  middle- or lower-income families and White students experience the greatest cognitive growth if they take courses  where diversity is highlighted (Bowman 2009). As the American society has become increasingly more diverse,   addressing methods that create a learning environment where students interact and learn from each other has become  apparent. This is especially important as it is expected that the U.S. population will be considerably more racially and  ethnically diverse by 2060 (U.S. Census, 2012). California State University, Northridge (CSUN) is a Hispanic Serving  Institution as well as Asian American, Native American, and Pacific Islander Serving Institution. It continually seeks  opportunities to sustain diversity and forge pathways to inclusion. One avenue in promoting diversity is to engage  disparate (privileged and marginalized) students in a service-learning environment.   At CSUN, service-learning (SL) is defined as a teaching and learning strategy that integrates community  engagement with classwork instruction to enrich the learning experience (Gandhi et al. 2015). Moreover, SL intends  to teach students civic responsibility and buttress their link to the communities around campus. It also strives to  establish collaboration between the university and the larger communities for the mutually beneficial exchange of  knowledge and resources. Such actions create partnerships and coalitions that help mobilize resources, influence  systems and serve as catalysts for change of policies, programs, and practices. SL has demonstrated to be an effective",csun.edu,"California State University, Northridge",United States,34.2455346,-118.52632210641266
74,M,Missing,,,Missing,,,46.3144754,11.0480288
75,IMPACTS OF THE SARBANES OXLEY ACT ON PRIORITIZINGPROJECTS: A CASE STUDY IN BRAZILIAN CHEMICAL INDUSTRYWITH NEW YORK STOCK EXCHANGE,@pupr.edu.br,"Project Management; Prioritization of Projects, Risk Management and Sarbanes Oxley Act ","Credibility requires transparency and corporate governance. Consequently, the projects should be prioritized through  factors that contemplate the risk diagnosis, sustain the production condition and observe auditable economic criteria.  How to promote the appropriate adaptations applying project portfolio prioritization and respecting legal requirements  is what this article proposes to investigate. The research method adopted was a case study on project management  office in a Brazilian Chemical Industry that is active in the stock market of the New York Stock Exchange, obliged to  conform to locals’ laws. Among the main results had the improvement in the reliability of the results of the projects  with effects on the environment, and the increase of the transparency of the information of the corporate management,  reducing the influence of the departments in favor of the whole organization. This article contributes to the evolution  of engineering management, increasing the instrument s for project management effectiveness. In this example, one  Brazilian Industry acting in the American stock market, may serve like a model to others in promotes cultural changes,  governance and management that can transform, for the better, the management practices.  Keywords  Project Management; Prioritization of Projects, Risk Management and Sarbanes Oxley Act  Introduction  The commercial visibility provided to an organization that has shares traded on the US stock exchange, New York  Stock Exchange - NYSE, raises the condition of attracting investments on an exponential scale. However, in 2002,  when Sarbanes -Oxley - SOx was e nacted, corporate governance and accountability requirements (statements of  income, expenses, balance sheet and total assets and liabilities) are demanded in order to prevent fraud (Freitas,2012  and site https://www.treasy.com.br/blog/sox-lei-sarbanes-oxley/).   Globalization has attracted many consumer market opportunities as well as influences from various levels of  instabilities. To address this scenario, risk management actions that s upport production and under auditable criteria  are among the measures adopted by many organizations. All these procedures aim to achieve compliance, which aims  to ensure that the organization complies with legal regulations (https://endeavor.org.br/pessoas/compliance/).  Matching these standards has become a requirement at all levels (strategic, tactical or operational) of organizations.  By deploying the organizational strategy in deliverables, each project responds, at appropriate levels, to the  requirements that make up the whole of governance and compliance. In this way, these isolated projects or in the  composition of programs can constitute portfolios, from which information is generated to sensitize investors. The  veracity of these data signals management transparency for the market.  Project and portfolio management, on an internationally recognized basis, can serve as a starting point to achieve  credibility with investors. In this way many organizations adopt the management practices advocated by the Project",pupr.edu.br,Polytechnic University of Puerto Rico,United States,18.4223,-66.0559
76,ASSESSMENT OF DIVERSITY OF OFFERINGS IN UNDERGRADUATEINDUSTRIAL AND SYSTEMS ENGINEERING DEGREE PROGRAMS,Missing,"Industrial engineering, systems engineering, competencies, higher education, curriculum  development ","In the digital age, technology is evolving exponentially.  What is useful and needed, quickly becomes obsolete.  Industrial and systems engineering education continues to evolve in an effort to adapt to challenges and meet system  needs, now and in the future. As demand for this path of study increases, these degree programs will be more critically  assessed as prospective students and recruiters  filter through available supply. Given that the methods, tools, and  techniques are rapidly advancing, competency in personnel management and soft skills must also evolve.  Universities  programs must develop those most demanded by employers, such as critical and  analytical skills, systems thinking,  stakeholder communication, information and knowledge management, project management, and agile development,  as well as a total lifecycle emphasis to support system evolution and sustainment.    Our study will examine the diversity of courses and topics offered in an undergraduate industrial and systems  engineering (ISE) degree program s and evaluate similarities, differences, and gaps using the listings in available  curricula and descriptions of requirements. We will conclude with recommendations for new programs and thos e  seeking to enhance their curricula  to provide more value to students , to more effectively address the challenge of  providing the supply of curricula  and ISE graduates, to meet the demands of its current and future students’  competencies, and to be of val ue to government and industry seeking to employ individuals with ISE degrees and  competencies.  Keywords  Industrial engineering, systems engineering, competencies, higher education, curriculum  development  Introduction  Industrial Engineering and Systems Engineering (IE/SE) are often paired together and share a definition:  ‘‘An Industrial and Systems Engineer is one who is concerned with the design, installation, and  improvement of integrated systems of people, material, information, equipment, and energy by  drawing upon specialized knowledge and skills in the mathematical, physical, and social sciences,  together with the principles and methods of engineering analysis and design to specify, predict, and  evaluate the results to be obtained from such systems’ ’ (Womack and Jones , 1996; as cited in   Salvendy, 2001, p. 5).  There are many articulated definitions of both “industrial engineering” and “systems engineering” used in academic  and professional literature, as well as a considerable number of variations for how the engineer in this discipline  conducts their role, that are beyond the scope of the paper to discuss.  Rather, it is of interest that ISE is ubiquitous in  industries where college graduates seek employment, and a discipline r equiring integrated levels of knowledge to  provide value to potential employers’ projects.  The systems developed to encompass a host of life cycle challenges,  constraints and boundaries requiring systems thinking, and consideration of diverse stakeholder interests that are all  significant to the success of the project (de Souza, 2008).  The International Council on Systems Engineering define a system as a construct or collection of different  elements (e.g. people, hardware, software, facilities, policies, and documents ) that together produce results not  obtainable by the elements alone, and all are required to  produce system -level results such as desired  qualities,  properties, characteristics, functions, behavior, and performance (INCOSE, 2015).  It is widely recognized in systems  literature that a system as a whole produces value “beyond [what is] contributed independently by the parts , is",Missing,,,46.3144754,11.0480288
77,"A FRAMEWORK FOR UNDERSTANDING ILLEGAL BUSINESSACTIVITIES, FROM COMPETITION TO CORRUPTION - THE CASE OFSNC LAVALIN",@uqo.ca,"Accountability, collaboration, competition, cooperation, collusion, corruption, firm life cycle and oligopoly. ","Markets go from early stages of entrepreneurial firms, linked to ecosystems to late stage value chains dominated by  mature firms. In early stages, pure competition dominates with plenty of market space available to distance the firm  from direct competitive pressures and whenever these pr essures materialize, the firm can reposition somewhere else  in the market and pursue its destiny based on its own competencies. As the market develops and firms start to mature,  the competition is partially supplemented with cooperation. The first steps are taken towards common capabilities, or  the grouping of several firms' competencies. When these capabilities harden by the time the market reaches the cluster  stage, the informal coordination is slowly replaced by active and deliberate collaboration and the first prototype of the  value chain emerges. By late stages when market boundaries firm up and the market growth is exhausted, the  competitive game becomes a zero sum and firms start displaying strategies of harm towards each other. After a wave  of massive M&A, the market is reduced to an oligopoly, where strategies of collusion start to happen. If these activities  breach the principles of transparency and accountability, and are abetted by crumbling corporate values, corruption  can take hold. This paper will explore the market conditions, external factors and societal tolerance that leads to active  and contagious business corruption. We shall rely on the Canadian SNC-Lavalin case to illustrate many points.  Keywords  Accountability, collaboration, competition, cooperation, collusion, corruption, firm life cycle and oligopoly.  Introduction  In this paper, the authors are lev eraging on three theor etical models to build  a consolidated framework to explain  corruption in  market maturity. This paper is about progress in theory and recognizes that sound theories, the kind that  explain and  predict what will cause corruption to happen does not develop overnight. Even if a theory does not explain  some particular circumstance, it’s s till valuable because knowing when a p articular theory doesn’t help elucidate  something will allow you to turn  to others to find a better answer. That’ s the hallmark of a good theory. It di spenses  advice in if-then statements (Christensen, Hall, Dillon, & Duncan, 2016). This paper capitalizes on previous research  done by the authors on lifecycle as well as  research on fraud by Albrecht, Cressey, Festinger, Gottfredson, Kohlberg,  Langer, Shutterland, Smith, Tarde and Tyler.  Three Perspectives on Market Dynamics  The market has a life of its own , s tarting from the underlying customer base that defines each market surface  phenomenon, including threats and opportunities for firms churning through the market lifecycle . The customer base  can be imagined as a n ormal distribution curve where each customer group occupies a place and spawn s market  dynamics that push, pull and squash the firms through various stages of market evolution. Stages succeed each other  in a time sequence that signals the evolving profile of each firm. Exhibit 1 shows the link between the customer base  and the aggregate market evolution.",uqo.ca,Université du Québec en Outaouais,Canada,45.42226325,-75.73909824426678
78,APPLICATION OF NATURALISTIC DECISION MAKING TO THEDOMAIN OF UNMANNED AIR VEHICLES OPERATIONS,@odu.edu;,"Naturalistic Decision Making (NDM), UAV, human factors, aviation, ACT-R, Crew Resource Management. ","Naturalistic Decision Making (NDM) explains how decisions are made in dynamic, precise and sensitive settings  such as Unmanned Aerial Ve hicles (UAV) operations, fire events, nuclear power plant processes and put forward  that people decide on a diagram arose from past experience before carrying the necessary action.  The use of UAVs  in the military is mounting due to a diminishing tolerance of societies to losses in human life, advances in  technology, augmentation of the effective impact power of defense systems, and advances in information systems,  robot, and artificial intelligence technologies. Conversely, the current state of UAV technol ogy places additional  demands on the human control pilot’s situational awareness and ability to adapt to dynamic combat environments,  because intelligent autonomous systems capable of decreasing human piloting errors are still far away from the  status quo.  Understanding how decision errors in UAV operations arise in accident situations are vital for  realignment of the organizational context to mitigate or eliminate decision errors.  This paper reports an analysis of  UAV operations within the context of Klei n’s (1993) recognition-primed decision-making (RPD) model, proposes a  modification to the RPD model to incorporate C rew Resource Management (UAV CRM- RPD), and sets forth a  research agenda for future testing and validation of the UAV CRM-RPD model.  Keywords  Naturalistic Decision Making (NDM), UAV, human factors, aviation, ACT-R, Crew Resource Management.  Introduction  Decision-making is the action of selecting from a set of alternatives through attributes analytically  or deciding on an  action through past experience. The intention in deci sion-making is to proceed through steps free from error and  ensure the result of the given decision succeed the goal . Given that the t erms “error” and “decision making” are  close and reciprocally dependent, decision making is conducted to abstain from errors and to succeed the aimed task  either in an emergency situation or a usual task . The importance of decision -making increases under time-restriction  and stressed missions.  Naturalistic Decision Making (NDM) explains how decisions are made, rather than how should be made, in  dynamic, precise and sensitive settings such as Unmanned Aerial Vehicles (UAV) operations, fire events, nuclear  power plant processes. NDM is an attempt to understand how people make decisions in real -world contexts that are  meaningful and familiar to them. (Lipshitz, Klein, Orasanu, & Salas, 2001)  The assumption in NDM is that people  decide on a schema ascended from past experience before carrying the necessary action. Understanding  how people  make decision s in UAV or such sensitive,  stressed operations can help improve the decision quality  of the  individuals and the crew . This understanding is likely to contribute to  training and selectio n of phases of the stuff  and managers. The exertion of understanding about how decisions are made has the potential of preventing errors in  decisions and put forward new suggestions and methods of decision-making.  The use of UAVs in the military is mountin g due to a diminishing tolerance of societies to losses in human  life, advances in technology, (Hing, Sevcik, & Oh, 2009)  augmentation of the effective impact power of defense  systems and advances in information systems, robot and artificial intelligence technologies.  The usage of UAVs in  the private sector increases due to many factors such as security, cost-effectiveness and flexibility. A UAV operation  can simply be defined as a mission executed using a UAV for various goals such as military, transportation, disaster  recovery and preparation. The success of a UAV operation is based on the precise planning, rapport coordination,  clear, concise and correct communication between the players such as the operator, air -controller and ground  services.",odu.edu;,Old Dominion University,United States,36.8853,-76.3059
79,MEASURING ECONOMIC IMPACTS OF INLAND WATERWAYTRANSPORTATION,@lemoyne.edu,"Inland waterway, transportation, economic impact, input-output analysis  ","The McClellan-Kerr Arkansas River Navigation System (MKARNS), located in Oklahoma and Arkansas, contains  445 miles of inland waterways and is a crucial part of the United States’ transportation system. The MKARNS  strategically connects the heartland of the United States with the rest of the world via the Mississippi River and Port  of New Orleans. We investigate the regional and nationwide economic impacts of the MKARNS in order to help  transportation stakeholders to make informed investment decisions. A multi-regional social accounting matrix model  (MRSAM), an extension of the economic input-output (I-O) model, is employed to conduct a regional economic  impact analysis. Our study considers regional economic impacts based on hydropower energy generation, United  States Army Corps of Engineers ( USACE) operations and maintenance (O&M)  expenditures, private sector  investment expenditures, port activities, shippers’ activities, transportation cost savings, and recreation benefits related  to the MKARNS. Our findings show the MKARNS contributes total impacts of $5.8 billion in Gross Domestic Product  (GDP), 65,388 jobs, and $362 million in indirect business taxes to the national economy. The findings of this study  will inform future MKARNS investment decisions , which can result in  sustainable growth in both regional and  nationwide economies.  Keywords  Inland waterway, transportation, economic impact, input-output analysis   Introduction  The McClellan-Kerr Arkansas River Navigation System ( MKARNS) is comprised of the Verdigris River, Arkansas  River, and White River (Oklahoma Department of Transportation (ODOT), 2018). The MKARNS originates from the  Port of Catoosa in Oklahoma and flows in the southeast direction through Arkansas to the Mississippi River, as shown  in Exhibit 1. The system is 445 miles long , with approximately 308 miles located in Arkansas  and 137 miles in  Oklahoma (ODOT, 2018) . The MKARNS has a minimum navigation channel depth of nine feet. The width of  MKARNS ranges from 150 feet on the Verdigris R iver, to 250 feet on the Arkansas River,  and 300 feet on the  Arkansas Post Canal and the White River. The major cities that are located along the MKARNS are Tulsa, Fort Smith,  Conway, Russellville, and Little Rock.   In 2015, the MKARNS was designated as a high-use waterway system, which means its annual tonnage flow  is greater than 10 million tons (United States Army Corps of Engineers ( USACE), 2015). There are eighteen locks  along the MKARNS, with thirteen in Arkansas and five in Oklahoma (ODOT, 2018); each lock is approximately 110  feet wide and 600 feet long. The vessel traffic along the MKARNS varies from lock to lock, with the most commonly",lemoyne.edu,Le Moyne College,United States,43.04834115,-76.08517610832246
80,THE EFFECTS OF BODY ARMOR LOAD AND SPEED ON SOLDIERSURVIVABILITY,@usma.edu,"Survivability, Speed, Mobility, Load ","During combat, soldiers carry a full combat load of about 9 -60 kg, which typically consists of a weapon, helmet,  ammunition, soft and hard body armor, fighting load carrier (FLC), rucksack, and other essentials. Extensive research  has been conducted exploring the effects of soldier load configuration on speed and mobility. However, there has been  little to no research done to determine the point at which reduction in speed and mobility compromises soldier  survivability, even with a high level of protection. Using a spreadsheet simulation model, this research explores soldier  protection and load level combination s for different combat scenarios based on the trade- offs they induce regarding  speed and mobility. The main contribution of this research is an analysis of survivability results that show the trade - off between speed and load from body armor protection . This analysis aims to educate military leaders on the trade- offs of soldier load and survivability, as well as serve to incite further research and development of a survivability  index tool to help them make better informed decisions on the protection levels and load th ey should put on their  soldiers, dependent on threat. Outside of the military domain, this research can also be applied to law enforcement  and first responders who experience similar load versus survivability trade-offs. Overall, this research aims to  determine when more protection, and therefore load, counterintuitively becomes detrimental to survivability, and how  to optimize this trade-off.  Keywords  Survivability, Speed, Mobility, Load  Introduction  Research and analysis of equipment that interfaces with and augments the human body remains an open field of inquiry  and significantly relevant to the engineering management community.  This paper illustrates an analytical approach  for one case that involves military equipment.  The United S tates Army is constantly trying to update equipment and  get the next best thing. However, with this constant evolution in technology comes some drawbacks such as increased  weight and soldier load. For instance, the evolution of body armor has resulted in putting more and more protection  on the solider because it has been thought that more protection equates to higher survivability. However, this may not  be the case. This study aims to look at the effects of soldier load and speed on survivability  to determine the optimal  soldier load-speed configuration that results in the highest level of survivability for the soldier.  Literature Review  As the importance of American capabilities in counterinsurgency and guerilla environments has received increased  attention as compared to conventional tactics, the importance of soldier speed and mobility has increased heavily.  Counterproductive to that, the increase in technology has also led to the increase in soldier load. As a result, several  studies have been conducted over the past few decades to determine the optimal soldier speed and mobility vs load  and protection trade-off. This research has resulted in an evolving soldier load model that has transformed  repeatedly and will most likely continue to change in the foreseeable future. Thus, this literature review focuses on  how the importance of speed and mobility in small-unit tactics has evolved over time, the current research on the  effects of soldier load, related studies on how soldier load effects speed and mobility, how these effects are  represented in current mathematical models, and a brief analysis of how this relates to survivability and this study.",usma.edu,United States Military Academy,United States,41.3927227,-73.95986305044411
81,THE EFFECT OF ENGINEERING LEADERSHIP IDENTITY RESEARCHON THE IDENTITIES OF STUDENT RESEARCHERS,@montana.edu,,"Undergraduate research is a common method for students to gain experience in fields related to their major during  their time in college. While involvement in research has many possible outcomes for undergraduates, the study of its  effect on engineering, leadership, and engineering leadership identity development is underdeveloped and  inconclusive.  To contribute to this area of study the experiences of four undergraduate engineering students who were  involved in research were examined through combined collective case study and autoethnographic methods. The  research the students participated in centered on understanding the development of the identities of interest in  engineering students more broadly, giving the four students repeated opportunities to engage with the subject. This  combination of involvement in research and exposure to engineering, leadership, and engineering leadership concepts  was found to have mixed results. The impact on the student's own identity development was inconsistent, ranging  from positive to negligible to negative. It is hypothesized that this discrepancy can be attributed to diversity of  individual experience both before and during involvement in research.   Key Words  undergraduate research, engineering identity, leadership identity, engineering leadership identity, case study   Introduction  The need for engineers with leadership skills has been acknowledged since the early 1930s and has increased in  prominence in the past decades (Waddell, 2002) . Repeated calls from industry, publicati on of seminal reports, and  recognition of the dearth of professional skills in engineering graduates have all highlighted this need  (Duderstadt,  2008; National Academy of Engineering, 2013) . In response researchers and educators have increased focus on  engineering leadership development within engineering education by developing engineering leadership models and  increasing the number of engineering leadership development programs (Klassen et al., 2016) .   This paper and the multiphase research project encomp assing it also respond to the recognized need for  engineering leaders. The literature on the subject lacks clarity on how undergraduate students develop a professional  identity as an engineer, how students make meaning of their exercise of leadership, and how these two phenomena  occur within each other's context  (Schell & Hughes, 2016) . These ideas have been  conceptualized using the  theoretically based concepts of engineering identity (EI), leadership identity (LI), and engineering leadership identity  (ELI) development (e.g., Knight & Novoselich, 2017; Komives, Owen, Longerbeam, Mainella, & Osteen, 2005;  Morelock, 2017). While various models are used to explain EI, LI, and ELI development, none of the identities have  a single, agreed upon definition (Schell & Hughes, 2016). A description of common models and their impact on our  research can be found in our previous work (Schell & Hughes, 2016) . Our larger project seeks to make headway into  filling the literature gap on ELI as well as further understanding of EI and LI. To do so the project  examines student  experiences using both quantitative and qualitative data to develop an empirically supported understanding of the  definition of, development of, and effective interventions on ELI as well as EI and LI.",montana.edu,Montana State University - Bozeman,United States,45.6638859,-111.07928704602077
82,PERFORMANCE ASSESSMENT OF SERVICE SYSTEM EFFICIENCY:ILLUSTRATIVE EXAMPLE OF DRIVE-THRU SERVICE CHAIN,@pdx.edu,"Service System, Efficiency Assessment, Drive-Thru Service Chain, Performance, Data Envelopment Analysis ","Due to the increase in competition and innovation, the importance of quality of service and performance evaluation to  improve the provider's customer satisfaction have been taken into consideration more than ever. Performance  management helps to check the performance of the chain, and indications of individual network elements or services  that are forming the overall quality of service system. In that sense, this study focuses on efficiency measurement  modeling for service systems. Additionally, the initial model was built to measure the efficiency of the units in a chain.  We implemented the model on the artificial data of several  coffeeshop chains using satisfaction factors while  connecting to the financial aspect to determine the potential improvements that will help the operator enhance their  services by learning from best practices. Data Envelopment Analysis (DEA) is used as a method, and the performance  matrix will be adopted as a second stage analysis. DEA aims to find the Decision Making Units (DMUs) that produce  high output outcomes using the low input resources compared with their peers. The paper provides recommendations  to improve the productivity and efficiency of the inefficient units in a chain and develop a decision model to enable  better best practices decision making.   Keywords  Service System, Efficiency Assessment, Drive-Thru Service Chain, Performance, Data Envelopment Analysis  Introduction  Due to the increase in the competition, it is critical to assist the quality of service (QoS) and evaluate the performance  of the units to improve customer satisfaction. To provide a better QoS and guarantee significant chain performance, it  is critical for operators and providers to be able to measure the performance of the chain ’s assets. Therefore, many  firms have generated quality measurement programs tha t endeavor to connect services to quality evaluation  (Hauser  & Clausing, 1988). Thus, to maintain the QoS, several challenges, which require a slightly different approach, such  as the complexity among inputs and outputs to operate the efficiency evaluation stand as a barrier and the bewildering  array of algorithms and models available (Dabab, Freiling, Rahman, & Sagalowicz, 2018). This leads to the needs of  a comprehensive tool and advanced performance model to enhance the performance of the service industry as a whole  and individual assets. Data Envelopment Analysis (DEA) is commonly used to evaluate the efficiency of a group of  producers that is referred to as a Decision Making Unit DMU, and it allows the  estimation of a production function  that reveals the right input-output relations with a group of related units. DEA has been widely applied for measuring  and benchmarking the relative efficiency in different applications.   DEA has been used for performance assessment in many services industries, and it helps to assist providers  and foodservice operations such as restaurants in adopting  efficiency measurement modeling  (Dabab & Anderson,  2018). Banker and Morey used a network of fast food restaurants analysis as a case study to develop their model that  involves multiple outputs with multiple discretionary inputs and exogenously fixed inputs (Banker & Morey, 1986).  Reynolds adopted a simple one input and one output model in the first analysis, and the study simplified how to apply  DEA to enhance the productivity for the hospitality providers, and to improve resource allocation to maximize services  and profit (Reynolds, 2003). The primary two studies that have taken a more advanced approach in assessing restaurant  performance include the productivity analysis of a chain of 36 restaurants using nonfinancial data (Reynolds & Biel,  2007), and one that evaluated a chain of 62 full-service restaurants data, and made a multi-unit restaurant productivity  assessment using a three-phase DEA (Reynolds & Thompson, 2007). Another study benchmark ed the network of a  set of restaurants in Spain to improve their output by reallocati ng the adjustable inputs without changes in the  environmental context variables (Giménez-García, Martínez-Parra, & Buffa, 2007). However, there is not a study that  focuses on the drive -thru fast food service , and that considers customer satisfaction factors and the profitability to",pdx.edu,Portland State University,United States,45.51181205,-122.68493059820187
83,STATE-OF-THE-ART AND FUTURE OF ONLINE EDUCATION INPROJECT MANAGEMENT,@drexel.edu,"Information and communications technologies (ICTs),  online learning technologies , project management degrees , ","The rapid growth of project management and its applications, the increasing demand for education, the remarkable  expansion of information and communications technologies (ICTs), the progress of online learning technologies, and  the meaningful pedagogical developments have led to an explosion of interest and enhanced opportunities for  delivering online education programs in project management throughout the world.   For the foreseeable future, the need for online education in project management can be expected to continue  to increase. ICTs, online learning technologies, and online experiences can be expected to continue to advance  allowing the expansion of project management content that can be offered using the online mode of instruction. More  institutions of higher education are likely to offer project management programs entirely online as a completely new  initiative. It is also likely that there will be  an expansion of project management courses being offered to extend  existing online programs in other fields.   The demand and availability of project management degrees , academic certificates, professional  development and professional credentials training programs, in the online, hybrid, and blended modes can be expected  to continue to grow. Enrollment in such programs can also be expected to increase. However, the distribution of  participants among various existing and new programs may change. The quality of education and the internal, external,  academic, and professional reputation of the institution , degrees, and credentials, as well as the resousrces provided  to support them are likely to be the main determinants of success for many of these programs.  Keywords  Information and communications technologies (ICTs),  online learning technologies , project management degrees ,  academic certificates , professional development , training programs , credentials, hybrid, blended, determinants of  success.  Introduction  Educational paradigms are experiencing rapid changes in Institutions of Higher Education (IHEs) due to the increase  in demand for online / distance education (DE) courses, degrees, and training programs. The new online / distanc e  education / hybrid / blended model poses specific challenges that are causing IHEs to re-think face-to-face pedagogical  methods, organizational and administrative structures, financial strategies, and the c riticality of technological  innovations.  Schrum & Ohler (2005) note that “institutions are feeling particularly vulnerable because the advantage  of location no longer ensures them a market based on geography, and instead they must reach out to lifelong learners  using a variety of distance delivery techniques.”  Interest in education and training in project management has been growing at an extremely rapid pace. This  interest is being propelled by the growing recognition of the important contributions of Project Management to  organizational competitive position, individual career progress, economic and societal development, and remedies for  shortcomings of project outputs, outcomes, and impacts. Opportunities for delivering project management education  and training and the availability of effective  programs in project management have been steadily increasing through  research, applications, and the development of courses, curricula, and degree programs in this field.   Growing interest in learning  and education , globalization, opening of political and virtual boundaries,   developments in ICTs, and expansion of online learning technologies have strengthened these globalizing tendencies.  Understanding the major issues and current trends in online learning / DE in project management allows  educational institutions to take adv antage of promising practices, deploy their resources more efficiently, manage  barriers to success more effectively, and enhance the contributions they make to their local, national, and international  communities.",drexel.edu,Drexel University,United States,39.9569305,-75.18992654517834
84,HOW DO ENGINEERING UNDERGRADUATES DEFINEENGINEERING IDENTITY?,@montana.edu,"Engineering identity, engineering development, engineering education ","Identity is central to learning in engineering , and development of an engineering identity is a core aspect of the  education and training process for engineers.  Identification with engineering has been shown to assist in the  recruitment of diverse students into the field and improve student retention a mong all groups. For these reasons,  engineering educators should consider the formation of professional identity as they make decisions about how to best  prepare graduates to enter their chosen fields.  In order to utilize professional identity, these educators must understand  how their students conceptualize engineering identity.    This work seeks to promote that understanding by investigating conceptualizations undergraduate engineers  hold of engineering identity , their self-view as engineers, and the sources of th ese views. Using data collected from  pilot focus groups of ten undergraduate students at two different U.S. engineering schools, we applied a grounded  theory approach to explore these topics.  This exploration found many elements consistent with prior work in  engineering identity (e.g. a focus on technical knowledge defining engineering) while adding new elements, such as  students’ surprise at the breadth of engineering and desire to use their engineering education as a vehicle to positively  impact the world.  Keywords  Engineering identity, engineering development, engineering education  Introduction  As the challenges facing humanity increase in scope and complexity, the need for technical experts to participate in  cross-disciplinary teams has only  increased.  To address this societal need, many are calling for more engineers to  enter the workforce.  However, of those who begin their training as engineers in college, only 60% persist, and only  43% of those who expressed interest actually enter the engineering profession (Lichtenstein et al., 2009).  Substantial  research suggests that a significant influence on this fallout may be misconceptions in engineering education:  “Research in engineering education has shown that academic programs are often designed based on a projected image  of engineering practice, which may be outdated or unrefined ” (Lichtenstein, McCormick, Sheppard, & Puma, 2010,  p. 315).  Moreover, if societal interest is not only cultivating engineers, but preparing engineers to be successful, more  must be understood about how engineering students’ identities develop in their education .  The concept of identity— how people see themselves, how others see them, and their role in society—provides a useful framework to understand  the dynamics that lead to both degree completion and participation in a profession.  In fact, evidence suggests that  engineering identity growth significantly correlates with persistence in both degree completion and entrance into the  engineering profession (Carlone & Johnson, 2007; Matusovich, Streveler, & Miller, 2010)  The purpose of this paper is to report how engineering undergraduate students think of identity, and the  sources of these ideas.  The research questions that guide this paper are:  1) How do undergraduate engineering students define engineering?  2) How do students see their identity aligning with that of their definition of engineering?",montana.edu,Montana State University - Bozeman,United States,45.6638859,-111.07928704602077
85,RESILIENCE AND IMPACT ANALYSIS FOR BIOFUEL SUPPLY CHAIN,@mst.edu,Biofuel supply chain; Resilience; Security ,"Biofuel is considered a promising alternative to traditional gasoline. The resilience of the biofuel supply chain system  under various disruptions or attacks plays a critical role in determining the robustness of the supply chain system and  facilitating a large scale substitution of biofuels for fossil fuels. In this paper, we explore the resillience under potential  disruptions and disturbances for a four-layer biofuel supply chain network from the perspective of economic viability.  A numerical case study employing the biofuel supply chain system in Missouri of the U.S. is conducted to quantify the  potential impacts on performance with respect to cost effectiveness.  Keywords  Biofuel supply chain; Resilience; Security  Introduction  Biofuel is considered one promising sustainable energy source that can substitute for traditional petroleum based fuel s  on a large scale. National Renewable Energy Laboratory has reported that if less than 1/7 of the area used to raise corn  in the U.S. can be dedicated to biofuel manufacturing, it would be enough to meet all ground transportation needs of  the nation (An, Wilhelm, & Searcy, 2011) . The U.S. and European governments have set the target that around 25%  conventional gasoline should be replaced by biofuels in the next two decades (Sorda, Banse, & Kemfert, 2010).   The research on biofuel technology has been widely implemented from various perspectives, such as lifecycle  analysis, process investigation, and supply chain optimization . The lifecycle analysis of biofuel manufacturing from   biomass planting, harvesting, to biofuel consumption has been conducted  (Acquaye, Wiedmann, Feng, Crawford,  Barrett, Kuylenstierna, ... & McQueen -Mason, 2011; Zhang,  Johnson, Wang, & Yu, 2016;  Tan, Culaba, & Purvis,  2002). For example, in 2016, Zhang et al. developed harvesting cost models to assess the cost, life cycle energy and  greenhouse gas emissions of forest-based biomass harvesting for different harvesting scenarios.   The investigations for different individial manufacturing processes such as size reduction, pelleting, hydrolysis,  and fermentation have been performed (Li, Sun, Yao, & Wang, 2016; Zhang, Shi, Zhang, Li, & Jaberi-Douraki, 2017;  Zhang, Zhang, Pei, & Wang, 2017 ; Sun, Wang, Li, & Zhang, 2014 ). For example, a predictive model of pelleting  temperature, which is identified as a key parameter influencing pellet quality, w as developed using spatio -temporal  dynamics to study the influence of multiple factors (ultrasonic power, pelleting pressure, and pellet weight)  on the  temperature rise (Zhang, Shi, Zhang, Li, & Jaberi-Douraki, 2017).  The research aiming at the optimization of the entire  biofuel supply chain including biomass  collection,  biofuel production, and bioethanol  delivering has also been reported  (Ekşioğlu, Acharya, Leightley, & Arora, 2009;  Kesharwani, Sun, & Dagli, 2018; Papapostolou, Kondili, & Kaldellis, 2011). For example, Eksioglu et al. developed a  mathematical model that can be used to optimize the supply chain and manage the logistics of a bio -refinery plant  (Ekşioğlu, Acharya, Leightley, & Arora, 2009). Kesharwani et al. have conducted a systematic analysis and comparison  for two strategies of conducting preprocessing operations to restructure the existing supply chain of corn based biofuel  manufacturing for accommodating the adoption of corn- stover based biofuel manufacturing tech nology have been  (Kesharwani, Sun, Dagli, & Xiong, 2019).   Although the research on biofuel supply chain optimization has been widely studied, it is not well known yet  how potential disruptions in certain parts of the supply chain can affect the cost and production of an optimized supply  chain network. Unpredictable events are happening  every day, such as equipment malfunction, natural disasters, fire,  cybersecurity attacks, and labour strikes . It threatens the normal production and operation and cause s severe supply  shocks.",mst.edu,Missouri University of Science and Technology,United States,37.9532435,-91.77426666814159
86,RISK AWARENESS ENHANCEMENT SYSTEMS FOR HAZMATTRANSPORTATION: PROTOTYPING AND TECHNOLOGYEVALUATION,@mst.edu,"Hazardous material, safety, transportation workers, smart connected systems, cyber -physical systems ","Workers of hazardous material (hazmat) transportation have a higher chance than other workers to be exposed to  various risks in their workplace. Assisting them to safely operate in their workplace in a near real -time manner is in  particular need. This  paper presents a study of designing , prototy ping and developing feedback systems to help  increase the risk awareness of workers in the loading and uploading phases of hazmat transportation. The first system  was prototyped on an Arduino board, serving as the reference for system development. Then, the second system,  named a Bluetooth Low Energy (BLE) beacon based system, was designed as a smart connected system. It integrated  technologies of Bluetooth low energy sensor, mobile smart device, the Cloud, w ireless communication, and mobile  applications. The smart connected system is more capable than the Arduino based system in providing  safety  information to workers. A comparison of the respective technologies utilized in the two systems further indicates that  the improved capability of the smart connected system  is mainly on the dimensions of interactivity, mobility,  information richness, and connectivity.  Keywords  Hazardous material, safety, transportation workers, smart connected systems, cyber -physical systems  Introduction  In the United States, there are more than 800,000 hazardous material (hazmat) shipments per day (Lasisi, Bai, & Sun,  2012). Hazmat transportation research  has various focuses . For example, an Integrated Emergency Management  System for hazmat transportation  was developed in order to address the issue of insufficient information  sharing  among transport companies, drivers and government agencies  (Ma, Wang, Lu, & Jiang, 2014).  The safety of hazmat  transportation has been a  particularly important subject of s tudy. For example, a  system was developed to help  minimize the impact to first responders’ health in a hazmat transportation  incident (Fruhling, Achutan,  Medcalf, &  Yoder, 2018). Workers of hazmat transportation have a higher chance than other workers to be exposed to  various  risks in their workplace ( Incident Statistics, 2018). Many studies on the safety of hazmat transportation workers are  mainly focused on the in-transit phase. Top reasons for hazmat incidents during this stage largely overlap with those   in moving other goods and passengers. A large portion of the incidents in transporting hazmat has occurred due to   human error, particularly during the loading and unloading phases of transportation ( Bureau of Transportation  Statistics, 2017; Godse, Long, Qin, & Xue, 2018).  The economic, social, and  environmental consequences of the  incidents are traditionally severe in nature (Office of Hazardous Materials Safety, 2017) . Protecting transportation  workers from these potential risks and improving their ability to operate safely in their workplace is important. For  example, drivers transporting hazmat must receive initial and recurring training s on general awareness and  familiarization of  hazmat, safety training on emergency response, and measurements to protect themselves from  exposure to the hazmat (An Overview of 49 CFR parts 172-173, 2019). Well-trained transportation workers may still  make mistakes that cause exposure to risks in their respective workplaces. Some of the leading factors are that human  beings have bounded abilities in vision, cognition, making a judgment, and simultaneously handling multiple tasks,  particularly in complex, dynamic working environments, or in  response to suddenly occurred situations. Improving  their ability to safely operate in their workplace through assisting  them from various needed aspects in a near real -",mst.edu,Missouri University of Science and Technology,United States,37.9532435,-91.77426666814159
