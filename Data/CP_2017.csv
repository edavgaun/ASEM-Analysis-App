,Title,email,KeyWords,Abstract,domain,Institution,Country,Latitude,Longitude
0,IMPROVING THE GOVERNMENT PURCHASE CARD APPROVALPROCESS AT THE U.S. MILITARY ACADEMY: A LEAN SIX SIGMAAPPLICATION,@gmail.com,"Lean, Six Sigma, Government Purchase Card ","The U.S. Army adopted the Lean Six Sigma (LSS) methodology for process improvement in 2004 and has been  training LSS practition ers ever since.  As part of this training, the Army requires green -belt level candidates to  successfully complete a project using the Define, Measure, Analyze, Improve, and Control (DMAIC) process.  This  paper presents the results of a six -month effort tha t applied this methodology to government purchase card (GPC)  approval process within the Dean’s staff at the U.S. Military Academy.  Although many associate the LSS process  with manufacturing or supply chain processes, this application is an example of how  the same methodology will  result in the improvement of administrative processes.  Through the DMAIC process, the team conducted detailed  analysis of the available data, identified several areas for improvement, and implemented controls and procedures to  get the process in control and reduce the number of defects in turn -in documentation.  The results of the effort were  profound and reduced the processing time by over 50% and improved the sigma quality level from 0.5 to 2.4.   Additionally, the teams recommended changes to the GPC process are being adopted across the Academy to  decrease processing time and improve quality associated with this administrative process.  This paper provides an  overview of the process and its application to the excessive time and effort required to approve simple purchases  with a government credit card as a case study for a successful implementation of the Army’s LSS process.    Keywords  Lean, Six Sigma, Government Purchase Card    Introduction  This paper presents the findings and results of a six -month effort to improve the government purchase card (GPC)  approval process at the U.S. Military Academy.  It applies the Army’s Lean Six Sigma (LSS) methodology to define  the problem, measure the current process, analyze those measurements, improve the process, and implement  controls to sustain the improvements.  The initial dialogue on this project grew during a meeting between the project  sponsor and project team.  Due to a dynamically changing force structure and voiced frustration among customers,  the key stakeholders identified a need for an improvement to the GPC approval process.  The team drafted a  problem statement of, “The government purchase card process is currently operating at approximately  6 days from  need identification to purchase approval within the Dean’s directorate. Over the past 12 months, it has taken an  average of 15.25 calendar days to make a purchase. Dean’s departments experienced delays at some level in over  50% of their depart ment’s purchases. The expected performance standard is within 3 days according to our  organization’s prescribed standard.” The thinking behind the problem statement was rooted in the need to make  measurable financial improvements and improvements to the pr ocess so that the customers within the Dean’s  directorate could receive their goods quicker.   The root of the business impact was to reduce process lead -time (PLT) required to make purchases and to  reduce the manpower requirement and the associated costs w ith the current government purchase card process. This  resulted in the project team’s focus on the speed and cost of the process. Our initially stated goals were to improve  the government purchase card process by adjusting our organization’s prescribed standard operating procedures,  remove any unnecessary process steps to increase the efficiency of the process, and evaluate the way our approval  process structure was nested at the Academy.  The delta between the time that the need for items was identified an d ",gmail.com,,,46.3144754,11.0480288
1,A PHENOMENOLOGICAL INQUIRY INTO ENGINEERS' MOTIVATIONTO LEAD,Missing,"motivation to lead, MTL, phenomenological, qualitative, engineering managers, engineers, teach, mentor ","The present paper describes a qualitative (phenomenological) study of six engineering managers who were, within the  past two years, promoted into managem ent roles at a medical device manufacturer in Southern California. The  objective of this study was to understand their motivation to lead. Each engineer participated in an interview which  was approximately 30 minutes long, semi-structured, and guided by an eleven-question interview guide based on the  literature. The transcriptions of each interview were then analyzed using first and second cycle coding . In all, eight   themes emerged to explain why these engineers accepted leadership roles: (a) some simply en joy leading, (b) some  felt a social obligation, (c) some were motivated by values higher than mere money, (d) some were motivated by a  sense of benevolence, (e) some were motivated by observing other leaders in the organization, (f) some found  additional motivation to lead as they experienced success as managers, (g) some were motivated by their engineering  skills, and, most significantly, (h) some found motivation to lead in a desire to teach and mentor. The study contributes  to the literature by identifying a previously unrecognized motivation to lead (motivation to teach and mentor). Because  a qualitative design was used, this study demonstrates only that this motivation to lead was present in these six  engineers; no claim regarding generalizability is made. Additionally, three tentative practical implications for training  potential engineering managers are described. However, a follow-on quantitative study is required before generalizing  these findings.   Keywords  motivation to lead, MTL, phenomenological, qualitative, engineering managers, engineers, teach, mentor  Introduction  According to Clemmons and Fields (2011), the research stream on m otivation to  lead (MTL) began with the  quantitative work of Chan and Drasgow (2001). Since their se minal work, there have been a number of other  quantitative studies focused on MTL, including several quite recently (e.g. Cho, Harrist, Steele, & Murn, 2015 ;  Guillén, Mayo, & Korotov, 2015; Stiehl, Felfe, Elprana, & Gatzka, 2015; Rosch, Collier, & Zehr, 2014; and Mascia,  Dello Russo, & Morandi, 2014). However, a journal search revealed few qualitative articles . Fortunately, Patton  observes that qualitative inquiry can still be used later in the process “to add depth and detail to statistical findings”  (p. 230). Accordingly, this paper presents the results of a qualitative (phenomenological) inquiry into MTL with the  intent of adding the depth and detail that Patton refers to. As such, this paper is organized in four sections. The first  section is a  review of  the literature related to motivation to lead . The second section describes the methodology ,  including descriptions of phenomenological inquiry, the coding methodology, and the research sample. The third  section describes the results of the analysis and the themes which emerged. The final section provides a discussion of  the findings both as they relate to the research question and as they relate to implications for practice. In total, eight  motivations to lead were observed, one  of which was previously unknown to the literature. Furthermore , three  implications for practice are described.  Literature Review  In their quantitative study of over 2,000 soldiers and college students, Chan and Drasgow (2001) concluded that there  are three components of MTL which they called “affective- identity motivation to lead (AI -MTL), non-calculative  motivation to lead (NC -MTL) and social -normative motivation to lead ( SN-MTL)” (p. 492). The affective -identity  component involves both an innate desire to lead and the formation of an identity as a leader, hence the first two  questions in the interview guide were What feelings do you associate with your motivation to lead?  and How does  your sense of self-identity contribute to your motivation to lead? The social-normative component involves the leader’s  sense that they have an obligation, either social or moral, to lead, hence the next two questions were How does a sense ",Missing,,,46.3144754,11.0480288
2,ANALYZING COST-TO-SERVE QUANTIFICATION METHODOLOGIESIN A WHOLESALE INDUSTRY SETTING,@tamu.edu,"Cost-to-serve, wholesale distribution, case study ","The major business function of a wholesale company is to provide supply chain services to its customers. Such  services include inventory management, solution based se rvices, credit terms, and transportation & logistics  services. Unlike its manufacturing counterparts, wholesale companies are still based on rudimentary legacy systems  of pricing that do not have a proper way of accounting for different types of costs-to serve (CTS). As a result, many  companies struggle to become cost -competitive. This paper investigates two of the most common CTS  methodologies (that is, activity based costing  and surrogate method)  currently described in literature. Both  methodologies are examined by employing data from a real world wholesale distribution company. Finally, based on  the findings from the case analysis, the paper recommends few optimal strategies for CTS which can be applicable  to the wholesale distribution industry beyond the case company.     Keywords  Cost-to-serve, wholesale distribution, case study    Introduction   Industrial distributors provide supply chain services to their customers. I t is a six trillion -dollar industry and is also  one of the largest  employers in the US. Distributors help  move products from point of manufacturing to point of  sale. Their services include warehousing, inventory management, transportation, credit management (although not  all provide credit management services), and provi ding technical solutions to their customers. The types of  customers include residential, commercial, industrial, and government depending upon the type of products. The ir  operations involve  business to business transaction s. However, the challenges facing the distributors are also  enormous which range from shrinking profit margins to inefficient legacy processes  (Jennings, Narayanan, Nepal, &  Clark, 2017). Many industry channels have not adopted technology in a way that it cou ld enhance the efficiency for  their operations thereby resulting in higher profitability . One of big issue s contributing to lower profitability  of a  distribution firm  is the  lack of scientific cost accounting  approach to track all cost -to-serve (CTS) drivers.  As a  result, companies are subject to risk of  making both underpricing and overpricing  decisions thereby affecting their  log term sustainability.    That said, it is certainly true that m any of CTS variables are hard to quantify because they are hidden.  For  example, customers will place different orders via different methods, are located in different geographical locations,  and make different demands on service, support, and returns (Van Triest, 2005).  Companies can gloss over the  hidden costs by making the assumption that ‘cost plus margin’ price will cover the expense (Lawrence,  Gunasekaran, & Krishnadevarajan, 2009) . However, glossing over of the hidden expenses “fails to capture each  customer’s significance and treats all customers alike” (Lawrence, Gunasekaran, & Krishnadevarajan, 2009)      .    Two definitions that captures the essence of CTS come  from Lahutta & Wronski (2014) and Lawrence,  Gunasekaran, & Krishnadevarajan (2009) .  CTS can be defined as “the total pre- sale, order related, distribution and  post-sale service cost required to maintain an ongoing exchange relationship with a customer firm” (Lahutta &   Wronski, 2014).  Lawrence, Gunasekaran, & Krishnadevarajan (2009) add  to the definition by indicating that CTS  contains the allocation of total costs to each customer beyond the cost of goods. Other researchers  also discuss the  importance of quantifying the cost t o serve for distributors ( Gebert, Goldenberg, & Peteres,  1996). Norek & Pholen  (2001) describe that the  detail cost knowledge can be used to make unprofi table customers profitable by lowering ",tamu.edu,Texas A&M University - College Station,United States,,-96.35206061388457
3,APPLICATION OF STRUCTURAL EQUATION MODELING (SEM) INTHE EVALUATION OF THE RELATIONSHIP BETWEENFACILITATING FACTORS TO KNOWLWDGE SHARING IN THESUPPLY CHAIN AND SUPPLIERS’ DELIVERY PERFORMANCE,@gmail.com,"Knowledge sharing, knowledge complexity, supplier’s performance, structural equation modeling, suppliers. ","The study evaluates the relationship between practice of  knowledge sharing involving customer and supplier and  suppliers’ delivery performance.  A  model proposed in  Structural Equation Modeling (SEM)  with data collected  from 172 suppliers and 15 customers has explained the suppliers’ performance in 64.5% of the cases.The model has  pointed out that the construct “interlocution formalization”, in which stands out the facilitating factor “complexity of  shared knowledge”, is what most influences this performance.    Keywords  Knowledge sharing, knowledge complexity, supplier’s performance, structural equation modeling, suppliers.    Introduction  Organizations have  increasingly acted in a manner  dependent on  each ot her . For instance, i n the case of a final  product of an industry, it is obse rved that the execution of  some stages of the production process tends to be passed  to suppliers.  This procedure demands that supplier and customer  keep good integration , including the sharing of  knowledge and information. K nowledge sharing among organizations  has been suggested as  a condition for   improving supplier’s and customer’s performance (Davenport &  Prusak, 2003). In this context , one realizes the  importance of analyzing the factors that facilitate knowledge sharing between customers and suppliers, and the need  of relating them quantitatively  to suppliers’ performance. Thus, the  objective of the study  is to assess  the  relationship among the characteristics  of practicing knowledge sharing  between customers and  suppliers of  industrial processe s and suppliers’ performance.  Specific objectives of this research  can be highlighted:  a) to  identify in the literature  a number of  factors (or indicator variables ) contributing to   knowledge sharing;  b) to  propose metrics of facilitating factors  (or indicator variables) in order to characterize knowledge sharing  relationships between customers and suppliers; c) to develop an instrument of data collection in order to characterize  the relationship of knowledge sharing with the customer, from the suppli er’s point of view ; d) to develop an  instrument to measure supplier’s performance, from the customer’s point  of view; e) to propose a  statistical model  which relates the factors contributing to  knowledge sharing (or indicator variables) within supplier’s performance;  and f) to identify which factor has greater influence on supplier’s performance.    Knowledge Sharing  In today's competitive environment, competition tends to  occur  within chains rather than individual companies.  Thus, the performance of a company is influenced by ties it keeps with suppliers. Knowledge is an important  element in the integration among companies, and a source of competitive advantage (Yang, 2011; Lai,  2011,  Davenport & Prusak, 2003). Hence, it justifies the fact that organizations develop systems to identify, develop, ",gmail.com,,,46.3144754,11.0480288
4,A TALE OF TWO AIRCRAFT: HOW NON-FUNCTIONAL ATTRIBUTESIMPACT A SYSTEM’S LIFECYCLE,Missing,"Systems Engineering, illities, System Retirement ","The decision to retire a system within the Department of Defense (DoD ) has proven difficult for defense department  officials to make and systems are often extended beyond their expected lifecycle.  During the system design process,  engineers often use rules of thumb to guide the planned retirement date of a system and only considered retirement  for the lifecycle cost estimates.  However, there are inconsistencies in following these estimated retirement dates for  DoD systems and the age of a system does not have an impact on the decision to retire or extend a system.  This  paper examines two distinct examples of DoD systems; the F -117 Stealth Fighter, retired in 2008 after 25 years of  service, and the B -52 Bomber, currently active and expected to retire in 2045 after 90 years of service.  This  discrepancy in service life of tw o aircraft leads to the question of what non -functional attributes lead DoD decision  makers to favor extending a system as opposed to retiring a system as planned.  The paper uses grounded theory to  examine articles that discuss the non -functional attributes, referred to as ilities, of these two aircraft to determine if  there is a difference between the two.  Based on 40 articles, the B -52 displays attributes of: flexibility, extensibility,  versatility, interoperability, and robustness more than the F -117.  It is likely that these ilities are the driving factor  behind the DoD’s decision to extend the life of the B-52 and the lack of these iliies in the F-117 led to its retirement.      Keywords  Systems Engineering, illities, System Retirement    Introduction  The Department of Defense (DoD) manages hundreds of weapon systems that they design to meet the needs of  warfighters within the DoD.  As part of this management, the DoD makes retirement decisions on systems as they  age to a planned retirement date that engin eers specify during the design process.  However, it appears that many  DoD systems extend well beyond their planned retirement date, while others retire as scheduled.  One of the most  prolific examples of a system that the DoD has extended well beyond its initial service life is the B -52H bomber,  which first entered service in 1955 and the DoD plans to extend the life until 2045 (U.S. Air Force, 2015).  On the  other hand, some systems, such as the F -117, do not experience the same service life extensions an d are retired as  planned.  The F -117 entered service in 1983 and the Air Force retired that aircraft in 2008 after a 25 -year lifecycle  (Air Combat Command, 2005).  So, the question becomes why are some DoD systems extended well beyond their  planned service life while others are retired at or before their planned retirement date.  The paper examines twenty  articles for both the B -52 and F -117 to determine if system attributes influence the decision to extend or retire a  system upon completion of its planned service life.  The research uses the systems engineering ilities as coding for a  grounded research approach to addressing this issue.  It found that the ilities of extendibility and flexibility enable  the service life extension of these systems and that th e ilities of interoperability, versatility, and robustness increase  the chance that a system will be extended.  The ility of quality, or the ability of a system to perform at a high level,  did not influence the decision to extend or retire a system and this attribute is common to both groups of systems.   Retirement is the final phase of a system life cycle, in which the system’s performance has degraded to a  point where it no longer provides value to the stakeholders (International Standard Organization, 20 15).  In some  cases, this is a systematic process of retiring a system, as in DoD systems, or it can be left up to the consumer of a  system to make that decision (Buede, 2000).  In the systems engineering literature, this decision is generally left ",Missing,,,46.3144754,11.0480288
5,INVESTIGATING THE APPLICATION OF PROJECT MANAGEMENTPRINCIPLES TO RESEARCH PROJECTS – AN EXPLORATORY STUDY,Missing,"Research projects, project management, systematic literature review. ","The management of research projects can be subject to significant uncertainty due to the knowledge creation process  that is undertaken.  The systematic investigation of a r esearch area requires adoption of a scientific approach along  with an appropriate level of creativity and this can present certain challenges in regard to managing research  projects.  Project management has developed to support industrial projects in areas  such as construction,  manufacturing and information technology.  Therefore,  the question arises: Are the standardized techniques of  project management adequate to support effective delivery of research projects  that involve a high level of  knowledge based  activities?  This paper will report on the results of a n exploratory study based on a  systematic  literature review, which has been carried out in order to improve our understand ing of the key features and issues  arising from the application of project man agement principles to research projects .  The literature has been  considered in regard to the process, structure, people and technology dimensions.  Th e paper includes synthesis of a  proposed research agenda in order to advance the knowledge base on the management of research projects.    Keywords  Research projects, project management, systematic literature review.    Introduction  Research projects are an essential part of knowledge production in contemporary society and this extends to the  social sciences as well as science and technology applications (Gibbons et al., 1994).   Indeed research projects are  undertaken by different types of organizations,  including industrial companies, governmental agencies, independent  research institutes and academic institutions.  Although there is much literature on the subject of conducting  scientific research, for example,  on the need to ensure adequate design principles ( Bordens and Abbott, 2002) and  robust research methodologies are employed  (Teddlie and  Tashakkori, 2009) , there is much less material on the  actual management of research projects.  The importance of conducting the scientific research itself should of course  not be underestimated (Bush, 1945); the specific approaches and features of the  research will be associated with the  knowledge base of the corresponding subject area, e.g. physics, biology, or chemical engineering .  But in order to  conduct scientific research there is a need to have the necessary resources (such as the researchers or graduate  students) and associated funding as well as the required equipment, supporting infrastructure and  any consumables  and other materials.  There is also a need for a research plan that describes how the research work will be undertaken  and specifies the goals and objectives of the project ; such a plan will likely articulate the deliverables that are to be  produced as well as important milestones for the project.  Rese arch is therefore implicitly delivered through projects  that have a schedule and a budget as well as a research specification that needs to be achieved  according to a pre- defined set of quality criteria.  Indeed the selection and prioritization of research  projects can be an important  consideration for technology -driven industrial companies ( Mottley and Newton, 1959) , which need to ensure that  the project outputs contribute to the company’s competitive advantage.  Although research projects have structural, process and people dimensions just like other projects, there is  additionally the need for creativity in regard to the knowledge discovery process  (Bush and Hattery, 1956) .   Adoption of management systems for research projects should support such creativit y and knowledge -based  activities, and consequently a fine balance is needed between implementing management approaches to support the  efficient and effective delivery of projects while not stifling creative activities  and innovation.   If we consider the  case of higher education  institutions, there  are academic freedom s in regard to research directions  along with  a  culture of not implementing overly commercial or rigid management approaches while still ensuring that the  strategic plans of the university are delivered ( Nickson, 2014) .  Universities are also increasingly engaged in  research and technical work that results in knowledge exchange with third -parties, such as through technology ",Missing,,,46.3144754,11.0480288
6,USING SOCIAL NETWORK ANALYSIS TO UNDERSTANDRELIABILITY IN A LARGE NETWORK OF SYSTEMS,Missing,"Social Network Analysis, System of Systems Engineering, Reliability ","Over the past several decades, the Department of Defense (DoD) has developed an expansive network of systems  that must interoperate on the battlefield to deliver value to the users.  However, it is difficult to manage and  understand the complex interactions between these systems and the potential impact a system failure may have on  the entire network of systems.  To address these problems, this paper prop oses adapting social network analysis  metrics, specifically the betweeness centrality, to identify key systems in the network that affect the overall  interoperability of the network by serving as bridges between groups of systems.  Additionally, this metri c may lead  affect the overall reliability of the network of DoD systems as systems with a high betweeness centrality may cause  systemic failure of the network.  As an example network, the paper utilized the tactical aircraft within the DoD that  spans all f our services and over a hundred individual systems ranging from aircraft to munitions to command and  control systems.  This work identified several key systems within the network that are essential to the overall  operation of the network of systems.  The b etweeness centrality metrics calculated based on the interaction network  are consistent with the qualitative assessments of the systems importance for reliability and interoperability of the  overall network.  This work is an initial step in broadly applying social network analysis metrics to networks of  systems to provide insights into the emergent behavior of networks of systems.     Keywords  Social Network Analysis, System of Systems Engineering, Reliability    Introduction  The DoD  applied social network analysis (SNA) to visualize and analyze complex networks of terrorists in Iraq,  Afghanistan, and across the globe.  The applied SNA to pinpoint the location of Usama Bin Laden after special  operations forces searched for Bin Laden i n the mountains of Afghanistan.  Through SNA, a Central Intelligence  Agency analyst identified a courier within the Bin Laden network that the DoD was able to determine his location  (Schmidle, 2011).  The DoD has an opportunity to apply SNA methods and tec hniques to look inward and analyze  their network of warfighting systems, specifically the reliability of the overall network of systems.  Traditional  system engineering tools and methods are inadequate to describe, visualize, and analyze this complex network of  systems.  This paper proposes a method for understanding the reliability of the network of systems with the SNA  centrality metrics to quantify the ility of reliability.    In 1996, the Vice Chairman of the Joint Chiefs of Staff predicted warfighting c apability would be more  reliant on networked systems and more reliant on other systems to provide capability on the battlefield (Owens,  1996).  The hierarchal structure of the military services that develop individual DoD systems amplify this challenge  as DoD systems operate on the battlefield where service boundaries are not as evident (Dahmann & Baldwin, 2008).   The DoD manages warfighting capabilities with the Joint Capability Integration and Development System (JCIDS)  process that was designed to ensure that validated military capability requirements drove acquisitions.  The JCIDS  process requires sponsors to generate three main documents to support different phases in the development and  acquisition process by providing traceability from warfighter capability requirements to fielded systems (Joint  Chiefs of Staff, 2012).  A key aspect of these documents and the capability requirements is the sustainability of the  system, which the DoD generally specifies as the reliability and availability of the system (Joint Chiefs of Staff,  2012).  However, this fails to address the reliability of the overall network of systems that each of these individual  systems operates within.  This paper contains four additional sections, a literature review, a methodology section discussing SNA, an  application to the U.S. Air Force (USAF) network of systems, and a conclusion section.  The literature review ",Missing,,,46.3144754,11.0480288
7,OPTIMIZING INVENTORY THROUGH ABC CLASSIFICATION ANDDEMAND FORECASTING,@stcloudstate.edu,"Inventory control, invdentory optimization, ABC classification, demand forecasting, exponential smoothing,  ","This project focused on the inventory management and optimization challenge at a cleaning products services  provider (SP). Due to changes in the business model from distributor to wholesaler,  the company faced new  challenges, namely - warehouse space management, IT systems for business and account management, competition  posed by re -distributors, forecasting sales demand, etc. The most significant challenge was inventory control and  optimization. Inventory optimization is the process of ensuring the right product at the right place, right time, right  quantity and right quality to meet the demand and supply of goods and or services.  The objective of th e proj ect was to optimize  inventory management by classifying  inventory and demand   forecasting model for better prediction of demand to manage inventory. An ABC classification  resulted in  categorizing inventory into class A ( high value), B (medium value) and C (low value) SKU’s and locations. From  this classification, one SKU and location was selected to forecast demand using exponential smoothing. This  showed  how managing high value SKUs can result in effective management of such  SKUs to avoid over or out  of stock  situations and to maintain customer satisfaction. The methodology included: understanding operational requirements  of the business, gathering monthly sales volume/revenue data for its top two customers, conducting an ABC analysis  on all SKU’s/locations and forecasting demand for one class ‘A’ SKU using exponential smoothing method. A total  of 629 SKU’s across 61 locations were analyzed which revealed those locations and SKUs that the SP should focus  on, in order to optimize, control and manage inventory and enhance customer satisfaction.    Keywords  Inventory control, invdentory optimization, ABC classification, demand forecasting, exponential smoothing,     Introduction  This project focused on the challenge of inventory management and optimization at a cleaning products services  provider (SP). The SP was established in 1985 and had done brisk business since 1989. Head quartered in Blaine,  Minnesota, the company specialized in the distribution and marketing of facility cleaning and maintenance products,  to various businesses across the US. The company core value was to serve few customers (~60) and thrived on repeat  business with them. There was a strong focus on customer service with several instances where orders were delivered  in exceptional circumstances – for example one order delivered during a snow storm and another at 2am. Based on  this philosophy, the order cycle time was typically between 24 to 48 hours. The SP used its own fleet of  transportation for local deliveries and 3PL’s for out-of-state deliveries. At inception, the business model was that of a  distributor of products. The SP procured products from the wholesalers and delivered them to the customers. As  competition in the market place grew, the model changed to a wholesaler one. The compan y now stocked several  SKU’s in its warehouse. The average value of inventory in the warehouse was ~ $200,000. With the change in the  business model, the company faced new challenges, namely - warehouse space management, IT systems for business  and account management, competition posed by re- distributors, forecasting sa les demand, etc. On meeting the ",stcloudstate.edu,Saint Cloud State University,United States,45.55139,-94.14833
8,INTEGRATING IDEF0 INTO A SYSTEMS FRAMEWORK FORSTATISTICAL ENGINEERING,@odu.edu,"Qualitative Framework, Statistical Engineering, Systems ","Driven by a growing requirement  during the 21 st century for the integration of rigorous statistical analyses in  engineering research, there has been a m ovement within the statistics and quality communities to  evolve a unified  statistical engineering body of knowledge ( Horel and Snee, 2010; A nderson-Cook, 2012) .  Outside of the 2014  Statistical Engineering Agreement among the ASQ Statistics Division, DOT&E, NASA, and IDA, there has been little  formal progress toward this goal since the May 2011 NASA S ymposium on Statistical Engineering in Williamsburg  Virginia.  In the ASEM -IAC 2012, Cotter (2012) identified the gaps in knowledge that statistical engineering needs  to address, explored additional gaps in knowledge not addressed in the prior works, and set forth a working definition  of and body of knowledge for stat istical engineering .  Again in the ASEM -IAC 2015, Cotter (2015) proposed a  systemic causal Bayesian hierarchical model that addressed the knowledge gap needed to integrate deterministic  mathematical engineering  causal models within a stochastic framework.   Missing, however, is the  framework for  specifying the hierarchical qualitative systems structures  necessary and  sufficient for specifying systemic causal  Bayesian hierarchical models.  This paper proposes revisions to and integration of IDEF0 as the frame work for  developing hierarchical qualitative systems models.    Keywords  Qualitative Framework, Statistical Engineering, Systems    Introduction  The systems approach to the design of new systems or correction of performance problems with existing systems  involves some form of hierarchical  decomposition of functional requirements following the V model.  The major  problem with functional hierarchical decomposition is maintaining the relevant between layer and within layer cross  correlations and causal environmental and functional effects at each sub -system, module, and component level.      Cotter (2012) proposed statistical engineering as a causal Bayesian hierarchical modeling approach to directly address  functional decomposition while assuring maintenance of between layer and within layer cross correlations and causal  environmental and functional effects.  He defined statistical engineering as the discipline that solves applied complex  organizational and societal problems that involve elements of risk , imprecision, or uncertainty in their  systemic  mission outcomes.  Statistical engineering integrates stochastic,  technical, engineering, information, human factors,  managerial, financial, and economic knowledge as necessary  to understand, model, and correc t deficiencies  (the  problems) in, systemic performance relative to required  mission outcomes within an environmental context.   Latent  design or existing manifested efficiencies in systemic performance, however, are only symptoms.  They must be  decomposed into their subsystem, module, and component level root causes that contribute to the  deficient systemic  performance, modeled,  redesigned, corrected,  and synthesized into improved systemic performance that can be  verified against the redesign intent and validated in the environmental context.  This paper reports research into  development of a statistical engineering qualitative decomposition -synthesis modeling framework over which  systemic causal Bayesian  hierarchal models can be overlaid t o facilitate th e modeling, redesign, and correction   activities.    Causal Bayesian Hierarchical Modeling Framework  Cotter (2015) developed the quantitative causal Bayesian hierarchal model as,    ",odu.edu,Old Dominion University,United States,36.8862699,-76.30972478839735
9,LESSONS LEARNED IN THE TAILORING OF LIFE CYCLE MODELSAND SYSTEMS ENGINEERING PROCESSES TO SOCIOCULTURALDIVERSITY,@isdefe.es,"Sociocultural tailoring process, cultural singularities, pre-training, handbooks adaptation. ","Standards and handbooks address life cycle models and systems engineering process usually in clude tailoring  guidelines to adapt them to a product sector or a domain application. The organizations of the Western world have  tailored these standards to manage the complex and long -life-cycle systems in the main sectors of activity: defense,  aerospace, automotive, space, transportation or infrastructure among others. Based on the experience of the authors,  this paper analyses the influence of the sociocultural aspects in the use of these standards in countries whose culture  differs from that of the West. In the first section of the paper, three cases are presented  to show the lessons learned  in implementing sociocultural ta iloring of systems engineering standards, guides and models: the training program  in nuclear power plants in China, the spares management project for Saudi Arabia’s Military Industries Corporation  (MIC) and the requirements engineering in the elaboration a nd implementation of a Master Plan for the main Naval  Base of the Peruvian Navy. In collaboration with local engineers and managers, different changes were introduced  to the system engineering processes in order to adapt them to each sociocultural environm ent. In the second section  of the paper, a broad number of recommendations for engineering managers  are made. These recommendations are  intended to be a help to those who want to accomplish a sociocultural tailoring of systems engineering in similar  environments.    Keywords  Sociocultural tailoring process, cultural singularities, pre-training, handbooks adaptation.    Introduction  There is no single moment or milestone that marks the birth or foundation of systems engineering. A number of  initiatives, mainly between the late forties and the late eighties in the defense and aerospace domains, represented a  substantial change in the way large complex systems were conceived and dealt with. In the 1940s, Bell Laboratories  was the first to use the term systems engin eering. The study in 1945 of anti -aircraft guided missile systems was  regarded as a milestone precisely because it was comprehensive enough to address a whole system. Systems  engineering was born with analyses of ends and with  the definition of objectives as integral parts of the overall  engineering effort. Several authors have described the origins and evolution of systems engineering (Blanchard &  Fabrycky, 1981; Brill, 1998; Sols, 2014).  Since its advent in the middle of the 20 th century, the field of systems engineering is witnessing an  exponential growth in all domain s, to include handbooks and textbooks, educational programs, specialized journals  and conferences, professional associations and worldwide practitioners.  Harry H. Goode and Robert E. Machol,  from the University of Michigan, published in 1957 the seminal book Systems Engineering: An Introduction to the  Design of Large-Scale Systems (Goode & Machol, 1957) . Their book addressed the systems  engineering philosophy  and methodology. The United States Air Force (USAF) was the first organization to publish a comprehensive  systems engineering document. In 1966, the USAF published Handbook 375- 5 Systems Engineering Management  Procedures, which described in detail the systems engineering approach (AFSC, 1966) . The handbook was replaced  with the first systems engineering military standard, the MIL- STD-499 Systems Engineering Management  (DoD,  1969). In 1992 the National Aeronautics and Space Administration (NASA) published a draft Systems Engineering ",isdefe.es,,,46.3144754,11.0480288
10,AN OVERVIEW OF CHANGING PRODUCT DEVELOPMENTPHILOSOPHIES,@fsw.edu,"Planned Obsolescence, Product Development, Lifecycle, Sustainability ","In the past few decades, product development has migrated towards a different philosophy of repair. Originally,  product philosophy was to design products to last without designing for a specific lifecycle. When the products  malfunctioned, different components were readily available, whether made by the original manufacturer or  generic components. This concept was very effective in extending the overall system or product life, because  broken components could be swapped out with ease and minimal cost . The focus of maintaining a product’s  viability has shifted to three different areas. The first is a philosophy where the focus has shifted from replacing  or repairing com ponents of an inoperable system to a focus on replacing the entire system or product  with an  entirely new system or product.   The second is where the ability to diagnose what is wrong with an inoperable  system requires advanced technology and software only available through the original manufacturer and at their  price-point and their requirements. The third is where it is obvious what the system or product requires in order  to be fully functioning again, but the replacement parts required to be purchased from the original manufacturer.  In this scenario, it is often not possible to install a more cost -effective component not made by the original  manufacturer that will restore the original product or system.   As these philosophies  gain acceptance and even   expand, economies of scale are diminished, consumer cost can increase, and the environm ent is impacted. This  paper investigates these changing philosophies so managers can evaluate the influences they invoke. As a result  of this cursory review, managers and engineers should recognize that changing their  product development  philosophy can impacft business sustainability goals and/or business strategies.     Keywords  Planned Obsolescence, Product Development, Lifecycle, Sustainability        Introduction  In the past few decades, product development has migrated towards a different philosophy of repai r.  Originally, product philosophy was to design products to last without designing for a specific lifecycle. When  the products malfunctioned, different components were readily available, whether made by the original  manufacturer or generic components. This  concept was very effective in extending the overall system or  product life  because broken components could be swapped out with ease and minimal cost. The focus of  maintaining a product’s viability has shifted to three different areas.   As this philosophy gains acceptance and  even expands, economies of scale are diminished, consumer cost can increase, and the environment is impacted.  This paper investigates these changing philosophies and the influences they invoke.      Shifting Focus  The first is a philosoph y where the focus has shifted from replacing or repairing com ponents of an inoperable  system to a focus on replacing the entire system or product with an entirely new system or product.   Not that long ago, products were designed and built with maximum pote ntial for sustained use, where  the life of the product was not a limiting, predetermined factor. Profit maximization strategies employed by  more and more companies are being achieved via planned obsolescence.  Designing products so that the ",fsw.edu,Florida SouthWestern State College,United States,,-82.01942947055863
11,CREATIVE CONFIDENCE IN ORGANIZATIONAL KNOWLEDGECREATION: A SYNTHESIS OF THE LITERATURE,@odu.edu,"Creativity, Organizational Knowledge, Creative Confidence. ","Creative confidence is a newly rising topic in the innovation study area. In a world where creativity has become a  vital source of knowledge creation, not believing in one’s own creative capacity could be a barrier. At the  organizational level, many good ideas are disappearing before ever being written down or shared. Organizations may  lose talented people who have great creative potential by either not giving them the opportunity to express their  creative ideas or due to a lack of conf idence from the employee side, in sharing these ideas . This paper will  contribute to the research stream on the role of creative confidence in generating organizational knowledge by  exploring a synthesis of the current literature on creative confidence.    Keywords  Creativity, Organizational Knowledge, Creative Confidence.    Introduction  Knowledge creation is of the utmost importance for every organization's innovation. Nonaka, Toyama et al. (2000)  stated that “The raison d’etre of a firm is to conti nuously cr eate knowledge” (p.6). The topic of organizational  knowledge is a part of the resource-based theory of the business. It is also seen as an important resource and valuable  foundation of capabilities and competencies for innovations and creation of new produ ct development (Grant and  Baden-Fuller, 1995; Endres et al., 2007).  Rhodes (1961) described creativity in four dimensions namely process (i.e.  cognitive process), person (i.e. personality, or behavior), product (i.e. innovation), and place (i.e. press, or   environment). Since information or knowledge only gains competitive advantage when integr ated with individual  experience (Dougherty, 1999; Endres et al.,  2007), cognitive processes and personality are central to the  understanding of knowledge creation. Creative confidence ties strongly to self -efficacy theory which is explained as  people's beliefs about their capabilities to produce and it is an ideal theory to understand why people choose to take  creative risks and the knowledge that the ideas they create have value (Bandura, 1994; Kelley & Kelley, 2013).  Thus, it is important to understand the role of individual’s behavior and personality in the knowledge creation  process characterized by social and epistemological challenges. The purpose of this paper is  taking a deep look at  what is supporting this process and how to improve the process, explicitly at the individual level we focus how  creative confidence empowers knowledge creation.    Knowledge Creation Within Organizations  The conce pt of knowledge is bro ad as it usually covers interpretat ions, insights, and information  (Schulz, 2001) .  Today, businesses don’t spend their time and resources just to solve problems, they create and define problems,  develop and apply new knowledge to solve the problems, and th en gain new knowledge through the process of  problem-solving. To survive in the competitive market they must become entities that create knowledge through  action and interaction (Nonaka, 2000).  In the context of organizations, knowledge is defined as an ou tcome and a process for incorporating new  experience and information (Tsoukas, 2001) to create value ( Liew, 2007), this is called organizational knowledge or  digital information (Gates, 1999; Lehner, 1990; Terrett, 1998).  Basically knowledge and its creati on are related to  human activity. Reading information and interpretation of information by expert results in knowledge. According to ",odu.edu,Old Dominion University,United States,36.8862699,-76.30972478839735
12,A THEORETICAL FRAMEWORK FOR A DYNAMIC TEAM LEARNINGAND ADAPTATION SYSTEM,@gmail.com,"Virtual teams, learning, team learning, adaptation, knowledge sharing, team cognition. ","This paper will discuss a model to facilitate double-loop learning in teams by applying sociotechnical and cognitive  systems concepts to a model previou sly developed by Ackoff (1999). The proposed model will provide a holistic  means for implementing a problem solving methodology within sociotechnical and cognitive systems contexts.     The main audience of this paper are practitioners interested in improv ing his or her team learning and knowledge  sharing capability. Individuals from a cademia interested in team learning and knowledge sharing may also find   elements of the model of interest. The contents of this paper focuses on learning within a problem-solving context but  could be applied to other types of engineering team activities with little effort.    Keywords  Virtual teams, learning, team learning, adaptation, knowledge sharing, team cognition.    Introduction  Problem solving scenarios provide organizations with a unique opportunity to evolve and improve existing  technologies, competencies, and capabilities to wards constantly changing environmental conditions. These  opportunities are rarely capitalized as tradit ional organizational structures and the methods used for capturing and  sharing knowledge are ill-equipped at applying organizational resources towards value-centered knowledge creation.  This failure is compounded at the team level as individuals operating within a peculiar environmental context (such  as virtual teams) can face difficulties in learning from others, identifying those with valuable knowledge, and sharing  lessons learned with others within the organization . The ability of teams to adapt organizational resources to address  social and technical challenges is also jeopardized due to the inefficiency of knowledge sharing and coordination  systems to reach outside those directly influenced by the problem (Ackoff, 1999).   Ackoff (1999) designed a learning and adaptation system as a means to improve organizational decision - making and understanding of long-term consequences of decisions. The system allowed for management functions to  learn through iterative actions where decisions are made, the effects of these decision are compared to desired  outcomes, and modifications to prevous decisions are made . Adaptation of previous decisions are facilitated using  information gleaned through understanding of the differences between actual and desired outcomes. This learning  loop, called “dual-loop” learning, provides a means for organizational elements to learn through applying knowledge  of prior decision effects to identify more effective long-term solutions (Sexe, 2012; Ackoff, 1999). Although the model  is effectiv e at improving managerial decision -making the model elements as stated were insufficient to improve  problem-solving behaviors due to subtle differences between decision-making and problem-solving behaviors.    The purpose of the learning and adaptation mode l proposed in this paper is to increase team learning  efficiency by aligning learning with individuals and knowledge assets throughout the organization. The learning and  adaptation model proposed in this paper provides value to teams and organizations in several ways. The model reduces  improves understanding of a team’s ability to learn from problem solving by reducing confusion related to comprehend  the effectiveness of a team’s design (Boisot, 1998). The majority of team designs are based on models assuming that  all team members have access to adequate resources and are in contact with other team members, and that knowledge  is similar to capital  in which it can be captured and stored for future use (Boisot, 1998).  The concept of knowledge  as a tangible asset ignores the fact that most knowledge is tacit and context-specific and cannot be captured (Boisot,  1998). These assumption also fail to consider the peculiar social and technical context of teams (i.e. virtual teams) that  can differ significantly from that of other teams (Sexe, 2016). These differences in team behavior and performance  cause dysfunctions in team behavior that can elude traditional methods and tools. Examples of this would be the ability ",gmail.com,,,46.3144754,11.0480288
13,OPERATIONAL AVAILABILITY AND OPERATIONAL RELIABILITYMETRICS OF THE EMERGING CAPABILITIES OF SYSTEMS OFSYSTEMS,@usn.no,"system of systems, operational, availability, reliability, metrics ","There is a significant amount of literature on system effectiveness, mainly addressing operational availability and  operational reliability. Today’s systems are more and more inter -connected, yielding emerging capabilities. Despite  the growing relevance and presence of systems of systems, little has been done in the development of metrics to  assess the effectiveness of systems of sys tems. Without the appr opriate metrics  that are duly defined and are  quantifiable, it is much more difficult to establish the needed non -functional requirements on system effectiveness,  to perform the necessary assessments that can influence the design effo rts, or to validate actual effectiveness in the  operational life. This paper proposes a comprehensive model to assess the operational availability and the  operational reliability of systems of systems. Definitions for the proposed metrics are given and the  mathematical  model for their prediction is shown. An example is provided to illustrate the applicability of the proposed model.     Keywords  system of systems, operational, availability, reliability, metrics    Introduction  Systems are designed to fulfill either a need that is identified by an end customer or a perceived market opportunity.  Although the definition of system is broad enough to encompass any human design and development effort, there  are cases that deserve special denominations. A series of s ystems is called a family of systems if there is some type  of relationship between them, whether in the nature of their end purpose or in their capability of co -operating  together, yielding emergent capabilities. Two families of systems are the federations  of systems and the systems of  systems (SoS) (Sage & Cuppan, 2001) . In an SoS, individual needs are satisfied with their corresponding system s.  The interactions and cooperation among them enables the fulfilling of additional needs, as a result of the emergent  capabilities, as shown in Exhibit 1 (Sols, 2014).   An SoS is a system integrated by entities that are each of them systems in their own right and that can work  separately and independently, although by working together they are collectively capable of achieving goals that  none of them could separately attain (Maier, 1998). An SoS can be defined also as a set or arrangement of systems  that results when independent and useful systems are integrated into a larger system that delivers unique capabilities  (DoD, 2004). A system of systems is a system of interest whose elements ar e managerially and/or operationally  independent systems (INCOSE, 2015).  There are four different types of SoS : virtual, collabora tive, acknowledged and directed  (MITRE, 2014).   The component systems of an SoS may have different ownership and/or management, as shown in E xhibit 2. The  distinction is releva nt for the purpose of assessing the effectiveness of an SoS, as a function of the effectiveness of  its component systems. I n the case of a virtual or a collaborative SoS the decisions taken by the different owners of  the component systems will clearly affect the emerging capabilities that require their concurrence. In an  acknowledged SoS  the existence of a coordinated management the ne gative impact on emerging capabilities as a  result of decisions taken by system owners is less likely, due to the joint ownership and/or coordinated management .  Such likelihood is far less in the case of a directed SoS. It is worth noticing that the members of an SoS may be  unavailable not only due to technical reasons, such as failures that need to be corrected or planned,  preventive  maintenance that is no compatible with system utilization. The members of the family may decide to leave it  voluntarily, or be forced to doing so.  If they choose to abandon the system the act is called abandonment (Salado,  2015). If on the other hand it is some of members of the family who decide to expel a system from the system of  systems, the situation is called exile (Salado, 2016) . Therefore, if in all SoS a component system may be temporarily ",usn.no,,,46.3144754,11.0480288
14,IMPROVING PATIENT ACCESS SERVICES THROUGH WORKLOADAND WORKFLOW ANALYSIS,@newhaven.edu,"Lean, healthcare, workflow analysis, workload analysis ","Patients’ experience during their initial encounter with the provider’s services may adversely affect their satisfaction  with subsequent care. Streamlined and standardized processes lead to efficient and effective oper ations, which  ultimately result in higher quality of service to patients. This paper presents a case study using statistical tools and  lean methods about improving business processes that contain point of access for the patient.   The study was  conducted in a neurosurgery department at a teaching hospital in New Haven. The neurosurgery department has five  teams, which are spine, pediatric, neurovascular, oncology, and epilepsy; the spine team was selected for pilot  implementation. Based on interviews and on site observations key business processes were identified. Then, factors  that lead to process inefficiency such as loopbacks where a patient has to access the system more than once to  receive the service requested or flaws in internal communication flow were studied through process mapping and  historical call data analysis, and the results were used to determine staffing requirements to operate effectively, i.e.  meet patient expectations. The implementation approach in the pilot study and the lessons learned during  implementation provided basis for development of a model for implementation with the other five teams.    Keywords  Lean, healthcare, workflow analysis, workload analysis    Introduction  Streamlining operations are essential to reduce response times, optimize the use of resources and  improve overall  effectiveness of any organization. In healthcare streamlining operations will lead to enhanced employee satisfaction  (Halogen Software, 2008 ) and better delivery of healthcare services, which result  in improved patient experience.   Streamlining a process involves eliminating non -value added activities or simplifying those that cannot be  eliminated, determining resource requirements, creating a flow that maximizes process efficiency, as well as   streamlining individual steps (Allnoch, 1998). Workflow and workload analysis, and standardization of work based  on the analysis results are typical methods used in efforts to streamline operations. Workflow is a series of steps  completed to achieve a goal. It consists of information, documents, tasks and usually multiple participants  completing these tasks. Workflow analysis focuses on the process followed to achieve the goal. Workload analysis,  on the other hand, is used to anticipate and plan work and resource requirements based on the analysis of historical  or projected data.    Streamlining operations and standardization of work have been used for a long time in manufacturing as  part of lean thinking and practice. There are numerous examples of proven benefits of lean on productivity, cost,  and quali ty in literature. As a result of lean implementation with a focus on streamlining manual assembly  operations, a burner manufacturing company was able to reduce average set up times from 5 minutes to less than a  minute and increase consistency in the work p erformed by different workers ( Chen and Erdil, 2015) . A bearing  manufacturer increased its on -time delivery performance from 76 to 99 percent using value stream map, widely  utilized lean tool that captures workflow ( Urs, Mahesh, and Sandesh, 2014) . Aircraft manufacturing giant Boeing  after streamlining its processes had successfully cut its defect costs by 75 percent, saving about $655,000 per  aircraft (Jenkins, 2002).   It has been a while now that lean thinking and practice, originated in the manufacturing  sector, extended  beyond manufacturing, and translated in service, retail, healthcare, and others. Applications of lean can be found ",newhaven.edu,University of New Haven,United States,41.29091365,-72.96263883692575
15,ANALYZING THE CHALLENGING GROWTH OF ENERGYCONSUMPTION IN SAUDI ARABIA,@ttu.edu,"Energy systems, energy consumption, systems engineering. ","The continuous growth of energy consumption is a global concern. Because energy is mainly generated by burning  fossil fuel resources in processes that involve greenhouse gas emissions, controlling that growth is especially  important. In Saudi Arabia , currently  world’s top oil exporter, the growth of domestic energy consumption is  exceptionally alarming. The domestic energy consumption, whi ch is subsidized by the government, curbs Saudi  Arabia’s petroleum export capability, which accounts for about 90% of the country’s export earnings. If the prevailing  structure and policies of the current energy system remains unchanged, Saudi Arabia is expected to be an oil importer  within the next two decades. Thus, it is critical for the country’s economy to efficiently manage and control its  domestic energy consumption and maintain its petroleum exporting strength. This paper provides a systematic and  comprehensive review of the impact of Saudi Arabia’s energy policies on motivating the fast growth of energy  consumption and its subsequent issues. In addition, it presents a comprehensive review of some of the discussion in  the literature about the effectiveness of various  managerial and strategic solutions to lower the domestic ene rgy  consumption.     Keywords  Energy systems, energy consumption, systems engineering.    Introduction  Global greenhouse emissions have noticeably increased in the last ten years, which increased the global concerns  about their environmental consequences, especially regarding their contribution to the global warming issue. These  emissions are released when fossil  fuels are burned to generate energy. Residen tial use of energy is a significant  portion of the overall consumption of energy, which contributes heavily to the environmental concerns that are caused  by the relea se of greenhouse emission (Abrahamse et al., 2007). For instance, during the last three decades, in the  Western Nations about 33% of the energy was consumed by households (Gram -Hanssen, 2013).  Households’  consumption of energy can occur in two forms: direct consumption , such as electricity use, or indirect consumption,  which, results from the delivery and manufacturing processes of consumed goods in households (Abrahamse et al.,   2007; Steg, 2008).  This paper comprehensively reviews the literature that analyzes the possible solutions of energy consumption  in Saudi Arabia and its economic and environmental consequences. Saudi Arabia is currently the top oil exporter in  the world, a nd it sits on an estimated 267,000 million barrels of oil reserves, which comprise about 16.2% of the  world’s proven reserves (EIA, 2016). Saudi Arabia’s population was estimated to be 30,770,375 in 2015 (CDSI, 2016).  Even though the population of Saudi Arabia is fairly small by world averages, its growth rate is higher than the average  global growth rate with an estimated 3.7% annual growth rate (Al-Ajlan et al., 2006). In 2014, approximately 70% of  the consumed energy in Saudi Arabia was used to generate Saudi Arabia’s demand for electricity  (MEP, 2014).  Households’ electricity usage comprised 44% of the sold electricity across all sectors of electricity consumption in  the country (ECRA, 2014). The government of Saudi Arabia supplies energy to the resident s at subsidized prices. ",ttu.edu,Texas Tech University,United States,33.59375255,-101.89959552302756
16,K-MEAN CLUSTERING IN TRANSPORTATION: A WORK ZONESIMULATOR CASE STUDY,@mst.edu," Data mining, Transportation, Pattern recognition, Decision analytics ","Transportation engineering considers many different categories such as accident management, infrastructure  management, driver behavior, and traffic manage ment and generates large amount of data. Data mining methods are  a common engineering approach to understand data- intensive scenarios and use techniques to extract patterns,  correlations, and information from large amounts of data. This research uses a sim ulator to compare driver patterns  and behaviors when comparing reactions to the Missouri Department of Transportation (MoDOT) alternate  sign  with the Manual on Uniform Traffic Control Devices (MUTCD) current sign.    K-mean clustering method is used to  cluster driver response to work zone sign configurations  presented in the simulator environment  and uncover  patterns that can assist engineers with usability of work zone signage. Key findings of this research will help the  transportation engineering manager make data-driven decisions regarding work zone safety and design.    Keywords   Data mining, Transportation, Pattern recognition, Decision analytics  Introduction  Due to increas ed volumes of  data in all engineering fields, utilizing methods that can help decision makers best  determine how to use that data are essential . It  is important to apply  methods to analyze data and to extract  knowledge. Data mining methods can assist managers and decision makers to extract pattern s and identify decision  points suggested by the  data. Data mining methods are  a new generation of methods that are widely used in fields  such as engineering, industry, and management.  Transportation engineering is one of the  areas that commonly uses  data mining for data analysis. This p aper presents the results of a simulator -based study comparing two different  sign configurations. Driver performance and categorization of behaviors is determined through the use of k -mean  clustering.   Literature Review  Data mining methods us e statistical algorithms and techniques to determine relationship between the data.  In other  words, data mining methods are useful for extracting meaning and hidden relationships among data ( Rygielski et al.,  2002). Data mining methods  are divided into cluster analyses, classification and prediction, as well as association  rules (Liao et al., 2012). For this project, the clustering method is used . A short discussion of this technique follows  below.    Clustering:   The Clustering method is one of the common data mining methods. Based on findings from the literature , clustering  methods are effective and reliable  for partition ing traffic data into different regimes such as free-flow and  congested-flow regimes. In a tra ffic study, the most common clustering method estimates annual average daily  traffic (AADT); this method is considered more acceptable than the other methods (Gecchele et al., 2011) in  determining traffic flows. The clustering method is frequently applied to partitioning traffic flow data. Clustering  methods divide data into groups (clusters) based on similarities and dissimilarities between groups  and are useful for  finding patterns between large amounts of data. K -mean clustering is one of the most common clustering methods  and is used to determine the center of a cluster.   ",mst.edu,Missouri University of Science and Technology,United States,37.9532435,-91.77426666814159
17,COST ANALYSIS FOR HIGH VOLTAGE TRANSMISSION LINEINSPECTION USING ROBOT,@mst.edu,,"The electricity transmission lines are conventionally inspected and maintained by linemen with hot sticks that can  directly touch the line. The major limitation of this conventional method is high risk and time consuming. With the   rapid development of robot technology in recent years, the utilization of robot instead of human being for the regular  inspection of the high voltage transmission line has drawn wide attention from both industry and academia. Utility  companies aim to harness this modern  technology for saving costs and increasing their customer satisfaction. In this  paper, we focus on the cost model for using robot for transmission line inspection. A heuristic routing strategy is  proposed to guide the motions of robot and supporting team in inspection . The corresponding cost model is derived  considering different cost components such as robot depreciation cost, staff salary cost, team ground motion cost, and  others. A simulation model is developed to study different working scenarios and estimate the variation of co st  considering random factors like the occurrence of the obstacles on inspected lines.     Key words  Robot, Transmission line inspection, Cost model.    Introduction  Overhead high voltage  transmission line systems form a crucial part of  the infrastructure for providing electricity  service to the public . Since the lines are mainly made of steel and aluminum materials, they are subjected to  environmental corrosions that may lead to continuous deterioration. Utility companies must invest millions of dollars  to maintain their transmission line systems so that they can  be normally operated to provide the service. The  transmission line inspection , one of the major maintenance task s, is conventionally performed by l inemen using  sophisticated hot sticks with the aid of boom trucks and helicopters (Roncolatto et al., 2010).   As reliability requirements increase, limitations of line inspection employing linemen, such as  strong safety  concern, energy supply interruption, weather constraint, low inspection speed, and others, have also been gradually  revealed (Roncolatto et al., 2010). It has pushed utility companies to adopt some new alternative technologies that can  perform safe and reliable inspection operations on live wire without any additional risk to the linemen.  One promising alternat ive technology that has drawn wide interests from utility companies is robot  technology. Applications of robot technology in the power sector can be categorized into three groups : land based,  aerial based, and suspended based robots (Elizondo, Gentile, Candia & Bell, 2010).   Land based robot is usually placed on the boom trucks or land and remotely controlled by the radio  (Elizondo,  Gentile, Candia &  Bell, 2010) . It is  used for replacing insulators and doing other heavy duty work, for example   providing a temporary support to the conductors in absence of a steel structure  (Elizondo, Gentile, Candia &  Bell,  2010). The aerial based robot  is unmanned helicopters used solely for inspecting the state of conductor’s condition    (Elizondo, Gentile, Candia & Bell, 2010). It is controlled by radio with geographical position system. The suspended  based robot is used for inspecting the conductor lines and performing minor repairs when suspending on the conductors  via motion wheels that facilitate the motion on the conductor (Elizondo, Gentile, Candia & Bell, 2010).   In this pap er, we will focus on the cost modeling and analysis of using the third type of robot ; that is,   suspended based robot in transmission line inspection. The suspended based robot generally is semi-autonomous tele- controlled device which can perform basic functions  such as motion and data transmission according to the whim of ",mst.edu,Missouri University of Science and Technology,United States,37.9532435,-91.77426666814159
18,HBCU TECHNOLOGY TRANSFER SUPPLY CHAIN NETWORKS’SUSTAINABILITY: BUDGET RESOURCE PLANNING TOOLDEVELOPMENT,@gmail.com,"budget resource planning, theory of distribution management, social comparison theory, patent licensing, university ","This study describes the development of a university technology transfer supply chain network sustainability tool that  Historically Black Colleges and U niversities (HBCUs) can use to become more self -reliant financially.  HBCUs lag  behind their peer non-HBCUs because historically they have been under-served and were originally established largely  as teaching and blue collar trade schools.   Increased involvement in research oriented activities such as technology  transfer will likely enable HBCUs to grow into new or stronger research institutions.   The literature review revealed  several problem areas with non -HBCUs university technology transfer include a resource planning issues.   These  problem areas for non -HBCUs would be challenging for HBCUs as well.   Problems with university technology  transfer have led to unethical behavior among faculty inventors and university technology transfer specialists at non - HBCUs (C. Hamilton, Schumann, D., 2016).   Despite these problems, the non -HBCUs are generating licensing  revenues.  Systems dynamics is the process of combining the theory, method and philosophy necessary to analyze the  behavior of a system in order to provide a common foundation that can be applied whenever it is desired to understand  and influence how things change over time.   Applying the systems dynamics approach, a budget resource planning  tool was developed using a linear programming optimization techni que.   This study illustrates that classic industrial  uses of linear programming optimization techniques can uniquely be used to optimize budget resource planning for  sustainable HBCU supply chain networks and other emerging research institutions.    Keywords  budget resource planning, theory of distribution management, social comparison theory, patent licensing, university  tech transfer, technology commercialization, HBCUs    Introduction  HBCUs lag behind their peer non -HBCUs because historically they have been under -served and were originally  established largely as teaching and blue collar trade schools (Lorenzo L. Esters, 2013; Nia Imani Cantey, 2013).  This  empirical study seeks to view university technology transfer as a supply chain network for which the theory of  distribution management can be applied.  Most of the research in supply chain management (SCM) addresses problems  from a tactical standpoint.  So, a major challenge is to increase research focused on the development of models for the  strategic and tactical planning  of SCM (Amaro, 2008) .  Optimization and advanced optimization  tools can be  developed to address problems with university technology transfer and to level the playing field for HBCUs.  When  old paradigms lose their effectiveness, one of the reasons leaders do not solve problems right away is the lack of  technological tools (Barker, 1992 ).  Advanced supply chain planning addresses a host of decisions about the  coordination, design and short term scheduling of supply chain processes (B. M. Fleischmann, Herbert, 2003).    The development of the proposed Budget Resource Planning Tool is important because the literature review  revealed that the TTOs need clear goals, priorities, resource planning, and planned investments of their financial  resources (Friedman, 2003; Siegel, 2003; Van Hoorebeek, 2004).   This is even more imperative for emerging research  institutions such as the HBCUs which have more limited resources.  Further, TTOs need to be adequately resourced  with, for example, adequate legal budget, TTO staff compensation, in-house venture capital program (esp. for medical  related inventions), and a business incubator (Degroof, 2004; S. Shane, 2002; S. S. Shane, Toby, 2002; Siegel, 2003).  It costs money to make money.  Investments have to be made in providing and managing the necessary resources  to operate a technology commercialization program successfully.  The proposed Budget Resource Planning Tool is  designed with the theoretical framework for research in mind.  In particular, it was designed from the viewpoint that  university technology transfer is a supply chain network.  Five (5) steps were taken to develop the Budget Res ource  Planning Tool are described and include the: ",gmail.com,,,46.3144754,11.0480288
19,DOD ACQUISITION STRUCTURES FOR A DYNAMIC WORLD:CASE STUDY OF LAND WARRIOR VS TALOS,@usma.edu,"Acquisitions, JCIDS, Innovation ","The United States Special Operations Command (USSOCOM) is revolutionizing the capabilities of the warfighter  with the Tactical Assault Light Operator Suit (TALOS) program. The program will equip USSOCOM operators with  a powered, armored, exoskeleton to enhance their survivability, lethality, and mobility. The project launched in 2013,  with a functional prototype scheduled to be complete in 2018. The aggressive development timeline necessitated that  USSOCOM use a novel acquisition structure—the Joint Acquisition Task Force (JATF).  The JATF structure mandates  a government team as the lead integrator, consisting of acquisition personnel, engineers, and users.  This study  compared the TALOS acquisition structure to that of Land Warrior, a similar project in regards to scope that used a  traditional acquisition structure.  The Land Warrior program launched in 1993, underwent numerous scope changes,  and was eventual ly cancelled in 2007 with only limited fielding.  This study identified that a root cause for Land  Warrior’s cancellation is that its acquisition structure failed to capitalize on commercial innovations and changing  requirements. These issues are critical considering the increasingly rapid advances in technology and the dynamic  nature of the global socio-political climate. Meanwhile, the JATF structure allowed USSOCOM to avoid many of the  pitfalls that Land Warrior experienced.  This study analyzed developments to date to collect lessons learned from the  TALOS project, focusing on its ability to capture innovation.  This analysis found that the JATF structure allowed  TALOS to foster innovation and account for changing requirements in a dynamic world.     Keywords  Acquisitions, JCIDS, Innovation    Introduction  Historically, technology developed by the United States military has out -paced that of the commercial sector.   However, modern commercial technology is rapidly and unpredictably advancing, causing some military technologies  to be obsolete by the time that they are fielded.  These issues are coupled with dynamic changes on the global socio - political stage, which can result in changing needs for warfighters.   Land Warrior, a project that intended to augmen t the situational awareness of dismounted Soldiers through  advanced electronics, faced these problems. The project was conceived in 1993; however, the inability of the project  to keep-pace with commercial technology and adapt to the Global War on Terror, r esulted in numerous delays, with  the project eventually being cancelled in 2007. Despite 15 years of development and $500 million spent, the system  was never fielded. This paper performed a root cause analysis on the failure of the Land Warrior system; the analysis  identified that a fatal issue arose from the traditional Department of Defense (DoD) acquisition structure. The  acquisition structure could not readily adapt the development process to account for changes in requirements due to  commercial technology advances and changes in warfighter needs.  A new United States Special Operations Command (USSOCOM)  initiative, the Tactical Light Assault  Operator Suit (TALOS), is similar in scope to Land Warrior. However, this project uses a novel acquisition structure,  the Joint Acquisition Task Force (JATF).  The JATF structure allows the government to more readily leverage novel  technology advances and account for changing warfighter needs. The TALOS program serves as an excellent example  of how the government can design complex systems in a dynamic world.    Challenges to Developing Military Systems in a Dynamic World   ",usma.edu,United States Military Academy,United States,41.3927227,-73.95986305044411
20,TECHNOLOGY VALUATION MODEL,@ttu.edu,"Technology Valuation, Technology Acceptance, Technology Imprint ","Technology is seen as a strategic enabler.  Organizations implement technology not only to enable their efficiency  and effectiveness in carrying out their mission but also to gain a competitive advantage in the marketplace.  There  are many techniques for d etermining the economic value of a technology (e.g., ROI).  While organizational  executives and project teams may utilize such formal techniques in order to select the technologies that are in the  economic best interest of the organization, users are not always aligned with the organizational decision.  This can  lead to user behaviors such as immediate criticism without first giving the technology an objective consideration,  project sabotage and other behaviors that are detrimental to a successful technolog y implementation.   Trillion s of  dollars are spent on consumer and organizational information technology  every year.  However, many organizations  experience costly technology project failures .  Previous research  analyzed the user adoption process  and provided  useful insights such as the Technology Acceptance Model (TAM) .  The present research seek to expand on previous  bodies of work by proposing a Technology Valuation Model (TVM) that measures the user’s perceptions of the  organization’s technology decision and provides insight into the contributing factors so that the organization may  take proactive steps to try to influence such factors in order to better align the user with the organization’s   technology decision.    Keywords  Technology Valuation, Technology Acceptance, Technology Imprint    Introduction  According to Oxford Dictionaries (2015), technology is “the application of scientific knowledge for practical  purposes, especially in industry.”  This would mean that technology must be associated with purpose; serve some  need or want.  Knowledge by itself is not technology but rather its application to fulfill a purpose.  Organizations  spend a great deal of resources to acquire, develop, and mai ntain sets of technologies they believe enable their  business to compete in their industry (i.e., achieve a set of purposes).  Likewise, employees leverage technologies to  enable their work.  Focusing on just information technology (IT), studies such as El lis (2008) found that many  organization experience failures in the IT projects and Gartner (2014) projected that organizations were to spend  $3.8 Trillion on IT.  Failures can result from a misalignment between the organization and their end users.  The  user’s perceptions the technology’s fulfillment of their needs and wants may not be aligned with the organization’s  perceptions and/or formal analysis.  Simply put, just because the organization put out a Request for Proposal,  selected the technology that best fits its criteria, and projects a positive return on investment does not mean that the  employees will embrace the change; even if it is in the employees economic best interest.  As seen in Ariely (2009)  “human beings are motivated by cognitive biases of which they are largely unaware” (p. 80).  The problem is that organizations spend a substantial amount of human and financial resources to analyze,  acquire, develop, and implement technologies aimed at enabling the organization as a whole to accomplish its   mission.  However, personnel , at times, undermine the organizational technology direction thereby negatively  impacting the financial resources the organization needs to accomplish its mission.  These negative impacts may be  in the form of (1) implementation delays and increased implementation costs (2) increased maintenance costs from  having to over customize the technology to pacify various groups (3) increased cost from having to maintain  redundant technologies (4) sunk costs of project failures.  Theref ore, “understanding and creating the conditions  under which information and systems will be embraced by the human organization remains a high -priority research ",ttu.edu,Texas Tech University,United States,33.59375255,-101.89959552302756
21,EXPLORING ASSESSMENT METRICS FOR AIRPORT OPERATIONALSUSTAINABILITY,@purdue.edu,"Sustainability, airport, management, triple bottom line ","There are over 3300 public airports in the US, some with management structures as complex as large corporations  with multi-year projects spanning numerous technical disciplines, and others with only a manager and small staff. The  larger hub and regional airports typically have their own planning and engineering departments. One of the major  challenges for airport management teams of any size is to provide safe, accessible and sustainable air transport for  people and cargo. Airports may conduct technical projects that improve sustainability, which is the subject of section  3.5.13 in ASEM’s Engineering Management Body of Knowledge (EMBoK), and similarly a irport sustainability has  become more and more important for airport management  teams and for policy -makers. The aviation industry is  developing airport sustainability plans, ty pically basing them  on the United Nation’s  viewpoint on sustainable  development that uses the three pillars: economic, environmental, and social. The US Federal Aviation Administration  and the Airports Council International– North America (ACI -NA) consider operational efficiency one of the four  pillars of airport sustainability. Although operational sustainability has become a significant aspect of airport  sustainability, its assessment is a challenge for airport management reviewing technical projects for t heir potential  impacts on sustainability. Because there is no general agreement on what comprises airport operational sustainability,  this paper explores definitions and assessment metrics for airport operational sustainability by comparing the  viewpoints of aviation organizations and airports. The outcome of the paper is an attempt to harmonize the different  viewpoints into a definition and framework for assessing operational sustainability.     Keywords  Sustainability, airport, management, triple bottom line    Introduction  There are over 3300 public airports in the US, some with management  structures as complex as large cities or  corporations, and others with only a manager and small staff. Airport management teams often include engineering  managers and larger airports typically have a planning and engineering department, just as many cities or corporations  have. Smaller municipal airports may have access to the municipal planning and engineering departments. One of the  major challenges for airport management teams of any size is to provide safe, accessible and sustainable air transport  for people and cargo. Airports conduct technical projects to improve sustainability, which is the subject of section  3.5.13 in ASEM’s Engineering Management Body of Knowledge (EM BoK), and similarly a irport sustainability has  become more and more important for airport management teams and for policy-makers.   Airports are under pressure to serve more customers and bring in more revenue while not impinging on the  community and environment. Because airport management teams have limited budgets, there is a limit to the number  of projects or initiatives that can be accomplished over time. To be effective, the airport management team must select  and conduct projects carefully, and include sustainability in decision-making from the beginning and not as an added  activity at the end of the process. The ASEM describes engineering management as ""an art and science of planning,  organizing, allocating resources, and directing and controlling acti vities that have a technological component""(Shah  and Nowocin, 2015, p. 3). One component of controlling activities in the management function is to measure  performance as compared to baselines and desired outcomes (Shah and Nowocin, 2015). While the EMBoK is silent  on measuring sustainability, it does emphasiz e the importance of measurements throughout the EMBoK and that  “Sustainability has to be integrated into daily operational process, and transparency is essential” (Shah and Nowocin,  2015, p.100). Without an agreed upon and accepted definition  of sustainability, it is difficult to establish consistent,  definable, verifiable, and meaningful metrics that are transparent.  ",purdue.edu,Purdue University,United States,40.430028,-86.92642114650494
22,A STUDY ON THE SPATIAL CONVERGENCE ANALYSIS OFREGIONAL S&T INPUT-OUTPUT EFFICIENCY IN CHINA BASED ONDEA-GIS,@tju.edu.cn,"regional S&T, spatial analysis, DEA, GIS, the efficiency of input and output ","For the incompletely random problem : the spatial distribution of regional S&T input and output efficiency in China,  a new evaluation method based on DEA -GIS is proposed.  This method makes the index of  S&T quantified and  homogeneity, and it can also qualitatively diagnose the space layout differences and dynamic imbalance of the relative  efficiency of regional S&T input and output. Firstly, the traditional DEA method is used to calculate the relative  efficiency and analyze effectiveness of regional S&T input and output from 2009 to 2012. Then, the Moran’s I index  is used to analyze the global relevance of the regional S&T input and output efficiency. Finall y, Moran scatter plot  and LISA cluster map are used to analyze the local relevance of regional S&T input and output efficiency, and the  spatial agglomeration and abnormality of the efficiency are discussed. The new evaluation method provides the basis  for reasonable allocation of the investment in S&T resources.    Keywords  regional S&T, spatial analysis, DEA, GIS, the efficiency of input and output    Introduction  For a country, S&T (Science and Technology) development could enhance regional competitiveness and domestic  economy. Recently, Chinese government has input more capital and human resources to S&T field, so that this field  has made great development and promoted economy in some degree. However, S&T’s  promotion on economy  development rely s on not only input quantity of S&T, but also output efficiency of it. Therefore, the reasonable  evaluation on S&T output efficiency has become a wide focus of scholars.  Nowadays, study in this field has gained many achievements, and methods such as DEA (Data Envelopment  Analysis, DEA) evaluation, Grey Relational Analysis and Entropy Weight Analysis are usually used by many  researchers. Among those methods, scholars prefer DEA because it fits problems with various input -output indexes,  hard to be quantified and homogenized.  Although research methods on S&T evaluation have been mature, most scholars focused on relatively  effectiveness of input and output process, and they seldom study efficiency during this process in regional view.  Chinese S&T development are unbalanced between eastern and western regions, and are great different between  developed and undeveloped areas. According to the basis, this paper shows a new method to evaluate regional input  and output efficiency in spatial view.    Establishment of Chinese Regional S&T Input-output Efficiency Index System  Based on relevant literatures and characteristics of Chinese regional S&T work, this paper will pick S&T input indexes  in three aspects: human resources, capital and property. Since some data under different S&T statistic indexes are  relevant, one or two  representative indexes are picked out under each secondary index. Index system and literature  sources are shown in Exhibit 1.      ",tju.edu.cn,Tianjin University,China,,117.17789778037583
23,SYSTEMIC INTERVENTION FOR COMPLEX SYSTEM GOVERNANCEDEVELOPMENT,@odu.edu,"Complex System Governance, Systemic Intervention, System Development  ","This paper explores the issues related to systemic intervention for Complex System Governance (CSG) development.  Systemic intervention seeks to intentionally engage a system to influence trajectory or outcomes. CSG is an emerging  field focused on the design, execution, and evolution of the functions necessary to provide continued system  performance (stability) in the midst o f incessant turbulence and increasing complexity.  Integral to this field is the  necessity to ‘intervene’ in a complex system to enhance system behavior, structure, or performance. Arguably, system  interventions have an unremarkable record of success, ranging from declared success in improving a situation (system)  to abysmal failure (doing more harm than good).   However, little emphasis has been placed on a more rigorous exploration of the nature of systemic  intervention as it influences our ability to more effectively enact change in complex systems.  To address this sparse  accounting in the literature, following a n essential introduction to Complex System Governance , this paper pursues  three primary objectives. First the nature of ‘systemic intervention’ is examined. Second, the different forms and roles  in systemic intervention for complex systems are explored.  Third, an approach for beginning an intervention in CSG  (CSG Entry) is examined for broader implications for engaging complex systems and problems. The paper concludes  with critical issues and suggests considerations for more effective systemic intervention.    Keywords  Complex System Governance, Systemic Intervention, System Development     Introduction: Complex System Governance  To achieve our introduction to Complex System Governance (CSG) we have focused on three primary objectives.   First, we introduce and acknowledge the complex system problem domain that is the target for CSG . We suggest a  present and continuing trajectory for the confounding landscape that must be navigated by practitiones (designers,  owners, operators, maintainers, and evolvers)  of complex systems . These practitioners, although having different  orientations with respect to a system, all faced the same problem domain. Second, we introduce a systemic perspective  that seeks to provide an explanation for our difficulties in grappling with this problem domain . This examination  provides a uniquely ‘systems’ perspective in offering an alternative viewpoint. Third, CSG as a responsive alternative  to address development of complex systems is introduced.  Our focus is to provide a general overview such that the  remainder of the paper will have a sufficient foundation upon which it can be built.    Landscape of the Modern Complex System Practitioner  The landscape of the modern practitioner of complex systems (organizations as well as people), might be summarized  with a set of characteristics . While these characteristics are certainly not intended to present an  ‘absolute’ depiction  of the landscape, they serve as a reminder of the stark reality faced by practitioners. The domain of the complex system  practitioner (Exhibit 1) appear to be intractable and are marked by conditions that have been previously established  (Jaradat & Keating, 2014; Keating, Katina, & Bradley, 2015; Keating, 2014; Keating & Katina, 2011): ",odu.edu,Old Dominion University,United States,36.8862699,-76.30972478839735
24,INVOLVING FRONTLINE WORKERS IN INNOVATION: APRELIMINARY INVESTIGATION OF LITERATURE,@gmail.com,"Frontline workers, subject matter experts, employee engagement, innovation ","In today’s increasingly competitive marketplace, companies are constantly looking for new ways to innovate and  improve their products and services. Unf ortunately, these efforts are often not as successful as expected. One reason  for this lack of success is failure to adequately consider the current state of the system and design innovations that  appropriately build from this state. It is well documented that one of the best ways to build this foundational  understanding of current state is partnering with frontline workers who participate in the system every day. It would  follow that these frontline workers should act as a resource to any improvement proje ct. This review investigated  current practices to harness this critical knowledge across a variety of industries including  the understanding of the  motivations of frontline workers involved in the process and identification of key gaps in current practice   Frontline workers are subject matter experts (SMEs) for the systems in which they perform daily work. Based  on the literature that explore s using frontline workers as SMEs, it is clear they are an underutilized resource that is  available in every organization. The conclusions drawn from the literature review emphasize the important role SMEs  could have in the innovation and improvement process.     Keywords  Frontline workers, subject matter experts, employee engagement, innovation    Introduction  The rapid developments in technology and society have resulted in an ever changing and competitive marketplace.  This dynamic has resulted in companies seek ing to continuously improve products and services in order to remain  viable and stay ahead of the competition. These types of c ontinuous improvement efforts are grounded i n current  operations that are managed day-to-day by front line workers . Before improving a work system, there must be a full  understanding of how the current system operates. Otherwise, t hese projects can easily fail due to a lack of process  understanding, identification  of the wrong issues, or lack of input from end users of the system  (Longenecker &  Longenecker, 2014; Moyo, Francis, & Bessong, 2017). Frontline workers who operate daily within a work system are  key subject matter experts of that system and therefore should be a resource in initiating improvement efforts. If this  logic follows, why are frontline workers not widely recognized for the important contributions they could make in  projects aimed at improving their work systems?    There are many applications of frontline workers as SMEs  in a project. One of the most utiliz ed roles of  frontline SMEs is as a  source of information to better understand day -to-day operations and special scenarios. By  using frontline SMEs to build the framework and understanding of the system , an improvement initiative can be  designed around real end users, day -to-day tasks, and special scenarios (Rinehart, Smith, & Spencer, 2014). In  organizations where the goals have already been established by others, frontline SMEs can also serve as reviewers on  projects, providing input on project proposals, gates, and conclusions (Gandhi & Sauser, 2008). However, in cases  where frontline SMEs are relied upon as a resource or reviewer, their contributions are limited to during or at the end  of an established project. Neither of these roles allows for the frontline SMEs involvement. When frontline SMEs are  not identifying and initiating improvement initiatives in their o wn work systems, a company may be missing out on  potential improvements and innovations. There is a need to utilize frontline SMEs in the role of initiator or  improvement projects; but, how can organizations best  motivate a frontline worker to identify and improve issues in  a work system? ",gmail.com,,,46.3144754,11.0480288
25,IMPROVED SCHEDULING OF OPERATING ROOMS,@gmail.com,"Operating room scheduling, mixed integer programming, healthcare. ","Healthcare cost represents a large part of the economy and efforts on having efficient healthcare management systems  are frequently developed. It is known that Operating Rooms (ORs) are one of the biggest cost and revenue centers in  healthcare, and that is why they are one of the most important areas to improve healthcare systems. ORs have limited  resources and budget, and patient demand for surgeries are increasing. There is a need for improved scheduling of  ORs to better manage the resources to have an efficient management. Thus, this paper addresses an Operating Room  (OR) Scheduling and Sequencing problem to decrease costs and improve the quality of care given to patients. This  study develops a mixed integer linear programming model which minimizes the cost of opening an OR, overtime  utilization of the ORs, makespan, and patient waiting time.    Keywords  Operating room scheduling, mixed integer programming, healthcare.    Introduction  National Health Expenditures in the United States, between 2000 and 2012, increased from around $1.3 trillion to  around $2.8 trillion, which accounts for around 17% of the Gross Domestic Product (Centers for Medicare and  Medicaid Services, 2012). In 2012, Hospital expenditures were around $880 billion which is one-third of the total  health expenditures (Centers for Medicare and Medicaid Services, 2012). A report published by UNICEF in 1997  shows that between 13 and 18% of Gross National Product (GNP) goes to health care expenses in Western European  Countries (Ogulata, S. N., & Erol, R., 2003). The cost of “overuse, underuse, misuse, duplication, system failures,  unnecessary repetition, poor communication, and inefficiency” is more than half a trillion dollars per year for the  health care system (Lawrence, D., 2005).  Improving the quality of care given to patients and decreasing hospital costs are two of the most challenging  problems that health care providers need to manage along with the limited resources (McLaughlin, M. M., 2012).  While improving the quality of care and decreasing costs, hospitals need to minimize patients’ length of stay, waiting  time in hospitals, and optimize the utilization of service rooms to improve efficiency (McLaughlin, M. M., 2012).  Operating rooms (ORs) are considered the central engine of the hospitals and responsible for generating more  than 40% of a hospital’s total revenue and resource costs (Jackson, R. L., 2002; Healthcare Financial Management  Association, 2003; Macario, A., Vitez, T. S., Dunn, B., & McDonald, T., 1995; Marques, I., Captivo, M. E., & Pato,  M. V., 2012). Even though ORs constitute a significant portion of total revenue and costs, most hospitals use them  inefficiently and they are utilized at approximately only 68% of the capacity (Denton, B. T., Rahman, A. S., Nelson,  H., & Bailey, A. C., 2006). Increasing the usage of them may generate additional $5 million annual revenue for  hospitals (Healthcare Financial Management Association, 2003). However, due to the unexpected arrival of  emergency patients, uncertainty in the surgery durations, conflicting priorities and preferences of patients and  surgeons, managing an OR department is not a simple task. One of the effective ways of managing the OR planning  and scheduling is optimal allocation of available resources to ORs. Therefore, this study develops a mixed integer  programming model to allocate a hospital's limited resources to multiple ORs. The main goal of this mathematical  model is to optimize the cost of ORs and improve the quality of care of patients.  Literature Review  Optimization of OR scheduling and sequencing is studied by many researchers in literature. Since it is a very  common topic, the various ways and methods have been studied. One of the methods is the minimization of the cost  in ORs. Erdem et al., 2012 develop a stochastic mathematical programming approach for day-to-day scheduling and  sequencing of patients in ORs. They consider the availability of surgical teams, ORs, and Post Anesthesia Care Unit ",gmail.com,,,46.3144754,11.0480288
26,CYNEFIN SENSEMAKING FRAMEWORK FOR DECISION SUPPORT INDESIGN AND DEVELOPMENT OF LARGE SCALE COMPLEXENGINEERED SYSTEMS,@iastate.edu,"Systems Engineering, Sensemaking, Complex systems  ","The design and the development of Large -Scale Complex Engineered Systems (LSCES) requires the interactions  and involvement of mult iple teams and numerous levels of the organization. Traditionally, requirements -driven  systems engineering approaches are used to capture the preferences of the stakeholders for LSCES. For LSCES, the  requirements driven approach often leads to overrun in c ost and time, which in turn leads to requirement creep  during the development phase. Hence, the LSCES require rigorous approaches, such as value -based approaches,  Multidisciplinary Design Optimization (MDO), Decision Analysis (DA) during the design and dev elopment phase  to control the creep. Before these rigorous approaches can be used on the LSCES, a solid foundation of Systems  Engineering (SE) is required. The decision maker should make sense of the system by understanding the  requirements creep and how i t affects the system. The requirements are often ever changing  and are subjected to  uncertainty within multiple organizational levels and as well as with demands of stakeholders. In this paper, the  authors analyze the uncertainty in requirements and the creep that may occur at various levels of an organization and  map it to a sensemaking framework, the Cynefin framework to determine the different rigorous methods that can be  used during the design and development of the system. A sample organizational structure is used to illustrate the  effects of requirements creep and Cynefin dynamics. Two types of system, a simple system and a complex system  are used to demonstrate the state and movement of the system in the Cynefin framework.     Keywords  Systems Engineering, Sensemaking, Complex systems     Introduction  Large-Scale Complex Engineered System (LSCES) is a system, which is large in size with many entities,  subsystems and interdisciplinary systems. This involvement  of different systems  increases the complexity of  the  system thereby increasing the risk associated with it. LSCES also involves multiple interactions between the  different levels and departments in an organization (C. L. Bloebaum & McGowan, 2010) . The design and  development of such complex system involves various forms of risks, uncertainties, and ambiguity during the  different development stage of a LSCES. With increase in complexity and size,  the costs and time taken to develop a  LSCES is relatively huge (Bloebaum, Collopy, & Hazelrigg, 2012; Deshmukh & Collopy, 2010; Lewis & Collopy,  2012). The failure of a LSCES is not uncommon and when the failure oc curs it is a loss to the company, project  cancellations and loss in time and money. These failures are mainly due to ever -changing requirement of the  stakeholders during the design and development of a LSCES (C. L. Bloebaum & McGowan, 2012) .  These changes  in requirements are the requirement creep  and they bring about a change in cost a nd time thus increasing the scope  of the design and development of LSCES.   Traditionally the design and development of a LSCES involves a series of Vee model of the systems  engineering for every stage of the development process  (Calvano & John, 2003; Griffin, 2010) . The Vee model is  extremely high level, and is largely requirements driven. The design and the development of the LSCES involve  three ph ases of the development process: conceptual design, preliminary design and the detailed design phase. ",iastate.edu,Iowa State University,United States,42.0279608,-93.64473746093857
27,"INTRODUCTION TO OPTIMIZATION OF DECISION-MAKING INCOUPLED, DYNAMIC AND UNCERTAIN PRODUCTION,MAINTENANCE AND PRODUCT DEVELOPMENT ENVIRONMENT",@ens.etsmtl.ca,"Decision-making, dynamic project management,  production, scheduling under uncertainty, dynamic environment,  ","The joint use of m anufacturing facilities for production, repair of goods or new products development is an ever - increasing reality for several companies. In a context of increasing demand for manufacturing facilities with finite and  variable capacity over time, we are particularly interested in develop ing an approach for planning control to plan  operations in such way of maximizing performance, flexibility and agility . This es pecially addresses the problem of  dynamic allocation of resources in an uncertain and dynamic environment of production, repair of goods and product  development. The goal of this work is to review a set of pas t studies that can contribute to future researches in the  optimization of decision-making in such coupled, dynamic and uncertain environment. A synthesis of approaches and  models developed in previous  work is presented as well as their limits. Potential areas of research are discussed in  relation to the terms of manufacturing system performance measurement, capacity and reliability of dynamic  manufacturing systems, product development and scheduling  under uncertainty. The future work introduced by this  paper and the industry 4.0 concepts implications are also discussed.    Keywords  Decision-making, dynamic project management,  production, scheduling under uncertainty, dynamic environment,   maintenance, product development, resource allocation.    Introduction  Manufacturing systems management problems exist since the 20th century , marking the end of the craft industry and  the beginning of an industrial era (David & Christian, 1999) . Several researchers have addressed this issue and have  developed many approaches to assist managers in decision -making. Emphasis had been placed on manufacturing  systems intended solely for production and on several of its variants. For example, Rivera-Gómez, Gharbi, and Kenné  (2013) have studied the influence of quality control on production planning. On their side, Muchiri, Pintelon, Martin,  and Chemweno (2013) have worked on the influence of maintenance policy on the performance of production systems.  Most of these decision support models are based on performance evaluation whose foundations had been analyzed by  Benita (1999) thru the development of a universal framework for the selection of performance measures. However,  the study of multiservice manufacturing systems has received very little attention in contrast to systems designed  solely for production. This is the case for coupled manufacturing systems dedicated to production, repair of goods and  product development. The joint use of manufacturing facilities for production, repair of goods and product  development is a reality for several companies. This entails a number of advantages (less investment, maximum  occupancy of facilities, less maintenance activities), but also disadvantages (in case of large and varied demand, there  is a risk of lack of resources, failure to meet deadlines etc.). For such multiservice manufacturing systems, in a context  of ever-increasing demand and facilities with finite and variable capacities o ver time, it is legitimate to question the  performance incurred and the optimal approach for planning activities. Eickemeyer, Herde, Irudayaraj, and Nyhuis  (2014) have worked in this direction, but they have limited their studies to repair of goods. It is also the case of  Beauregard (2010), who has worked on the planning of activities in a product development environment through the  optimal allocation of resources to tasks. Although those approaches proposed for resource a llocation problems work,  they lie on a static principle. Indeed, the optimization is done only during the planning phase, before the start of  activities. It is not possible to adapt in real time the initial planning to integrate changes observed during the  projects ",ens.etsmtl.ca,,,46.3144754,11.0480288
28,AN INTEGRATED FRAMEWORK FOR ASSESSMENT OFSUSTAINABLE MANUFACTURING,@d.umn.edu,Sustainability; sustainability assessment; manufacturing system; optimization.. ,"Sustainable manufacturing systems should be profitable and environmentally friendly while being safe both  physically and socially for everyone in the system. This paper highlights the main aspects and requirements of  sustainability, which are related to manufacturing systems, demonstrating that there are other aspects of sustainability  in general that are not reflective on manufacturing. The paper also highlights many useful assessment indices of  manufacturing sustainability, which makes quantification, and then comparison and optimization of system  performance possible. A comparative study on the existing sustainability assessment tools is performed to classify  these tools based on appropriateness to manufacturing systems and limitations. The paper also reviews the significant  research work in system modeling for assessing and optimizing manufacturing sustainability. The review has  revealed that the triple bottom line TBL factors, economic, social and environmental, are difficult to evaluate and  optimize simultaneously due to the complex nature of manufacturing systems and the wide variety of processes and  type of the system. Furthermore, the review has demonstrated that there is significant research gap in considering  social sustainability for overall sustainability characterization. This paper presents a new integrated framework to  connect the economic, environmental and social factors, and to optimize sustainability performance of the system by  balancing these factors. The consideration and the integration of social sustainability with other factors make this  framework unique and more functional. Finally, the scope of future research work is also presented for the proposed  framework.    Keywords  Sustainability; sustainability assessment; manufacturing system; optimization..    Introduction  The concept of sustainability was officially coined  in 1987 from the Brundtland Report (Brundtland, 1988) where  sustainable development was termed as “meeting the needs of the present generation without compr omising the  ability of future generations to meet their needs”. This definition illustrates that organizations are vulnerable to  sustain in future without caring not only economic but also the environmental or social aspects.  Sustainability is the  most challenging issue for every firm and organization because the perfect balance among  the triple bottom line of  sustainability is the key to future success. The triple bottom line of sustainability is the aggregate consideration of  economic, social and environ mental factors (Elkington, 2001). Assessing or measuring sustainability is a big  challenge because there is no numerical limit for assessing the sustainability (Elkington, 1997). T here are various  proposed indices and frameworks (Ness, Urbel -Piirsalu, Anderberg, & Olsson, 2007)  (Chen, Thiede, Schudeleit, &  Herrmann, 2014) (Harik, EL Hachem, Medini, & Bernard, 2015), which have focused on developing a systemic path  for assessing sustainability in organizations. However, these proposed frameworks are either v ery time consuming or  very difficult to implement in real  world. As sustainability is a very dynamic and versatile issue, different authors  have emphasized on various bottom lines. Even the strategy and planning towards sustainability vary from an  industry to another industry. For instance, sustainability strategies  (Al-Majed, Adebayo, & Hossain, 2012) of oil &  gas industries are different compared to other industries due to the fact that here, oil spill is a common problem in   achieving sustainability. On the other hand, automobile manufacturing companies normally follow different types of  strategies compared to oil & gas industries although automotive companies work on the same triple bottom line  concepts (Rosen & Kishawy, 2012) (Schmidt & Butt, 2006).  Thu s, it is quite difficult to generate a simple ",d.umn.edu,University of Minnesota - Duluth,United States,46.8203898,-92.08527412081386
29,AN ECOLOGICAL FOOTPRINT ANALYSIS FOR INDUSTRIALAPPLICATIONS,@gmail.com,"Ecological Footprint Analysis, Industrial, Sustainability, Natural Resources ","In a recent 65 year span, the population on Earth increased from 2.5 billion to 6.5 billion people —an average growth  of 80 million people per year.  To support this large and ever growing population, an enormous amount of natural  resources is required.  Every individual in the human population requires natural resources in varying amounts to  survive.  Some of these resource needs, such as the amount of water an individual drinks, are easy to quantify.  Others,  such as the amount of cropland required to produce the food supply for that individual are a little more difficult to  calculate.  The Ecological Footprint Analysis is a tool used to calculate in hectares  the amount of land required to  support an individual.  The user of the tool incorporates information on an individual’s housing, food consumption,  energy usage, and regional location to calculate the number of hectares  it would take to supply the materials for the  housing, the number of acres to grow the vegetables eaten, and even the land needed to support the animals to be  eaten.  This tool, however, is specific to human applications.  In this research, a tool to calculate resource requirements  to support an industrial facility is explored.  The tool investigates adaptability to various locations and facilities.  Input  resource requirements specific to facilities to determine the number of hectares required to support current resource  demands is a critical aspect of the analysis.  Developing an Industrial Ecological Footprint Analysis can be used as a  planning tool for future operations or construction needs.    Keywords  Ecological Footprint Analysis, Industrial, Sustainability, Natural Resources    Introduction  From 1950 to 2005 the population of the Earth  increased from 2.5 billion people to 6.5 billion people (PRB, 2016).   This population equates to an average growth of 80 million people per year.  Based on this growth rate, the population  of the E arth could reach 9 billion people by 2050 (PRB, 2016).  For this same timeframe in the United States, the  population increased from 152,271,417 people to 296,410,404 people (USC, 2016), resulting in an average growth  rate of approximately 2.9 million people per year.  To support this large population, a large amount of natural resources  are required.  Many of these natural resources are finite resources, meaning that once they are used there is no  replacement.  The Earth cannot remake these resources.  In 1969, the United States Environmental Protection Agency  was authorized to address the need to conserve the Earth’s natural resources.   As part of its role, the Environmental  Protection Agency is responsible for developing regulations to protect these resour ces.  The efforts put into developing environmental regulations are all taken to ensure sustainability.  The ultimate  goal of each of these regulations is to make sure the human population does not continue to cause new damage to the  Earth’s natural resources or fail to mitigate previous damage.  The majority of environmental regulations are written  to govern federal and often private industrial facility activities.  Many times, these regulations are not applicable to an  individual or a private household.  The magnitude of potential damage from an industrial facility is likely to be much  larger than the magnitude of potential damage from a single household, justifying the need for regulations directed at  industrial facilities.  Therefore, it is vitally important that industrial facilities are aware of their impacts  on the  environment and what is required for the sustainability of the facility.  Currently there is no method or model available for industrial facilities to associate actual natural resource  consumption with energy or resource conservation.  The Ecological Footprint Analysis, used to determine the impacts  of an individual on natural resources, is available but not applicable to an industrial facility.  Regulations are requiring  industrial facilities to reduce their energy consumption by specified percentages or amounts in a given timeframe.   However, there is not a method for correlating the resulting natural resource usage reduction with the required ",gmail.com,,,46.3144754,11.0480288
30,"A COMPARISON OF THE ENVIRONMENTAL IMPACT OFSUSTAINABILITY BETWEEN AMERICAN, EUROPEAN ANDJAPANESE AUTOMOTIVE COMPANIES",@csun.edu,"Corporate Social Responsibility, American, Japanese and European Automotive, GRI ","The issue of climate change has attracted increasing  attention from various industries in both the manufacturing and  service domains in the past decade. Climate change is one of the main  subjects in affecting the industry, with  sustainability being one of the major challenges that top management personnel are concerned about. This is also true  in the automotive sector where the amount of CO2 emitted from the automobile industry is about 20% of total carbon  emissions. As a result, to reduce CO2 emissions and thus create a slowdown in global warming, reducing the amount  of CO2 from the automotive industry is a crucial issue.  Growing environmental concern in automotive industries  motivates automotive sectors to search   for sustainable solutions. Automotive  manufacturers have focused on achieving their goal of sustainability with an  enhanced concentrate on the environmental aspect of sustainability. This is shown by investments made in vehicle  technology and intelligent transport programs which play a vital role in lowering waste, increasing safety, making an  improvement in environmental performance, and reducing emissions.  The aim of this paper is to review the impact of current carbon emissions of actual vehicles from American,  European and Japanese automotive co mpanies that are currently available on the market and also to evaluate the  measures that each of these companies have undertaken to reduce the CO2 emissions in the downstream part of the  product lifecycle    Keywords  Corporate Social Responsibility, American, Japanese and European Automotive, GRI    Introduction  The definition of “environmental sustainability” is everything which we need for our survival and wellbeing depends,  either directly or indirectly, on our natural environment. The Environmental aspects of sustainability  is one of the  most significant concerns of organizations  across the world. Corporate activities may have many types of effects  on environment, some of these Company's impacts on living and non-living natural systems, are including ecosystems,  land, air, and water are considered in the environmental dimension of sustainability. Most of the automotive industries  have done sustainability achievement with environmental tasks have encouraged the competitive landscape of the  marketplace to improve operational efficiency, rethink product designs, and are seeking out new and innovative era.   Effective resource management and strength performance are predominant environmental sustainability desires that  are relevant for the prevailing contributors. This results opportunity for cost savings, revenue generation, and can even  influence overall brand strength through positive environmental re  The perspective of sustainability has expanded from an internal concentrate the company to a gl obal aspect  of the supply chain. ( Miller, E 2007). Supply chain management is important not only in impr oving organizational  performance, customer satisfaction, but also enhance  profitability. (Andre 2011). In addition, sustainability has been  defined as an important issue for businesses and companies that they contribute to the satisfaction of human needs and  protecting the environment. So, monitoring the level of sustainability has become an important part of making decision  support in any management system. Indicators of sustainability are identified as effective tools for determining  production performance, providing information and contributing avoid environmental, economic and social damage,  also are helpful in supporting decision making (Kimmet, 2004). The issue of climate change has attracted  increasing attention from various industries in both the manufacturing and service domains in the past decade.   Ecological impacts of manufacturing processes can be small but cumulative. Take for example any metal shav ing ",csun.edu,"California State University, Northridge",United States,,
31,CONVERGENCE OF RESEARCH ON HIGH RELIABILITY THEORYAND CRITICAL INFRASTRUCTURE PROTECTION: ANOPPORTUNITY TO USE RESULTS FROM EITHER DOMAIN TOMANAGE THE OTHER,@uta.edu,"normal accident theory, high-reliability theory, high reliability organization, HRO, critical infrastructure protection  ","The ter m critical infrastructure (CI) derives from  a series of Presidential Executive Orders and Policy Directives  which evolved from July 1996 as a systematic way of defining the Nation's public and private infrastructures and  protecting them from failure.  The current iteration of those initiatives, titled as Presidential Policy Directive #21  (PPD-21), identifies the components of the Nation's 16 CI sectors, but does little to identify tools, techniques, or  measures for implementing actionable protection for those infrastructures.  The purpose of this paper was to survey  the literature using a systematic review to determine whether sufficient guidance  exists to manage the emerging CI  domain.  The survey found that governmental sources provided significant definitional information  and general  guidance, but provided little which would direct actual protection. In contrast, however, academic and practitioner  evidence did suggest implementation strategies and tactics.  Although never formally validated, High Reliability  Theory (HRT) has been suggested as an implementation  approach to CI protection (CIP). Resilience, one of the five  hallmarks of HRT , was found to be  the most frequently recommended mechanism , while the remaining four  hallmarks were also fre quently found, although described with varying semantic language .  The contribution of this  paper consists of showing that the progress of the work toward defining CI protection has validated HRT , and  suggests that the separate research streams and independent progress toward defining HRT and CI have converged  into a single construct which can be generalized to guide practitioners in developing and managing strategies, tools,  and implementation techniques in either domain.     Keywords  normal accident theory, high-reliability theory, high reliability organization, HRO, critical infrastructure protection     Introduction to High Reliability Organizations and High Reliability Theory  Four years after  his participation on then -President Carter’s commission to investigate the circumstances which led  to the meltdown of the nuclear reactor at Three Mile Island, Pennsylvania, in 1979, Charles Perrow (1984) posited  that due to systems design and complexity,  accidents with widespread consequences are inevitable .  In response that  same year , researchers at University of California -Berkeley, including Todd La  Porte, who was also on the  President’s commission, began what became known as the High Reliability Organizations (HRO) Project to study  organizations (e.g. aircraft carriers, nuclear power plants, and the air traffic control system) which were safely  managing hazardous, complex systems  (La Porte, Roberts, and Rochlin, 1989; Rochlin, 1993 ).  The HRO Project  found that some organizations exhibit extraordinarily high reliability while sharing several common characteristics   (Roberts, 1989; Roberts and Rousseau, 1989; Roberts, Bea, and Bartles,  2001).  Sagan (1993) characterized t he ",uta.edu,University of Texas at Arlington,United States,32.728471299999995,-97.11202127009975
32,THE INFLUENCE OF INNOVATION IN SHAPING THE UNDERLYINGPROJECT MANAGEMENT DELIVERY STRUCTURE,@uqo.ca,"Innovation focus during lifecycle, project alignment with innovation, market dynamics. ","High technology markets can be extremely dynamic and grow very quickly, but they generally evol ve in a specific  lifecycle manner.  Innovation is ever present, and some may argue the life-blood of all high technology firms, but the  types of innovation and the projects that are harnessed to deliver these innovations change as firms grow, mature,  and move through the high technology market lifecycle.  Company age and size will have an effect upon the project  organizational structure and management approach, but the types of innovation required at certain times in the  lifecycle also concurrently drive the manner in which delivery projects are conceived.  This paper builds on previous  literature of high tech markets and firm innovation strategies,  by the authors, to examine why projects are less  formalized, product or technology-focused in smaller or earl y start-ups and growth companies , but evolve to highly  formalized process-focused in mature companies.    Keywords  Innovation focus during lifecycle, project alignment with innovation, market dynamics.    Introduction  As a first step, we will present the logic al framework of market forces and their causes . Markets, firms and  products/services all undergo a natural evolution defined by the lifecycle. This lifecycle imposes amazing discipline  on the behavior of each as markets transit through start-up to maturity  and eventually decline phases, but what  defines and drives this process?   In all markets, but especially in hi- tech markets, the behavior dynamics can be  explained by the underlying customer base and its succession profile during the lifecycle (Moore, 199 1; Koplyay &  Mitchell, 2014ab) .   In early markets, innovators and early adaptors rule the customer landscape; they seek out  innovative, breakthrough and relatively immature products that they help shape and finalize. They are fairly immune  to prices and concentrate on product present and potential future performance. Exhibit 1 captures the distribution of  the customer base as a bell curve.   The early market is inelastic, with high growth potential and rich margins which attract the newcomers,  especially since the market borders are fairly open and the price to pay to enter is low.  Firms indulge in product  differentiation and market positioning to distance themselves from existing competitors and find the customer  segment they can service with their core competencies.  Life is good and the future is bright for the blue sky  innovative firm (Kim and Mauborgne , 2005) and the entrepreneurial spirit may be buoyed with some stimulus from  angel; either venture capital investment or the occasional parent firm capital.   But this phase of the market does not  last long and there comes a tipping point  at “the chasm” (Moore, 1991) where firms need to transit from purely ",uqo.ca,Université du Québec en Outaouais,Canada,45.42226325,-75.73909824426678
33,REVIEW OF EXISTING MODELS FOR FORMAL STRUCTURES INRELATION TO INNOVATION,@gmail.com,"Formal structure, innovation, model, measurement, organizational factors ","Formal structure of any organization is concrete and visible. It is responsible for the processes, roles, and  interdependencies of all aspects existing in an organization; thus it would be a driving force in how an organization  operates and innovates. How we study and measure formal structures can give a greater understanding to what  structures enable or discourage innovation and improvement of processes and services. This is done t hrough a  systematic literature review of measurement systems that relate formal structure of an organization to innovation and  improvement. Upon searching for a baseline measurement of formal structure it is clear that the understanding of  formal structure in relation to innovation is rather abs tract and new.  Formal structure needs be measured in relation  to other organizational elements such as informal structure and technology.    Three measurement systems that related  formal structure to innovation and improvement were found and  evaluated: a second-order model, a psychometric properties tool, and a learning and growth model. The second-order  model proved the strongest candidate on the basis of consideration of interac tion between formal structure and other  organizational factors, validity, and cross-culture and cross-industry application.     Keywords  Formal structure, innovation, model, measurement, organizational factors    Introduction  With the accelerated rates of development  in modern economic and societal landscape, organizations can no longer  remain static in methods of achieving goals. Innovation, improvement, and staying ahead of change are the new  strategy. There are various organizational factors on which organizations design in order to encourage innovation and  improvement; those factors being formal structure, informal structure, people,  and technology (Nadler & Tushmen,  1980). These four factors have subsequent characteristics that are adjusted for each organization, but all four interact  together in operation of an organization. There have been many studies focusing on people and informal structure in  relation to performance of organization, but the literature focusing on formal structure along the same vein is lacking  (Rank, 2008).    Much of the literature on formal structure in relation to performance of innovation and improvement are  limited to industry, culture, or singular case study observation s (Koenig, 1997; Kotnour & Matkovich, 1999; Va n  Aken,, Groubergen, Letens, 2003; Manley, McFallan, Swainston, & Kajewski, 2008; West, 2008). Rather than finding  measures or creating a model demonstrating  the connection of  formal structure as an indicator for innovation and  improvement, several studies  provide anecdotes of solutions to improve creativity from employees through altering  the formal structure (Manley et al., 2008). Teams have been proven to encourage creativity in employees when given  varying degrees of autonomy and self -direction (West, 2 008). Most of these solutions are to shift the  hierarchy into  teams of varying autonomy for a matrix-like structure, which improves performance measures in many ways but only  accomplishes so much in consideration to all aspects of formalization that go into making up an organization’s formal  structure (Davis & Coleman, 1999; Rank, 2008). Changing the structure to teams is not the only answer, and in many  cases, not the best solution (Davis & Coleman, 1999). Between the limited exploration of formal structure in relation  to innovation and improvement and the lack of measures  and models  used to deduct these conclusions, the  understanding of how formal structure can be used to improve innovation and improvement in any organization is  clearly lacking (Rank, 2008).    Formal structure in an organization pertains to the hierarchy structures, policies and procedures, the division  of work, the description of tasks and role, the division of departments and work units, and the relations hips between ",gmail.com,,,46.3144754,11.0480288
34,TECHNOLOGICAL ADVANCEMENTS CHANGING THETRADITIONAL APPLICATIONS OF OPERATIONS MANAGEMENT.,@my.csun.edu,"Operations Management, Internet, Technological Advancement. ","Operations Management (OM) is a multi -disciplinary domain that emphasizes administering all facets of an  organization's operations (Product, Process, Quality Improvement and tools). Previously, it had been primarily alluded  to the manufacturing industry and was originally known as production management. However, over the last two  decades, organizations have applied principles of Operations Management to areas such as marketing, logistics, supply  chain, information technology as well as human resources.  Due to technical advancements, gone are the days where human resources are required for information to  flow. The development in  communication systems has changed the work environment in private and public sectors,  and is a key factor in the emergence of internet based technologies. This provided a new platform for Operations  Management to fulfill the supply and demand of their cus tomers seamlessly. With these technological furtherance,  new tools and concepts have been created, which enhance organizational operations in the areas of supply chain and  customer relationship managements. These developments also help in the evolution of new key performance indicators  (KPIs) for organizations.  In this paper, the authors focus on how the internet and information technology have revolutionized  traditional approaches to Operations Management in the e -commerce domain, and caused a shift toward s a holistic  vision of business models. This vision has implications for supply chain management, production planning and  scheduling, product Lean operation, lean six-sigma methodology, information-based strategy, Information technology  system, risk and environmental management. The paper will investigate in future trends mentioned above by providing  observations, a cause and effect model, and a predictive framework of future developments in the field .    Keywords  Operations Management, Internet, Technological Advancement.    Introduction  Operations management supports an organization in achieving the best business results in a short and long term. It  concerns with the planning and controlling of all activities necessary for a firm’s product and its services. According  to the author, Operations management deals with ideas and technologies to increase productivity and reduce costs. It  improves flexibility to meet rapidly changing enhanced product qualities, customer needs, and services . (Weiss &  Gershon, 1989)  Operations management thrives continuous improvement to supplement quality, productivity and customer  satisfaction, which involves “overseeing, designing, controlling the process of production and redesigning business  operations in the production of goods and/or services.” (Stolperia, 2012)  Operations management functions varies depending upon the industry. In case of the manufacturing industry,  OM includes designing a process to produce the product, proper maintenance of machine and equipment, procurement  of raw materials as well as training and analysis of human resources whereas OM in service industry deals with  customer service dictated by customer requirements and specifications.  Operations Management takes part in  multitudinous decision and ac tivities that give rise to product design and conveyance issues. The design and  management of operations unequivocally affect how much resources are utilized or consumed in producing goods or  services, large portions of these choices can be unreasonable. C onsequently, Operations Management is a necessity  of an organization in managing their cost and improve performance.  This paper talks about the evolution of Operations Management from an organizational  perspective, covering the methodologies and practices  used in different i ndustries as they shift from  1. A ",my.csun.edu,"California State University, Northridge",United States,34.2407,-118.53
35,"FORECASTING TECHNOLOGY OBSOLESCENCE: ASSESSING THEEXISTING LITERATURE, A SYSTEMATIC REVIEW",@swri.org,"Technology Forecasting Obsolescence, Systematic Literature Review ","The purpose of this paper is:  to provide a systematic review of the existing literature on the topic area of forecasting  technology obsolescence and to  provide guidelines and recommendations for future research.  All business and  government organizations that can be affected by technological change inevitably engage in forecasting for the  primary reason of making i nformed decisions.  Technology f orecasting is the systematic attempt to anticipate and  understand the potential direction, rate, characteristics, and effects of technological change, based on assumptions  about the external world.  Forecasting gives probabilistic information on what is believed will happen based on current  assumptions, providing decision makers with insights on what the future might look like to make informed decisions.   An organization's withdrawal from a t echnology segment area is often difficult (typically due to sunk cost bias and  general lack of information) and often occurs too late; resulting in financial losses and missed opportunities.  The  ability to predict when a technology sector has reached maturity has high financial implication (e.g. when to exit from  a technology sector and when resources should be transitioned from one technology sector to another.)  A systematic  review of technology forecasting and applicability to predict the maturity and o bsolescence of a technology segment  in its life cycle is explored .  Guidelines for future research into forecasting the maturity and obsolescence of a  technology sector in its life cycle are presented.       Keywords  Technology Forecasting Obsolescence, Systematic Literature Review    Introduction  William Shakespeare wrote, “If you can look into the seeds of time, and say which grain will grow  and which will  not, speak then unto me.”  No one can prophesize the future with certainty, but by understanding the likely and  potential outcomes of the future, an organization can improve their chances of maximizing gain and reducing losses   (Morlidge, 2010) .  This paper ventures to start the examination process to analy ze if technology forecasting  improvement can be attained by looking both at the emerging and declining stages of the technology life cycle  of  technology sectors.  To accomplish the above goal, a systematic literature review of this topic area was explored, and  recommendations for future research into fo recasting the maturity and obsolescence of a technology i n its life cycle  are presented herein.       Systematic Review  The analyses conducted followed the systematic review process for management research which enables researcher(s)  to document literature r eviews in stepwise and organized manner, reducing errors and bias .  A systematic literature  review can lead to identification, appraisal, and summarization of a research topic in question (Tranfield, 2003) .  A  systematic literature review attempts to identify, appraise and synthesize all the empirical evidence that meets pre- specified eligibility criteria to answer a given research question  or provide insight into a topic area  (Higgins JPT,  2011; Tranfield, 2003).  An adapted Tranfield’s systematic review steps, Exhibit 1, was followed in this paper.         ",swri.org,,,46.3144754,11.0480288
36,ARE ENGINEERS’ LEADERSHIP ATTITUDES AND EXPERIENCESDIFFERENT THAN OTHER STUDENTS?,@montana.edu,"Leadership development, engineering identity, engineering leadership, undergraduate education  ","Only through successful collaborations from multi-disciplinary teams will society be able to solve our most complex  engineering challenges. In order to be successful, these collaborations require effective technical leadership, a role  that engineers can an d should fill. However, most engineering students complete their undergraduate degrees  underprepared to begin assuming a leadership role. One reason for this lack of preparation is a conflict between the  development of an engineering identity and a leadership identity. This work explores this conflict using data from a  national data set of college student leadership experiences compiled by the National Survey of Student Engagement.  The data was used to explore the difference between engineering majors and others with regard to their leadership  experiences, perceptions of leadership, and leadership development activities. Initial results indicate significant  differences between engineering students, other STEM majors and non-STEM majors in their perceptions about how  their leadership experiences complement their education and support their future career goals .     Keywords  Leadership development, engineering identity, engineering leadership, undergraduate education     Introduction  Engineers enter college with some of the highest measures of academic potential (Betz & Hackett, 1983; Wang, 2013)  and are some of the highest performing college students (Brint, Cantwell, & Saxena, 2012) . Given these indicators,  one might expect that a high proportion of engineering stud ents would go on lead all types of organizations later in  their career.  Yet, outside of technical industries, only a small number of leaders of major companies or U.S. political  leaders have a background in engineering (Joint Committee On Printing Of The United States, 2016; Stuart, 2006).   Perhaps of equal importance to this lack of engineers in formal leadership roles is the fact that engineers often find  leadership distasteful (Rottmann, Sacks, & Reeve, 2015). If we are to solve the increasingly complex challenges facing  our society and realize the full potential of the increasing numbers of engineers being called for by politicians and  industry (National Academy of Engineering, 2013; The White House, 2014), engineering educators must develop and  deploy more effective ways to prepare engineering students to assume leadership roles in greater numbers. A key first  step in this process may be getting engineering students to see themselves as leaders.   In order to effectively enact this change, engineering educators must first understand how leadership currently  fits into the education of engineering students. This begins with the recognition that the formation of engineers is, at  its core, an identity development process (Johri, Olds, & O’Connor, 2014; Meyers,  2009). However, the place of  leadership within this development process is little understood as most approaches to understanding engineering  leadership are grounded in perspectives that privilege the development of leadership skills or dispositions rather  than  how engineers integrate leadership into their sense of self -concept. The overall project seeks to address this gap  through a sequential mixed-methods study of the process of engineering leadership identity development. Our aim is  to develop a grounde d theory of the process of developing an engineering leadership identity as an aspect of  engineering students’ professional formation. This paper presents initial findings from the quantitative phase of the  project. These findings demonstrate differences i n perceptions of gains from leadership experiences between  engineering undergraduates and their peers.     Development of an Engineering Leadership Identity  In order to better understand how engineering students might develop an engineering leadership identi ty within the  context of completing their undergraduate degree, we must first understand the individual components hypothesized ",montana.edu,Montana State University - Bozeman,United States,45.6638859,-111.07928704602077
37,THE RISE OF COMPLEXITY DUE TO STAKEHOLDERS STRUCTUREALONG THE LIFECYCLE IN PROJECT MANAGEMENTORGANIZATIONS,@uqo.ca,"Complexity, market lifecycle, project delivery structures, effectiveness and efficiency focus, market dynamics. ","Much of complexity is hidden in structures of organizations, and the market fo rces significant adjustments to these  structures during the dynamics of interactions as the market lifecycle unfolds.   Market customer based profiles drive  strategic choices, which in turn, exercise pressures on the alignment of organizations and their all iances or special  delivery subsystems, such as projects .  Early market strategies seek the right positioning and are effectiveness  focused, and forgive mistakes and inefficiencies, whereas late market strategies search for alignment with the  looming final cost leadership strategy by relentlessly concentrating on efficiency.   Firms progress from many  strategic choices to just one, and live the rest of their market lives under the inexorable dictates of efficiency, unless  the market is rejuvenated by some disruptive intrusion.  Both effectiveness and efficiency have their organization  structure counterparts that best respond to these market signals.   This paper will examine the rise of complexity due  to stakeholders’ structures in projects and the implications  for the type of results delivered for host firms by the  process.     Keywords  Complexity, market lifecycle, project delivery structures, effectiveness and efficiency focus, market dynamics.     Introduction  Existing research sorts  complexity into three catego ries: decision -making complexity, structural complexity and  behavioral complexity (Calinescu et al, 2001). The authors have published several articles dealing with structural  complexity, arising from complicated connections between an organization’s  compo nents and traced the evolution  of this complexity profile for both the market and the its constituent firms along with the  firm’s accompanying  alliances (K oplyay and Mitchell, 2014ab; 2015ab). Firstly, we present s ome remarks about complexity and  nonlinearity. The essence of the research is captured by exhibit 1, market and firm complexity along the lifecycle.  Nonlinearity arises from network effects of these connections and this nonlinearity tends to follow the  complexity profile, as complexity is ironed out from the market by the linearization of external alliances, ranging  from early market ecosystems to late stage value chai ns nonlinearity progressively becomes a linear dynamic for  market efficiency reasons (Koplyay et al, 2015ab).       ",uqo.ca,Université du Québec en Outaouais,Canada,45.42226325,-75.73909824426678
38,ORGANIZATIONAL PROBLEM SOLVING IN CONTINUOUS PROCESSIMPROVEMENT,@oregonstate.edu,"Cynefin Framework, Jishuken Process, Toyota Production System, Pluralism, systems paradigms, System of Systems ","To sustain and remain competent in a dynamic e nvironment, it is important for organizations to adopt continuous  process improvement strategies. Continuous process improvement programs are  a group activity of establishing,  maintaining, and improving a standard continuously. Just employing tools of continuous process improvement without  understanding the problem context and the nature of relationship s between the participants will not gurantee the  expected results. To achieve desired results in continuous process improvement program, it is important to respond to  problems according to the problem context  while having strong problem solving structure . In some  cases, i t is  important to follow a participative method to obtain consensus among the group members involved in the activity.  The objective of this research is to address these issues by providing a complementarist approach to continuous process  improvement programs by providing a understanding of the problem context and bringing a pluralist approach to this  activity. This research provides an i nference of Cynefin decision model to Jishuken process, which can provide  flexibility to Jishuken process to solve problems which lie in different problem contexts . This inference offers an  adaptable approach towards regulating a goal seeking systems archt ype having unitary relationship amo ng  participants. Further, the study also introduces pluralism among participant relationships  and measures to address  them. The research outcome is expected to assist managers, systems practitioners and organizational leaders in  flexibily use Jishuken in different problem context.    Keywords  Cynefin Framework, Jishuken Process, Toyota Production System, Pluralism, systems paradigms, System of Systems  Methodology, Soft Systems Approach    Introduction  To remain competitive in the 21st century, organizations seek different tactics to ensure they can adapt to ever their  changing environment. One of the most prominent strategies is to establish contin uous improvement programs, often  in the shape of Lean and/or six sigma initiatives. One of the cornerstones of continuous process improvement programs  is problem solving, which serves as the basis of identifying waste or sources of variation, and more importantly  generating a solution that will satisfy the bottom line of the organization. Examples of these tools include Jidoka,  Kaizen, and Jishuken, which can be very successful if used in the right context and for the right purpose. In this  research, we define context as the degree of difficulty in identifying cause-and-effect relationships in a given problem;  we define purpose as the intent and/or need to maintain or improve an existing standard or to establish a new standard  in a participative approach. The outcome is a complementary (Midgley, 2000) conceptual model to assist engineering  managers to better align problem solving tools with the problem context and purpose of solution by providing a critical  systems thinking approach which acknowledges pluralistic relationship between participants within the current  Jishuken process. To il lustrate this complementary approach, Jishuken, Cynefin and Soft Systems Approaches to  management are selected.    Jishuken Context and Purpose Analysis  There have been several attempts to explain Jishuken in the past (Montabon, 1997; Liker & Meier, 2006; Marksberry,  Badurdeen, Gregory & Kreafle, 2010) but, most of them described Jishuken as a management lead kaizen blitz model,  developed for scenarios where instant action and solutions are essential. Marksberry et.al. (2010) saw the higher  potential for Jish uken and how it can be used as a continuous problem solving as well for establishing a culture of ",oregonstate.edu,Oregon State University,United States,44.56305595,-123.28392337694638
39,INFERENTIAL EVIDENCE FOR COMPLEXITY MIGRATION FROMMARKETS TO FIRMS DURING THE LIFECYCLE,@uqo.ca,"Lifecycle, Market Complexity, Market Ecosystems and Value Chains, Market Structure/Dynamics. ","Markets evolve very quickly and companies form, grow, and then oftentimes fail in quick succession .  The  complexity of interactions change throughout the market and the firm’s evolution, as companies navigate within their  markets, manage their internal staffing and product development, and handle external funding imperatives.    The inability or unwillingness to address complexity at any of the various life cycle stages, a firm could be  forced into rapid decline and ultimately fail. C omplexity is a collection of interacting objects: human, technological,  financial, or management issues; and these factors  change along the high tech lifecycle as well.  Complexity cannot  be completely managed, but it can be often reasonably contained; this paper will provide inferential evidence for  complexity migration from markets to firms, and the authors will examine fac tors that influence the nature of  complexity in markets at various stages in the firm and market life cycle and discuss the boundary layers and tipping  points that change the complexity landscape.   The concept appears to be paramount because the literature on complex markets indicates that decisions can  only be made on the margin when the future is made uncertain by high level of uncertainty due to complexity.  And  the firm will have to readjust its behavior without guidance from strategic plans and corpora te vision, in some  circumstances without the benefit of a stabilizing feedback generated through corporate learning under these  circumstances of extreme decision pressures.      Keywords  Lifecycle, Market Complexity, Market Ecosystems and Value Chains, Market Structure/Dynamics.    Introduction  Complexity as a concept is widely used to analyze the manufacturing complexity. Calinescu et al (2001) classified  complexity into three categories: decision-making complexity, structural complexity and behavioral complex ity.  In  complexity measurement, a state is perceived as a description of the target (order), the resources, a recipe, and  constraints (Meijer, 2002). It is common in all studies on complexity to find systems with multiple elements adapting  or reacting to the pattern these elements create, helping us understand  phenomenon such as market instability   (Arthur, 1999; Morgan, 2006).  In this paper, the complexity evolution is viewed from the perspective of market/firm lifecycle concept as  argued by the authors in previous papers; complexity drifts into early phases market through the introduction of new  firms.  The white hole  [where firms are fed into the market]  starts the process and then as market looks attractive  during tornado [tornado refers to action to exp and out of that first niche  market, the tornado that results when the ",uqo.ca,Université du Québec en Outaouais,Canada,45.42226325,-75.73909824426678
40,A MODEL BASED SYSTEMS ENGINEERING FRAMEWORK FORPEACEBUILDING,@drexel.edu,"Peacebuilding, systems engineering, model based engineering ","Peacekeepers have been utilizing systems approaches as a means o f conflict analysis and peacebuilding wherein the  factors of conflict and their causal effects are identified and mapped. It provides for a more comprehensive  understanding of the conflict and aids in developing more targeted solutions by identifying key drivers. Peacebuilding  missions that employ this approach can benefit from increased effectiveness and efficiency; however, it suffers from  lack of widespread adoption due to its abstract, qualitative nature and lack of structure. In this age of intractable   conflict, many of which are termed wicked problems, a more rigorous analysis is necessary to avoid unintended  consequences and make better use of limited peacebuilding resources. A systems engineering based framework is  proposed here to provide for a more  rigorous analysis, which  includes measurable, tangible elements to quantify  outcomes, factors and relationships, leading to better decision making and efforts that are more effective. The  framework utilizes the existing qualitative systems mapping methodo logy and extends it to a model based approach  of the systems engineering process spanning the requirements analysis of the conflict through the peacekeeping, life  cycle phase. Techniques such as predictive modeling, game theory, analysis of alternatives and optimization can then  be employed to arrive at solutions that ensure a higher probability of success.     Keywords  Peacebuilding, systems engineering, model based engineering    Introduction  A simple internet search on  peacebuilding organizations yields a staggering number of entities ranging from very  small-scale, single mission focused operations to large -scale efforts. One familiar large -scale organization is the  United Nations (UN ), which, as of March 2017, is operating 16 missions, mainly in Asia an d Africa and involving  1,577 UN volunteers, over 14,000 civilians and 96,000 uniformed personnel. (Information, 2017). The cost to operate  the UN and similar missions is extensive as well  with the UN’s 2016-2017 fiscal year budget slated at $7.87 billion  (Nations, 2016). Smaller scale efforts range from local grassroots organizations to bigger domestic and internationa l  missions, but the primary function of all of them is to supply various forms of services and products to areas in need  of peacebuilding interventions.  The type of activities that occur on these peacebuilding missions range from conflict assessment and conflict  management, to post -conflict stabilization, reconstruction and education. They can include tasks  like education,  negotiation, resource building and management and economic and governmental rebuilding with the end goal of  building or maintaining peace in an era of conflict or post-conflict. The complexity of these conflict situations cannot  be understated; the political, social, economic and environmental factors that each conflict situation presents is  extraordinary and unique.  A single peacebuilding  mission often commences  with one end goal in mind such as  affordable, clean water or increasing school attendance rates, typically without considering the other factors that its   mission affects. For example, a mission to increase attendance in school can influence the economic situation of  families that rely on the labor of their chi ldren for agricultural purposes. Then, one must consider the multiple, often  independent peacebuilding missions operating in the same conflict zone, with obviously all good intentions of  reinforcing each other. However, without an understanding of the causalities that exist between factors, efforts can be  duplicated, negated, or at worst, have opposite effects.  ",drexel.edu,Drexel University,United States,39.9569305,-75.18992654517834
41,IMPACT EVALUATION OF MINING PROJECT: A CONGOLESE GOLDMINE CASE STUDY,@banro.com,"Mining Projects, Impact Evaluation, Ore Throughput, Project Success, Gold Mine. ","Mining projects are capital intensive and practically irreversible endeavours with long, but often limited economic  duration. Twangiza Mining (TM) is the one of the most advanced gold mining projects in the Democratic Republic of  Congo (DRC). TM, a subsidiary of the Canadian  company Banro Corporation,  launched a project in 2012 to address  the production hurdles and challenges that prevented the company’s process plant from achieving the design target of  1.3 Millions Tonnes/annum (MT/pa). The Twangiza Mining Optimizing and Expansion Project (TMO EP) aimed not  only to address the processing plant challenges but also to expand the plant to process 1.7 Mtpa.   The purpose of this research is to evaluate the impact of TMO EP on the processing plant production and  economic key indicators from the commissioning of the processing plant to December 2015.   This case study uses  documentation review and the direct observation of the researcher as research methods in order to achieve the aims of  this paper. The research finds that the process plant ore throughput has significantly increased to achieve 1,714 MT/pa.  This paper also fi nds that the moisture content of the ore has been reduced even though the plant recovery is still  struggling to improve. Moreover, the processing plant economic indicators analyzed, namely the cost per tonne milled  and the cash cost per ounce,  are both showing a positive trend.   Although these results are satisfactory, the research  recommends to sustain the momentum gained wit h the implempentation of the TMO EP. Sustainability  recommendations are made based on international best practices.     Keywords  Mining Projects, Impact Evaluation, Ore Throughput, Project Success, Gold Mine.    Introduction and Problem Statement   The development of mining projects requires intensive  capital investments with long but limited economic durations   (Savolainen, 2016). The economical viability of mining projects depends typically on the uncertain development of  world market prices. The investments in mining are very significant placing and their success depends on the type of  uncertainty that surrounds them.   Projects in the field of mining are principally made of new projects, change to an existing or expansion of  active mining projects (Gałaś & Gałaś, 2016) .The first type of projects in the mining industry revolves around eight  phases: exploration, development, active mining, disposal of overburden and waste rock, ore extraction, beneficiation,  tailings disposal and finally the site reclamation and closure phase  (Elaw, 2010). The second type of mining project  addresses the shortcoming of the existing mine processes. The last type, expansion of a mine, addresses the need to  increase or expand the performance of an existing mine project.   These last two types of mining projects that address the challenges encountered during the mining project  lifecycle are the foundation of this research paper. The researcher’s interest is to assess the impact of these last types  of mining projects on the production and economic indicators of a gold mine project developed in the DRC.    TM background  TM gold process plant was initially designed to process oxides ore at a nominal throughput of 1.3 Mtpa.  This mining  company is located in the Eastern part of the Democratic Republic of Congo (DRC).  The commissioning of this gold  plant started on the 19th of September 2011. With this TM newly designed plant, no major problem were noted during  the cold commissioning. TM process flowsheet incorporated a mineral sizer for the primary crushing of oxide run-of- mine. A wet scrubbing of the crushed ore followed to remove fine clays. The oversized ore at the discharge of the  scrubber screen feeds the secondary and tertiary crushing using cone crushers to nominally - 10 mm. ",banro.com,,,46.3144754,11.0480288
42,SME INNOVATION: A CASE STUDY,@temple.edu,"Innovation, small and medium enterprise, management of innovation ","A case of organizational innovation is examined where a successful medium -sized manufacturing firm is faced with  the need to increase the development and launch of new products. The case demonstrates that organizational  innovation at an SME depends upon developing internal capabilities to proactively manage the innovation process  and the ability to leverage architectural innovation approaches to offset the greater size of rival firms.   A literature review identifies the theoretical framework and key concepts. A presented case illustrates these  key concepts. Emerging concepts are identified through case incidents  The literature suggests that innovation can be valuable to SMEs by enabling them to serve niche markets  with innovative pro ducts. The management of SMEs are  presented with the dilemma that value is best achieved by  internal processes as opposed t o external collaborations yet the lack of internal capabilities is noted in the literature  as a significant barrier to SME innovation  The extant literature leads us to expect SMEs to struggle with innovation due to an inability to manage the  process unless they rely on a deep-niche strategy. However, a case is examined where an SME with a limited history  of innovation embarks on a successful strategy of innovation. The internal barriers to innovation are overcome with  a modest investment in internal resources. A reliance on a deep -niche strategy of avoiding conflict with larger rivals  is obviated by applying architectural innovation to gain a competitive advantage.     Keywords  Innovation, small and medium enterprise, management of innovation    Introduction  Engineering management practitioners may be faced with the challenge of managing the process of developing and  introducing innovative new products and services to increase the competitiveness of their firms.  Given the large  number of small and medium enterpri ses (SMEs) it is likely that an engineering management practitioner will be  faced with this challenge for one of these smaller firms.  The abundant literature on innovation has been developed  from the study of mostly large firms and must be applied cautiou sly to SMEs.  The literature specifically addressing  innovation in SME s identifies the barriers that these firms face but guidance to the engineering management  practitioner to overcome these challenges is sparse.  This paper makes use of the case study me thod of investigating  new theory to examine potential solutions to the challenges of innovation in SMEs.  The new theory emerging from  this paper provides practicing engineering managers with guidance to help manage this challenge.     Literature Review  Much of the research into innovation has focused on larger firms, including the concepts of ambidextrous  management (Tushman, Anderson, and O’Reilly, 1997), core rigidities (Leonard ‐Barton, 1992), and streams of  innovation (Tushman et al, 1997) .  However small and medium enterprises, referred to as SMEs, are an important  part of the overall economy that may require different innovation management approaches than larger firms.  The  first challenge is to define an SME.  The United States Government defines an SME as a firm with fewer than 500  employees.  This is quite a large range and it is not reasonable to assume that management approaches that work  with a five -person firm will work with a 500 -person firm.  If we assume that SMEs must be at least a 100 -person  firm to have the resources to innovate and the complexity to require specific management approaches, then this  would represent over 82,000 firms in the U.S. according to the U.S. census data of 2010.   In addition to the sheer number of SMEs they also make a significant contribution to the total innovative  output of the economy.  The small and medium firms spent 24% of all the R&D spending in 2005 (Van de Vrande,  De Jong, Vanhaverbeke, and De Rochemont, 2009) a significant increase from 4% in 1981 in accordance with the ",temple.edu,Temple University,United States,39.981188,-75.15628280757346
43,MODELING EFFECTIVE DEPLOYMENT OF AIRBORNE FULFILMENTCENTERS,@buffalo.edu,"Airborne Fulfillment Centers, Logistics, Modeling. ","The United States Patent and Trademark Office recently approved  for a patent for an Airborne Fulfilment Center  (AFC) of Amazon. An AFC is an airship that will fly at high altitudes and deliver packages to customers on the ground  through Unmanned Aerial Vehicles (UAV). The AFC will be deployed  near events or large gatherings areas, such as  sporting events and stadiums, which are characterized  by high customer demand for items stored onboard. The AFC  can be used as well for advertising through billboards. Shuttles will be used to replenish the AFC’s inventory with  goods from ground fulfillment centers and provide it with supplies and fuel. The AFC should be deployed in a manner  that maximizes its proximity to large gatherings and potential customers, maximizes its billboards exposure to  customers for advertising purposes, and minimizes the distance that shuttles will cut to replenish the AFC wit h  inventory and other supplies. We use a dynamic programming modeling approach to support the decision-making the  process of AFC’s deployment to achieve the objectives mentioned above.    Keywords  Airborne Fulfillment Centers, Logistics, Modeling.    Introduction  A patent by Berg, Isaacs, and Blodgett (2016) that was recently awarded to Amazon through the United States Patent  and Trademark Office (USPTO) introduces a flying distribution center called an Airborne Fulfillment Center or AFC.  An AFC is an airship or a blimp that is designed to fly at an altitude of 45,000 feet and used to deliver items to  customers using Unmanned Aerial Vehicles (UAVs), commonly known as drones. A smaller airship or a shuttle will  be used to replenish the AFC with items, UAVs, fuel, etc. Exhibit 1 from the Amazon patent shows a schematic of the  main components of the AFC system.  The current concept is to have the AFC carry lightweight items that can be delivered  via UAVs to nearby  ground customers located at distances less t han the maximum allowable flying distance of the UAV enforced by the  UAV’s battery life.   Parcel last-mile delivery using UAVs has gained momentum in the recent years with more companies, such  as Amazon, Google, and UPS, conducting experiments to test the feasibility of the use of UAVs in last-mile delivery  (Murray & Chu, 2015). However, full-scale implementation of parcel delivery using UAVs is still facing technological  and regulatory difficulties. One major technological constraint is the limited flight time, and accordingly distance, of  the UAV. For example, Amazon’s delivery service using UAVs, commonly known as Amazon Prime Air, has drones  that can fly and deliver packages in 30 minutes (Reisinger, 2016). On the other hand, in countries like the United   States, parcel delivery using drones has not yet been approved by the Federal Aviation Agency (FAA) due to safety  concerns (Mirzaee & Awwad, 2017).  The AFCs are envisioned to fly over crowded locations with high customer demands of a small product mix  of items, such as sporting events, in which items like snacks, drinks, or sports souvenirs are ordered by the customers  and delivered to them in a few minutes. However, AFCs can be made to fly at lower altitudes to be used for advertising  proposes as well (Molina, 2016) . The use of aircraft  or blimps for advertising purposes is not a new idea, in fact, a  company like Goodyear has a fleet of blimps that are used  for advertising in areas congested with people. Although ",buffalo.edu,State University of New York at Buffalo,United States,43.00188805,-78.78521350495271
44,SUSTAINABLE SOLID WASTE MANAGEMENT SYSTEMS IN SUBURBANLOCATIONS,@starmail.co.za,"Solid waste, waste management, separation at source, community awareness ","Solid waste generation has proven to have a significant, if not critical environmental impact, on the economy and  human health. It is crucial to plan very carefully the handling and effective management of solid waste. This study  is conducted in the suburban area of Soweto, Johannesburg. Formal  (structured questionnaires)  and informal  interviews and discussion s with some of the residen ts as well as  municipal solid waste management employees  are carried out, and results analysed  in order to  evaluate the level of community awareness, perceptions,  constraints and concerns regarding municipal waste management. The current level of participation, although not  adequate, is useful for future planning and more meaningful participation of the public in solid waste management  of the City of Johannesburg Municipality. Results indicate that historically, a significant amount of unsorted solid  waste in Naledi has always gone to the landfill. Source separation of household waste is not legally binding, it  currently only relies on the attitude and willingness of a household  to reduce waste or sort waste at  the source.  Generally, waste generated in most households are disposed as a mix waste in one plastic bag, before taken to the  roadside for weekly collection by Pikitup. However, some households try to separate plastics, ti ns and bottles;  and a private recycler comes and collects that separated waste for selling  to reprocessing companies . Also, the   relationship between the municipality and the community can be vastly enhanced in an effort to find common  ground to work together.      Keywords:   Solid waste, waste management, separation at source, community awareness    Introduction   Human beings’ lives depend on a healthy e nvironment to carry out day -to-day activities. Earth being a  closed  space makes it difficult, if not impossible for human s to detox all solid waste. Therefore, it remains everyone’s  responsibility to manage and maintain the environment for the current and future generations . Due to an ever- increasing global population and ever-increasing waste  creat ion, the manner in which individuals handle waste  needs to change urgently as the first contribution towards resolving looming environmental problems. This  constraint is especially relevant without new spaces becoming available for the elimination of waste,  There are various factors influencing human behaviour and consumption, and how waste generation occurs, these  include socio-economic and educational factors. Waste volume increases in tonnes every year due to urbanisation.  Unfortunately, poor waste managem ent, partially caused by  urban authorities not having been fully prepared to  deal with the huge amount of waste , is exasperated by limited disposable budgets for such tasks and shrinking  access to refuse dumps, where solid waste generation already exceeds available facilities or resources to deal with  the solid waste caused by urbanisation (Mukisa, 2009).   Various authors (Harrison Market Research, 2005; Mukisa, 2009) agree that limited community participation  / engagement in solid waste management is one o f several major issues. This study seeks to explore community  engagement in solid waste management , particularly in Naledi Township. The  level of community  awareness  about solid waste management, the attitude towards solid waste and what can be done by the public and authorities  to perceive waste as an income to others, need to be established. Awareness and education could play an important  role in the success of implemented initiatives to reduce, reuse and recycle waste. However, in order to establish a  suitable waste management programme and an effective communication platform , the City need s to understand  the socio-economic impact factors of the selected area.  A key component of engineering management is to manage products from the initial stage until the disposal phase.  It is of major significance that the used products are disposed of appropriately without causing any harm to the   environment. It is impossible to address the subject of logistics in solid waste management, without understanding  the environment between the customer, producer and the supplier. Both the producer and the supplier might clearly  envision the final stage of particular products (disposal), but this could leave out the role of the customer.         ",starmail.co.za,,,46.3144754,11.0480288
45,SME TURNAROUND STRATEGY: A CASE STUDY,@temple.edu,"Turnaround, strategy, retrenchment, recovery, small and medium enterprises, engineer -to-order ","A case is examined where a small engineered -to-order firm faces the need for a turnaround from prolonged poor  financial performance. The case demonstrates that both retrenchment and recovery are applicable to the turnaround  of a small and medium enterprise, or SME.  A literature review identifies the theoretical framework and key concepts. A presented case illustrates these  key concepts. Emerging concepts are identified through case incidents  The literature presents a model of business turnaround as a strategy of retrenchment followed by recovery.  However, the literature focused on SME turnaro und strategies presents the practicing engineering manager with a  confusing array of recommendations: retrenchment only, or recovery only, or holistic changes to structures and  practices, or even a focus on policies, procedures, and rules. This confusion is  compounded by the dearth of research  into engineered-to-order firms where the only conclusion seems to be that engineered -to-order firms are somehow   different. A case is examined where an SME is successfully turned around by an application of both retrenc hment  and recovery strategies. This leads to the emergent construct that retrenchment and recovery applies to both SMEs  and engineered-to-order firms.  The extant literature does not lead us to necessarily expect a successful turnaround of an SME by the  application of a retrenchment and recovery strategy. However, the outcome of this case is that retrenchment and  recovery can be extended to SME turnarounds. This unpredicted outcome helps bring resolution to the debate  between retrenchment versus recovery in the SME turnaround literature and extends the literature to engineered-to- order firms.    Keywords  Turnaround, strategy, retrenchment, recovery, small and medium enterprises, engineer -to-order    Introduction  One of the most daunting challenges to be faced by engineering management pra ctitioners is the need to turnaround   an organization that has suffered a decline in revenues and profitability.  The literature on turnarounds is not helpful  in guiding the engineering manager through this dilemma, particularly if  the engineering manager is leading a small  and medium enterprise or an engineered -to-order firm.  This paper makes use of the case study method of  investigating new theory to examine the effect of both retrenchment and recovery on a small and medium enter prise  that requires a turnaround due to an erosion of financial performance.  The new theory emerging from this paper  provides practicing engineering managers with a new tool to manage such situations and then extends the potential  applications to include engineer-to-order firms.    Literature review  A turnaround is often described as a management response to significant financial distress. Sudarsanam and Lai  (2001) further define financial distress as the risk of potential bankruptcy.  Leading such a turnaround is a significant  challenge to engineering management practitioners that requires the maximum support from scholars of engineering  management.  This review of the extant literature seeks to establish what guidance scholars have provided for the  leaders of small and medium sized firms and engineer-to-order firms that require a turnaround.    When faced with a strategic question, engineering managers will often turn to the seminal work of Porter  (1979) to examine their situation through the lens of the gene ric strategies of cost leadership, differentiation, and  focus. However, the Porter model assumes that the firm is operating  in a normal environment and not in a situation  of financial distress that requires a turnaround (Pretorius, 2008). In a turnaround s ituation “it is not enough to choose ",temple.edu,Temple University,United States,39.981188,-75.15628280757346
46,A IPD TEAM’S DYNAMIC CAPABILITIES AND THEIR IMPACT ONTEAM COLLABORATION SATISFACTION,@163.com,"Integrated Project Delivery, Dynamic Capability, Team Capabilities ","Integrated Project Delivery (IPD), as a new type of delivery approach, has become more and more popular in recent  years and various organizations are expressing interest in its benefits to the AEC industry. In IPD, project participants  come together as an integrated team, with the common goal. While a team can only gain advantage and achieve  superior collaboration satisfaction when it has the right capabilities. However, limited research has systematically  studied the capabilities of IPD team from the perspectives of Dynamic Capability Theory. This paper aims to develop  the capability model of IPD team and explore the influence of each capability on team collaboration satisfaction based  on the literature, interview and questionnaire survey. Results indicate that dynamic capabilities of IPD team are  classified as four components, which are capability of resource absorption, capability of resource integration,  capability of decision optimization and capability of trust -based communication, and that dynamic capabilities  have  strong positive influence on team collaboration satisfaction.    Keywords  Integrated Project Delivery, Dynamic Capability, Team Capabilities    Introduction  Integrated Project Delivery (IPD), as a new type of delivery approach, has become more and more popular in  engineering field in recent years. This delivery method makes use of a collaborative approach of combining the  incentives and risks with goals of the  team to improve project performance. IPD abides by the principle of relational  contracting and focuses on the implementation of the organization’s goal by using the advantages and capabilities of  designers, contractors and owner. In order to illustrate the benefit of IPD, Kent et al. use empirical study to investigate  and the results show that “the most commonly observed benefits are fewer change orders (70.3%), cost savings  (70.3%), and shorter schedule (69.4%)”, also the survey of American UT Austin Univ ersity indicated that early  participating and collaboration could bring effective improvement (Kent, 2010).   In IPD, project participants come together as an integrated team, with the common goal (AIA, 2007).  Therefore, we can treat the IPD team as an organization. An organization can only gain advantage and achieve superior  collaboration satisfaction when it has the right capabilities (Smallwood  & Panowyk, 2005). Capabilities represent the  ability of the organization to integrate  efficiently a number of r esources to engage in productive activity and attain a  certain objective (Amit &  Schoemaker, 1993). With the trend toward the integration of all project parties, dynamic  capability appears to be critical for the team to achieve project success. Teece et al. (2015) initially defined a dynamic  capability as “the firm's ability to integrate, build, and reconfigure internal and external competencies to address  rapidly changing environments”. The increasing complexity and dynamics of construction projects have led to a  number of researches on dynamics, such as product and process dynamics (Gil et al. 2005 ), contract dynamics  (Rahman &  Kumaraswamy 2008), and relation dynamics among construction activity components (Blacud et al.  2009). However, limited papers study the advantages of IPD team from this perspective. Therefore, it is necessary to  make clear what the IPD team’s dynamic capabilities are and their impact on team collaboration satisfaction.   Wang and Ahmed (2007) have identified three main components of d ynamic capabilities, which are  correlated but conceptually distinct: absorptive capabilities, innovative capabilities and adaptive capabilities. Besides, ",163.com,,,46.3144754,11.0480288
47,THE EVALUATION OF PROJECT SUCCESS AND FAILURE IN ANELECTRICITY DISTRIBUTION ENVIRONMENT,@uj.ac.za,"Energy in Africa, Project optimization, Electrical energy. ","South Africa’s power utility distribution division executes numerous projects every financial year. The utility utilises  project-management processes to execute these pr ojects. Numerous projects in the organisation  are found to have  succeeded; while various other projects appear to have barriers. Projects are also delayed at the execution phase of  the project lifecycle . Delayed projects have caused  the irregular expenditure of approved budget s. The objective of  the research is to critically review and understand what leads to the utility distribution projects’ successes and  failures. Based on the clear correlation found between the literature’s findings and questionnaire’s  results, the  summarized project success factors at the distribution division are found to be, management support, proper  planning, scope management, competency of the project manager , effective communication, and contractor  competence.    Keywords  Energy in Africa, Project optimization, Electrical energy.    Introduction  South Africa has one key electricity supplier.  The utility produces about 95% of the electricity used in South Africa;  and supplies 45% of the electricity used in different countries in Africa (Eskom, 2015). The SA utility is strategically  divided into three divisions or line functions so as t o achieve the provision of electri city and operate the business,   namely: Generation, Transmission, and Distribution. The mandate of the distribution divis ion as stated by the utility  “is to operate network assets and to provide reliable electricity by building, operating and maintaining the se assets;  while also acting in the national interest by actively partnering with the wider industry in resolving distr ibution- industrial issues and enhancing stakeholder relations” (Eskom, 2012). The distribution network is maintained and  operates optimally when projects are initiated and executed successfully. Projects at distribution level are executed  by the Project-Management Office (PMO). The PMO follows the utility’s developed distribution project life -cycle  process.  Distribution projects are planned, designed and executed by project engineers and the project management  office. Projects are often delayed; and thus, i mpact the expected delivery of supply to the customer. Several projects  in distributions are delayed, while still at the execution stage.  Due to project delays , a review of the capital  expenditure (Capex) indicated inconsistencies, as from 2012 through to 2015. Project execution delays have resulted  in under expenditure on annual budgets.  Management pressures have resulted in a worsening of the budget impacts.  A focus on capital costs is thus required; as these costs are key considerations in annual tariff-price adjustments. The  utility average price adjustments have been above the C onsumer Price Index (CPI) , since 2007. The average  adjustments and CPI are reported as presented in Exhibit 1.    Exhibit 1. Average Price Adjustment and CPI.    Year 2010/2011 2011/2012 2012/2013 2013/2014 2014/2015  Average Price Adjustment 24.8% 25.8% 16% 8% 8%  CPI 5.4% 4.5% 5.2% 6% 6%   ",uj.ac.za,University of Johannesburg,South Africa,-26.18493745,27.99979246435022
48,M,Missing,,,Missing,,,46.3144754,11.0480288
49,APPLICATION OF AGILE METHODOLOGY TOELECTROMECHANICAL DESIGN: A CASE STUDY,@temple.edu,"Agile methodologies, stage gate, electromechanical design ","The case of an electromechanical design project is examined where speed -to-market is critical. The case  demonstrates that software design methods such as agile design can be applied to the design of complex  electromechanical products.  A literature review identifies the theoretical framework and key concepts. The presented case illustrates  these key concepts. Emergent concepts are identified through case incidents.  The literature suggests that complex electromechanical design is best pursued by stage- gate or similar  methodologies. The literature further suggests that software development can  be improved by abandoning the stages  and gates approach in favor of an iterative agile methodology. Engineering managers are not encouraged to apply  agile methodologies to the design of complex electromechanical devices and thus these design efforts do no t benefit  from the attendant cycle time reduction.  A case is examined where schedule pressure and the availability of high -powered simulation tools with  hardware-in-the-loop capability results in the improvisation of an approach approximating what is now r eferred to as  agile design. The construct emerges of a complex electromechanical design facilitated by high -powered simulation  tools and methodologies analogous to software agile design.  The extant literature argues that a successful electromechanical desi gn should have followed a stages and  gates methodology. However, the outcome of the case project argues that agile methodologies applied to  electromechanical design produce exceptional results. This unanticipated outcome suggest s that engineering  managers should closely track the development of advanced simulation tools to determine when the application of  an agile-like design methodologies will yield a competitive advantage for their firms.     Keywords  Agile methodologies, stage gate, electromechanical design    Introduction  Engineering management practitioners are often faced with managing the design of complex electromechanical  products where rigorous performance must be delivered under challenging schedule and budget constraints.  The  literature on design methodologies leads the engineering manager to conclude that a phased approach such as stage- gate is the best alternative.  This paper makes use of the case study method of investigating new theory to examine  the potential role of agile methodologies in the design of complex electromechanical products.  The new theory  emerging from this paper provides practicing engineering managers with options for managing such situations.     Literature review  The common model for the development and design of electromechani cal devices evolved from t he Cooper and  Kleinschmidt (1986) study of industrial new product development that Cooper (1988) subsequently developed into  the ubiquitous stage -gate model.  The stage- gate model consists of incrementally investing in an idea thr ough a  series of increasingly more detailed design stages while being subjected at the end of each stage to  an increasingly  rigorous gate review where the decision is made to either precede to the next phase or to terminate the project.  This  concept has been widely accepted and is the foundation of the formal process es recommended by practitioners such  as the United States Department of Defense (DODI 5000.02) and the National Society of Professional Engineers  (NSPE 1990).   Despite the wide acceptance, this  model it is not without its critics.  The process management activities  inherent in the stage -gate model were found by Benner and Tushman (2002) to be biased toward the production of ",temple.edu,Temple University,United States,39.981188,-75.15628280757346
50,MISSION ENGINEERING AND ANALYSIS: INNOVATIONSIN THE MILITARY DECISION MAKING PROCESS,@nps.edu,"Mission Engineering, Military Decision Making Process, Systems Analysis. ","We propose mission engineering and analysis to examine and develop viable solutions for complex issues.  Systems  engineering addresses technological and managerial challenges in the design and development of physical and virtual  systems.  The military decisi on making process is a recognized  method to develop a mission plan.  The structure of  mission engineering and analysis establishes the military planning process as its backbone, while systems engineering  techniques serve as the internal controls and mechanisms.  Scenario methodologies, modeling and simulation,  hierarchical and value- focused thinking are systems engineering tools that shape the system of interest .  This paper  explains our ideas for creating a robust framework for tackling multidimensional problems.  Mission engineering and  analysis offers a holistic view of a system’s development as part of a larger system.  It begins with the combat mission  that the system would support and ends with the system’s integration in the operational  unit that woul d apply it to  achieve the mission.  The process treats the system acquisition process as a sub-system. Previous methods have seen  the operational mission as a start point.  W e designate the mission and mission plan,  which may include weapon  system development, as the complete  system of interest.   In doing so, we seek to deliver more robust and capable  military and non-military systems.  A notional implementation of mission engineering and analysis to assist fledgling  countries conceptualize and develop solutions for border security issues captures the ideas presented in the paper .    Keywords  Mission Engineering, Military Decision Making Process, Systems Analysis.    Introduction  The rapid growth of technology, globalization, emergent challenges in the politico -military and socio -economic  dimensions demand improved, systematic, and interdisciplinary decision making processes  (Brown 2003).  Decision  making has evolved throughout human history, solving problems that range  from the simplistic to the extremely  complex.  Making the “right” choice in the current environment requires  a hybrid methodology that can adapt to the  depth and scope of many multidimensional problems.  Integration of the interdisciplinary framework for decision  making in systems engineering (SE) with the military decision making process (MDMP) provides a holistic approach  to analysis and development of viable solutions to complex issues.  Both disciplines offer a set of knowledge, methods,  and techniques to explore problems as they pertain to military and non -military as well as engineering and non - engineering problem domains.  Poor decisions have historically resulted in severe waste of resources, loss of lives,  and long term catastrophic outcomes.  The risks of poor decisions are even more pr ominent in today’s complex  environment, where former Soviet countries are committed to building, enhancing, and sustaining their defense  capabilities, policies, and institutions in the post-independence era.    Assisting Emerging Nations Build Credible Defense Structures  In the late 1980s, the political, social, and economic environment in the Soviet Union was decidedly unstable. Many  Soviet republics were ready to proclaim sovereignty and start building a sustainable path towards their independent  future. With the eventual downfall of the Soviet Union, former Soviet republics were left to autonomously build their  own national defense. Each newly independent state had to individually devise means to establish national armed ",nps.edu,Naval Postgraduate School,United States,,-121.87327056526772
51,STRATEGIC PERFORMANCE MEASUREMENT FOR DEFENSEORGANIZATIONS: A PRELIMINARY FRAMEWORK,@hotmail.com,"Performance Measurement, Defense, Military, Assessment approac h, Thematic Analysis, Performance ","Many public organizations, including defense organizations, are experiencing the need to demonstrate performance  improvement to meet expectations of  increasingly diverse and complex stakeholders. Several Armed Forces have  therefore introduced performance measurement systems to support their top -level decision -making and reporting  processes. However, significant factors hinder the design, imp lementation, and use of such systems in defense  organizations. An important challenge identified by NATO nations pertains to the use of traditional frameworks  such as the Balanced  Scorecard or its derivatives for public sector organizations. For many military leaders, such  frameworks lack face validity as they do  not conceptualize critical defense information in a meaningful overarching  structure that reflects the decision patterns of strategic defense decision -makers. Therefore, there is a need to design  a framework that better reflects the priorities of defense departments. Following an initial literature review,  qualitative data pertaining to eight NATO nations was collected through semi -structured questionnaires and the  analysis of strategic -level docume nts. Whereas a six -phase thematic analysis of the data is ongoing, this paper  reports on a preliminary framework resulting from the first three phases. This framework consists of themes   structured along the means -ways-ends perspectives, which resembles the input-process-output logic model but also  subscribes to strategic defense planning terminology. Mapping of the strategic objectives  resulted in a visual  representation of the causal link between strategic themes. This facilitates the communication of the strategy that  connects key performance areas to the various defense stakeholders. Finally, the framework can be an important  assessment tool to orient existing and future initiatives.    Keywords  Performance Measurement, Defense, Military, Assessment approac h, Thematic Analysis, Performance  Measurement Framework, Strategy Map    Introduction  Various organizations, including defense organizations , are facing several challenges , such as doing more with less  resources, demonstrating added value to customers and stakeholders , and managing the changing expectations of an  increasingly diverse workforce (Van Aken, Van Goubergen, & Letens, 2003). As the pressure to improve the  performance of military organizations intensifies, many Armed Forces have introduced  performance management  systems to support top- level decision -makers (NATO, 2017). As a result, the need to build Performance ",hotmail.com,,,46.3144754,11.0480288
52,RISK ASSESSMENT OF OIL AND NATURAL GAS DRILLING PROCESSBY EMPLOYING FUZZY SETS AND ANALYTICAL HIERARCHYPROCESS (AHP),@odu.edu,"Fuzzy Analytical Hierarchy Process, Risk Factors, Fuzzy Risk Assessment, Loss of Circulation ","Risk evaluation of oil and natural gas drilling process is a challenging task, due to high uncertainty and  ambiguity in the available data, as well as the complexity of technical processes. A  systematic approach is required  to handle both quantitative and qualitative data. Lack of data for calculating the failure rate of components is a  common obstacle in the drilling industry. A proposed model us ing Fuzzy Risk Assessment (FRA) and  AHP is  presented for determining and prioritizing the aggregate risk for the scenario of Loss Of Circulation (LOC) . A Fuzzy  Analytical Hierarchy Process (FAHP) methodology is designed to deal with an alternative selection and justification   problem by integrating the concept of fuzzy set theory and AHP. Risk Factors (RFs) in a hierarchical framework are  expressed as fuzzy numbers  which is a combination of the likelihood of a failure event and the associated failure  consequence. AHP is used to estimate weights required for grouping non-commensurate risk sources. Probability and  the severity of risk factors are expressed by multiple levels, qualitative scaling scheme using linguistic variables  which are calculated through fuzzy numbers to reflect the subjective nature of risk definition. The risk mapping of  risk factors on the fuzzy scale can help to figure out the dependency of each risk factor to the risk levels. By  employing this model the critical risk factors in LOC are identified. As a result, the research can provide theoretical  and practical contributions to drilling process safety and environmental protection.    Keywords  Fuzzy Analytical Hierarchy Process, Risk Factors, Fuzzy Risk Assessment, Loss of Circulation    Introduction  Work-related accidents increase even further as  countries and organizations are challenged by rapid  advancements  in technology, changing nature of accidents, hazards and risks, changing societies views of accidents, introduction of  new forms of regulations, and increasing levels of complexity and coup ling (Pillay, 2015) . Increased complexity  makes it difficult for the designers to consider all the potential system states or for the operators to handle all normal  and abnormal situations and disturbances safely and effectively  (Leveson, 2011) . Such complexity requires a  systemic management of implemented engineering programs to ensure that the programs are sustained and  continuous improvements in the form of learnings are captured and incorporated into existing practices (Haight,  2013). When a risk becomes a problem it leads to a system’s malfunction and acts such as a disturbance affecting the  normal function behavior of a system (Carr & Tah, 2001). Based on report provided by Bevere et. al (2017), in total,  there were 327 disaster events in 2016, of which 191 were natural catastrophes and 136 were man -made. Globally,  approximately 11000 people lost their lives or went missing in disasters.    Incidents in drilling processes may cause frequent damage, fatality and may produce severe environmental pollution.  These can bring the cost to property and reputation for the industry. Thus, risk man agement is necessary to improve  the performance and secure the success of the drilling projects (Liu, Borthwick, Lan, & Zeng, 2013). LOC appeared  since the early history of drilling and overtime attention increases as the operators start to dig deeper (Sanders,  Williamson, Ivan, & Powell, 2003) . The main purpose of this study is to  purpose a methodology to evaluate and  prioritize the risks of LOC in oil and gas drilling processes.    ",odu.edu,Old Dominion University,United States,36.8862699,-76.30972478839735
53,BUSINESS PROCESS QUATIFICATION: A HOLISTIC APPROACH,@gmail.com,"Business process optimization, Business variables, Simulation toolset, Multinationals. ","Business optimization is a fundamental driver to multinational entities specifically geared towards global delivery.  Multinationals are considered business process centric entities with core business activities captured through  business processes.  Optimization of delivery via business process optimiz ation is fundamental but the variables  affecting the execution of business processes are not fully understood. Testing variable impacts and significant on an  actual multinational could harvest significant predictive knowledge on potential business impact.   The research defines multinational processes, reviews international literature and benchmarks all  significant variables from automation, change, skills, business capacity, and business escalations together with a   statistically defined set of critical variables. The resea rch extends into defining a model framework to test impacts of  these critical variables on multinational processes. A key consideration is to ensure the processes modelled  are  comprehensive and represent all key functional areas of the business.  The research delivers the model framework, exp erimental protocol and a thin slice development of the solution with  basic testing of variables . The key  value-add of the resear ch included simulation of change and impact to  the  business.    Keywords  Business process optimization, Business variables, Simulation toolset, Multinationals.    Introduction/Background Context  Exploring measures directed towards optimizing business processes has become a prevalent research domain. Large  multinationals execute enterprise functions via business processes. Thus, business process optimization is essential  for corporate sustainability. Comprehensive literature search presents a challenge in effectively evaluating and  optimizing b usiness processes relative to corporate predictability due to change. Limitations exist in identifying  together with quantifying true variables impacting the execution of corporate functioning.  Corporate sustainability  refers to the efficient optimization of enterprise set of operations . This business paradigm entails the application of  skills, knowledge, techniques together with tool  sets in executing enterprise operations, services , and products.   Business sustainability is a means to achieve an organizati on’s vision and mission through the application of  corporate sustainable practices. Corporate sustainability, a strategic and continuous improvement imperative is the  way to assess an enterprise current operation. This research adopts a simulation toolset in developing a framework  for corporate susta inability via business models. A  business model  is a conceptual tool comprising sets of  components aligned with distinct relationships which allows for expression of a business lo gic relative to a business  unit. These toolsets are available for business process optimization activities presenting elements explaining the  functions of a corporate.  Business processes described as essential constituents  of multinationals  is defined as a collaboration of  enterprise operations (Bradford & Gregory, 2015 & Paradiso & Cruickshank, 2007). Business processes add value to  corporate entities, by  transforming process inputs into outputs.  This research presents a business model case for  effectively quantifying effects of certain business variables relative to business change. Key relevance of the research  is the adoption of an enhanced holistic approach and analytical hierarchy process in mitigating the limitations of  previous publications relative to quantifying business processes. Proposed model is based on local, regional or global  domains of multinationals. A framework integrating several Information Technology (IT) systems is designed to  collaborate the business functions in large multinationals. These automation systems include but not limited to  Enterprise Resource Planning (ERP), Manufacturing Execution System (MES) and Plant Control (PC). ",gmail.com,,,46.3144754,11.0480288
54,AN UPDATED APPROACH FOR DEPICTING SWOT FACTORS ANDSTRATEGIC ACTIONS,@fiu.edu,"SWOT, Strategic Planning ","Typical SWOT analysis consists of creation of lists for strengths, weaknesses, opportunities and threats.  Visualizing  relationships between the SWOT categories can be difficult and when performed is typically related to two  dimensions, internal influences (strengths and weaknesses) versus external influences (opportunities and threats).   Generally, the classical technique used relates the proposed strategies or actions within the two dimensional (four  block) relationship framework.  Often a strategy to address an opportunity or threat will be influenced by both  strengths and weaknesses of the organization, thus resulting in duplication within the blocks.  The four block  approach also does not maintain related actions in a logical grouping.  This paper proposes a mechanism for showing  relationships between the SWOT categories as well as proposed strategic actions without duplication and while  maintaining logical groupings.  The context for development and application of the mechanism was planning for the  future of a university program.  However, the technique has potential application beyond academics for presenting an  integrated SWOT analysis.    Keywords  SWOT, Strategic Planning    Introduction  A SWOT analysis was required as a part of a strategic planning effort for an academic program at a major university.   In an effort to “correctly” perform the analysis, a review of relevant literature was undertaken and an attempt was  made to employ techniques discussed to relate the strength/weakness /opportuitites/threats factors to identified  strategic actions.  Limitations found in employing the techniques prompted development of a new framework.     Background  SWOT analysis is a technique often used by organizations to assess the organizations Streng ths, Weaknesses,  Opportunities and Threats.  This assessment is ideally performed as a part of a more comprehensive strategic  planning initiative.  There appears to be no definitive evidence of the origins of SWOT but the basic concepts of identifying the  Strengths, Weaknesses, Opportunities and Threats as a precursor to strategic planning are thought to have originated  in the 1950’s by academics at Harvard Business School (Panagiotou 2003).  An expansion of the technique was offered by with the TOWS Matrix i n a seminal paper by Weihrich  (Weihrich 1982).  Weihrich’s TOWS matrix offered a “conceptual framework for analyzing the threats (T), and  opportunities (O) in the external environment and assessing the organization’s weaknesses (W)s and strengths (S).   This oft cited paper proposed the use of a matrix where strategies were identified as related to the internal and  external factors.  For example, in the matrix at the intersection of strengths and opportunities (SO), actions were  identified where a strength c ould be used to take advantage of an opportunity.  Or with a “WT” strategy, actions  would aim at mitigating both weaknesses and threats.  While there were other aspects of the paper, this integrative  framework appears to be the lasting contribution of his work.  Since its introduction, the SWOT technique has found wide spread use in businesses as evidenced in the  substantial number of SWOT application papers published (Ghazinoory, Abdi & Azadegan -Mehr, 2011).  In a ",fiu.edu,Florida International University,United States,25.7553898,-80.3762832779774
55,A RISK-BASED CRITICAL CHAIN BUFFER MANAGEMENTMETHODOLOGY,@wne.edu,"Project Management, Project Scheduling, Critical Chain, Buffer Management  ","In the broadest perspective, project success comes in two phases: planning and executing. In the planning phase, it’s  the job of a project manager (PM) to build a schedule, level resources (time/people), size and insert buffers to  protect the project from uncertainty, and then adjust the schedule so there is equilibrium amongst all factors. In the  execution phase, it’s the PM’s job to monitor the project charter and implement corrective action as necessary.  Critical Chain Project Management (CCPM) was presented by Goldratt as a methodology for PM’s to regain control  of projects by eliminating frequent cost and time overruns. Since being presented, roughly 30% of all Critical Chain  related research has focused on improving the methodology and 50% of those improving studies have focused on  buffer sizing. This paper assumes that buffer sizing is based on a multitude of project attributes including the risk  associated with each task. This research will present a new methodology for buffer management allowing the PM to  oversee the project with more clarity  and less effort. Currently, a Critical Chain  PM tracks the project using a fever  chart that has three zones and two linearly increasing (fixed -slope) threshold lines to suggest when corrective action  is required. This fever chart assumes that risk is proportional across the duration of a project which is a flawed  notion. The newly proposed buffer management methodology will utilize task-risk information to depict a more  accurate project status and allow the project manager to make better decisions regarding corrective action.     Keywords  Project Management, Project Scheduling, Critical Chain, Buffer Management     Introduction  The world as we know it is changing at an unprecedented pace due to the continuing evolution of technology and  many other fields of study, there is competition amongst countries, businesses, departments, and even individuals to  develop the next revolutionary idea. Whether it is a country or a corporation, the stakes are high to produce  successful projects that can lead to increased market share, increased revenue, or even an improved reputation  within the associated sector. Despite the importan ce of successful projects, many researchers have highlighted  statistical data that show projects failing at an alarming rate; 56% of projects finish late, 70% of projects reduce the  original specifications agreed to by the customer and corporation, and 30%  of projects are killed off before  completion (Izmailov, Korneva, & Kozhemiakin, 2016b) . Goldratt (1997) defines a successfu l project as one that  finishes on time, under budget, and meeting the original specifications agreed to by all parties; this is formally  known as the triple constraint. When this topic is put into the context of a government or industrial project, it is th e  citizens or stockholders of that establishment who see the negative impacts such as increased spending and  ultimately budget overruns.   Goldratt proposed a project management methodology based on the theory of constraints (TOC) called  Critical Chain (CC), its purpose was to regain control of projects by introducing critical chain scheduling with buffer  management (CC/BM). The theory behind this project management methodology is to build buffers into the  abbreviated CC schedule to absorb project delays cau sed by activity risks and uncertainties. The main buffer is  called a project buffer and it is placed at the end of the CC schedule to protect the chain of activities that has the  longest overall duration. Chains of activities that are shorter in duration a nd feed into the CC are known as feeding  chains and they are protected from project delays by feeding buffers. Feeding buffers are located at the end of the  feeding chains before they are merged with the CC. Once the project manager builds a robust schedule they must ",wne.edu,Western New England University,United States,42.1125825,-72.51478135708936
56,SYSTEMATIC REVIEW OF SYSTEM DYNAMICS APPLICATIONS INPERFORMANCE MEASUREMENT RESEARCH,@ttu.edu,"Performance Measurement, System Dynamics, Systematic Literature Review, Bibliometric Analysis ","The use of performance measurement (PM) systems has evolved over the years for academic researchers and industry  practitioners which has changed the way systems are designed, implemented, used, and reviewed. PM  systems  highlight the shortcomings of an organization including the processes, people or product that allow for improvements  and contribute to success in the organization. PM system  implementation comes with much complexity and, while  scholarly resear ch suggests that over 50% of PM system  implementations fail, there is little agree ment on how  elements in the system interact over time or why the implementations fail. System dynamics (SD)  modeling is an  approach that can be applied to complex systems and processes such as PM system implementation because it  recognizes the system struc ture, explores and understands the relationships among components, and helps describe  how elements interact. This research uses a systematic literature review methodology for evidence-informed research.  This includes defining and establishing  consistent se arch terms across platforms , and an evidence -based and  systematic review with the goal of collecting and studying existing research through a bibliometric analysis. The aim  of this research is to identify past and current trends in research that applies SD approaches in PM. This paper provides  research trends in applying SD in PM, identifies areas where SD has been used in PM to add value, and sets priorities  for future research work.    Keywords  Performance Measurement, System Dynamics, Systematic Literature Review, Bibliometric Analysis    Introduction  Performance measurement (PM) systems provide the platform for determining the overall productivity of an  organization (de Waal, 2002; Spitzer, 2007)  so that managers can make rational decisions to understand,  adapt,  advance and grow the business . The advancement of research on PM has evolved to support managerial strategies,  practices and activities towards the overall success in an organization. Although there have been significant advances  in PM , increasing industrializ ation, complex organizations and global competition  (Bititci, Garengo, Dörfler, &  Nudurupati, 2012), have led to PM  systems that are constantly faced with disruptive changes (Vaneman & Trianfis,  2001), due to various complexities in the system. SD modeling is an approach that models complex systems to improve  understanding of time delays, behavior and interactions of the system for better organizational performance (Sterman,  2000). In recent times, academic researchers and industry practitioners have combined the use of PM and SD principles  to have a systemic view on how to deal with the complexities of organizations.   This paper presents the initial results of a s ystematic literature review , focused on identifying how SD  approaches and principles have been used in organizational performance measurement. The approach uses a consistent  search strategy across four platforms and studies the evidence using a bibliometric analysis. This analysis will examine  the existing research on developments in PM and SD, trends of use in  different industries, authorship and  methodological rigor. The results are discussed and the conclusions will highlight the areas for future development  and research.     Background  ",ttu.edu,Texas Tech University,United States,33.59375255,-101.89959552302756
57,PRELIMINARY SIMILARITIES OF MILESTONES IN THEATREPRODUCTIONS AND SYSTEMS ENGINEERING,@uah.edu,"Systems engineering, theatre productions, milestones. ","Engineering, the science that focuses on the design and development of systems, spanning from buildings to space  shuttles, is a field considered by most to be filled predominately with numbers, theorems, and strict rules. However,  the human aspect of systems engineering has a major impact on the success of a project.  At its heart, systems  engineering is a cultural activity that involves multidisciplinary teams of engineers having different roles and  responsibilities in the system. The engineering organization  is itself a complex system, sometimes more so than the  product, which has a significant influence on the development through the interactions among its stakeholders. Along  with dealing with these complex interactions, another major issue in systems engineering is how to validate approaches  when the life -cycle of the system from concept to salvage spans decades and a true replication of a specific desig n  process is practically impossible.   The current validation process happens through models, with humans typically  represented by simple heuristics.  The authors propose that surrogates having a short time span, wide availability, and  similar human interactions should be identified in the real world, offering a novel validation approach. The authors  believe that theatre productions, in which similar system and human interactions are found, may be a suitable  surrogate.  In order to determine if this is a sui table surrogate, comparisons must be made.   This paper examines the  relationships and similarities between milestones in systems engineering (e.g. PDR and CDR) and creative checks in  theatre productions (e.g. run throughs and technical rehearsals).      Keywords  Systems engineering, theatre productions, milestones.    Introduction  The discipline of systems engineering, that originated due to compelling  need to understand and coordinate  interactions within large complex systems, is such a broad domain  that it is complicated to define. Hence the many   definitions and labels for this branch of engineering.  Some describe it as a management technology whose main focus  is multidisciplinary interactions in a system (Sage, 2000), while others simplify the task of systems engineers as being  the guide  in complex systems . Large complex  systems have extremely intricate relationships and require extra   attention and guidance  from the systems engineer  (Kossiakoff, Sweet, Seymour, & Biemer, 2011) . Large complex  systems employ all kinds of disciplines and the comm unication between the multidisciplinary teams  (and the  stakeholders) can prove to be quite complex in itself. These complex interactions can result in misunderstandings due  to different backgrounds , personal beliefs, preferences, and biases . Unlike mathematics, where answers are either  wrong or correct, disciplines were human beings are involved are extremely complicated and their interactions can be  hard to capture. This is, nonetheless, the beauty of these kind s of jobs where the human fac tor makes every project  unique. People are unique and they all bring a different set of experiences and creativity to the table. They are the ones  behind every single aspect of an engineering project, they could be classified as the artists of the system.    Large, complex engineered systems  have a recurring problem of  exceeding the original budget and  overrunning the schedule  due to the unpredictability of people and their relationships, miscalculations and  miscommunication, and uncertainties. An example  of a program that ran both over budget and over schedule  is the  James Webb Space Telescope that was delayed 4 years and experienced a cost growth of approximately $3.6 billion   (Chaplain, 2009). This is just one of the many programs that did not meet the scheduled launch date or budget.  It was  observed that 60-82% of projects fail and one of the main causes is miscommunication (Morris, 2008).   Due to the issues prevalent in large complex engineered systems many approaches have been offered to  reduce the concerns.  Such approaches are Agile design (Buckl et al., 2011) (Martin, 2002), Value-Driven Design (P. ",uah.edu,University of Alabama at Huntsville,United States,34.7252,-86.6405
58,ENERGY SANS WATER: MOVING TOWARDS SUSTAINABILITY INTHE NATURAL RESOURCES NEXUS WITH NATURAL GAS,@ttu.edu,"Energy-water nexus, natural resources sustainability, thermoelectric electrical generation ","A 2011 World Economic Forum publication warns that, by 2030, the worldwide demand for water will exceed the  current reliable supply by 40% and as the cost of water increases with h igher demand and a fixed supply  the cost of  goods will increase proportionally.  The present supply of easy -access freshwater is near exhaustion and acquiring   additional supply through processing (desalination, wastewater reclamation, etc.) represents a step increase in cost  that will have broad economic impacts.  West Texas is known for electrical power generation with the cost of producing electricity among the lowest  in the U.S.  With the expectation that water prices will increase and availability will decrease due to over extraction  from the Ogallala aquifer, the economic future of West Texas’ energy generation sector is linked to the future cost  and availability of water.  A study shows that natural gas thermoelectric and gas turbine electrical generation has the potential to  significantly reduce freshwater consumption.  It will be shown that natural gas thermoelectric generation has the lowest  life-cycle water consumption (less than 750 gallons/MWh) of any energy production method except  solar and wind  energy and will therefore experience the lowest water -related cost increase (excluding solar and wind energy).  The  load on thermoelectric plants of all fuel t ypes can be further reduced by installing standby gas generators in strategic  locations to provide flexibility and robustness against droughts, or power grid failures.  An economic analysis of the  cost of thermoelectric and gas turbine generation is presented for a variety of future water costs.    Keywords  Energy-water nexus, natural resources sustainability, thermoelectric electrical generation    Introduction  Energy and water are vital resources and no advancement of mankind can take place without them.  A certain amount  of energy is required to produce useable water, and useable water is required to produce energy.  “Energy sans water”  is a phrase that illustrates the tension between the use of energy and water resources for the creation of other things  and the use of energy and water to acquire more energy and water.  Since water, in particular, is a limited resource, it  becomes extremely important to manage it efficiently so that scarcity does not become a limit to growth.  This article will address some of th e interrelationship elements of energy and water, water scarcity, policy  and environmental concerns, and the anticipated increase of water cost as its supply becomes more constrained.  The  second section introduces the energy-water nexus (EWN) in the specific context of electricity generation and explores  possibilities for more efficient water use in that area.  The future of water costs is also explored although this is an  area ripe for future research as there is very little information available on the topic.  Finally, a discussion focused on  the potential of natural gas to offset the water intensity of electrical generation while creating a backup power source  to enhance the flexibility and robustness of the electric grid is presented.    Overutilization of Water Resources and Water Scarcity  The give-and-take between any two major resources is known as a resource nexus.  Examples can include the water- energy nexus, the water-food nexus, or any combination of water, energy, food, and climate.  A systems engineering  approach to tackling the problems of resource scarcity is critical to avoiding unintended consequences at the  interaction points between resources and building towards a 100% sustainable natural resources value chain.   Resource overuse is already occurring broadly throughout the world.  “In Yemen, parts of India, and northern  China, water tables are falling by more than 1 meter per year. In Mexico, extraction rates in a quarter of the country’s ",ttu.edu,Texas Tech University,United States,33.59375255,-101.89959552302756
59,RELIABILITY ENGINEERING MANAGEMENT IN THEPETROCHEMICAL ENVIRONMENT: THE AIR SEPERATION UNIT,@uj.ac.za,"Reliability, Maintenance, Cold box, Equipment, Strategy, Stability, Critical. ","The key processing unit, the “cold box"", is fundamentally responsible for air extraction and separation in a chemical  plant. The cold box is critical in the Sasol Che mical Industries (SCI) environment, due to the importance of oxygen  in several processes. Due to the criticality of the equipment, it became necessary to streamline the maintenance  process utilized on the cold box.  Irregular and unplanned maintenance can l ead to unforeseen events and may have safety and environmental  implications. The maintenance philosophy that is followed to maintain the equipment is of utmost importance. Sasol  conducts maintenance on their cold box with a black box approach, which makes it difficult for the maintenance  team to predict failures, resulting in significant losses. The study investigates the potential benefits of an alternative  maintenance strategy. The key focus of the research includes an evaluation on the impact of an alternative  maintenance approach has on the reliability and stability of the equipment. The research approach includes a global  literature study providing potential options for improvements. The viability of these options is tested via a  questionnaire conducted with plant personnel. The results of the respondents indicated that proactive maintenance  and all aspects thereof is the key to success for improving the reliability of the cold box. Reliability engineering  management is essential for the stability of the cold box.    Keywords  Reliability, Maintenance, Cold box, Equipment, Strategy, Stability, Critical.    Introduction/Background  Maintenance on the cold box cannot always be conducted as required to enhance productivity in the petrochemical  industry. The cold box is a critical component to the Sasol Coal to Liquid (CTL) petrochemical process. The cold  box is fundamentally responsible for air extraction and separation. Air separation of several gasses is made possible  by the drastic change in temperatures within the vessel. The Sasol oxygen demand is very high and the process  followed to extract oxygen from air is called cryogenic air separation. This process offers a high volume of oxygen at  an extremely high purity (Drioli & Barbieri, 2011). Maintenance on the c old box should comply with a safe reliable  working environment and must be cost effective for competitiveness (Mishra & Pathak, 2012).  The improvement of  reliability engineering on the cold box results in the need for an alternative maintenance strategy to  maintain the cold  box. In technical terms, reliability is defined as “the probability that a product performs its intended function without  failure under specified conditions for a specified period of time” (Yang, 2007).  Maintenance can only be correctly  implemented once an individual understands the meaning and the consequences of their actions. According to  (Telang & Telang, 2010), maintenance can be defined as the process to keep equipment in good condition to perform  its intended function. (Márquez, 2007), agrees with the definition of (Telang & Telang, 2010) and extends the  definition by arguing that maintenance management is the management of all assets owned by a company to  maximize the return on investment on the specific asset. Addressing the method of conducting maintenance on the  cold box is crucial to improve the reliability of the equipment.  There are different maintenance strategies to improve the reliability, maintenance efficiency, and  management on the cold box. Reactive, proactive, and desi gn out maintenance are the traditional strategies  commonly known in the industry (Conradie, 2015). Proactive maintenance is strengthened with risk- based  maintenance, total productive maintenance, and reliability centred maintenance strategies (Vlok, 2012).  Reactive ",uj.ac.za,University of Johannesburg,South Africa,-26.18493745,27.99979246435022
60,DERIVING QUANTITATIVE MEASURES FOR HIGH RELIABILITYORGANIZATIONS,@utsi.edu,"High Reliability Organization, HRO hallmarks, strategic planning framework, performance measurement system. ","The High Reliability Organization (HRO) literature contains numerous observations that the five HRO hallmarks have  not been empirically tested and are difficult to implement directly.  One literature review focused  on HRO in health  care noted there is no evidence that  practitioners have heeded suggestions made in the one article by Dr. Karlene  Roberts that provided guidance for managers in HROs .  This begs the question, why is HRO so easy to understand  but difficult to quantify?  One group of researchers  noted that taking Roberts’ advice may be as simple as applying  standard Industrial Engineering and business tools with a focus on HRO; i.e., understand organizational  culture and  systems, apply tools such as economic analysis , simulation modeling, and performance managem ent and  measurement. This paper argues that quantitative measures for the qualitative  hallmarks of HRO can be developed  that will make organizations better able to implement HRO practices, track performance, and understand whether their  vision to operate as an HRO is achievable.  A framework that translates the qualitative HRO hallmarks into quantitative  actions is desirable.  The HRO Strategic Measurement Framework with notional strategies, objectives, measures,  targets, and initiatives adaptable to any or ganization was developed for operationalized HRO hallmarks, including a  sixth hallmark.    Keywords  High Reliability Organization, HRO hallmarks, strategic planning framework, performance measurement system.    Introduction  How do some organizations consistently operate safely in complex, and hazardous situations; what is their secret?  This question spurred researchers at the University of California-Berkeley in 1984 (Rochlin, 1996). Roberts (1989)  identified high-risk organizations who consistently, over long periods of time, operated without any failures and  disastrous effects on the public and environment and labeled them High Reliability Organizations (HRO).  Later  Roberts and Rousseau (1989) noticed these organizations possess all of the following eight characteristics which  differentiate HROs from other organizations.  1. Hyper complexity  2. Tight coupling   3. Compressed time factors  4. More than one critical outcome that must happen simultaneously  5. Extreme hierarchical differentiation  6. Large numbers of decision makers in complex communication network  7. Degree of accountability that does not exist in most organizations  8. High frequency of immediate feedback about decisions ",utsi.edu,University of Tennessee Space Institute,United States,35.3191,-86.1013
61,BENCHMARKING ESTONIA’S CYBER SECURITY: AN ON-RAMPINGMETHODOLOGY FOR RAPID ADOPTION AND IMPLEMENTATION,@usma.edu,"Cyber defense and security, cyber resiliency, on-ramping adoption and implementation framework ","In April of 2007, Estonia fell victim to  a s eries of distributed denial of s ervice (DDoS) attacks that  crippled its  government websites, email servers, media outlets , and banking system  for nearly a month . Due to t he devastating  effects of the se cyber attacks, Eston ia took great efforts to strengthen  its cyber security protocol s. This research  analyzes the reforms that Estonia has implemented  in its domestic and fore ign policies and attempts to determine if  any of it systemic improvements can help to also bolster cyber security in the United States (US). The findings from  this research are that Estonia’s policy reforms  in cyber security have be en the most significant in areas that the U S  currently lacks. Domestically, Estonia has a cyber education program that significantly highlights awareness of the  risks to its critical cyber infrastructure. Estonia has also p romoted public and private partnerships to jointly analyze,  assess, and de fend itself against future cyber attacks.. In foreign affairs, Estonia has bolstered its relationship with  allied nations in new ways and has synchronize d its foreign policies to imp rove stakeholder engagement on cyber  defense. The critical changes that Estonia has adopted and i mplemented throughout the past decade are what this  research endeavors to recommend for the US to consider  into its defense of the cyber domain.  Furthermore, this  research proposes an on-ramping methodology that helps to frame how an organization can more easiliy integrate new  processes, practices, and procedures that have worked well for others.    Keywords  Cyber defense and security, cyber resiliency, on-ramping adoption and implementation framework    Introduction  After the collapse of the Soviet Union in 1991, the Republic of Estonia’s technological capabilities were virtually non- existent. Beginning in 1992, an economic foundation established under t he new Estonian Prime M inister allowed  businesses to be created  without substantial delay. By 1998 , all Estonian schools had computers equipped in the  classroom for their students. Soon afterwards, I nternet access was considered a critical enabling infrastructure , and  free Wi-Fi spread throughout the country and became the national standard. In 2007, Estonia became the first country  to allow online voting in a general election. Today, Estonia  is a world leader in t echnology and is considered one of  the most wired countries in Europe (Davis, 2007).  On April 30th 2007, pro- Russian hacktivists show cased the devastating impact that cyber  effects can have  on the world . Never before had a n entire nation become rendered completely impotent due to a cyber  attack. As a  result of this unprecedented attack, cyber  warfare was quickly added into the military lexicon. No longer were cyber  attacks merely a nuisance that only banks and e-commerce sites had to contend with; the 2007 Russian cyber attacks  on Estonia showed  to the world just how dangerous and deadly a cyber adversary  can be and exposed just how  vulnerable nations are to attacks in the cyber domain (Herzog, 2011). In spite of the calamity it suffered , Estonia has  demonstrated considerable resili ency after this attack, and the nation  has helped to spur a substantial amount of  significant improvements in cyber defense. In fact, w ithin the span of just o ne decade Estonia has transitioned into  becoming one of the most advanced nations in cyber security and cyber d efense. As cyber attacks directed against  American citizens, campanies, and the government increase, it will prove advantageous to examine the measures that  Estonia has taken following Russia’s cyber attack towards advancing the cyber security posture of the US . By  analyzing and benchmarking the Estonian cyber security strategy after its 2007 cyber attack , this research identifies  ",usma.edu,United States Military Academy,United States,41.3927227,-73.95986305044411
62,TOWARD A FRAMEWORK FOR DEVELOPING COMPUTINGPROFESSIONAL ETHICS: A REVIEW OF LITERATURE,@illinois.edu,"Professional computing ethics, professional development, ethics education ","Engineers are playing important roles in today’s organizations which are oper ating in knowledge economy.  Computing professionals might have a great influence on modern societies due to the prevalen t usage of information  and computer -based technology. Therefore, their ethical development is of great importance. The aim of this  manuscript is to (1) review history, theories, and approaches to ethics in professional development, (2) to provide a  critical evaluation of the current status of knowledge on ethics and ethical education in professional development, and  (3) to introduce a fram ework for ethical education in professional development. Suggestions for future research will  be provided and discussed.    Keywords  Professional computing ethics, professional development, ethics education    Introduction  Experts and professionals produced by higher education have a significant role in shaping the current and future lives  of people and society (Forester & Morrison, 1990). However, due to the narrowly  defined technical education they  receive, as Forester and Morrison (1990) stated, one cannot assume that students majoring in computer “possess a  social conscience or indeed have much awareness of social trends or global issues “(p. vii). Therefore, the inclusion  of ethics education  in professional development curriculum,  in our case  computing professionals, is inevitable. In  response to this necessity, many degree programs in the field of computer engineering have included mandatory  courses on ethics of computing in their curriculum.    Ethics of computing is ubiquitous. From privacy  issues in social media to the fears of artificial intelligence  (AI), influencial individuals such as Bill Gates and Professor Stephen Hawking have publically warned about the  possible threats of AI and computer -based technology (Rawlinson, 2015)  have shown the need for a close attention.  Due to the increase in the use of computer -based technology and its impact on and its integration into the lives of  people in today's societies, ethical considerations of computing are of immense importance (Stahl et al., 2016). The  recent intense debates on the Facebook’s trending news (e.g., Thottam, 2016)  is an example. One can argue that a  great deal of responsibility is on computing professionals who design, develop, implement, and test these systems  (Stahl et al., 2016). Handling ethical dilemmas, for computing professionals, is a challenging task since they work in  a complex and changing environment. At the same time, in today’s societies, more and more responsibilities are  assumed for higher education and organizations regarding the promotion of ethics (Foote & Ruona, 2008).    In next sections, first, we review the background of ethics and ethical education with the focus on computing  professionals. Second, we discuss several relevant theories of ethical development and ethical decision making. Third,  we identify a list of considerations for ethical development of professionals and propose a model for such development  of computing professioals. Finally, we provide suggestions for future research.    Background of Ethics for and Ethical Education of Professionals     Computing Profession, Professional Ethics, and Computing Professional Ethics   Computing profession is defined as “the set of people and institutions who take care of people’s concerns in  information processing, computation, and coordination over networks of computers” (Denning, 2000, p. 35). It  includes a wide range of occupations such as “programmers, hardware designers, software engineers, database ",illinois.edu,University of Illinois Urbana-Champaign,United States,40.102,-88.2272
63,SYSTEMIC SIMILARITIES BETWEEN GROUNDWATERMANAGEMENT AND MONETARY POLICY:  IMPLICATIONS FORSUSTAINABLE GROUNDWATER MANAGEMENT,@ttu.edu,"Sustainability, Systems Analysis, Groundwater Management ","Unsustainable groundwater consumption is a growing global problem. Managing for groundwater sustainability  requires an understanding of complex systems and the interactions of many interrelated parts.   Technical man agers  can use modeling and simulation to test groundwater policies and better understand the system in question.   They  may also choose to apply knowledge about successful policies from similar systems to identify effective management  strategies for groundwater systems.  It is common for managers and policymakers to relate concepts and components  in water systems to those in monetary systems in order to aid in understanding.  However, tr ansferring knowledge  across systems is only viable if the systems are sufficiently similar.  This work  presents a systemic , structural   comparison of groundwater systems and monetary systems  using a combination of logical argument and  systems  analysis to demonstrate that these systems may be sufficiently similar to justify the application of knowledge and  policies fro m monetar y systems to groundwater systems.   A  mental model of groundwater systems is developed  based on the structure of the United States monetary system.  Elements critical to simulation modeling are identified.  Validation tests are used verify the structure of the model . This analysis may help justify the transfer of knowledge  across systems and help technical managers to develop simplified simulation models in order  make better policy  decisions.      Keywords  Sustainability, Systems Analysis, Groundwater Management    Introduction  Groundwater is an important  resource for  modern society.  Unfortunately, the use of this resource has become  unsustainable in many areas due to over -consumption.  Solutions to the problem may lie in management rather than  technology.  Groundwater can be seen as a form of environmental credit to be used to support current consumption  (Hudson & Donovan, 2014) .  Like financial credit, groundwater use can be seen as a way to borrow from future  supply to support current needs.  This research argues that the nature of groundwater as credit is sufficiently similar  to financial credit to justify the examination of monetary policy for solutions to groundwater over -exploitation.  The  systems may be sufficiently similar to be considered isomorphic, or of the same general class.    In economics, monetary policy has been used to control credit creation in an attempt to regulate overall  aggregate demand.  Contracting the supply of credit can curtail economic growth leading to a reduction  in aggregate  demand.  Contracting groundwater credit may result in a similar reduction in groundwater demand .  As such, it may  be valuable to transfer kno wledge about the monetary system, and monetary policy to groundwater systems in order  to make better policy decisions about sustainability.    This research examines the similarities between monetary policy and groundwater policy and concludes that  the two systems may be isomorphic.  Although there is no way to ultimately prove isomorphism, a preponderance of  evidence suggests that the systems may be isomorphic and that the transfer of knowledge between the systems may  be warranted.  Systems analysis techniques are used to evaluate the structural homology between the two systems by  identifying and comparing the components and  systemic structure .  An analysis of the governing mathematical  equations shows significant similarities between the systems.  Finally, an analysis of the behavior of each system  under similar policy changes shows that the systems behave in a similar manner.   ",ttu.edu,Texas Tech University,United States,33.59375255,-101.89959552302756
64,STAKEHOLDER PREFERENCE SOLICITATION WITH A FOCUS ONSURVEYS AND VALUE MODELS,@uah.edu,"Preferences, requirements, small satellite, stakeholders. ","Systems engineering can be described as the observation, communication, representation, and execution of stakeholder  preferences. A stakeholder can be defined as any individual involved with any  decision-making process associated  with the system in question. Stakeholders can range from CEOs, project managers, and design engineers to end-users  and regulatory bodies. The preferences of each of these stakeholders will likely vary.  It is important to capture the  preferences of all the stakeholders in order to enable a well-informed system design process . Multiple methods of  preference elicitation exist currently. One of the easi est and cheapest methods is the use of surveys. The goal of this  paper is to lay the foundational work for the formation of surveys that can be handed out to a multidisciplinary team  of stakeholders that may have varied preferences.  It lays out the first steps of a very detailed study aimed at eliciting  stakeholder preferences. These surveys will be useful for examining the relationships between group and individual  preferences in the future.  A future research plan will also be described that envisions the use of survey analyses to  form value models, comparisons of value models to individual rank orderings, and incorporation of a multi -cultural  aerospace design team.    Keywords  Preferences, requirements, small satellite, stakeholders.    Introduction  The design of systems involves a spectrum of people from conceptualizers and realizers (in terms of design, funding,  regulations, etc.) to users. Each of these stakeholders has different expectations for the system. For example, the  objective of the CEO of the company developing the system may be to maximize the company’s profit; whereas, the  non-shareholding employees at the company may not care about profit. Examples of non-shareholding employee  objectives might be: wanting to get promoted to the managerial level or freedom to make design choices based on  field expertise. Users of the system may care about, for example : cost effectiveness, ease o f use, or aesthetics. The  challenge is capturing the preferences of all stakeholders and translating these preferences into a meaningful, collective  system design. This also begs the question: is there an individual’s preference that dominates t he others that should  be maximized or minimized in a design process ?  This question stems from Arrow’s Impossibility Theorem (Arrow,  1950).  This paper looks at general preference elicitation, with the understanding that future work will explore how  the stakeholders’ preferences currently and should influence each other to result in a design artifact.  Gaps in stakeholder preferences impact the design. Bad or suboptimal designs may be attributed to  incompatible, irrational, ineffectual, or ill- phrased preferences from stakeholders impeding informed  decision- making. Present methods such as user-centered design (UCD)  (Abras, Maloney-Krichmar, & Preece, 2004; Garrett,  2010; Vredenburg, Mao, Smith, & Carey, 2002)  mainly focus on the needs of the consumer, and various methods of  consumer preference solicitation currently exist. However, this paper argues it is necessary to extract the preferences  of all stakeholders. Numerous methods of preference elicitation exist; however, the aim of this study is to use surveys  as a cheaper, faster way of gathering data. The overall objective of the study will be to substantiate that data gathered  from the surveys could be useful in creating effective value model s for the system. A future study will be performed  on the SPORT project team compris ed of approximately 20 members (stakeholders)  who like ly have different  preferences. An existing survey will be modified to gather the necessary data.  SPORT (Scintillation Prediction ",uah.edu,University of Alabama at Huntsville,United States,34.7252,-86.6405
65,REIMAGINING TRADSPACE DEFINITION AND EXPLORATION,@uark.edu,"DoD Acquisition, Engineering Resilient Systems, Analysis of Alternatives, Tradespace, Trade-off Analysis, Set-based ","On many defense programs, performance, cost, and risk analy ses are performed by three separate groups with little  integration.  Many times the tradespace is a finite list of alternatives, sometimes as few as three.  Trade- off analyses  are typically performed in an ad hoc basis using performance and cost data that may or may not be consistent. Risk  analysis is sometimes only qualitative. We propose an approach that uses model based engineering, set-based design,  decision analysis, and Probability Management  to integrate design choices, design options to improve system  resilience, performance models, physics models, cost models, value models, and risk analysis.  The modeling approach  allows design choices to simultaneously impact performance, cost, value, and risk models. This approach provides an  integrated definition and exploration of the design tradespace.      Keywords  DoD Acquisition, Engineering Resilient Systems, Analysis of Alternatives, Tradespace, Trade-off Analysis, Set-based  design, Integrated Performance, Cost, and Risk Analysis    Introduction  The Department of Defense (DoD) uses the systems acquisition framework shown in Exhibit 1.  DoD policy requires  the identification of the need for the new product , the analysis of alternatives , cost analysis  to ensure affordable  alternatives, and risk assessment and reduction prior to commitment of resources  (DoD, 2017) .  The focus of this  paper is on the Analysis of Alternatives (AoAs) in the Pre-Milestone A period up to the beginning of the Preliminary  Design stage (DoD Acquisition Portal, 2017) .   The AoA provides important information on the potential of new  concepts to meet the needs of future users.  This requires assessment of evolving future threats, operational   environments, performance requirements, available technologies, operational concept s, system concepts , and  affordability.   Defense policy provides considerable guidance for analysis of alternatives , cost analysis, and risk  analysis (DoD Acquisition Portal, 2017) .  In addition, defense organizations have been assigned responsibilities to  perform each of these three analyses.   S ome services have developed AoA handbooks to provide guidance on best  practices (OAS, 2013).        ",uark.edu,University of Arkansas - Fayetteville,United States,36.0970389,-94.17033216657404
66,POWER-TO-GAS TO PRODUCE HYDROGEN ENRICHED ANDRENEWABLE NATURAL GAS FOR ENERGY STORAGE IN THESOUTHEASTERN UNITED STATES,Missing,"Power-to-gas, Market Mechanisms, and Hydrogen Generation ","Natural gas is an abundant fuel which offers environmental and efficiency improvements over coal. Although most  natural gas is not renewable, it is possible to generate Renewable Natural Gas (RNG) through the addition of hydrogen  to biogas –  referred to as methanation. Another sustainable use of hydrogen is the creation of hydrogen enriched  natural gas (HENG) a blend of low concentrations of hydrogen in natural gas that emits less greenhouse gasses per  unit of energy. The creation of RNG and HENG can be integrated into a Power -to-Gas energy storage system, which  utilizes renewable electricity to generate hydrogen via electrolysis. Creating natural gas -based energy storage is  particularly effective, as the hydrogen can provide grid management and easier transportation of energy, through  existing natural gas infrastructure. With large natural gas infrastructure in the southeastern United States, there is a  significant amount of potential energy storage available through a Power-to-Gas system. This energy storage could be  used to provide backup power for seasonal variation in energy demand or for turnkey energy production after a natural  disaster. In the follow ing paper, the authors examine  the environmental performance of  an integrated Po wer-to-Gas  system for energy storage.     Keywords  Power-to-gas, Market Mechanisms, and Hydrogen Generation    Introduction  As renewable energy sources are an ever -increasing part of the electrical grid’s generating capacity it has become  difficult for utilities to balance the intermittent supply of energy with demand of electricity. Power -to-Gas is a  technology which can offer energy storage and transformation between intermittent renewable power sources and the  electrical and gas grids. In a Power -to-Gas scheme, hydrogen is generated by electrolyzers or from thermochemical  water splitting and is either sent directly to hydroge n end users, or injected into the natural gas system where it can  provide long term energy storage (Fowler & Mukherjee, 2014). An advantage of a Power-to-Gas system is the ability  to move energy between the thermochemical, electrical and natural gas systems seamlessly. Converting renewable  and surplus electricity to hydrogen through Power-to-Gas optimizes both the natural gas and electricity networks and  increases the capacity and overall efficiency of the electrical system wit hout the cost of new generation facilities. A  Power-to-Gas system can also move energy more effectively over long distances than electricity transmission by wires  (Walker, Mukherjee, Fowler, & Elkamel, 2016). The energy in Power-to-Gas systems, in the form of a mixed gas, can  be sent from one location to another, where the gas can be used to generated electricity or heat by pipeline. With  Power-to-Gas, the natural gas infrastructure can offer the electricity system a large, distributed, energy storage network  that can transport energy from one area of the state , or nation, to another while shifting the time between generation  and end-use from hours to days or months. In Exhibit  1, below, the Power-to-Gas system includes multiple sections:  energy supply, energy conversion, the transmission and storage systems, distribution, conversion and final use.  Note ",Missing,,,46.3144754,11.0480288
67,APPLYING ENGINEERING MANAGEMENT CONCEPTSTO A LEAN PROJECT,@llnl.gov,"Chemical Inventory, Lean, Radio-frequency Identification, Technology, Engineering Management ","This paper presents a case study using engineering management principles and concepts in the implementation of a  lean project at a research and development (R&D) institution. As such, this paper will only present the case study and  will not include a literature review. The project involved improving and optimizing the chemical inventory process  used to track hazardous chemicals used by a large R&D enterprise from purchase and use,  through disposition.   Previous inventory practices consisted of a hands-on process that subjected the workers to various health hazards that  could arise from handling a la rge variety of hazardous chemicals in varying amounts, weights, and container  configurations. The process also created ergonomic -related challenges for the workers as they began to experience  health impacts.  The project involved the implementation of radio-frequency identification (RFID) technology in tracking and  maintaining the chemical inventory consisting of Class 1, Generation 2 Passive RFID tags, Ultra High Frequency  (UHF) capable readers, a tag encoder and printer, and tablet -based inventory software. A thorough understanding of  the existing inventory process aided development of a pilot effort to scope, test, and refine the choice of tags, readers,  and printer prior to deployment.  Tracking performance metrics was used to inform future refinements and   opportunities. Going forward, the expectation is that the use of the RFID technology will improve technician safety,  while significantly increasing inventory efficiency and effectiveness in addressing operational and  regulatory  reporting requirements.    Keywords  Chemical Inventory, Lean, Radio-frequency Identification, Technology, Engineering Management    Introduction  The concept of lean is widely used across the globe by many organizations that strive to  improve efficiency and  quality, and deliver excepti onal products and services to their customers.  Lean strategy implementation can be  challenging; it requires clear objectives, a thorough understanding of work- flow, mitigation of identified risks, and  performance metrics to quantify performance.  Implementation must be flexible , but tailored to achieve the desired  outcomes. Successful implementation of lean strategies incorporates  sound engineering management techniques to  anticipate, evaluate, and address issues early -on during the project.  Effective engineering managers are often at the  forefront of technology development and implementation to ensure success of these projects from inception through  planning and implementation,  as well as long -term sustainability. These managers are generally known  for having  unique skills and abilities to effectively plan, organize, direct,  and control project resources and functions to include  the care and handling of the people aspects of implementing lean in a project or organization.   The task of maintaining chemical inventories for a large R&D enterprise is logistically challenging and time  consuming, with detailed protocols for minimizing negative impacts to research operations, following stringent facility  access and security controls as well as safety procedures and personnel protective requirements.  It involves the manual  handling of hazardous, sometimes highly-hazardous, chemicals weighing grams to 50+ pounds. There is an additional  risk to the worker through ergonomic -related stress resulting from manual and repetitive container handling and  associated body positioning and mechanics such as crouching, reaching, lifting, turning containers , etc., while  scanning chemicals and products that are stored in various configurations and locations.    Because of the physical stress on the body and workers taking time away from work citing ergonomic-related  discomforts, management became concerned for the health of the workers and began soliciting a safer and more ",llnl.gov,,,46.3144754,11.0480288
68,RETURNS INVENTORY: ITS INFLUENCE ON TOTAL PRODUCTIVITYMANAGEMENT AND WORKING CAPITAL MANAGEMENT,@ttu.edu,"Productivity, Working Capital, Product Returns, Cost of Quality. ","With increasing competition and a growing emphasis on customer satisfaction, companies are pursuing policies that  enable them to attract and retain a customer base. One such strategy is to allow customers time to assess a product and  return it if it is not in alignment with their expectations. As beneficial as such a strategy can be  in terms of growing  the customer base, it ca n have potentially adverse effects too, one of which is a growing returns inventory. Any sale  made cannot potentially be considered as such until the time for returns is past. Given inventory is considered to  comprise working capital (WC) by conventional a ccounting standards, returns inventory can be expected to impact  cash conversion cycle (CCC), which is used as the basis for Working Capital Management (WCM). The same holds  true for the theory of Total Productivity Management (TPMgmt), which places WC fro nt and center based on its  ability to influence productivity and profits. This paper explores the effects of returns inventory on both CCC and  productivity with the aim to unearth synergies between TPMgmt and WCM.  In doing so, it explores the common  grounds for both management theories based on the Cost of Quality framework.    Keywords  Productivity, Working Capital, Product Returns, Cost of Quality.    Introduction – The Product Returns Issue  As industries become increasingly customer -centric in order to attain a greater share of the market and retain it, so  have the organizational strategies evolved to attract a new customer base and ensure loyalty. One such strategy that  permits such customer-centrism is allowing the customer to return a prod uct within a pre-defined period of purchase  (Stock, Speh, & Shear, 2006) . Such flexibility allows the customer to assess product quality and its fit to the desired   expectations and return it if it does not meet those expectations.    According to estimates,  the consumer electronics retailers and manufacturers in the US received product  returns to the tune of 16.7 billion USD in 2011, a jump in value of 21% compared to returns in the year 2007 that were  pegged at 13.8 billion USD (Douthit, Flach, & Agarwal, 2 011; Steger, Sprague, & Douthit, 2007) . Best Buy, a huge  consumer electronics retailer, listed its sales returns reserve to be 25 million USD for both 2015 and 2016, both huge  absolute values in terms of opportunity cost (Best Buy, 2016). Product return is now often considered an unavoidable   challenge. Reinforcing this notion, Blanchard (2007) demonstrates that returns reduce profitability by 3.8% on average  for a manufacturer. There is however another stream of thought that product returns, assuming they are here to stay,  may be a blessing in disguise for manufacturers for the opportunity they provide to understand customer expectations  better, thereby raising  the likelihood of a product purcha se (Chu, Gerstner, and Hess, 1998) . Petersen and Kumar  (2009) believe product returns are a great way to build customer loyalty  given customers may purchase more if the y  realize the effort involved in  the returns process is minimal.  In addition, they empir ically show that up to a certain  threshold value, increasing product returns may actually translate into greater customer loyalty in the future. That  proves that there may be an  optimal point for maximizing revenues in the presence of returns and that there are  balancing forces at play.   Given the significant monetary impact of the product returns issue  for both retailers and manufacturers ,  remanufacturing and reverse logistics  can be expected  to provide the opportunity for the next wave in productivity  boost in the US  (Giuntni & Gaudette, 2003) . Given that a perturbation in one part of the supply chain tends  to  systemically travel through it, it can be expected that all manufacturers and suppliers will eventually be affected   potentially wit h a lag . In fact, a breakdown of these values reveals that the total cost of handling returns is  approximately 2-3% of the g ross revenue for retailers and 5 -6% for manufacturers, suggesting the higher stakes for ",ttu.edu,Texas Tech University,United States,33.59375255,-101.89959552302756
69,EVIDENCE NEEDED TO DESTROY AND REPLACE MACHININGCAPABILITY,Missing,"Machine tools, Technology transfer, Computer numeric control ","Machining Capability in its traditional f orm employed several thousand skilled craftsmen called machinists in every  country and was the backbone of industrial development. Development of Computer Numeric Control, CNC, has  taken machining capability to new heights where the traditional machines have become co mparatively very  inefficient. This paper explores the question ‘if a technology management decision to destroy the traditional  machining capability and replace it with CNC what are the evidences that would be needed to support this drastic  decision?’. Background and contemporary analysis revealed that  (a) CNC is essential for a thriving manufacturing  sector (b) s trong traditional manufacturing capability helps to build advanced CNC capability (c) s ome capabilities  would become obsolete during and after the  migration (d) CNC provides an opportunity for traditional machinists to  ascend and (d) existing knowledge -base is a key factor for deciding the steps. Based on the analysis the key  evidences needed for the decision are identified as (a) t ypes of machines in use (b) t ypes of work handled (c)  existing knowledge base  (d) alternative replacements (e) maturity of the alternatives in particular the controller  (f)  ease of migarting out from the alternative and (f) avalability in vocational and higher education establishments.    Keywords  Machine tools, Technology transfer, Computer numeric control    Introduction  Technology Management addresses the technology an organization already has or wishes to have in a three pronged  approach namely  (a) destroy (b) preserve or (c) develop. Destroy,  eliminates certain technological capabilities and  replace with better ones. Preserve believes that those capabilities still have utility. Develop  means developing new  technological capabilities to give the c ountry a competitive leap. Machining Capability in its traditional form  employed and continues to employ several thousand skilled craftsmen called machinists in every country and was  the backbone of industrial development. Development of Computer Numeric C ontrol, CNC, has taken machining  capability to new heights where the traditional machines have become com paratively very inefficient. This raises the  multi-dimensional technology management question ‘whether to destroy the traditional maching and replace i t with  CNC or not to destry’ and it is addressed in this paper.     The Nature of Technology and Function of Technology Management  Technology is the application of scientific knowledge for practical purposes. It is the knowledge embedded in  products and processes, and the knowledge of creating, producing, reproducing, and using these products and  processes. The acquisition of technolo gical capability is not a one -off process but a cumulative one in which  learning is derived from the development and use of  technology. Bennet and Vaidya (2001)  assert that the  accumulation of skills, experiences and technical know -how at the levels of fir ms, industrial sectors and countries  takes time and is essential for the long run development of national competitiveness. The existing knowledge base is  important for developing further knowledge and capabilities , and new products and processes. Therefore  a  structured approach to management of technology is needed. Management of Technology is the linking of  engineering, science, and management disciplines to plan, develop, and implement technological capabilities to  shape and accomplish the strategic and operational objectives of an organization (US National Research  Council1987).  ",Missing,,,46.3144754,11.0480288
70,A FRAMEWORK FOR THE SELECTION OF HEAVY CONSTRUCTIONEQUIPMENT,@uaeu.ac.ae,"Construction Project, Equipment Selection, Equipment Economics, Equipment Productivity.   ","With the high cost of heavy construction equipment, contractors are striving to select the most cost -effective  equipment. The process of selecting a suitable  equipment is a key factor in the success of any construction project.  This decision should account for equipment productivity, capacity, and cost, among other factors such as  environmental and social impacts. However, selecting the most appropriate equipment from the available options is a  difficult and highly challenging task.    This study suggest s selection criteria then propose s a framework for selecting the m ost appropriate  equipment for  construction operations. To achieve this objective, a questionnaire survey was first conducted among leading  contractors in the United Arab Emirates to elicit information pertaining to the selection criteria of equipment. Based  on the findings of the survey, a framework  was structured to help construction contractors select the right equipment  for their operations. The framework  includes five main modules: 1 ) construction operations module; 2) types of  construction equipment module; 3) equipment data module  (i.e., productivity, cost, efficiency, etc.); 4) equip ment  selection criteria module; and 5) selection criteria features and calculations module. As a future extension to this study,  the suggested framework will be used to develop a dynamic system that will allow contractors update the equipment  selection databases in order to include new equipment, update cost data, and add new selection factors. The findings  of this study are expected to guide contractors in making the correct and most economical decisions when selecting  heavy equipment for construction operations and, therefore, keep them competitive locally and internationally.     Keywords  Construction Project, Equipment Selection, Equipment Economics, Equipment Productivity.      Introduction  Construction projects require different types of equipment that have their own level of application. For example, low- rise residential projects may have a low level of equipment usage and, therefore, this type of projects requires simple  and traditional machines like forklifts, backhoes, hauling and hoisting e quipment, material- handling tools, and  pneumatic tools. On the other hand, commercial projects have moderate usage of equipment and machineries while  industrial and heavy construction projects required intense and high utilization of machinery for carrying out mass  excavation, stabilizing, compacting, asphalt paving and finishing, pipelines, railroads and many other special activities  (Waris et al., 2014). The common application of  construction equipment includes earthwork, structural steel works,  concreting, building, lifting and positioning of components (Gransberg et al., 2006; Mahbub, 2012).   Selecting the most suitable equipment for a construction operation is very important and  affects the success  of any project. The decision of selecting the right equipment for a construction operation is a difficult task . It should  account for equipment productivity, capacity, and cost, among other factors such as environmental and social impacts.  Economic, engineering, environmental, and social factors are discussed and addressed later in the paper. The cost of  construction equipment is considered a major financial burden during the construction phase beside other expenditures  (Prasertrungruang a nd Hadikusumo, 2007). P ast research attempts show  that the acquisition of heavy equipment  constitutes 36% of the total proje ct cost (Yeo and Ning, 2006; Jrade and Markiz, 2012; Waris et al., 2014). This  increased level of awareness is considered as posi tive; however, its adoption has significant drawbacks for the  environment and the people working in its vicinity.  The main objective of this study, therefore, is to investigate the main factors that affect the selection of  construction heavy equipment considering the economical and engineering criteria in addition to the environmental ",uaeu.ac.ae,United Arab Emirates University,United Arab Emirates,24.19718435,55.680583440887546
71,PROCUREMENT AND LOGISTICS ANALYSIS FOR A CHEMICALCOMPANY,@stcloudstate.edu,"Logistics, Procurement, Supply Chain, Transporta tion Management, 3PL (Third party logistics), LCL (Lesser than ","This paper focuses on analyzing and providing solutions related to supply chain logistics problems faced by a  chemical company based in Chennai, India. Their operations include manufacturing, importing, and expor ting of  components and chemicals required for water treatment. Sea, rail, and road contribute to 90% of their mode of  transportation and remaining 10% is through air. Imports and exports are carried only through 3PLs. The company  doesn’t own a warehouse an d uses a bonded warehouse in Chennai port for storage of their consignment. The  company experienced challenges with: a) Delays in transshipment  and non traceable shipments; b) Lack of  automation tool to verify import and export documentation work; c) Inability to fulfil orders from overseas suppliers;  and d) High shipment cost for imports and exports. Solutions provided included: a) Recommendation to use charter  services, bringing goods in a single vessel, use of Transportation Management Systems in conjunc tion with  satellite capabilities, and use of other visibility tools such as ‘SeaRates’; b) For documentation problem, automated  software such as ‘ShippingEasy’ should be used and going for Open Credit instead of Letter of Credit; c) Having  safety stock; an d d) Importing/exporting on Cost Insurance and Freight instead of Free On Board. Currently, the  company has started implementing the proposed solutions thereby eliminating their problems one by one.  Keywords  Logistics, Procurement, Supply Chain, Transporta tion Management, 3PL (Third party logistics), LCL (Lesser than  container load).    Introduction  The chemical company is rapidly growing into manufacturing, global outsourcing, networking and distribution of  specialty chemicals for industrial process/waste water and potable water treatment. They are the official distributors  in Asia Pacific regions for many of the leading chemical companies in the world. They import chemicals and other  components from around the globe. The company’s import and export hub is located in Chennai, India. The  company faced 4 major problems during its operations which are described in detail below.    Problem 1: Delays in transshipment and non traceable shipments  Transshipment happens as the freight forwarder routes the shipment to som e other port. Transshipment is happening  even for FCL (Full container load) or LCL (Lesser than container load). Delays due to transshipment  are acceptable  and are un-avoidable as any vessel which is destined to Chennai port doesn’t come directly. But the problem here is,  they are facing a delay of more than 4 weeks (due to multi vessel) for LCL loads, that is if the shipment has to take  28 days, it is taking 60 days. Whereas for FCL there is no problem as the delay period due to transshipment is only 2  days. Due to this, they are not able to track the shipment when they are importing LCL loads for the above said  reason.    Problem 2: Lack of automation tool to verify import and export documentation work  For any import/export, there is a lot of documentation w ork which has to be done properly. Without proper  documentation, there will be a problem in customs clearance. The maximum time the customs will hold the shipment  is 7 days (retention period) after which the company has to pay leverage. So it is necessary to clear the shipment ",stcloudstate.edu,Saint Cloud State University,United States,45.55139,-94.14833
72,M,Missing,,,Missing,,,46.3144754,11.0480288
73,EVALUATION AND VALIDATION OF A MATURITY MODEL INOBSOLESCENCE  MANAGEMENT  FOR  INCREASEDPERFORMANCES,@gmail.com,"Technological obsolescence, Obsolescence management, DMSMS, Maturity model. ","The paper aims to improve and validate a maturity model in obsolescence management. Based on analogous tools in   project management, this tool will allow managers to easily measure their companies’ maturity levels in obsolescence  management, and thus allow  continuous improvement, obsolescence is a major  issue for engineering management,  maintenance and support , especially for systems having long life cycles, such as avionics systems. The major issue  relates to lifecycle mismatchs: these systems are made to last for decades while some of their sub-systems, equipments,  or components have shorter lifecycles . Therefor, long life cycle systems vulnerability and risk exposure to  obsolescence becomes higher with time. The risk impacts not only the final product performance, maintenance , and  readiness, but also the company’s capabilities, its supply chain performances, and its competitiveness. Based on our  experience as well as the current  literature in systems management, obsolescence management activities are diverse   and thus companies are unable to assess their obsolesce nce management systems with regard to  efficiency and  effectiveness. This work uses a robust design research metholodoly  for the validation of a standard maturity model,  with the aim of helping managers enhance their  obsolescence management system s. The model’s evaluation and  validation were performed via case studies and satisfaction surveys, resulting in an improved and validated maturity  model which is presented. The maturity model describes different levels, categories, process areas, generic and specific  goals and practices, all designed to measure a company’s maturity level and then suggest concrete actions to reach a  higher performance maturity level if required to support and promote improvement in obsolescence management  practices.    Keywords  Technological obsolescence, Obsolescence management, DMSMS, Maturity model.    Introduction  Because of the rapid technological growth in all fields especially electronics, companies suffer today from a big issue  called technological obsolescence. With either a high or low production volume, technological obsolescence is  unavoidable. It can be defined  as the loss, or impending loss,  of the manufacturers or suppliers of items or raw  materials (Tomczykowski, 2003). A more realistic working definition of obsolescence was given by  Bartels, Ermel,  Sandborn, and Pecht (2012) , it is when a part (material or technology) that is needed to manufacture or support a  product or a system is not available from existing stock or from the Original Component or Equipement Manufacturer  (OCM or OEM). Parts and components obsolescence also called Diminishing Manufacturing Sources and M aterial  Shortages (DMSMS) has several causes: technological development (Feldman & Sandborn, 2008), the disappearance  from the market of the Original Component Manufacturer (OCM)  or the Original Equipment Manufacturer (OEM)   for different reasons, the disruption of production by the Original Component Manufacturer (OCM) or the O riginal  Equipment Manufacturer (OEM)  and the chemical or physical aging processes in storage that can dest roy parts or  make them useless (Bartels et al., 2012) Of these causes technological development is the most important.  The issue of obsolescence goes beyond aging military systems, considered as the most vulnerable systems to  obsolescence. The problem is increasing dramatically and more and more industries are affected. They are facing a  pace of technological innovation moving faster than product life cycles  (Gravier & Swartz, 2009) and find themselves ",gmail.com,,,46.3144754,11.0480288
74,IDENTIFICATION OF RISK FACTORS AND INFLUENCES ONAERONAUTICAL PRODUCT DEVELOPMENT PERFORMANCE,@gmail.com,"Risk management, product development, performance measurements, continuous integration, big data. ","Organizations are now forced to not only continuously introduce new products, but also to shorten development times,  reduce costs, and improve the variety and quality of their products. In product development process, risk management  is too often poorly use d and set aside from planning tools. Moreover, measurement of its performance is not well  defined and does not allow comparisons with peers  or supports of continuous improvement of the in-placed process.  The research objective is to provide a framework to enhance  risk management performance acr oss aeronautical  product development. It gives risk managers the proper tools to monitor and know where resources and efforts should  be allocated to improve their process. In this paper, we define what risk is in product development, how to represent  it an d how to measure its impact on performance markers. Through surveys across key players in the Canadian  aeronautical industry, the research highlights the various practices and needs in risk management, product  development, and their performance measurement s. Finally, through design science, we propose a methodology,  which defines what risk is in product development and how to measure the performance of its management. As one  of the key processes to limit usual delay and cost overrun in the aeronautical industry, the key contributions of this  research are the establishment of specific characteristics and methods that can serve as reference practices and as a  basis for the future design of a tool to assist in the evaluation of aeronautical development projects .    Keywords  Risk management, product development, performance measurements, continuous integration, big data.    Introduction  Product development process management is far from a new concern in the aeronautical and defense industry. These  companies have studied these issues  for decades. Despite the fact that they remain globally strong and have deep  management expertise in their product development programs , a number of projects are still facing cost overruns,  scheduling delays and quality issues. Althoug h these are sometimes commercial successes, both private and public  clients want these development programs to be well managed, both in terms of the technologies used and the in place  processes.   Last decade, i nformation technology created  many opportuniti es for improvement that were impossible  before. For example, evolu tion in business intelligence support ed by new data analysis techniques and capabilities  have brought tremendous improvements to marketing operations. With data automatically stored since the introduction  of complex integrated management tools  in organizations, product development processes can now  benefit from the  big data  era. Through better integrated and data supported risk management  processes, organizations have  considerable potential to improve their decision-making processes across product development (Tsumoto, 2010).   The l ast risk oriented  audit from PricewaterhouseCoopers (PwC, 2016), conduct ed across 23 industry  segments, highlighted two parallel skills companies need to have in order to succeed in a sustainable way: risk agility  and risk resilience. As a matter of fact, in high end technological developments such as airplanes, the growing system’s  complexity and increasingly stringent certification requirements , tend to lead to increased  costs and to longer   development cycle time. To support the integration of an incredibly fast technologi cal evolution and for historical  organizations to always be a step ahead of  the competition, processes, controls,  tools and management techniques   need to step up and enter into this new technological era.  Design science aims to produce systems that do not yet exist or to modify existing systems in order to obtain  better results for a given problem. By  reinforcing the knowledge of a specific problem, by  developing new methods  of resolution to solve these specific problems by creating new tools (Dresch,  Lacerda and Antunes Jr., 2015), t his ",gmail.com,,,46.3144754,11.0480288
75,THE USE OF COMPOSITE INDICES IN PEFORMANCEMEASUREMENT: A LITERATURE REVIEW,@oregonstate.edu,"composite index, performance measurement, literature, engineering management systems. ","Composite indices have been used to measure performance in various fields for a long time. In the recent years, the  use of composite indices has  grown. Composite indices are used to measure complex multi -faceted variables of  interest. The rationale behind composite indices vary from mere convenience to complex statistical theory. This  research looks at the different composite indices that have been used i n measuring the performance of engineering  and management systems in an effort to categorize the development, use, and strength of these indices. The eventual  question of interest is how effective are composite indices, and how effectively are they being constructed and used  by researchers and practitioners. However, the scope of this paper is a review of recent literature to get an  understanding of the state-of-the-art of indices used in engineering and management systems.  Keywords  composite index, performance measurement, literature, engineering management systems.    Introduction  Composite index is defined as combining two or more variables (indicators, index, or measures) to form a single  indicator. The selection of these variables and the methods used to combine these variables provide for different  approaches to constructing a composite index.  The use of composite index has been shown to be effective in measuring performance in certain fields like  healthcare (Profit, et al., 2014; Profit, et al., 2010) , education (Gnaldi & Ranalli, 2016), environmental sustainability  (das Neves Almeida & Garcia-Sanchez, 2016) and corporate sustainability (Garcia, Cintra, Torres, & Lima, 2016). In  macroeconomic systems, composite indicators are used to compare performance of countries in various aspects of  economy, sustainability, development, and safety (Garcia-Sanchez & das Neves Almeida, 2015) . The reasons for  using a composite index varies based on industry and purpose. Composite indices have the advantage of providing an  easy tool to represent a complex scenario but at the cost of oversimplification (Profit, et al., 2010). This paper is a first  step in finding the answer to the question, “when can organizations use composite index to measure internal  performance?” With that question, the additional question of “how should these indices be constructed and presented?”  must also be answered. As literature showed in this paper, presenting the composite index to intended audience is just  as important as constructing the index.  In this paper, a review of literature is provided to show the method of constructing and presenting a composite  index and the different techniques used  in each step . The different industries in which composite index is used is  identified and the major advantages and disadvantages of using composite indices are discussed.     Literature Review Methodology  Literature for this paper was collected from different online archives such as EBSCO Academic Search Premier,  Compendex, Web of Science, and Google Scholar. Only peer reviewed articles were searched and included in the  study. Composite Index is referred to as composite indicator, composite score, and composite measure based on  preference and field of study. The scope of this literature review is to only understand composite indices in measuring  performance. So , all the different search terms were used along with performance measurement as a search term.   Exhibit 1 shows the different search terms used and the number of results from each search. These search results were  not unique and as such will not add up to the different papers used in this study. The articles from the search were  reviewed for fit with this research and some were discarded. After reading some of the articles, more articles were ",oregonstate.edu,Oregon State University,United States,44.56305595,-123.28392337694638
76,REIMAGINING THE DESIGN OF AN INTRAPRENEURSHIP COURSEFOR EXECUTIVE GRADUATE ENGINEERING MANAGEMENTSTUDENTS,@ucd.ie,"Intrapreneurship, engineering management education, action learning research. ","The design and delivery of a new, semester long corporate entrepreneurship/intrapreneurship course for execut ive  graduate engineering management (MEM) students is analyzed and the findings following two deliveries of the  course are shared . When designing the course, the aim was to create awareness around how to identify  entrepreneurial opportunities within an org anization, the process by which these opportunities can be realized or  commercialized, and the mindset required. The underlying framework for the course design is based on the Stanford  Lean Launchpad programme, supplemented with other approaches such as Design School Thinking and Lean  Startup. The research design for the paper follows an Action Learning Research approach. Faculty observations,  student feedback and student assignments provide the da ta for the analysis. The results show that many students did   not realize they were thinking in a traditional linear manner to solve problems. For growth strategies, they found the  use of frameworks empowering, particularly when trying to frame ideas as part of their ongoing day-to-day roles in  industry. This apparent science behind intrapreneurship significantly shifted perceptions of the subject. For problem  solving strategies, paying attention to customer signals and a willingness to pivot on ideas was found to be valuable.  There was a significant shift in mindset by the end of the course, as initial fear, skepticism and resistance gave way to  chaos, fun and eureka moments.    Keywords  Intrapreneurship, engineering management education, action learning research.    Introduction  Entrepreneurial activity by employees within organisations (corporate entrepreneurship –  CE, sometimes referred to  as intrapreneurship) has been an important research topic for scholars and practitioners since the beginning of the  1980s (Gawke, Gorgievski, & Bakker, 2017). Successful and innovati ve organizations (e.g. IBM, Google, 3M) rely  on CE to refresh their strategy and improve financial performance ( Byrne, Delmar, Fayolle, & Lamine, 2016) .  Through this entrepreneurial activity, employees are able to contribute to performance improvement in t wo ways;  new venture creation and strategic renewal ( Kuratko, Morris, & Covin, 2011).  New venture creation refers to the  creation of business units within an organization. Strategic renewal refers to organizational change through renewal  of the organizatio nal structure, a shift in allocation of resources, and the renewal of services, products and/or  administrative processes (Kuratko, Morris, & Covin, 2011).  Given the potential significant impact of employees’ entrepreneurial activity, organisations, education  institutions and training providers are interested in how they can develop the necessary conditions at the  organizational and in particular at the employee level to encourage this type of initiative. The focus of the research in  this paper is on the rol e of education institutions, in particular, graduate level engineering management programs, in ",ucd.ie,University College Dublin,Ireland,53.3068763,-6.224625093340977
77,COMPARISON OF KNOWLEDGE MANAGEMENT LITERATUREFROM 2002 THOUGH 2016,@emich.edu,"Knowledge Management, Information Management, Data, Wisdom, Tacit, Explicit  ","While sharing knowledge/information between colleagues and contemporaries is not a novel idea, the difference  between information and knowledge, in cont ext to Polanyi’s concepts of tacit knowledge is still not clear. In 2002,  Wilson examined journal literature from 1986 -2002 to investigate these concepts, and argued that although  Knowledge Management(KM) is defined as the process of capturing, distributin g, and effectively using knowledge.  In literature, KM as a term that covers mostly decision support, IT, Databases, information management and other  systems. Firms usually define knowledge as a collection of information gained through on the job training, formal  education, experiences or a combination of these, and use it for their competitive advantage. Although databases and  computers have made collecting and sorting large amounts of data simple, skilled workers still use instinct and  experience to solve complex problems. This paper extends Wilsons’ work by reviewing journal literature from 2000- 2016 to investigate if KM literature is still considered a management fad while keeping its foundations on information  management and management of work practices, or if current literature shows an evolution into Polanyi’s theories on  tacit and explicit knowledge.    Keywords  Knowledge Management, Information Management, Data, Wisdom, Tacit, Explicit     Introduction  In order to remain competitive within a particular market, many firms turn to innovative and new methods of  management (Forbes, 2014); Knowledge Management (KM) is one of the latest strategies used to maintain or develop  a competitive advantage. KM can be tracked back to Frederick Taylor’s principals of Scientific Management , which  sought to maximize efficiency of workers doing manual labor.(Dinnini, 2017) This paper will review the conclusions  by Wilson (2002) from his article “The Nonsense of Knowledge Management”, and review the differences between  knowledge and information. This paper will also review literature from 2002 -2016 and compare the ose results with  Wilson’s findings. We will discuss whether knowledge, as we define it , can actually be managed and the frequency  and importance of  the major knowled ge management dimensions, i.e. information technology and people  in recent  publication trends for the topic of KM . Finally, it will also compare them with Polanyi’s perception that tacit  knowledge exists only in a philosophical sense (Morgan, 2008).    Information vs. Knowledge  The journals and firms studied by Wilson (2002), used the terms ‘information’ and ‘knowledge’ synonymously. These  are very different terms, and seem to cause confusion to readers when researching these topics. To better understand  the concept of KM, we will define both knowledge and information, and how they are related to each other.   According to Wil son (2002), “knowledge is defined as what we know: knowledge involves the mental  processes of comprehension, understanding and learning that go on in the mind and only in the mind, however much  they involve interaction with the world outside the mind, and interaction with other s.” Wilson also states that  information sharing is done by one of several methods: oral, graphic, gestural, or throu gh “body language”. These  messages do not carry knowledge, but they contain information, which a capable mind may then translate into  knowledge. Wilson (2002) goes on to say that the person or group that receives the information will build a different  knowledge base than the person from which the information was received.  According to Merriam -Webster (n.d.),   knowledge is “the fact or condition of knowing something with familiarity gained through experience or association” ",emich.edu,Eastern Michigan University,United States,42.25224625,-83.62456151430587
78,UTILIZING ARTIFICIAL NEURAL NETWORKS TO PREDICTDEMAND FOR WEATHER-SENSITIVE PRODUCTS AT RETAILSTORES,@wayme.edu,"Supply chain, Inventory management, Big Data, Artificial Neural Networks ","One key requirement for effective supply chain management is the quality of its inventory management.  Various  inventory management methods are typically employed for different types of products based on their demand patterns,  product attributes, and supply network. In this paper, our goal is to develop robust demand prediction methods for  weather sensitive products at retail stores. We employ historical datasets from Walmart, whose customers and markets  are often exposed to extreme weather events which can have a huge impact on sales regarding the affected stores and  products. We want to accurately predict the sales of 111 potentially weather -sensitive products around the time of  major weather events at 45 of Walmart’s retail locations in the U.S. Intuitively, we may expect an uptick in the sales  of umbrellas before a big thunderstorm, but it is difficult for replenishment managers to predict the level of inventory  needed to avoid being out -of-stock or overstock during and after that storm. While they rely on a variety of vendor  tools to predict sales around extreme weather events, they mostly employ a time -consuming process that lacks a  systematic measure of effectiveness.    We employ all the methods critical to any analytics project and start with data exploration. Critical features are  extracted from the raw historical dataset for demand forecasting accuracy and robustness. In particular, we employ  Artificial Neural Network for forecasting demand for each product sold around the time of major weather events.  Finally, we evaluate our model to evaluate their accuracy and robustness.    Keywords  Supply chain, Inventory management, Big Data, Artificial Neural Networks    Introduction  Over the past few years Big Data has become the focus of IT innovation in business, science and industry. In general,  Big Data means having the ability to gather, store, explore, and an alyze with velocity, variety, and volume of data.  Analytics refers to the ability to explore insight data by considering many known methods and techniques, such as  statistics, mathematics, econometrics, simulations, and optimizations, to help business organizations and companies  become lean and make a decision based on quick changes in the world. Most companies, industries, and organizations  want to increase their ability to process their data (internal or external) efficiently. Some lean companies such as  Walmart, eBay, Progressive Insurance, and Target have reported the ability to consider Big Data and its benefits; they  store internal data such as transactions, last year’s sales, etc. in their databases automatically (Wang et al, 2016).These  companies are successful in extracting new insights and obtaining new forms of value by considering Big Data analysis  in their operation plans (Sanders, 2016). This literature review discusses previous research on routing and scheduling  logistics as well as the optimization operational network used in inventory and labor scheduling. Recently, other Big  Data analytics applications, such as segmenting suppliers, measuring and mitigating risk, forecasting demand and  informing suppliers have increased especially in the area of in sourcing (Kourentzes et al, 2014). Since a key aspect  of supply chain management is designing and controlling processes, operations and inventory to meet demand, then  forecasting demand by considering Big Data analysis is a huge step to deal wit h variations to decrease shortage or  overproduce.  By increasing the application of Big Data among many companies, choosing the best tools and methods to  analyze them is the key issue to consider. Because of the growth of computing power and the accessibility of data, the  use of Artificial Neural Networks (ANN) for forecasting concepts is now commonly applied (Kourentzes et al, 2014).  ANN is a mathematical model that includes the group of connected artificial neurons, which is like the human neural  network, to compute and store specific information. This method has the ability to investigate and submit the nonlinear ",wayme.edu,Wayne State University,United States,42.3485,-83.0603
79,"ANALYSIS OF MATERIAL FLOW IN A HIGH-MIX,LOW-VOLUME JOB SHOP: A CASE STUDY",@uark.edu,"Continuous Improvement, Modeling and Simulation, Quantitative Methods  ","This article presents a case- study analysis of a high- mix, low -volume government -operated repair and refurbish  operation that operates within a job -shop environment.  A brief literature review of these types of systems and the  techniques used in their analysis are presented.  Then, a multi -criteria methodology is discussed that can be used to  analyze product usage and prod uct flow within the facility.  In addition, ordering and resupply operations are  examined by illustrating a best practice approach analyzing inventory to support the operations.  The case study  illustrates the methods and the types of analy ses that can be performed.   Finally, motivations are given for future  work in this area.    Keywords  Continuous Improvement, Modeling and Simulation, Quantitative Methods     Introduction  During the past decade, the department of defense’s  Logistics Modernization Program (LMP) has attempted to  integrate production and supply systems within the war fighter’s supply chain under unified enterprise resource  planning (ERP) systems.  This effort is an attempt to modernize and standardize the wide  variety of production and  supply chain activities , including sourcing and acquisition, production, scheduling, order processing, inventory  management, transportation, warehousing, and customer service.  Despite significant integration efforts, there  remain a number of impedance mismatches between the assumed processes within the ERP implementations,  process re-engineering efforts, and actual current practices, especially in the area of production planning and control.   One area where the impedance mismatch is sever e is with in a high -mix, low-volume government -operated repair  and refurbish operation that essentially operates as a job -shop environment.   This area became a candidate for  logistics process improvement and re -engineering activities that can lever age alignment with ERP practices in order  to improve work planning, supply, and production capabilities.   Through a case -study analysis, this paper presents  the findings of 1) applying industry techniques to develop a modernization plan , 2) investigating the use of modern  automated machine tools, flexible automation, alternative processing methods and work flow analysis in a low - volume / high product mix production environment, and applying inventory best practices to the supply operations  of the job shop.   This paper is organized as follows : First a literature review presents background on the methods and  approaches required when applying industry practices to high -mix, low -volume production environments.   Additionally, a brief review of the analysis techni ques used in the paper is presented.  Then, the elements of the  case-study environment are described .  Afterward, the tasks and methods used within the case study are presented  along with their results.  Finally, a brief summary is given.     Literature Review  Group Techno logy is a method of identifying similar parts and grouping them together based on design or  characteristic similarities.  Cellular Manufacturing involves collecting and processing those similar parts (groups)  together in a cell consistin g of all machines needed to  process those parts  (Sule, 2008).  It is essentially the  application of group technology  (Heragu, 2006), which is most appropriate for batch production where workpieces  can be grouped into part families.  This grouping is typica lly done based geometric similarities , processing   similarities, or both (Groover , 2007).  A pioneering and still- common example is the Or itz system ( 1969).  Other  well-known algorithms include Beaulieu, Gharbi, & Ait -Kadi (1997); Black, 1983; Cantamessa & Turroni (1997); ",uark.edu,University of Arkansas - Fayetteville,United States,36.0970389,-94.17033216657404
80,CAPTURING TRUST AS ORGANIZATIONAL UNCERTAINTY IN AVALUE-BASED SYSTEMS ENGINEERING FRAMEWORK,@iastate.edu,"Systems Engineering, Value -Driven Design, Multidisciplinary Design Optimization, Organization Design, ","The design of Large -Scale Complex Engineered Systems (LSCESs), in a System Engineering (SE) framework,  generally requires multiple organizations, each with numerous decision makers that must exchange information to  realize the system. The difference in beliefs between decision -makers affects the design process for LSCESs. The  authors’ recent research using Value- Drive Design (VDD) and Multidisciplinary Design Optimization (MDO) has  demonstrated the potential of a preference-driven SE approach that captures critical physical and modeling interactions  by the addition of Organization Design (OD) elements to demonstrate the additional impact decision -makers’  interactions on the final system. In this pap er, the difference in beliefs on information held by decision -makers is  explored to identify the extent to which these differences affect the design process. A complex system will be used as  a test-bed to demonstrate effects of varied decision-maker beliefs on a system. The goal of this paper is to introduce a  methodology to improve value-based systems engineering frameworks.     Keywords  Systems Engineering, Value -Driven Design, Multidisciplinary Design Optimization, Organization Design,  Uncertainty    Introduction   Increasingly, engineered systems that are developed can be considered as Large-Scale Complex Engineered Systems  (LSCESs). These systems are characterized, in part, by the numbers of parts that make up the systems, the complexity  of the interactions that are present within the systems, the complexity of the interactions that these engineered systems  have with other LSCESs, the large costs associated with their design, development and retirement as well as the  extensive development time necessary to realize these systems  (C. L. Bloebaum, Coll opy, & Hazelrigg, 2012) .  LSCESs are designed to address the complex problems encountered in society today. This is accomplished by  designing these systems to interact with other systems such as aircraft carriers needing to interact with military aircraft  which allow for the successful execution of objectives to accomplish specific missions. LSCESs are not only  companions to other systems but also exist as parts of much larger systems. The success of these LSCESs is dependent  on the conglomerate of hundreds or even thousands of people that form the decision making units of the organizations  as either individuals or teams to achieve a shared goals (Baligh, 2006) . LSCESs can have multiple organizations  involved in their development processes such as when sub-contractors are tasked with development of certain portions  of systems.   Much like other organizations, the organizations that develop LSCESs are designed to provide infrastructure  that facilitates the design and development of these systems. Parts of this infrastruct ure in the organizations include  collaborative efforts amongst teams of decision makers and individual decision makers. The collaborative effort within  and between organizations is defined by rules and guidelines that dictate how members of an organization are able to  interact. This results in intentional forms of communication and information flow that define the structure of the  organization(Baligh, 2006). Each organization has a structure that is established or evolves to identify and steer the  collaborative effort necessary in the organization. Interfaces that are present in the organization serve as resolutions  to the need to relay information between decision makers during the design and development process. These links  provide part of an organization’s structure(Baligh, 2006; Mintzberg, 1980). The information that is relayed through ",iastate.edu,Iowa State University,United States,42.0279608,-93.64473746093857
81,MANUFACTURABILITY ASSESSMENT KNOWLEDGE-BASEDEVALUATION (MAKE) AND A PILOT CASE STUDY,@cavse.msstate.edu,"Manufacturability, Assessment, Metric, Life Cycle, Taxonomy ","Understanding the manufacturability concerns of a product design is a crucial part of a successful product introduction.   The literature suggests that a significant portion of a products life cycle  costs is committed in the early design phase  and that manufacturability concerns are one of the major drivers of these costs.  The lack of insight into the  manufacturability of a design can potentially lead to expensive design iterations, tooling modifications, the potential  for rework and other factors all resulting in costly delays and other potential risks to product introductions.  As a result,  there is a benefit in the development of a practical way to assess the manufacturability of a design.    This paper focuses on the enhancements of a methodology for perf orming manufacturability assessments of  product designs.  This new approach, referred to as Manufacturability Assessment Knowledge- based Evaluation  (MAKE), utilizes a taxonomy of key aspects of manufacturability combined with subject matter experts (SMEs) to  assess a product design.  The results from MAKE include detailed manufacturability concerns along with  recommendations for improvement.  A pilot software tool was developed to guide the assessor through the process.   A discussion of this methodology within the context of a defense industry case study is presented, along with lessons  learned and recommendations.      Keywords  Manufacturability, Assessment, Metric, Life Cycle, Taxonomy    Introduction  The impact of design activity on life cycle cost is signifi cant and well known among researchers and practitioners.   The literature indicates that approximately 80% of the life cycle costs are committed during the product design phase  (Anderson (2014), Dunk (2004), Rush & Roy (2000)) with manufacturing costs being  a significant portion of those  costs.  Therefore, addressing potential concerns that may affect manufacturing costs should be considered during the  early phase of the product development.  It is at this stage where the practice of design for manufacturabi lity (DFM)  is most critical.  While DFM is well documented, r eview of the literature yielded minimal  information pertaining to  the manufacturability assessment of a total system (i.e. total product) design nor development of a metric to represent  the manufacturability of a total product.  This research continues to support the development of such a methodology  that will assess the manufacturability of a product in a system design cycle.  For the purpose of this research,  manufacturability is defined as ‘the ease with which a product or component can be produced…and the freedom that  its design has from inherent quality and processing problems ’ (Bralla, 1996).  Included in this simple definition are  many factors that must be considered in order to ascertain a fundamental understanding of the manufacturing  challenges associated with a product’s design.  The basis of the Manufacturability Assessment Knowledge -based Evaluation (MAKE) taxonomy involves  the assessment of a product design to identify manufacturability concerns.  This judgment based assessment, involving  the use of a cross -functional team of subject matter experts (SMEs) , is intended to provide a relevant and thorough  assessment of a product design.  The resulting assessment includes a metric representative of manufacturability of the  system, identification of key aspects of the design that adversely affect the product’s manufacturability , and a list of  design recommendations aimed at mitigation of the impact of the identified concerns .  This provides a basis for  improving the manufacturability of the design (McCall, Walden, Gedik, et al., 2016).   ",cavse.msstate.edu,CAVS - Mississippi State University,United States,33.4736,-88.7932
82,PRACTICAL APPLICATION OF SOCIOLOGY IN SYSTEMSENGINEERING,@nasa.gov,"Systems engineering, system integration, discipline integration, specification of ignorance, social ambivalence, ","Systems engineering involves both the integration of the system and the integration of the disciplines which develop  and operate the system.  Integrating the disciplines is a sociological effort to bring together different groups, who often  have different terminology, to achieve a common goal, the system.  The focus for the systems engineer is information  flow through the organization, between the disciplines, to ensure the system is developed and operated will all relevant  information informing system decisions. The practical application of the sociology in systems engineering brings in  various organizational development concepts including the principles of planned renegotiation  and the application of  principles to address information barriers created by or ganizational culture.  Concepts such as specification of  ignorance, consistent terminology, opportunity structures, role-sets, and the reclama (reconsideration) process are all  important sociological approaches that help address the organizational social structure (culture).  In bringing the  disciplines together, the systems engineer must also be wary of social ambivalence, social anomie, social dysfunction,  and insider-outsider behavior. Unintended consequences can result when these social issues are present. These  issues  can occur when localized subcultures shift from the overarching organizational culture, or when the organizational  culture prevents achievement of system goals.  These sociological principles provide the systems engineer with key  approaches to manage the information flow through the organization as the disciplines are integrated and share their  information and provides key sociological barriers to information flow through the organization.  This paper will  discuss the practical application of sociological principles to systems engineering.     Keywords  Systems engineering, system integration, discipline integration, specification of ignorance, social ambivalence,  social anomie, social dysfunction, insider-outsider behavior, organizational culture    Introduction  Discipline Integration is a critical activity of the systems engineer. Information about the system resides in the  organization, and information about the system can be filtered or changed as information passes between disciplines.  This brings into play several practices from sociology.   The organization is an integration of the disciplines which develop, manufacture, and operat e the system.  The organization itself is a complex system, which is put in place to develop a complex system. Systems engineering  is focused on the development of elegant systems. Elegant systems  are robust in application, fully meeting specified  and adumbrated intent, are well structured, and are graceful in operation. The relationship between the system being  developed and the organization is a key factor in system elegance that results from the development process and the  execution of the manufacturing and operations of the system. Because of these relationships, the systems engineer has  a special interest in the organizational structure and relationships.   The organizational structure and relationships are primarily the responsibility of the line organization and the  program manager. They establish and manage the various disciplines or branches within the organization. These  relationships form the medium through which the system information flows during the development and operation of ",nasa.gov,,,46.3144754,11.0480288
83,SOLDIER LOAD EFFECT CONSIDERATIONS FOR MATERIALACQUISITION,@usma.edu,"Acquisitions, Load Effects Assessment Program - Army, Soldier ","The Load Effects Assessment Program –  Army (LEAP -A) is an obstacle course used by the Army to support  individual equipment decisions. The LEAP -A attempts to mimic the most salient and challenging combat tasks that  impact Soldier performance and limitations. This study seeks to provide a measurement method ology for the LEAP- A. Shoot, move, and communicate summarize the most significant Soldier tactical functions. Currently, the LEAP-A  methodology fails to address Soldiers shooting or communicating. Lacking measurement for the se two tasks limits  the effectiv eness of LEAP -A for acquisition  decisions. The recommended LEAP -A methodology includes  measurements for shooting and communicating, as well as improved movement assessments with electromyography  and heart rate sensors in a tactical environment. The recommended measurement methodology seeks to improve the  use of the LEAP-A to support individual equipment acquisition decisions.    Keywords  Acquisitions, Load Effects Assessment Program - Army, Soldier    Introduction  The LEAP -A system provides a platform to better  understand the impact of Soldier load and configuration. It is  currently under review for its usefulness for material acquisition decisions. According to the Maneuver Battle Lab,  the LEAP-A is “an instrumented obstacle course of repeatable and relevant warfighter tasks to measure the effects of  individual equipment configurations and combat loads on Soldier physical performance” (Maneuver Battle Lab  Report, 2015).  Consisting of 12 total obstacles, the LEAP -A course consists of the following obstacles: tun nel and  hatch, sprint, outer wall, low crawl, window #1, stair and ladder, window #2, agility run, inner wall, balance beam,  bounding rushes, and casualty drag. Prior and post tests included horizontal and vertical load transfer, and vertical  jump test. The problem statement of this research is to develop a Soldier load effects measurement methodology in  order to support current and future material acquisition decisions. This study seeks to critically analyze the  completeness of the LEAP -A and develop a measurement methodology for the system. A final product shall be a  measurement methodology that allows for more informed acquisitions decisions. After defining the scope of the  project, a five- phase methodology consisting of problem definition, measurement me thodology, experimentation,  system analysi s, and product delivery comprised the remaining work. In coordination with the Department of  Physical Education (DPE), a live LEAP -A experiment conducted at West Point tested 35 subjects over thirty  experimentation hours. The data collected through this experimentation p rovides the basis for the a nalysis in this  paper.    Related Work   In order to gain a better understanding of the LEAP -A system and relevant related systems, a r eview of related  literature focused on three components: human performance, related physical assessment tests, and Soldier load.  Initial research assisted in defining the scope of the project and how the LEAP -A can provide value to Army  acquisition decisions.  ",usma.edu,United States Military Academy,United States,41.3927227,-73.95986305044411
84,ORGANIZATION DEVELOPMENT IN THE DISTRIBUTION INDUSTRYTHROUGH INDUSTRY FOCUSED AND APPLIED GRADUATEPROGRAM,@tamu.edu,"Organization development, distribution, graduate program. ","Wholesale Distribution in the United States is more than a $6 trillion dollar industry with more than 370,000 businesses  that employ 6 million people. With evolving distribution business models, margin pressure, and an aging workforce,  distributors are faced with talent management crisis, especially with hiring, developing and retaining managers and  developing a leadership pipeline. Traditionally, distributors promoted for mana gerial and leadership positions based  on tenure and prior job performance. With an increase in the need for business competitiveness, customer experience,  value added services and innovative new solutions, distributors need to develop competency based mid-managers who  can effectively drive change and impact profitability.  This paper outlines a distribution focused graduate program  design, development, and continuous improvement to develop distribution industry mid -managers and leaders. The  program is a web -based, part-time graduate degree focused on professionals in the industrial distribution, industrial  sales, supply chain and logistics areas. The cohort program is designed for working professionals with at least 5 years  of experience. The paper outlines t he three immersive learning experiences of the program –  residency week, global  distribution course & trip and capstone project. Continuously improved over the past 15 years focus on four areas: (1)  applied content development include industry focused live case studies, videos, interviews and podcasts. (2) teaching  enhancement include quality matters certification and the use of industry executives to co -teach classes (3) learning  experience enhancement include reflective discussion boards, group projects and peer -group learning ( 4) content  delivery through mobile learning experience with iPad, eBooks and apps.     Keywords  Organization development, distribution, graduate program.    Introduction  Wholesale Distribution in the United States is more than a $6 trillion dollars’ industry with more than 300,000  businesses that employ 6 million people (US Census). The wholesale trade accounts for about 6% of the GDP in 2016  and one of the top 4 sectors of the U.S. economy.     The growth of a distribution organization does not rely solely on the distributor’s geographic reach, physical  assets, product selection, or access to capital. It also depends on its human capital. In fact, all organizations require  human capital to accomplish their goals; therefore, the organization’s ability to manage its human capital is key to its  business success. Treating people as capital means recognizing people as an asset rather than as an expense. While  most wholesaler-distributors understand how to leverage financial and physical capi tal, when it comes to managing  people, organizational leaders often find themselves struggling with attracting , developing and retaining key talent,  managing and developing employees effectively or measuring the return on their human capital investment.        ",tamu.edu,Texas A&M University - College Station,United States,,-96.35206061388457
85,ANALYTICAL ANALYSIS OF MEM ADMISSION CRITERIA,@stcloudstate.edu,"Predictive Analysis, Pearson’s correlation coefficient, Admission Criteria, CGPA. ","A study was undertaken to validate the admission criteria to the Master of Engineering Management (MEM) program  at St. Cloud State University . The final MEM Cumulative Grade Point Average (CGPA) was compared to the  admission criteria to gain a better understanding of admission criteria factors that can predict success in  the MEM  program. Various inputs were analyzed and the most important factors were considered. These factors either had direct  or a correlation in combination with the other selected factors towards the CGPA. The correlation was predicted using  Pearson’s correlation c oefficient (PCC) determination. The study only used historical admission data and did not  consider any other factors. The results indicated that the linear correlation existing between the Graduate Record  Examination (GRE) scores and the output CGPA was higher in strength than International English Language Testing  System (IELTS) and Undergraduate Grade Point Average (UGPA). However, the magnitude of the strength in each  factor combination was not enough to prove the existence of a strong linear  correlation between the important input  factors and output CGPA.    Keywords  Predictive Analysis, Pearson’s correlation coefficient, Admission Criteria, CGPA.    Introduction  This study addressed the problem of understanding th e factors which impacted  the CGPA of students in the MEM  program at St. Cloud State University . All the factors which contributed towards the admission of a student into the  MEM program were gathered  from the historical data  and a linear correlation analysis was performed  for all factor  combinations. The magnitude of PCC was inferred to find the strength of linear correlation between each factor  combination. A clear understanding of the factors  affecting the CGPA was achieved , which helped to highlight the  most important factors and eliminate those, which were least important to make the admission decisions for the MEM  program.    Literature Review  Cumulative Grade Point Average (CGPA) refers to the overall grade point average of a student across multiple  semesters of the pursued educational program. Graduate Record Examination (GRE) is a standardized test required  for admission at most of the graduate schools in United States of America. It has two sections i.e. Quantitative and  Verbal. According to the new pattern, each section can be scored in the range of 130 to 170 and higher score represents  higher proficiency  (The Princeton Review , n.d.). International English Language Testing System (IELTS) is an  international standardized test of English language proficiency for non -native English language speakers. IELTS has  four sections, listening, reading, writing and speaking. It can be scored in the range of 0 to 9, higher scor e represents  higher proficiency ( International English Language Testing System , n.d.) . Test of English as a Fore ign Language  (TOEFL) is a standardized test to measure the English language ability of non -native speakers. TOEFL also has four  sections, listening, reading, writing and speaking. It can be scored in the range of 0 to 120, higher score represents  higher proficiency (Educational Testing Services, n.d.-a). Undergraduate Grade Point Average (UGPA) is the overall  grade point average across all semesters attained by a student in an undergraduate degree.  ",stcloudstate.edu,Saint Cloud State University,United States,45.55139,-94.14833
86,PRINCIPLES OF SOCIOLOGY IN SYSTEMS ENGINEERING,@nasa.gov,"Systems engineering, system integration, discipline integration, specification of ignorance, social ambivalence, social ","Systems engineering involves both the integration of the system and the integration of the disciplines which develop  and operate the system.  Integrating the disciplines is a sociological effort to bring together different groups, often  with different terminology, to achieve a common goal, the system.  The focus for the systems engineer is information  flow through the organization, between the disciplines, to ensure the system is developed and operated with all relevant  information informing system decisions. Robert K. Merton studied the sociological principles of the sciences and the  sociological principles he developed apply to systems engineering.  Concepts such as specification of ignorance,  common terminology, opportunity structures, role -sets, and the reclama (reconsideration) process are all important  sociological approaches that should be employed by the systems engineer.  In bringing the disciplines together, the  systems engineer must also be wary of social ambivalence, social anomie, social dysfunction, insider -outsider  behavior, unintended consequences, and the self -fulfilling prophecy.   These sociological principle s provide the  systems engineer with key approaches to manage the information flow through the organization as the disciplines are  integrated and share their information. This also helps identify key sociological barriers to information flow through  the organization.  This paper will discuss this theoretical basis for the application of sociological principles to systems  engineering.    Keywords  Systems engineering, system integration, discipline integration, specification of ignorance, social ambivalence, social  anomie, social dysfunction, insider-outsider behavior, unintended consequences, self-fulfilling prophecy    Introduction  Systems engineering is responsible for integrating the various disciplines within an organization to develop or operate  a system. This aspect is a parallel aspect with system integration which involves understanding the system’s integrating  physics. If you understand the system, but not the organization structure and interrelationships you may never get the  system developed. If you unde rstand the organization but not the system’s discipline and integrating physics, the  system will not work. Systems engineering must deal with both aspects to design an elegant system.   Discipline integration is a highly sociological function and brings in aspects not traditionally thought of as engineering.  These sociological aspects are essential as complex systems are developed by complex organization (the organizations  are complex social systems ). The systems engineer must understand how the organization is structured, how  communication flows, and how information about the system is maintained. Information maintained within the  organization is not always readily identified in the system design, managing this is a crucial role of systems engineers.  Disciplines are reservoirs of information, information which they generate and maintain. The systems engineer  manages the channels between these reservoirs ensuring the right information is provided to the right discipline when  needed. Systems engineering applies many sociological functions in the development or operation of a system.    Opportunity Structures  Opportunity structures provide pathways for individuals advancement toward social goals in a social system.  (Merton,  1996, pp. 153- 161) Systems engineering is  concerned with information flow about the system through the ",nasa.gov,,,46.3144754,11.0480288
87,THE STRATEGIES OF CONSTRUCTION ENTERPRISES TOWARD THEMODERNIZATION OF CONSTRUCTION INDUSTRY,@tju.edu.cn,"Market participants, proactive behavior, construction industry modernization, pre-fabricated components ","It is an irresistible trend in the development of Chinese construction industry that construction enterprises adopt  modern project management mode, improve the efficiency and quality of construction projects com prehensively and  take the path of sustainable development to complete the transformation and upgrading of industrial modernization.  The modernization of construction industry is based on the multi- faceted behavior of market participants. Therefore,  it is o f important significance to identify market participants’ proactive behavior which affects the construction  industry modernization development and elevating its development level.  Based on literature review and summary, this thesis defined the concept of m arket participants’ proactive  behavior, identified the market participants’ proactive behavior and established a framework to analysis the market  participants’ proactive behavior.  The findings of this thesis could provide reference and suggestions for market participants on which   proactive behavior should be taken to promote the development of construction industry modernization and influence  paths and main point to elevating construction industry modernization development level.    Keywords  Market participants, proactive behavior, construction industry modernization, pre-fabricated components    Introduction  Nowadays, Chinese construction industry is still a traditional labor-intensive industry and relatively falls behind. The  “modernization development outline” issued by the ministry of construction clearly pointed ou t that more than 50%  new buildings will be prefabricated buildings by 2025.  The modernization of construction industry can integrate the whole process of construction into a  completely industrial chain, which will have a positive impact on budget, method a nd schedule during different  stages of the project. The modern project management mode can  improve the efficiency, effectiveness and quality of  construction projects. The advancement on the modern ization of construction industry mainly relies on the force  imposed by market participants from different perspectives 1. The purpose of this study is to analyze how Chinese  construction enterprises adapt to the transformation of construction mode by identifying the behavior of market  participants which consist of government, enterprises and consumers as well as conducting advice about the  modernization of construction industry to the government. Standing in the perspective of construction enterprises,  this paper puts forward some suggestions to promote the development of modern construction industry.  The s tudy on proactive behavior of market participants influencing the modernization of construction  industry mainly includes two aspects:①The motivation of proactive behavior of market participants;②The behaviors  which can promote the development of construct ion industry modernization by government, enterprises and  consumers. ",tju.edu.cn,Tianjin University,China,39.107253299999996,117.17789778037583
88,REIMAGINING UNCERTAINTY AND COMPLEXITY EVALUATION INAEROSPACE NEW PRODUCT DEVELOPMENT - TIME AND COSTPLANNING PERSPECTIVE.,@ens.etsmtl.ca,"Uncertainty, Complexity, Planning, Aerospace product development. ","Product development in aerospace industry runs through a complex system of process and resource. Concurrency  issues and diversity of uncertainty sources intensify this complexity. The presence of high uncertainty level makes it  more difficult to plan activ ities with the required accuracy. Thereby, product development is subject to severe cost  and schedule overrun. Thus, uncertainty and complexity evaluation is a key element for cost and time planning.   Current uncertainty and complexity evaluation approaches are in most cases hard to apply or not adequate for  aerospace new product development. This is due to the lack of factors customization or availability of required data.    The aim of this paper is to  explore uncertainty evaluation issues in aerospace new product development based on  existing research papers and ongoing experience with product development in aerospace industry. A new evaluation  method is developed for uncertainty. We deeply examine com plexity drivers regarding aerospace projects features  and issues. Finally, we introduce an integrated evaluation and measurement approach of uncertainty and complexity  with a focus on planning improvement. The measurement  method is illustrated  through a case study  from a recent  major aerospace project to facilitate the understanding of how to use the method.   This paper will emphasize the determinant effect of uncertainty and complexity factors on project performance and  how it is crucial to integrate these factors to improve accuracy of pro ject planning . Results sug gest that more  research efforts  must be given to uncertainty and complexity as key concepts in aerospace product development  performance.    Keywords  Uncertainty, Complexity, Planning, Aerospace product development.    Introduction  New Prod uct development projects have a vital  importance in aerospace and other industri es. However, project’s  success rate in terms of cost and time overrun remain too low. The study realized by  Bounds [8] showed that only  26% of new development project respect cost and schedule. Researchers and practitioner s tried first to develop new  methods and tools with a focus on process performance.  New models like concurrent engineering, set -based  engineering, system engineering, and Lean  product development have been integrated to enhance performance with  the hope of cutting cost and shorten delay. Unfortunately, results did not meet expected results.   Therefore, focus has been reoriented toward planning activities. In fact, researchers believed that  reliable project  plan and  accurate forcasts  are essential for project success. Many research efforts  are proposing  new concepts,  models and approaches related subjects such as scheduling models, cost estimation models, and resources allocation  models. Besides these models, s ome concepts should also  play a key role in project planning. C omplexity is  probably one of the most determinant s of these concepts not only for project planning but also for strategic decision  making like, portfolio selection, processes design, partners selection and financial engagements.  Considering the importance of this concept in prod uct development, research work  has been under taken with the  hope of getting a deeper understanding of complexity in a project manageme nt context. Research about this subject  could be classified into four groups. First group interest is about applying complexity science a nd theories to project ",ens.etsmtl.ca,,,46.3144754,11.0480288
89,DEVELOPING NEXT GENERATION DISTRIBUTION MANAGERSTHROUGH COMPETENCY DEVELOPMENT,@tamu.edu,"Competency development, managerial competencies, distribution manager development. ","Wholesale Distribution in the United States is more than a $6 trillion dollars  industry with more than 300,000  businesses that employ 6 million people. Due to changing business models, margin pressure, and an aging workforce,  distributors are faced with ta lent management crisis, especially in hiring, developing and retaining mid -level  managers. These include branch managers, operations managers, sales managers, regional managers, business  development and procurement managers. Traditionally, distributors pro mote professionals to managerial roles based  on tenure and prior job performance. Attention is not given to the selection and assessment of managerial competencies  for job functions or job families. Consequently, performance is often evaluated using subjec tive measures. Training  and development activities are not linked to competencies. In this paper, we propose a structured competency  development approach to hiring, managing, developing and retaining high -performing mid- level managers. The  process involves  selecting key competencies for job functions, developing assessment tools, identifying gaps in  competencies, and providing targeted interventions to close the gaps so that performance can be managed in a more  objective than subjective manner. This process can help develop competent distribution mid-level managers who can  effectively drive change and impact profitability. This paper is based on a two-year research project conducted with a  consortium of 18 distributors in multiple industrial sectors. The pro posed approach was developed from the results  from surveys, workshops, and conversations with more than 70 industry professionals.     Keywords  Competency development, managerial competencies, distribution manager development.    Introduction   Wholesale Distrib ution in the United States is more than a $6 trillion dollars’ industry with more than 300,000  businesses that employ 6 million people (US Census). The wholesale trade accounts for about 6% of the GDP in 2016  and one of the top 4 sectors of the U.S. economy.     Exhibit 1: Key U.S. Industries share of GDP in 2016    Finance, Insurance, Real Estate 20.6%  Manufacturing 11.7%  Healthcare 7.4%  Wholesale Trade 5.9%  Retail Trade 5.8%  Construction 4.2%  Mining 1.5%  Source: National Association of Wholesaler-Distributor    The growth of a distribution organization does not rely solely on the distributor’s geographic reach, physical assets,  product selection, or access to capital. It also depends on its human capital. In fact, all organizations require human  capital to accomplish their goals; therefore, the organization’s ability to manage its human capital is key to its business  success. Treating people as capital means recognizing people as an asset rather than as an expense. Wright, McMahan, ",tamu.edu,Texas A&M University - College Station,United States,,-96.35206061388457
90,MAPPING PROCEDURES FOR VALUE DETERMINATION OFTRANSPORTATION RESEARCH RESULTS,@mail.wvu.edu,"Research value, research benefits, benefit measures, thematic analysis, clustering/coding approach. ","Measuring the value of research results is vital for transportation agencies to justify the process efficiency and quality  of their research programs. However, only a small number of state Departments of Transportation (DOTs) currently  use quantification procedures that they have developed to determine the value of transportation research results. In  this paper, the authors report their work in progress on review synthesis and mapping procedures for determining the  value of state DOT research results. A comprehensive literature review and nationwide survey to state DOTs in the  U.S. were conducted. The collected data were processed using thematic analysis that automatically captures the  meaningful patterns in the data. A clustering and coding approach was then applied on the captured patterns to  characterize their horizontal and vertical relationships, enabling to develop a mapping table that includes all possible  benefit measures connected to each of research categories and subcategories. This table serves as a mainstay that  underpins analysis of research subcategories with complete, incomplete, and under -developed benefit quantification  procedures. Such results are expected to allow for state DOTs to understand what research areas require more  investigations of methods to determine the value of transportation research. Future work includes development of  measurement procedures for the incomplete an d under-developed research categories, and development and review  of quantification measures, both of which are indispensable to development of a guideline for quantifying the value  of DOT transportation research project results.    Keywords  Research value, research benefits, benefit measures, thematic analysis, clustering/coding approach.    Introduction  Every year, the U.S. Department of Transportation (DOT) and state DOTs fund millions of dollars in research to cope  with transportation issues, improve quality of lives, and facilitate economic growth. As a key to the research funding  management, measuring the benefits of the research results is indispensable to justif y the efficiency and  quality of  their research programs (Zmud, Paasche, Zmud, Lomax, Schofer, & Meyer, 2009; Ellis, Degner, O’Brien, & Peasley,  2003; Concas, Reich, & Yelds, 2002; Hartman, 2001; Anderson, 2010; Worel, Clyne, & Jensen, 2008; Sabol, 2001).  Unfortunately, many state DOTs have not truly measured the impacts of their transportation research projects  on the  transportation system due, in large part to, a lack of comprehensive and implementable quantitative and/or qualitative  methods to determine the value of transportation research projects (Schuler, 2010). A recent survey’s results revealed  that 88% of the state DOTs did not have any guideline or method to evaluate the quantitative or qualitative benefits  of their research projects; further clarification indicated that the 12% remaining that provided responses misunderstood  the questions and also did not have any guideline or method (Ashuri, Shahandashti, & Tavakolan (2014). As a result,  a scalable, flexible, and consistent method is missing that applies benefit measures and quantification procedures  considering data availability for measuring and documenting the value of the completed research projects.   With an overarching goal of developing a scalable, flexible, and consistent method for state DOTs to measure  and justify the value of their completed research projects, this paper presented the work of development of a mapping  procedure from benefit measures to various research categories/subcategories for value determination of transportation  research results. The main data to be collected included research categories and subcategories, benefit categories, and  benefit measures. To collect the data, a comprehensive literature review and nationwide survey to state DOTs in the  U.S. were conducted.  Thematic analysis was applied on t he collected data to capture the meaningful patterns in the  three data types. Then, a clustering and coding approach was applied to define the horizontal and vertical relationships  among the identified patterns. The final  result was a developed mapping table that include d all possible benefit ",mail.wvu.edu,West Virginia University,United States,39.64,-79.95
91,A SYSTEMATIC REVIEW OF QUANTITATIVE MODELINGAPPROACH IN SUSTAINABLE SUPPLY CHAIN UNDERUNCERTAINTY,@uta.edu,"Sustainable supply chain management, quantitative modeling, uncertainty, literature review.  ","It is vital to have a sustainable supply chain (SSC) to enhance and maintain the organization`s competitiveness in the  market. Quantitative modeling (QM)  techniques are widely used to analysis the behavior of system to ensure  organizations will meet their goals. Historically, QM is well -developed technique in sustainable supply chain  management (SSCM)`s body of science which was the main encouragement to review papers in which sustainability  of supply chain (SC) is quantitatively modeled in the past 10 years. Distribution of QM and sources of uncertainty  over the distinct aspects of sustainability were reviewed in this research. The results of this study show that application  of QM in SSCM is increasing  in recent years , even though, not all QM techniques and sustainability goals are  developed enough, and this area of research still needs a quite elevated level  of attention in future. Moreover, t his  review highlighted the impacts of various sources of uncertainty on efficiency of SSCM.    Keywords  Sustainable supply chain management, quantitative modeling, uncertainty, literature review.     Introduction  Economic profitability cannot assure sustainability of supp ly chain ( SC) in today`s competitive market. Although  supply chain`s main goal is to make profit, the efficiency of SC  can tremendously decrease by poor labor conditions,  or environmentally harmful products. Thus, sustainability in a supply chain encompass es all these three economic,  environmental, and social aspects which known as triple-bottom-line (TBL) (Elkington, 2004). In addition, due to lots  of pressure and incentives from public, government, NGO, and media, sustainability has become one of the major  concerns of supply chain management  (SCM). The critical question is how organizations can have a confidence to  reach a certain amount of sustainability in real world to maintain their competitiveness in the market.  Several types of uncertainty in real world rise lots of challenges in managing sustainable supply chain (SSC).  Uncertainty defined as a lack of required information comparing with available information to run an action (Gupta  & Maranas, 2003). Sustainability and uncertainty are always tied up together; a ny types of uncertainty can affect the  efficiency of SC either economically, socially, or environmentally. Uncertainty can cause undesired occurrence  through SC, and decisively decrease the efficiency of the sustainability in a SC. These uncertainties consist of several  types of activities in SSC, e.g. prediction of demand, fluctuation of price, raw material su pply, transportation, labor  performance. Therefore, any level of decision making confront with inherent uncertain ty of their related activities.  Although, this issue has not been paid enough attention in the SSCM literature  (Tseng, Lim, Wong, Chen, & Zhan,  2016).  Models are widely used to simply represent the real world. Models can be defined as conceptual models  which are representations of the concepts which do not explicitly defined objectives and process, or quantitative  models in which variable and their relations are considered  to reach goals of modeling  (Bertrand & Fransoo, 2002) .  Majority of models in sustainable supply chain management (SSCM) are conceptual, and literature shows conceptual  models used nine time more than quantitative models in this field (Seuring & Müller, 2008) . More recent researches  show increases in publication of quantitative models (Brandenburg, Govindan, Sarkis, & Seuring, 2014) .   The objective of this paper is to assist the readers to understand which types of quantitative models are used  in different TBL , and it will be followed by a discussion on the possible effects of uncertainty . Additionally, the ",uta.edu,University of Texas at Arlington,United States,32.728471299999995,-97.11202127009975
92,SOLVING THE FACILITY LAYOUT PROBLEM USING PROGRESSIVEMODELLING,@uregina.ca,"Facility Layout, System Optimization, Layout Software, Factory Design Software  ","This paper presents a new modeling approach called Progressive Modeling (PM) and demonstrates it by solving the  Unequal Areas Facility Layout Problem (UA-FLP). A problem solution is represented by a binary tree and an objective  graph. PM introduces a compo nent model to deploy the problem logic and its solution algorithm over several  interacting components. Component models isolates the objective space fr dsom the search space in a black -box  fashion. A novel solution algoithm is  presented to demonstrate how the search  process is managed and controlled  while searching for optimal or near optimal solutions. The solution process and the optimization algorithm are  demonstrated using the developed software framework. A set of well -known problems in the literature are reported  and solved. The developed problem analysis, solution algorithm, and results demonstrate why the proposed modeling  approach is promising and capable of handling more complex real-world problems.     Keywords  Facility Layout, System Optimization, Layout Software, Factory Design Software     Introduction  The layout of a facility has an important role to play in the effectiveness of a production system, profitability and  supply chain excellence in general. Hence, finding the most efficient arrangement of the departments within a facility  is key. Researchers have developed efficient algorithms to optimize this problem over the years. However, more often  than not, the departments in manufacturing and service providing facilities are not equal in size. The floor space  allocated to each department depends on its space requirement. Consequently, the unequal area assumption is a more  practical approach to solving the facility layout problem. Since each department has its space requ irement, there is a  need to arrange the departments within a designated area without violating area and shape constraints. This is the  unequal area facility layout problem (UA -FLP). The main objective considered in UA -FLP is to minimize material  handling cost which is usually calculated as the multiplication of the flow between department pairs with the rectilinear  distance between the department centroids. Layout decisions have direct implications on the operational efficiency in  both short and long terms.   The problem has been studied extensively and is still an active area of research as evidenced by recent surveys  of (Singh & Sharma, 2006) , and (Drira, Pierreval, & Hajri -Gabouj, 2007). The first computerized heuristic to solve  the UA-FLP was CRAFT of Armour and Buffa (1963). The objective was to minimi ze the material handling cost  given an initial layout. In some problems, it is difficult to quantify the flow data among the interacting departments  and qualitative data are used instead. Many heuristics followed CRAFT in the next three decades. Some of them start  from scratch; known as constructive heuristics, while some others improve an initial solution to create better ones,  improvement heuristics. The classical approaches used the grid-based layout or the block arrangement algorithm to  create the final  layout. In the early 1990s, better approaches that commonly use strict rectangular shapes for  departments with geometric constraints such as min side length and aspect ratios have dominated the UA -FLP  literature. One of such heuristic is the recursive slicing tree algorithm of Tam ( Tam, 1992 ). Each slicing tree  corresponds to a particular layout, and the nodes of the tree contain either a department label in case of a leaf node or  a cut node in case of an internal node. Scholz et al ( Scholz, Petrick, & Domschke, 2009)  associated each node in the ",uregina.ca,University of Regina,Canada,50.4152275,-104.58899996239825
93,ON CREATING ACCREDITATION CATALOGS AND COURSEINFORMATION SHEETS: A CANADIAN EXPERIENCE,@uregina.ca,"Accreditation Software, Outcome-Based Assessment, Continuous Improvement, Engineering Education ","OBACIS is an integrated framework being developed to accelerate the accreditation reporting workflow, cut down  the reporting cost by an order of  magnitude, and close the data- driven continuous improvement loop.  OBACIS is a  shorthand for Outcome -Based Assessment and Continuous Improvement System.  The framework integrates three  different pieces of software: 1) an Excel Add -in, or the “Xl-App”, for simultaneous grade and OBA reporting; 2) A  Windows Application, or the “Win-App” for program and faculty-level template creation, document compilation, and  program assessment; and, 3) a web -tool, or the “Web -App”, for document compilation and reporting.  This paper  focuses on creating a centralized database for compiling raw data related to accreditation reporting fro m various  resources such as previous visit accreditation reports, academic calendars, course schedules, and a handful of other  resources are used to create what we call OBACIS Catalogs. The Catalogs framework is a part of the bigger OBACIS  framework proposed in CEEA 2016 ( Ismail, 2016). The framework has been implemented  as a module of the Win - App. Automating the creation process of Course Information Sheets (CIS) , a mandatory sheet required for every  engineering course by the Canadian  Engineering Accreditation Board (CEAB), was the original goal and is still one  of the main outputs of the proposed framework. The OBACIS Catalogs are supposed to save a sheer amount of time  needed for accreditation reporting and should act as an instrumental tool for accelerating accreditation data collection,  creating insightful analyses, and identifying gaps for continuous improvement initiatives at both program and faculty  levels.    Keywords  Accreditation Software, Outcome-Based Assessment, Continuous Improvement, Engineering Education    Introduction  The new outcome-based assessment process is time-consuming and data-intensive. Switching from the previous event- based process that happens every three or six years to a continuously improving one makes the process more  overwhelming and costly than it simply looks (Ismail, 2016). There is no such a comprehensive off-the-shelf solution  that is readily available to facilitate, organize or guide the process of data collection. Many institutions have been  developing their systems to collec t, manage and distribute this data ( Kaupp, 2016) . Unfortunately, there is little  information on how institutions are developing their respective systems, and even less information on their specific  aspects, viewpoints, goals or barriers ( Kaupp & Frank, 2016 ). Accreditation activities are becoming overwhelming,  and software tools are much needed to assist in data collection, data analytics and closing the continuous improvement  loop. The current tools are still premature, and there is a dearth of integrated frameworks that address the new  accreditation and its continuous improvement cycle.   Of all the software tools currently in use, Excel is the most co mmonly used one for graduate attributes data  collection and course activities assessment. Excel reporting capabilities can be extended using office automation, i.e.  Excel Add-Ins. Brennan et al. (Brennan, Hugo, Li, & Taboun, 2016) have used Excel forms for linking course learning  outcomes to course assessments activities. Student achievement reports have been generated and utilized for continual  improvement activities. During OBACIS’ first phase of development, we introduced a tri -mapping and reporting  system using an Excel Add -in, the Xl-App, for graduate attributes, learning outcomes, and categorical analytics [1].  The add -in was driven from the Win -App environment. Currently, the Xl -App is a full -fledged one that could be  distributed to faculty members to be used for grade reporting automation and collecting all accreditation relevant data  (Ismail, 2017).  Collecting data for individual stakeholders need a program or a faculty level tool. Web tools are the most  appropriate to achieve the task of distributed data collection. The ABET’s course assessment tool (ACAT) system  ",uregina.ca,University of Regina,Canada,50.4152275,-104.58899996239825
94,HUMAN-INTELLIGENCE/MACHINE-INTELLIGENCE DECISIONGOVERNANCE: AN ANALYSIS FROM ONTOLOGICAL POINT OFVIEW,@odu.edu,"Decision Governance, Human Intelligence, Machine Intelligence, Artificial Intelligence. ","The increasing CPU power and memory capacity of computers, and now computing appliances, in the 21st century  has allo wed accelerated integration of artificial intelligence (AI) into organizational processes and everyday life.    Artificial intelligence can now be found in a wide range of organizational processes including medical diagnosis,  automated stock trading, integrated robotic production systems, telecommunications routing systems, and automobile  fuzzy logic controllers.  Self -driving automobiles are just the latest extension of AI.  This thrust of AI into  organizations and everyday life rests on the AI community’s unstated assumption that “…every aspect of human  learning and intelligence could be so precisely described that it could be simulated in AI.  With the exception of  knowledge specific areas …, sixty years later the AI community is not close to coding global human intelligence into  AI.”  (Cotter, 2015).  Thus, in complex mission-environment situations it is therefore still debatable whether and when  human or machine decision capacity should govern or when a joint human-intelligence/machine-intelligence (HI-MI)  decision capacity is required.   Most important, there has been no research into the governance and management of  human-intelligent/machine-intelligent decision processes.  To address this gap, research has been initiated into an HI- MI decision governance body of knowledge and discipline.  This paper updates progress in one track of that research,  specifically into establishing the ontological basis of HI -MI decision governance, which will form the theoretical  foundation of a systemic HI-MI decision governance body of knowledge.    Keywords  Decision Governance, Human Intelligence, Machine Intelligence, Artificial Intelligence.    Introduction  Despite the continuing march toward implementing autonomous AI enabled machines, there has been little to no work  in establishing an HI -MI decision  governance body of knowledge. Thus, a n HI -MI decision governance body of  knowledge is needed.  Artificial intelligence is still a long way from achieving human intelligence capabilities and  current AI design treats humans as discontinuities in the autonomous system; however, when autonomous AI systems  fail, control reverts to the human as the last resort to avoid system failure.  The problem this research seeks to address  is how the governance bodies of knowledge and best practices be integrated to develop a new body of knowledge for  human-intelligence/machine-intelligence decision governance.  As AI  technology continues to advance, the key  questions that we , t he human being , should be looking for from systems perspective are  (1) when should  human  decision capacity govern?, (2)  when should machine decision capacity govern?, and (3) when should  a joint human- machine decision capacity govern? This research, therefore, is to form a foundational ontological structure and axioms  that succinctly will specify the HI-MI decision governance body of knowledge  with the intent in mind to integrate  into the decision making process of autonomous systems given varying mission critical situations in order to minimize  the potential adverse outcomes or worse system failure.    Background  There has been little to no research conducted toward creating  an HI-MI decision governance ontology. A lso there  has been little to no research conducted toward establishment of governance ontologies in other disciplines.  Search  of the governance literature produced only the following few corporate, information technology, and knowledge  governance taxonomies-  ",odu.edu,Old Dominion University,United States,36.8862699,-76.30972478839735
95,INFLUENCE OF INCENTIVE AND BENEFIT PROGRAMS ON THEPERFORMANCE OF THE LARGE AND MIDSIZE COMPANIES OF THETEXTILE AND METALMECHANICAL SECTORS OF THE VALE DOITAJAI-SC / BRAZIL,@gmail.com,"Incentive and benefit programs, Organizational performance, Quality dimensions  ","In order to achieve better levels of performance, organizations seek to motivate their employees with incentive and  benefit programs that contribute to their strategies. These programs, when well deployed, can influence company  performance and encourage people to pursue high performance. However, many companies do not assess the impact  of implementing these programs on organizational performance. This quantitative survey, involving 64 medium and  large companies from the textile and metalworking sectors of the Itajaí Valley, in Santa Catarina, evaluates the  influence of incentive and benefit programs on the performance of Companies surveyed. It was observed that most  of the incentive and benefit programs mentioned in the literature are not implemented in the companies surveyed.  On the other hand, all programs when implemented in the companies surveyed have a high level of compliance with  the initial expectation. Through this study, it was also possible to identify which programs most influence the  performance of the company, as measured by the five quality dimensions.    Keywords  Incentive and benefit programs, Organizational performance, Quality dimensions     Introduction  The competitive scenario have influenced more and more companies to improve their processes a nd production  methods in order to remain active in the market. Given that employees are the main asset of a company, it is the task  of the human resources sector to correctly manage the employees, in order to stimulate them in achieving the  objectives of the proposed organizational goals (Fochesatto, 2002). An effective way of achieving this is through the  implementation of incentive and benefit programs, given that, according to Chiavenato (2010), these programs have  arisen from the need to maintain the workforce within a satisfactory level of morale and Productivity. However, in  practice, many companies do not evaluate the real benefits obtained with the implementation of such programs, only  that they’re costly to maintain. Considering this, this article seeks to evaluate through the perspective of human  resources and production managers the influence exercised by incentive programs and benefits on organizational  performance of medium and large companies in the textile and metalworking sectors of the Itaj aí Valley region in  Santa Catarina.    Human Resources Management  Over the years, organizations have undergone numerous transformations until getting to their current format, where  employees are no longer merely seen as a resource and have become the main as set of companies. This occurred,  according to Chiavenato (2010), because organizations depend directly and indirectly on people to remain  competitive in the marketplace and produce their goods and services. As a result, it may be noted that organizations ",gmail.com,,,46.3144754,11.0480288
96,AN OPERATIONS MANAGEMENT PERSPECTIVE ONCOLLABORATIVE ROBOTICS,@uark.edu,"Collaborative, Robotics, ISO/TS 15066 ","The industrial robotics industry has been innovating and advancing the capabilities of robots and their operator  interfaces for over fifty years, yet recent research estimates that only approximately 10% of manufacturing tasks are  currently automated.   Collaborative robotics represents the next step in the evolution of industrial robotics,  significantly reducing the extensive safety measures that have tra ditionally been a major technological and economic  impediment to robotic automation.   Removing barriers between people and robots also permits a much closer  integration of human sensing and cognition with robotic manipulation, resulting in a level of flexi bility that has the  potential to revolutionize industrial automation.   This paper reviews the current state of collaborative robotics and  discusses safety issues and the implications for key issues in operations management, including facility layout, job  design, process design, inventory management, quality management, and maintenance.      Keywords  Collaborative, Robotics, ISO/TS 15066    Introduction  With recent advances in the last two decades in robot flexibility, versatility, effec tiveness, and safety, there is a  growing interest in industry in investing in robotic solutions to reduce cycle times, perform undesirable jobs,  increase productivity, increase quality, bring back domestic jobs from foreign countries, compete with competit ors,  perform hazardous jobs, and improve responsiveness to customer demand, just to name a few motivations. One  example of these advances is in robotic safety. For over four decades, industrial robots have been very dangerous  and had to be isolated from human contact, usually with a protective fence. However, human -safe (collaborative)  robots have recently been developed, and have created a concept known as collaborative robotics, which is the  coordination between robots and humans to complete a task. The h uman-safe factor of collaborative robots (cobots)  means that robots can now interact with humans with a much smaller risk of injuring them. By working together,  humans and robots can combine their strengths to accomplish a task in the most productive way p ossible by  leveraging the strength and endurance of robots with the flexibility and decision making of humans (Djuric,  Urbanic, & Rickli).   A second major difference and advantage cobots over traditional industrial robots is in f lexibility.  Programming a traditional industrial robot usually involved coding in a language such as V+, which takes a  substantial amount of time and requires a technical worker to do the programming. In contrast, collaborative robot  technology has drastic ally changed the programming process by introducing ‘teaching by showing’ technology,  where the worker can physically move the robot arm to the desired location, as shown in E xhibit 1, and use drag and  drop style programming to teach the robot the task to perform. This programming style is not only more accessible  to the average worker, but also allows for quicker setup and changeover times between varying tasks. In addition to  changeover flexibility, cobots are much lighter and more mobile than traditional  industrial robots, allowing them to  be quickly moved throughout a work environment to accomplish a wide variety of needed tasks (Universal Robots,  2016).  Cobots can perform a wide variety of tasks across many different industries and are especially useful for  small to medium sized enterprises trying to automate some of their process. Some of the most common tasks for  cobots include machine tending, injection molding, picking and placing, CNC machining, packaging, assembl y, and  polishing, due in part to dull, dirty, distasteful, dangerous and generally  undesirable nature of these tasks  (Universal ",uark.edu,University of Arkansas - Fayetteville,United States,36.0970389,-94.17033216657404
97,SOLVING ASSEMBLY LINE BALANCING TYPE II PROBLEM USINGPROGRESSIVE MODELING,@uregina.ca,"Assembly systems, line balancing, systems optimization. ","This paper presents a new modeling approach called Progressive Modeling (PM) and demonstrates it by solving the  Assembly Line Balancing Type II (ALBP -II) problem. PM introduces some new concepts that make the modeling  process of large- scale complex industr ial problems more systematic and their solution algorithms much faster and  easily maintained. In the context of SALBP-II, PM introduces a component model to deploy the problem logic and its  solution algorithm into several interacting components. The proble m is represented as an object -oriented graph  G(V,E,W) of vertices, edges, and workstations which enables our solutions to start anywhere. The novel representation  relaxes the only forward and backward tracking approach used in the assembly line balancing problems in the related  literature. The developed problem analysis and solution algorithms demonstrate why the new modeling paradigm  should be promising and capable of handling more complex real -world assembly balancing problems. A set of well - reported problems in the literature is reported and solved. The paper concludes by demonstrating the efficiency of the  new modeling approach and future extensions.    Keywords  Assembly systems, line balancing, systems optimization.    Introduction  Addressing an assembly li ne balancing (ALB) problem starts with breaking down the assembly tasks into sensibly  smaller elemental tasks. The precedence constraints among these elemental tasks are usually predetermined. Further  constraints may be imposed due to the assumptions made during modeling the ALB problem. A good ALB model  would assign the elemental tasks to workstations in order to get a line balance with optimal objective value while all  of the constraints are satisfied. Based on the type of objectives and assumptions under  consideration, ALB problems  are divided into two broad classes: Simple Assembly Line Balancing (SALB) problems and Generalized Assembly  Line Balancing (GALB) problems. As the name implies SALB problems are simplified models of real life problems  and most studied problems in ALB literature . SALB problems are subjected to very specific assumptions and set of  objectives. Although from the modeling perspective, SALB assumptions make things easy ; however, they are often  found to differ significantly from real life environments. Exhibit 1 outlines the common assumptions used for SALB  problems (Scholl, 1999). Exhibit 2  demonstrates the given parameters and objectives for different types of SALB  problems (Scholl & Becker, 2006).  ALB problems other than SALB problems are classified  as GALB problems. GALB problems may  accommodate a large variety of problem categories relaxing some of the SALB assumptions to address multi -model  cases, zoning constraints, the existence of parallel stations and more (Becker & Scholl, 2006; Boysen, Flied ner, &  Scholl, 2007). Except for type F, SALB problems are NP-hard and computationally challenging. The challenges  become more prominent for larger and complex problems. Some definitions related to measuring  the complexity of  SALB problems are presented by Scholl (Scholl, 1995). In this paper, the SALB problem type II (SALB II) problems  will be analyzed and solved using a new modeling approach called progressive modeling.  ",uregina.ca,University of Regina,Canada,50.4152275,-104.58899996239825
98,ALGAL BIOMASS FOR WATER CLEAN-UP – A SLIGHTLYDIFFERENT TWIST ON ALGAE,@judsonu.edu,"Algae, economic resource, interdisciplinary collaboration.    ","Algae strains have been receiving attention lately as a biomass with many uses.   Much of the interest  has been for  growing algae in dedicated systems and focusing on strains with high lipid content for the production of  biodiesel.  Other algal varieties will grow in a more open environment under a wider range of conditions, including  in municipal water treatment operations.   These biomass cultures will concurrently reduce  the concentration of  certain nutrients which could otherwise require significant cost and effort to remove; thus, the algal biomass can  effectively perform work in a relatively passive, organic sense.   The resultant biomass is a co -product which results  from the growth process.  Such biomass represents an economic resource which may be used as a feedstock for  energy or other biomass products.   This paper outlines the development of a different approach for using algal  growth to clean up water and then re- purpose the resultant algal biomass as an economic resource.   The overall  effort in this development leveraged an innovative interdisciplinary approach including collaborators from  Engineering/Technology, Biology, Business, and Engineering Management realm s.    Keywords  Algae, economic resource, interdisciplinary collaboration.       Introduction  This paper expands upon an interdisciplinary collaboration investigating algae as an economic resource.  There are a  number of levels of effort and teamwork conducted primarily  by the Department s of Technology and Biolog ical  Sciences at Northern Illinois University, in conjunction with a public -private partnership for economic development  and the regional municipal water treatment operations.  While energy applications are part of the overall economic  equation of the value stream in this work, the alga l biomass  is first used as a means to clean municipal water  supplies.  This presents an alternative way of dealing with the problems facing numerous water treatment operations  in how to reduce the regulated nutrient levels of output water .  The algae effectively perform the work of reducing  nutrient levels and then are harvested a s co-products to be deployed for new uses.   This paper chronicles the process  of interdisciplinary collaboration which led to a different approach to using algae biomass for capturing economic  value.      The Problem  Polluting levels of nitrogen and phosphorous in our nation’s waterways and lakes are becoming more stringently  regulated to address current and future environmental impacts (EPA, 2008).  Municipal wastew ater is currently a  major source of these pollutants . Estimates suggest these added capital improvement expenditures may amount to ",judsonu.edu,Judson University,United States,42.0605,-88.2899
99,IMPROVING PATIENT CARE THROUGH EARLIER DISCHARGETIMES BY USING SIX-SIGMA TOOLS,@utc.edu,"Healthcare, Six-Sigma Tools ","Patient care is the primary goal of all hospitals.  This seems to be an obvious statement, but many people do no t  know that this extends even when the patient is sent home or to a post- acute care facility.  Many people believe that  once a patient steps foot outside the hospital, they are no longer important to the hospital.  This is false.  Making  sure that patients do not return with the same condition (barring follow ups visits) is very important to the hospitals.    Hospital readmission rates have been proposed as an important indicator of quality of care (Friedman and Basu,  2004; Miller, 2007) because they may result from actions taken or omitted during the initial hospital stay.  A  readmission may result from incomplete treatment or poor care of the underlying problem, or may reflect poor  coordination of services at the time of discharge and afterwards, such as incomplete discharge planning and/ or  inadequate access to care (Halfon et al.,  2006; Kripalani et al., 2007). The importance of this study is, at its core, to  improve patient care.  Studies have shown that patients disc harged earlier in the day from hospitals  are less likely to  return with the same condition within 30 days.  This project is designed to provide date driven analysis of the  barriers to “discharges before 11” that will, in turn, assist in developing a s olution that reduces  preventable  readmissions and improves emergency department ( ED) throughput.  These in turn will im prove patient care and  satisfaction which is a goal of any hospital.      Keywords  Healthcare, Six-Sigma Tools    Introduction  Welfare of patients is the primary goal of all hospitals.  This seems to be an obvious statement , but many people do  not know that this extends even to when the patient is sent home or to a post-acute care (PAC) facility.  Many people  believe that once a patient steps foot outside the hospital, they are no longe r important to the hospital.  This is false.   Making sure that patients don’t return with the same condition (barring follow ups or other scheduled visits)  is  actually very important to the hospitals.   The Center for Medicare & Medicaid Services (CMS) describes, on  CMS.gov, readmissions a s “Patients who are admitted to the hospital for treatment of medical problems sometimes  get other serious complications.  Some patients may experience problems soon after they are discharged and need to  be admitted to the hospital again” (“Hospital Readmissions Reduction Program”).   There are two main reasons why  readmissions are not favorably looked upon.  First is e thicalness.   Ethically, hospitals do not want patients to return with the same conditions because this likely means that a poor  quality of care was given at the hospital or an incorrect diagnosis was given  to the patient.  This could be cau sed by  the incorrect treatment, improper dosage of treatment given by the atte nding nurse and/or doctor or simply  because  of the patient  age or uncontrollable factors.  Either way, it could leave a smeared reputation for the hospital.  As a  result, the hospita l will be seen as ineffective beca use the patients have to come back subsequent times rather than  curing them in one visit.  This in turn will drive patients away and effectively send them to other hospitals.   Another big incentive  to reduce readmissions is M edicare penalties.  In October 2012, the CMS  started  reducing Medicare payments to Inpatient Prospective Pay ment System (IPPS) hospitals that had excessive  readmissions.  If this is found to be true  for a hospital , then a payment adjustment will be factored into future  payments to that same hospital.  The amount that payments are adjusted, how long the adjust lasts after the hospital  corrects this problem, how a “excessive readmissions” is calculated and more information about the penalties can be  found on CMS.gov (“Hospital Readmissions Reduction Program”; Readmissions-Reduction-Program, 2016). ",utc.edu,University of Tennessee at Chattanooga,United States,35.0459,-85.2953
